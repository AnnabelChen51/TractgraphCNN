Namespace(inputDirectory='data', outputDirectory='val', DisFile='data/dis_sort_roi2dis2000.npy', task='sex', type='binary', feature=['Nos', 'FA1'], CUDA_id='0', data_id='0', dataset='Classification', norm=True, channels=1, epochs=500, tensorboard=True, net_architecture='TractGraphormer', batch_size=32, rate=3e-05, weight=0.0, sched_step=300, sched_gamma=0.1, printing_frequency=1, seed=1, alpha=0, remix_kappa=0, remix_tau=0, loss='CE', sigma=0, k=20)
Training the 'TractGraphormer' architecture

The following parameters are used:
Batch size:	32
Number of workers:	0
Learning rate:	3e-05
Weight decay:	0.0
Scheduler steps:	300
Scheduler gamma:	0.1
Number of epochs of training:	500
Number of input channels:	1

Data preparation
Reading data from:	./data
Training set size:	6538
Validation set size:	1869

Performing calculations on:	cuda:0

Pretraining:	Epoch 1/500
----------
training:	Epoch: [1][1/204]	Loss 0.6857 (0.6857)	
training:	Epoch: [1][2/204]	Loss 0.7152 (0.7004)	
training:	Epoch: [1][3/204]	Loss 0.7038 (0.7016)	
training:	Epoch: [1][4/204]	Loss 0.6939 (0.6996)	
training:	Epoch: [1][5/204]	Loss 0.7197 (0.7037)	
training:	Epoch: [1][6/204]	Loss 0.7076 (0.7043)	
training:	Epoch: [1][7/204]	Loss 0.7120 (0.7054)	
training:	Epoch: [1][8/204]	Loss 0.6997 (0.7047)	
training:	Epoch: [1][9/204]	Loss 0.6908 (0.7031)	
training:	Epoch: [1][10/204]	Loss 0.6896 (0.7018)	
training:	Epoch: [1][11/204]	Loss 0.6840 (0.7002)	
training:	Epoch: [1][12/204]	Loss 0.6980 (0.7000)	
training:	Epoch: [1][13/204]	Loss 0.6943 (0.6996)	
training:	Epoch: [1][14/204]	Loss 0.6910 (0.6989)	
training:	Epoch: [1][15/204]	Loss 0.6865 (0.6981)	
training:	Epoch: [1][16/204]	Loss 0.6976 (0.6981)	
training:	Epoch: [1][17/204]	Loss 0.7026 (0.6984)	
training:	Epoch: [1][18/204]	Loss 0.6891 (0.6978)	
training:	Epoch: [1][19/204]	Loss 0.6730 (0.6965)	
training:	Epoch: [1][20/204]	Loss 0.6750 (0.6955)	
training:	Epoch: [1][21/204]	Loss 0.6819 (0.6948)	
training:	Epoch: [1][22/204]	Loss 0.6977 (0.6949)	
training:	Epoch: [1][23/204]	Loss 0.7137 (0.6958)	
training:	Epoch: [1][24/204]	Loss 0.7042 (0.6961)	
training:	Epoch: [1][25/204]	Loss 0.6857 (0.6957)	
training:	Epoch: [1][26/204]	Loss 0.6874 (0.6954)	
training:	Epoch: [1][27/204]	Loss 0.6826 (0.6949)	
training:	Epoch: [1][28/204]	Loss 0.6992 (0.6951)	
training:	Epoch: [1][29/204]	Loss 0.6984 (0.6952)	
training:	Epoch: [1][30/204]	Loss 0.7139 (0.6958)	
training:	Epoch: [1][31/204]	Loss 0.6942 (0.6957)	
training:	Epoch: [1][32/204]	Loss 0.7141 (0.6963)	
training:	Epoch: [1][33/204]	Loss 0.7190 (0.6970)	
training:	Epoch: [1][34/204]	Loss 0.6922 (0.6969)	
training:	Epoch: [1][35/204]	Loss 0.6928 (0.6967)	
training:	Epoch: [1][36/204]	Loss 0.6749 (0.6961)	
training:	Epoch: [1][37/204]	Loss 0.6703 (0.6954)	
training:	Epoch: [1][38/204]	Loss 0.6928 (0.6954)	
training:	Epoch: [1][39/204]	Loss 0.7042 (0.6956)	
training:	Epoch: [1][40/204]	Loss 0.6927 (0.6955)	
training:	Epoch: [1][41/204]	Loss 0.6855 (0.6953)	
training:	Epoch: [1][42/204]	Loss 0.6836 (0.6950)	
training:	Epoch: [1][43/204]	Loss 0.6838 (0.6947)	
training:	Epoch: [1][44/204]	Loss 0.6881 (0.6946)	
training:	Epoch: [1][45/204]	Loss 0.6972 (0.6947)	
training:	Epoch: [1][46/204]	Loss 0.6838 (0.6944)	
training:	Epoch: [1][47/204]	Loss 0.6812 (0.6941)	
training:	Epoch: [1][48/204]	Loss 0.6984 (0.6942)	
training:	Epoch: [1][49/204]	Loss 0.6869 (0.6941)	
training:	Epoch: [1][50/204]	Loss 0.6900 (0.6940)	
training:	Epoch: [1][51/204]	Loss 0.6930 (0.6940)	
training:	Epoch: [1][52/204]	Loss 0.6894 (0.6939)	
training:	Epoch: [1][53/204]	Loss 0.6836 (0.6937)	
training:	Epoch: [1][54/204]	Loss 0.6846 (0.6935)	
training:	Epoch: [1][55/204]	Loss 0.6893 (0.6934)	
training:	Epoch: [1][56/204]	Loss 0.6836 (0.6933)	
training:	Epoch: [1][57/204]	Loss 0.6797 (0.6930)	
training:	Epoch: [1][58/204]	Loss 0.6861 (0.6929)	
training:	Epoch: [1][59/204]	Loss 0.6983 (0.6930)	
training:	Epoch: [1][60/204]	Loss 0.6739 (0.6927)	
training:	Epoch: [1][61/204]	Loss 0.6902 (0.6926)	
training:	Epoch: [1][62/204]	Loss 0.6801 (0.6924)	
training:	Epoch: [1][63/204]	Loss 0.6981 (0.6925)	
training:	Epoch: [1][64/204]	Loss 0.6845 (0.6924)	
training:	Epoch: [1][65/204]	Loss 0.6902 (0.6924)	
training:	Epoch: [1][66/204]	Loss 0.6710 (0.6921)	
training:	Epoch: [1][67/204]	Loss 0.6654 (0.6917)	
training:	Epoch: [1][68/204]	Loss 0.6875 (0.6916)	
training:	Epoch: [1][69/204]	Loss 0.7017 (0.6917)	
training:	Epoch: [1][70/204]	Loss 0.6752 (0.6915)	
training:	Epoch: [1][71/204]	Loss 0.6760 (0.6913)	
training:	Epoch: [1][72/204]	Loss 0.6723 (0.6910)	
training:	Epoch: [1][73/204]	Loss 0.6739 (0.6908)	
training:	Epoch: [1][74/204]	Loss 0.6682 (0.6905)	
training:	Epoch: [1][75/204]	Loss 0.6714 (0.6902)	
training:	Epoch: [1][76/204]	Loss 0.6801 (0.6901)	
training:	Epoch: [1][77/204]	Loss 0.6728 (0.6899)	
training:	Epoch: [1][78/204]	Loss 0.6925 (0.6899)	
training:	Epoch: [1][79/204]	Loss 0.6548 (0.6895)	
training:	Epoch: [1][80/204]	Loss 0.6856 (0.6894)	
training:	Epoch: [1][81/204]	Loss 0.6692 (0.6892)	
training:	Epoch: [1][82/204]	Loss 0.6746 (0.6890)	
training:	Epoch: [1][83/204]	Loss 0.6765 (0.6888)	
training:	Epoch: [1][84/204]	Loss 0.6604 (0.6885)	
training:	Epoch: [1][85/204]	Loss 0.6703 (0.6883)	
training:	Epoch: [1][86/204]	Loss 0.6575 (0.6879)	
training:	Epoch: [1][87/204]	Loss 0.6709 (0.6877)	
training:	Epoch: [1][88/204]	Loss 0.6735 (0.6876)	
training:	Epoch: [1][89/204]	Loss 0.6610 (0.6873)	
training:	Epoch: [1][90/204]	Loss 0.6837 (0.6872)	
training:	Epoch: [1][91/204]	Loss 0.6555 (0.6869)	
training:	Epoch: [1][92/204]	Loss 0.6596 (0.6866)	
training:	Epoch: [1][93/204]	Loss 0.6478 (0.6862)	
training:	Epoch: [1][94/204]	Loss 0.6740 (0.6860)	
training:	Epoch: [1][95/204]	Loss 0.6851 (0.6860)	
training:	Epoch: [1][96/204]	Loss 0.6431 (0.6856)	
training:	Epoch: [1][97/204]	Loss 0.6517 (0.6852)	
training:	Epoch: [1][98/204]	Loss 0.6643 (0.6850)	
training:	Epoch: [1][99/204]	Loss 0.6833 (0.6850)	
training:	Epoch: [1][100/204]	Loss 0.6546 (0.6847)	
training:	Epoch: [1][101/204]	Loss 0.6959 (0.6848)	
training:	Epoch: [1][102/204]	Loss 0.6223 (0.6842)	
training:	Epoch: [1][103/204]	Loss 0.6395 (0.6838)	
training:	Epoch: [1][104/204]	Loss 0.6261 (0.6832)	
training:	Epoch: [1][105/204]	Loss 0.6365 (0.6828)	
training:	Epoch: [1][106/204]	Loss 0.6538 (0.6825)	
training:	Epoch: [1][107/204]	Loss 0.6375 (0.6821)	
training:	Epoch: [1][108/204]	Loss 0.6685 (0.6819)	
training:	Epoch: [1][109/204]	Loss 0.6518 (0.6817)	
training:	Epoch: [1][110/204]	Loss 0.6537 (0.6814)	
training:	Epoch: [1][111/204]	Loss 0.6406 (0.6810)	
training:	Epoch: [1][112/204]	Loss 0.6825 (0.6811)	
training:	Epoch: [1][113/204]	Loss 0.6669 (0.6809)	
training:	Epoch: [1][114/204]	Loss 0.6494 (0.6807)	
training:	Epoch: [1][115/204]	Loss 0.7294 (0.6811)	
training:	Epoch: [1][116/204]	Loss 0.6144 (0.6805)	
training:	Epoch: [1][117/204]	Loss 0.6971 (0.6806)	
training:	Epoch: [1][118/204]	Loss 0.6546 (0.6804)	
training:	Epoch: [1][119/204]	Loss 0.6700 (0.6803)	
training:	Epoch: [1][120/204]	Loss 0.6108 (0.6798)	
training:	Epoch: [1][121/204]	Loss 0.6980 (0.6799)	
training:	Epoch: [1][122/204]	Loss 0.5906 (0.6792)	
training:	Epoch: [1][123/204]	Loss 0.6534 (0.6790)	
training:	Epoch: [1][124/204]	Loss 0.5818 (0.6782)	
training:	Epoch: [1][125/204]	Loss 0.6575 (0.6780)	
training:	Epoch: [1][126/204]	Loss 0.6178 (0.6775)	
training:	Epoch: [1][127/204]	Loss 0.6140 (0.6770)	
training:	Epoch: [1][128/204]	Loss 0.6509 (0.6768)	
training:	Epoch: [1][129/204]	Loss 0.6621 (0.6767)	
training:	Epoch: [1][130/204]	Loss 0.6162 (0.6763)	
training:	Epoch: [1][131/204]	Loss 0.6730 (0.6762)	
training:	Epoch: [1][132/204]	Loss 0.5834 (0.6755)	
training:	Epoch: [1][133/204]	Loss 0.5671 (0.6747)	
training:	Epoch: [1][134/204]	Loss 0.5699 (0.6739)	
training:	Epoch: [1][135/204]	Loss 0.5832 (0.6733)	
training:	Epoch: [1][136/204]	Loss 0.6250 (0.6729)	
training:	Epoch: [1][137/204]	Loss 0.6219 (0.6725)	
training:	Epoch: [1][138/204]	Loss 0.5885 (0.6719)	
training:	Epoch: [1][139/204]	Loss 0.5572 (0.6711)	
training:	Epoch: [1][140/204]	Loss 0.6223 (0.6707)	
training:	Epoch: [1][141/204]	Loss 0.5630 (0.6700)	
training:	Epoch: [1][142/204]	Loss 0.6025 (0.6695)	
training:	Epoch: [1][143/204]	Loss 0.5557 (0.6687)	
training:	Epoch: [1][144/204]	Loss 0.6394 (0.6685)	
training:	Epoch: [1][145/204]	Loss 0.6256 (0.6682)	
training:	Epoch: [1][146/204]	Loss 0.7021 (0.6684)	
training:	Epoch: [1][147/204]	Loss 0.6475 (0.6683)	
training:	Epoch: [1][148/204]	Loss 0.5970 (0.6678)	
training:	Epoch: [1][149/204]	Loss 0.5804 (0.6672)	
training:	Epoch: [1][150/204]	Loss 0.6313 (0.6670)	
training:	Epoch: [1][151/204]	Loss 0.5610 (0.6663)	
training:	Epoch: [1][152/204]	Loss 0.5803 (0.6657)	
training:	Epoch: [1][153/204]	Loss 0.5834 (0.6652)	
training:	Epoch: [1][154/204]	Loss 0.6042 (0.6648)	
training:	Epoch: [1][155/204]	Loss 0.5885 (0.6643)	
training:	Epoch: [1][156/204]	Loss 0.6834 (0.6644)	
training:	Epoch: [1][157/204]	Loss 0.4882 (0.6633)	
training:	Epoch: [1][158/204]	Loss 0.5987 (0.6629)	
training:	Epoch: [1][159/204]	Loss 0.6462 (0.6628)	
training:	Epoch: [1][160/204]	Loss 0.5675 (0.6622)	
training:	Epoch: [1][161/204]	Loss 0.4584 (0.6609)	
training:	Epoch: [1][162/204]	Loss 0.6629 (0.6609)	
training:	Epoch: [1][163/204]	Loss 0.5955 (0.6605)	
training:	Epoch: [1][164/204]	Loss 0.5251 (0.6597)	
training:	Epoch: [1][165/204]	Loss 0.5370 (0.6590)	
training:	Epoch: [1][166/204]	Loss 0.5303 (0.6582)	
training:	Epoch: [1][167/204]	Loss 0.5983 (0.6578)	
training:	Epoch: [1][168/204]	Loss 0.6503 (0.6578)	
training:	Epoch: [1][169/204]	Loss 0.5888 (0.6574)	
training:	Epoch: [1][170/204]	Loss 0.5167 (0.6566)	
training:	Epoch: [1][171/204]	Loss 0.5466 (0.6559)	
training:	Epoch: [1][172/204]	Loss 0.6057 (0.6556)	
training:	Epoch: [1][173/204]	Loss 0.4755 (0.6546)	
training:	Epoch: [1][174/204]	Loss 0.4275 (0.6533)	
training:	Epoch: [1][175/204]	Loss 0.4525 (0.6521)	
training:	Epoch: [1][176/204]	Loss 0.4932 (0.6512)	
training:	Epoch: [1][177/204]	Loss 0.5577 (0.6507)	
training:	Epoch: [1][178/204]	Loss 0.5005 (0.6498)	
training:	Epoch: [1][179/204]	Loss 0.6425 (0.6498)	
training:	Epoch: [1][180/204]	Loss 0.4791 (0.6489)	
training:	Epoch: [1][181/204]	Loss 0.6413 (0.6488)	
training:	Epoch: [1][182/204]	Loss 0.6814 (0.6490)	
training:	Epoch: [1][183/204]	Loss 0.6613 (0.6491)	
training:	Epoch: [1][184/204]	Loss 0.5326 (0.6484)	
training:	Epoch: [1][185/204]	Loss 0.6363 (0.6484)	
training:	Epoch: [1][186/204]	Loss 0.4605 (0.6474)	
training:	Epoch: [1][187/204]	Loss 0.5463 (0.6468)	
training:	Epoch: [1][188/204]	Loss 0.6816 (0.6470)	
training:	Epoch: [1][189/204]	Loss 0.5027 (0.6462)	
training:	Epoch: [1][190/204]	Loss 0.5588 (0.6458)	
training:	Epoch: [1][191/204]	Loss 0.4928 (0.6450)	
training:	Epoch: [1][192/204]	Loss 0.5562 (0.6445)	
training:	Epoch: [1][193/204]	Loss 0.5625 (0.6441)	
training:	Epoch: [1][194/204]	Loss 0.4880 (0.6433)	
training:	Epoch: [1][195/204]	Loss 0.5664 (0.6429)	
training:	Epoch: [1][196/204]	Loss 0.5325 (0.6423)	
training:	Epoch: [1][197/204]	Loss 0.6378 (0.6423)	
training:	Epoch: [1][198/204]	Loss 0.5390 (0.6418)	
training:	Epoch: [1][199/204]	Loss 0.5993 (0.6416)	
training:	Epoch: [1][200/204]	Loss 0.6031 (0.6414)	
training:	Epoch: [1][201/204]	Loss 0.3953 (0.6401)	
training:	Epoch: [1][202/204]	Loss 0.5221 (0.6396)	
training:	Epoch: [1][203/204]	Loss 0.6365 (0.6396)	
training:	Epoch: [1][204/204]	Loss 0.4824 (0.6388)	
Training:	 Loss: 0.6378

Training:	 ACC: 0.7487 0.7489 0.7519 0.7455
Validation:	 ACC: 0.7434 0.7437 0.7513 0.7354
Validation:	 Best_BACC: 0.7434 0.7437 0.7513 0.7354
Validation:	 Loss: 0.5353
Pretraining:	Epoch 2/500
----------
training:	Epoch: [2][1/204]	Loss 0.4992 (0.4992)	
training:	Epoch: [2][2/204]	Loss 0.5788 (0.5390)	
training:	Epoch: [2][3/204]	Loss 0.5770 (0.5517)	
training:	Epoch: [2][4/204]	Loss 0.5565 (0.5529)	
training:	Epoch: [2][5/204]	Loss 0.4887 (0.5401)	
training:	Epoch: [2][6/204]	Loss 0.5087 (0.5348)	
training:	Epoch: [2][7/204]	Loss 0.4617 (0.5244)	
training:	Epoch: [2][8/204]	Loss 0.4829 (0.5192)	
training:	Epoch: [2][9/204]	Loss 0.4534 (0.5119)	
training:	Epoch: [2][10/204]	Loss 0.6599 (0.5267)	
training:	Epoch: [2][11/204]	Loss 0.5144 (0.5256)	
training:	Epoch: [2][12/204]	Loss 0.5354 (0.5264)	
training:	Epoch: [2][13/204]	Loss 0.5549 (0.5286)	
training:	Epoch: [2][14/204]	Loss 0.5014 (0.5266)	
training:	Epoch: [2][15/204]	Loss 0.4759 (0.5233)	
training:	Epoch: [2][16/204]	Loss 0.4739 (0.5202)	
training:	Epoch: [2][17/204]	Loss 0.3677 (0.5112)	
training:	Epoch: [2][18/204]	Loss 0.5659 (0.5142)	
training:	Epoch: [2][19/204]	Loss 0.5417 (0.5157)	
training:	Epoch: [2][20/204]	Loss 0.6172 (0.5208)	
training:	Epoch: [2][21/204]	Loss 0.6013 (0.5246)	
training:	Epoch: [2][22/204]	Loss 0.4799 (0.5226)	
training:	Epoch: [2][23/204]	Loss 0.5093 (0.5220)	
training:	Epoch: [2][24/204]	Loss 0.5378 (0.5226)	
training:	Epoch: [2][25/204]	Loss 0.5807 (0.5250)	
training:	Epoch: [2][26/204]	Loss 0.5736 (0.5268)	
training:	Epoch: [2][27/204]	Loss 0.5060 (0.5261)	
training:	Epoch: [2][28/204]	Loss 0.4141 (0.5221)	
training:	Epoch: [2][29/204]	Loss 0.5292 (0.5223)	
training:	Epoch: [2][30/204]	Loss 0.5838 (0.5244)	
training:	Epoch: [2][31/204]	Loss 0.4357 (0.5215)	
training:	Epoch: [2][32/204]	Loss 0.4701 (0.5199)	
training:	Epoch: [2][33/204]	Loss 0.5005 (0.5193)	
training:	Epoch: [2][34/204]	Loss 0.4415 (0.5170)	
training:	Epoch: [2][35/204]	Loss 0.5479 (0.5179)	
training:	Epoch: [2][36/204]	Loss 0.5198 (0.5180)	
training:	Epoch: [2][37/204]	Loss 0.4104 (0.5150)	
training:	Epoch: [2][38/204]	Loss 0.4500 (0.5133)	
training:	Epoch: [2][39/204]	Loss 0.5594 (0.5145)	
training:	Epoch: [2][40/204]	Loss 0.3972 (0.5116)	
training:	Epoch: [2][41/204]	Loss 0.4728 (0.5106)	
training:	Epoch: [2][42/204]	Loss 0.4548 (0.5093)	
training:	Epoch: [2][43/204]	Loss 0.4558 (0.5081)	
training:	Epoch: [2][44/204]	Loss 0.5515 (0.5091)	
training:	Epoch: [2][45/204]	Loss 0.5407 (0.5098)	
training:	Epoch: [2][46/204]	Loss 0.5646 (0.5109)	
training:	Epoch: [2][47/204]	Loss 0.4552 (0.5098)	
training:	Epoch: [2][48/204]	Loss 0.5847 (0.5113)	
training:	Epoch: [2][49/204]	Loss 0.5522 (0.5122)	
training:	Epoch: [2][50/204]	Loss 0.5303 (0.5125)	
training:	Epoch: [2][51/204]	Loss 0.5445 (0.5131)	
training:	Epoch: [2][52/204]	Loss 0.4481 (0.5119)	
training:	Epoch: [2][53/204]	Loss 0.5490 (0.5126)	
training:	Epoch: [2][54/204]	Loss 0.5678 (0.5136)	
training:	Epoch: [2][55/204]	Loss 0.4784 (0.5130)	
training:	Epoch: [2][56/204]	Loss 0.3983 (0.5109)	
training:	Epoch: [2][57/204]	Loss 0.5467 (0.5116)	
training:	Epoch: [2][58/204]	Loss 0.4068 (0.5098)	
training:	Epoch: [2][59/204]	Loss 0.3702 (0.5074)	
training:	Epoch: [2][60/204]	Loss 0.5825 (0.5086)	
training:	Epoch: [2][61/204]	Loss 0.4929 (0.5084)	
training:	Epoch: [2][62/204]	Loss 0.3852 (0.5064)	
training:	Epoch: [2][63/204]	Loss 0.3690 (0.5042)	
training:	Epoch: [2][64/204]	Loss 0.5434 (0.5048)	
training:	Epoch: [2][65/204]	Loss 0.5232 (0.5051)	
training:	Epoch: [2][66/204]	Loss 0.4352 (0.5041)	
training:	Epoch: [2][67/204]	Loss 0.3915 (0.5024)	
training:	Epoch: [2][68/204]	Loss 0.5228 (0.5027)	
training:	Epoch: [2][69/204]	Loss 0.4598 (0.5020)	
training:	Epoch: [2][70/204]	Loss 0.5802 (0.5032)	
training:	Epoch: [2][71/204]	Loss 0.3383 (0.5008)	
training:	Epoch: [2][72/204]	Loss 0.5520 (0.5016)	
training:	Epoch: [2][73/204]	Loss 0.5918 (0.5028)	
training:	Epoch: [2][74/204]	Loss 0.5081 (0.5029)	
training:	Epoch: [2][75/204]	Loss 0.5132 (0.5030)	
training:	Epoch: [2][76/204]	Loss 0.4066 (0.5017)	
training:	Epoch: [2][77/204]	Loss 0.5334 (0.5021)	
training:	Epoch: [2][78/204]	Loss 0.3671 (0.5004)	
training:	Epoch: [2][79/204]	Loss 0.4470 (0.4997)	
training:	Epoch: [2][80/204]	Loss 0.5972 (0.5010)	
training:	Epoch: [2][81/204]	Loss 0.5073 (0.5010)	
training:	Epoch: [2][82/204]	Loss 0.5653 (0.5018)	
training:	Epoch: [2][83/204]	Loss 0.4347 (0.5010)	
training:	Epoch: [2][84/204]	Loss 0.5602 (0.5017)	
training:	Epoch: [2][85/204]	Loss 0.5303 (0.5020)	
training:	Epoch: [2][86/204]	Loss 0.4803 (0.5018)	
training:	Epoch: [2][87/204]	Loss 0.3412 (0.4999)	
training:	Epoch: [2][88/204]	Loss 0.4509 (0.4994)	
training:	Epoch: [2][89/204]	Loss 0.5887 (0.5004)	
training:	Epoch: [2][90/204]	Loss 0.5168 (0.5006)	
training:	Epoch: [2][91/204]	Loss 0.5493 (0.5011)	
training:	Epoch: [2][92/204]	Loss 0.5658 (0.5018)	
training:	Epoch: [2][93/204]	Loss 0.5636 (0.5025)	
training:	Epoch: [2][94/204]	Loss 0.3866 (0.5012)	
training:	Epoch: [2][95/204]	Loss 0.6498 (0.5028)	
training:	Epoch: [2][96/204]	Loss 0.5894 (0.5037)	
training:	Epoch: [2][97/204]	Loss 0.5639 (0.5043)	
training:	Epoch: [2][98/204]	Loss 0.3164 (0.5024)	
training:	Epoch: [2][99/204]	Loss 0.4719 (0.5021)	
training:	Epoch: [2][100/204]	Loss 0.4290 (0.5014)	
training:	Epoch: [2][101/204]	Loss 0.7127 (0.5035)	
training:	Epoch: [2][102/204]	Loss 0.3930 (0.5024)	
training:	Epoch: [2][103/204]	Loss 0.5679 (0.5030)	
training:	Epoch: [2][104/204]	Loss 0.5423 (0.5034)	
training:	Epoch: [2][105/204]	Loss 0.4073 (0.5025)	
training:	Epoch: [2][106/204]	Loss 0.5988 (0.5034)	
training:	Epoch: [2][107/204]	Loss 0.5478 (0.5038)	
training:	Epoch: [2][108/204]	Loss 0.5195 (0.5040)	
training:	Epoch: [2][109/204]	Loss 0.5635 (0.5045)	
training:	Epoch: [2][110/204]	Loss 0.4214 (0.5037)	
training:	Epoch: [2][111/204]	Loss 0.4456 (0.5032)	
training:	Epoch: [2][112/204]	Loss 0.6146 (0.5042)	
training:	Epoch: [2][113/204]	Loss 0.5289 (0.5044)	
training:	Epoch: [2][114/204]	Loss 0.5859 (0.5051)	
training:	Epoch: [2][115/204]	Loss 0.5608 (0.5056)	
training:	Epoch: [2][116/204]	Loss 0.5816 (0.5063)	
training:	Epoch: [2][117/204]	Loss 0.6735 (0.5077)	
training:	Epoch: [2][118/204]	Loss 0.6362 (0.5088)	
training:	Epoch: [2][119/204]	Loss 0.6120 (0.5097)	
training:	Epoch: [2][120/204]	Loss 0.5080 (0.5097)	
training:	Epoch: [2][121/204]	Loss 0.5158 (0.5097)	
training:	Epoch: [2][122/204]	Loss 0.5004 (0.5096)	
training:	Epoch: [2][123/204]	Loss 0.3577 (0.5084)	
training:	Epoch: [2][124/204]	Loss 0.4552 (0.5080)	
training:	Epoch: [2][125/204]	Loss 0.5669 (0.5084)	
training:	Epoch: [2][126/204]	Loss 0.4073 (0.5076)	
training:	Epoch: [2][127/204]	Loss 0.4357 (0.5071)	
training:	Epoch: [2][128/204]	Loss 0.3543 (0.5059)	
training:	Epoch: [2][129/204]	Loss 0.4506 (0.5054)	
training:	Epoch: [2][130/204]	Loss 0.5440 (0.5057)	
training:	Epoch: [2][131/204]	Loss 0.4808 (0.5056)	
training:	Epoch: [2][132/204]	Loss 0.4462 (0.5051)	
training:	Epoch: [2][133/204]	Loss 0.5156 (0.5052)	
training:	Epoch: [2][134/204]	Loss 0.4768 (0.5050)	
training:	Epoch: [2][135/204]	Loss 0.4371 (0.5045)	
training:	Epoch: [2][136/204]	Loss 0.3911 (0.5036)	
training:	Epoch: [2][137/204]	Loss 0.4798 (0.5035)	
training:	Epoch: [2][138/204]	Loss 0.4567 (0.5031)	
training:	Epoch: [2][139/204]	Loss 0.4150 (0.5025)	
training:	Epoch: [2][140/204]	Loss 0.5280 (0.5027)	
training:	Epoch: [2][141/204]	Loss 0.3128 (0.5013)	
training:	Epoch: [2][142/204]	Loss 0.4584 (0.5010)	
training:	Epoch: [2][143/204]	Loss 0.4917 (0.5010)	
training:	Epoch: [2][144/204]	Loss 0.4736 (0.5008)	
training:	Epoch: [2][145/204]	Loss 0.4822 (0.5006)	
training:	Epoch: [2][146/204]	Loss 0.5848 (0.5012)	
training:	Epoch: [2][147/204]	Loss 0.4381 (0.5008)	
training:	Epoch: [2][148/204]	Loss 0.4609 (0.5005)	
training:	Epoch: [2][149/204]	Loss 0.5367 (0.5008)	
training:	Epoch: [2][150/204]	Loss 0.5608 (0.5012)	
training:	Epoch: [2][151/204]	Loss 0.4417 (0.5008)	
training:	Epoch: [2][152/204]	Loss 0.4418 (0.5004)	
training:	Epoch: [2][153/204]	Loss 0.4074 (0.4998)	
training:	Epoch: [2][154/204]	Loss 0.4109 (0.4992)	
training:	Epoch: [2][155/204]	Loss 0.4103 (0.4986)	
training:	Epoch: [2][156/204]	Loss 0.2965 (0.4973)	
training:	Epoch: [2][157/204]	Loss 0.4120 (0.4968)	
training:	Epoch: [2][158/204]	Loss 0.4426 (0.4964)	
training:	Epoch: [2][159/204]	Loss 0.4624 (0.4962)	
training:	Epoch: [2][160/204]	Loss 0.4204 (0.4958)	
training:	Epoch: [2][161/204]	Loss 0.3209 (0.4947)	
training:	Epoch: [2][162/204]	Loss 0.4639 (0.4945)	
training:	Epoch: [2][163/204]	Loss 0.4364 (0.4941)	
training:	Epoch: [2][164/204]	Loss 0.3715 (0.4934)	
training:	Epoch: [2][165/204]	Loss 0.3944 (0.4928)	
training:	Epoch: [2][166/204]	Loss 0.4813 (0.4927)	
training:	Epoch: [2][167/204]	Loss 0.5138 (0.4928)	
training:	Epoch: [2][168/204]	Loss 0.3487 (0.4920)	
training:	Epoch: [2][169/204]	Loss 0.4017 (0.4914)	
training:	Epoch: [2][170/204]	Loss 0.4983 (0.4915)	
training:	Epoch: [2][171/204]	Loss 0.4902 (0.4915)	
training:	Epoch: [2][172/204]	Loss 0.5549 (0.4918)	
training:	Epoch: [2][173/204]	Loss 0.5969 (0.4924)	
training:	Epoch: [2][174/204]	Loss 0.5027 (0.4925)	
training:	Epoch: [2][175/204]	Loss 0.4450 (0.4922)	
training:	Epoch: [2][176/204]	Loss 0.3373 (0.4914)	
training:	Epoch: [2][177/204]	Loss 0.3038 (0.4903)	
training:	Epoch: [2][178/204]	Loss 0.4545 (0.4901)	
training:	Epoch: [2][179/204]	Loss 0.3313 (0.4892)	
training:	Epoch: [2][180/204]	Loss 0.3877 (0.4886)	
training:	Epoch: [2][181/204]	Loss 0.4615 (0.4885)	
training:	Epoch: [2][182/204]	Loss 0.3450 (0.4877)	
training:	Epoch: [2][183/204]	Loss 0.4289 (0.4874)	
training:	Epoch: [2][184/204]	Loss 0.5064 (0.4875)	
training:	Epoch: [2][185/204]	Loss 0.3591 (0.4868)	
training:	Epoch: [2][186/204]	Loss 0.5211 (0.4870)	
training:	Epoch: [2][187/204]	Loss 0.5230 (0.4872)	
training:	Epoch: [2][188/204]	Loss 0.4950 (0.4872)	
training:	Epoch: [2][189/204]	Loss 0.4966 (0.4873)	
training:	Epoch: [2][190/204]	Loss 0.4659 (0.4871)	
training:	Epoch: [2][191/204]	Loss 0.4351 (0.4869)	
training:	Epoch: [2][192/204]	Loss 0.4043 (0.4864)	
training:	Epoch: [2][193/204]	Loss 0.4686 (0.4864)	
training:	Epoch: [2][194/204]	Loss 0.6022 (0.4869)	
training:	Epoch: [2][195/204]	Loss 0.6673 (0.4879)	
training:	Epoch: [2][196/204]	Loss 0.5639 (0.4883)	
training:	Epoch: [2][197/204]	Loss 0.5298 (0.4885)	
training:	Epoch: [2][198/204]	Loss 0.3262 (0.4877)	
training:	Epoch: [2][199/204]	Loss 0.5106 (0.4878)	
training:	Epoch: [2][200/204]	Loss 0.4469 (0.4876)	
training:	Epoch: [2][201/204]	Loss 0.5935 (0.4881)	
training:	Epoch: [2][202/204]	Loss 0.5149 (0.4882)	
training:	Epoch: [2][203/204]	Loss 0.4109 (0.4878)	
training:	Epoch: [2][204/204]	Loss 0.3830 (0.4873)	
Training:	 Loss: 0.4866

Training:	 ACC: 0.8174 0.8169 0.8060 0.8288
Validation:	 ACC: 0.7922 0.7913 0.7738 0.8105
Validation:	 Best_BACC: 0.7922 0.7913 0.7738 0.8105
Validation:	 Loss: 0.4528
Pretraining:	Epoch 3/500
----------
training:	Epoch: [3][1/204]	Loss 0.2779 (0.2779)	
training:	Epoch: [3][2/204]	Loss 0.3859 (0.3319)	
training:	Epoch: [3][3/204]	Loss 0.5629 (0.4089)	
training:	Epoch: [3][4/204]	Loss 0.4154 (0.4105)	
training:	Epoch: [3][5/204]	Loss 0.2877 (0.3860)	
training:	Epoch: [3][6/204]	Loss 0.4534 (0.3972)	
training:	Epoch: [3][7/204]	Loss 0.4851 (0.4098)	
training:	Epoch: [3][8/204]	Loss 0.4880 (0.4195)	
training:	Epoch: [3][9/204]	Loss 0.2711 (0.4030)	
training:	Epoch: [3][10/204]	Loss 0.3185 (0.3946)	
training:	Epoch: [3][11/204]	Loss 0.3858 (0.3938)	
training:	Epoch: [3][12/204]	Loss 0.3588 (0.3909)	
training:	Epoch: [3][13/204]	Loss 0.3443 (0.3873)	
training:	Epoch: [3][14/204]	Loss 0.3202 (0.3825)	
training:	Epoch: [3][15/204]	Loss 0.2196 (0.3716)	
training:	Epoch: [3][16/204]	Loss 0.4564 (0.3769)	
training:	Epoch: [3][17/204]	Loss 0.3653 (0.3762)	
training:	Epoch: [3][18/204]	Loss 0.5372 (0.3852)	
training:	Epoch: [3][19/204]	Loss 0.4443 (0.3883)	
training:	Epoch: [3][20/204]	Loss 0.4213 (0.3899)	
training:	Epoch: [3][21/204]	Loss 0.3337 (0.3873)	
training:	Epoch: [3][22/204]	Loss 0.5215 (0.3934)	
training:	Epoch: [3][23/204]	Loss 0.2908 (0.3889)	
training:	Epoch: [3][24/204]	Loss 0.4424 (0.3911)	
training:	Epoch: [3][25/204]	Loss 0.3658 (0.3901)	
training:	Epoch: [3][26/204]	Loss 0.5230 (0.3952)	
training:	Epoch: [3][27/204]	Loss 0.4618 (0.3977)	
training:	Epoch: [3][28/204]	Loss 0.5035 (0.4015)	
training:	Epoch: [3][29/204]	Loss 0.5749 (0.4075)	
training:	Epoch: [3][30/204]	Loss 0.4077 (0.4075)	
training:	Epoch: [3][31/204]	Loss 0.3859 (0.4068)	
training:	Epoch: [3][32/204]	Loss 0.4146 (0.4070)	
training:	Epoch: [3][33/204]	Loss 0.3472 (0.4052)	
training:	Epoch: [3][34/204]	Loss 0.5046 (0.4081)	
training:	Epoch: [3][35/204]	Loss 0.3738 (0.4071)	
training:	Epoch: [3][36/204]	Loss 0.4005 (0.4070)	
training:	Epoch: [3][37/204]	Loss 0.4415 (0.4079)	
training:	Epoch: [3][38/204]	Loss 0.3092 (0.4053)	
training:	Epoch: [3][39/204]	Loss 0.4116 (0.4055)	
training:	Epoch: [3][40/204]	Loss 0.5252 (0.4084)	
training:	Epoch: [3][41/204]	Loss 0.4415 (0.4093)	
training:	Epoch: [3][42/204]	Loss 0.3747 (0.4084)	
training:	Epoch: [3][43/204]	Loss 0.4732 (0.4099)	
training:	Epoch: [3][44/204]	Loss 0.2873 (0.4072)	
training:	Epoch: [3][45/204]	Loss 0.4519 (0.4081)	
training:	Epoch: [3][46/204]	Loss 0.4600 (0.4093)	
training:	Epoch: [3][47/204]	Loss 0.3955 (0.4090)	
training:	Epoch: [3][48/204]	Loss 0.2989 (0.4067)	
training:	Epoch: [3][49/204]	Loss 0.5145 (0.4089)	
training:	Epoch: [3][50/204]	Loss 0.4208 (0.4091)	
training:	Epoch: [3][51/204]	Loss 0.4891 (0.4107)	
training:	Epoch: [3][52/204]	Loss 0.4455 (0.4114)	
training:	Epoch: [3][53/204]	Loss 0.2997 (0.4093)	
training:	Epoch: [3][54/204]	Loss 0.3287 (0.4078)	
training:	Epoch: [3][55/204]	Loss 0.3876 (0.4074)	
training:	Epoch: [3][56/204]	Loss 0.4141 (0.4075)	
training:	Epoch: [3][57/204]	Loss 0.4430 (0.4081)	
training:	Epoch: [3][58/204]	Loss 0.3527 (0.4072)	
training:	Epoch: [3][59/204]	Loss 0.3256 (0.4058)	
training:	Epoch: [3][60/204]	Loss 0.3067 (0.4042)	
training:	Epoch: [3][61/204]	Loss 0.4042 (0.4042)	
training:	Epoch: [3][62/204]	Loss 0.3666 (0.4035)	
training:	Epoch: [3][63/204]	Loss 0.4924 (0.4050)	
training:	Epoch: [3][64/204]	Loss 0.4543 (0.4057)	
training:	Epoch: [3][65/204]	Loss 0.2765 (0.4037)	
training:	Epoch: [3][66/204]	Loss 0.4917 (0.4051)	
training:	Epoch: [3][67/204]	Loss 0.3623 (0.4044)	
training:	Epoch: [3][68/204]	Loss 0.3202 (0.4032)	
training:	Epoch: [3][69/204]	Loss 0.3334 (0.4022)	
training:	Epoch: [3][70/204]	Loss 0.4385 (0.4027)	
training:	Epoch: [3][71/204]	Loss 0.4758 (0.4037)	
training:	Epoch: [3][72/204]	Loss 0.6649 (0.4074)	
training:	Epoch: [3][73/204]	Loss 0.3043 (0.4059)	
training:	Epoch: [3][74/204]	Loss 0.5499 (0.4079)	
training:	Epoch: [3][75/204]	Loss 0.3462 (0.4071)	
training:	Epoch: [3][76/204]	Loss 0.4114 (0.4071)	
training:	Epoch: [3][77/204]	Loss 0.4263 (0.4074)	
training:	Epoch: [3][78/204]	Loss 0.5581 (0.4093)	
training:	Epoch: [3][79/204]	Loss 0.4811 (0.4102)	
training:	Epoch: [3][80/204]	Loss 0.4104 (0.4102)	
training:	Epoch: [3][81/204]	Loss 0.4874 (0.4112)	
training:	Epoch: [3][82/204]	Loss 0.3602 (0.4106)	
training:	Epoch: [3][83/204]	Loss 0.3717 (0.4101)	
training:	Epoch: [3][84/204]	Loss 0.4010 (0.4100)	
training:	Epoch: [3][85/204]	Loss 0.4210 (0.4101)	
training:	Epoch: [3][86/204]	Loss 0.5201 (0.4114)	
training:	Epoch: [3][87/204]	Loss 0.3505 (0.4107)	
training:	Epoch: [3][88/204]	Loss 0.5356 (0.4121)	
training:	Epoch: [3][89/204]	Loss 0.4979 (0.4131)	
training:	Epoch: [3][90/204]	Loss 0.3814 (0.4127)	
training:	Epoch: [3][91/204]	Loss 0.6140 (0.4149)	
training:	Epoch: [3][92/204]	Loss 0.3299 (0.4140)	
training:	Epoch: [3][93/204]	Loss 0.2896 (0.4127)	
training:	Epoch: [3][94/204]	Loss 0.3160 (0.4116)	
training:	Epoch: [3][95/204]	Loss 0.5670 (0.4133)	
training:	Epoch: [3][96/204]	Loss 0.5542 (0.4147)	
training:	Epoch: [3][97/204]	Loss 0.2745 (0.4133)	
training:	Epoch: [3][98/204]	Loss 0.5318 (0.4145)	
training:	Epoch: [3][99/204]	Loss 0.4102 (0.4145)	
training:	Epoch: [3][100/204]	Loss 0.3636 (0.4140)	
training:	Epoch: [3][101/204]	Loss 0.3892 (0.4137)	
training:	Epoch: [3][102/204]	Loss 0.3428 (0.4130)	
training:	Epoch: [3][103/204]	Loss 0.4745 (0.4136)	
training:	Epoch: [3][104/204]	Loss 0.2561 (0.4121)	
training:	Epoch: [3][105/204]	Loss 0.4555 (0.4125)	
training:	Epoch: [3][106/204]	Loss 0.4808 (0.4132)	
training:	Epoch: [3][107/204]	Loss 0.5096 (0.4141)	
training:	Epoch: [3][108/204]	Loss 0.4272 (0.4142)	
training:	Epoch: [3][109/204]	Loss 0.5014 (0.4150)	
training:	Epoch: [3][110/204]	Loss 0.3804 (0.4147)	
training:	Epoch: [3][111/204]	Loss 0.3736 (0.4143)	
training:	Epoch: [3][112/204]	Loss 0.5154 (0.4152)	
training:	Epoch: [3][113/204]	Loss 0.5753 (0.4166)	
training:	Epoch: [3][114/204]	Loss 0.3012 (0.4156)	
training:	Epoch: [3][115/204]	Loss 0.3123 (0.4147)	
training:	Epoch: [3][116/204]	Loss 0.3881 (0.4145)	
training:	Epoch: [3][117/204]	Loss 0.1880 (0.4125)	
training:	Epoch: [3][118/204]	Loss 0.4736 (0.4131)	
training:	Epoch: [3][119/204]	Loss 0.4126 (0.4130)	
training:	Epoch: [3][120/204]	Loss 0.3496 (0.4125)	
training:	Epoch: [3][121/204]	Loss 0.5373 (0.4136)	
training:	Epoch: [3][122/204]	Loss 0.3162 (0.4128)	
training:	Epoch: [3][123/204]	Loss 0.3591 (0.4123)	
training:	Epoch: [3][124/204]	Loss 0.4201 (0.4124)	
training:	Epoch: [3][125/204]	Loss 0.3280 (0.4117)	
training:	Epoch: [3][126/204]	Loss 0.3695 (0.4114)	
training:	Epoch: [3][127/204]	Loss 0.4973 (0.4120)	
training:	Epoch: [3][128/204]	Loss 0.4692 (0.4125)	
training:	Epoch: [3][129/204]	Loss 0.3525 (0.4120)	
training:	Epoch: [3][130/204]	Loss 0.3410 (0.4115)	
training:	Epoch: [3][131/204]	Loss 0.3590 (0.4111)	
training:	Epoch: [3][132/204]	Loss 0.3316 (0.4105)	
training:	Epoch: [3][133/204]	Loss 0.6936 (0.4126)	
training:	Epoch: [3][134/204]	Loss 0.3944 (0.4125)	
training:	Epoch: [3][135/204]	Loss 0.3425 (0.4120)	
training:	Epoch: [3][136/204]	Loss 0.3110 (0.4112)	
training:	Epoch: [3][137/204]	Loss 0.3697 (0.4109)	
training:	Epoch: [3][138/204]	Loss 0.3033 (0.4101)	
training:	Epoch: [3][139/204]	Loss 0.3747 (0.4099)	
training:	Epoch: [3][140/204]	Loss 0.5437 (0.4108)	
training:	Epoch: [3][141/204]	Loss 0.2855 (0.4099)	
training:	Epoch: [3][142/204]	Loss 0.4680 (0.4103)	
training:	Epoch: [3][143/204]	Loss 0.4208 (0.4104)	
training:	Epoch: [3][144/204]	Loss 0.3567 (0.4100)	
training:	Epoch: [3][145/204]	Loss 0.4254 (0.4102)	
training:	Epoch: [3][146/204]	Loss 0.2896 (0.4093)	
training:	Epoch: [3][147/204]	Loss 0.3339 (0.4088)	
training:	Epoch: [3][148/204]	Loss 0.2687 (0.4079)	
training:	Epoch: [3][149/204]	Loss 0.4281 (0.4080)	
training:	Epoch: [3][150/204]	Loss 0.4948 (0.4086)	
training:	Epoch: [3][151/204]	Loss 0.4812 (0.4091)	
training:	Epoch: [3][152/204]	Loss 0.2992 (0.4083)	
training:	Epoch: [3][153/204]	Loss 0.3719 (0.4081)	
training:	Epoch: [3][154/204]	Loss 0.3600 (0.4078)	
training:	Epoch: [3][155/204]	Loss 0.6029 (0.4091)	
training:	Epoch: [3][156/204]	Loss 0.2032 (0.4077)	
training:	Epoch: [3][157/204]	Loss 0.3239 (0.4072)	
training:	Epoch: [3][158/204]	Loss 0.4891 (0.4077)	
training:	Epoch: [3][159/204]	Loss 0.4657 (0.4081)	
training:	Epoch: [3][160/204]	Loss 0.3956 (0.4080)	
training:	Epoch: [3][161/204]	Loss 0.3857 (0.4079)	
training:	Epoch: [3][162/204]	Loss 0.5906 (0.4090)	
training:	Epoch: [3][163/204]	Loss 0.4974 (0.4095)	
training:	Epoch: [3][164/204]	Loss 0.2575 (0.4086)	
training:	Epoch: [3][165/204]	Loss 0.4353 (0.4088)	
training:	Epoch: [3][166/204]	Loss 0.5465 (0.4096)	
training:	Epoch: [3][167/204]	Loss 0.3673 (0.4093)	
training:	Epoch: [3][168/204]	Loss 0.4084 (0.4093)	
training:	Epoch: [3][169/204]	Loss 0.4438 (0.4095)	
training:	Epoch: [3][170/204]	Loss 0.3438 (0.4092)	
training:	Epoch: [3][171/204]	Loss 0.5588 (0.4100)	
training:	Epoch: [3][172/204]	Loss 0.2974 (0.4094)	
training:	Epoch: [3][173/204]	Loss 0.4080 (0.4094)	
training:	Epoch: [3][174/204]	Loss 0.5416 (0.4101)	
training:	Epoch: [3][175/204]	Loss 0.4955 (0.4106)	
training:	Epoch: [3][176/204]	Loss 0.2478 (0.4097)	
training:	Epoch: [3][177/204]	Loss 0.3893 (0.4096)	
training:	Epoch: [3][178/204]	Loss 0.4457 (0.4098)	
training:	Epoch: [3][179/204]	Loss 0.2783 (0.4090)	
training:	Epoch: [3][180/204]	Loss 0.5438 (0.4098)	
training:	Epoch: [3][181/204]	Loss 0.4509 (0.4100)	
training:	Epoch: [3][182/204]	Loss 0.4125 (0.4100)	
training:	Epoch: [3][183/204]	Loss 0.2762 (0.4093)	
training:	Epoch: [3][184/204]	Loss 0.4228 (0.4094)	
training:	Epoch: [3][185/204]	Loss 0.4220 (0.4094)	
training:	Epoch: [3][186/204]	Loss 0.4125 (0.4095)	
training:	Epoch: [3][187/204]	Loss 0.5157 (0.4100)	
training:	Epoch: [3][188/204]	Loss 0.5461 (0.4108)	
training:	Epoch: [3][189/204]	Loss 0.3691 (0.4105)	
training:	Epoch: [3][190/204]	Loss 0.4013 (0.4105)	
training:	Epoch: [3][191/204]	Loss 0.5418 (0.4112)	
training:	Epoch: [3][192/204]	Loss 0.4255 (0.4112)	
training:	Epoch: [3][193/204]	Loss 0.4351 (0.4114)	
training:	Epoch: [3][194/204]	Loss 0.5131 (0.4119)	
training:	Epoch: [3][195/204]	Loss 0.4546 (0.4121)	
training:	Epoch: [3][196/204]	Loss 0.3087 (0.4116)	
training:	Epoch: [3][197/204]	Loss 0.3310 (0.4112)	
training:	Epoch: [3][198/204]	Loss 0.5093 (0.4117)	
training:	Epoch: [3][199/204]	Loss 0.3513 (0.4114)	
training:	Epoch: [3][200/204]	Loss 0.3755 (0.4112)	
training:	Epoch: [3][201/204]	Loss 0.2497 (0.4104)	
training:	Epoch: [3][202/204]	Loss 0.4677 (0.4107)	
training:	Epoch: [3][203/204]	Loss 0.3637 (0.4104)	
training:	Epoch: [3][204/204]	Loss 0.3108 (0.4100)	
Training:	 Loss: 0.4093

Training:	 ACC: 0.8339 0.8305 0.7519 0.9158
Validation:	 ACC: 0.7889 0.7844 0.6888 0.8890
Validation:	 Best_BACC: 0.7922 0.7913 0.7738 0.8105
Validation:	 Loss: 0.4510
Pretraining:	Epoch 4/500
----------
training:	Epoch: [4][1/204]	Loss 0.3963 (0.3963)	
training:	Epoch: [4][2/204]	Loss 0.2823 (0.3393)	
training:	Epoch: [4][3/204]	Loss 0.4218 (0.3668)	
training:	Epoch: [4][4/204]	Loss 0.2835 (0.3460)	
training:	Epoch: [4][5/204]	Loss 0.4920 (0.3752)	
training:	Epoch: [4][6/204]	Loss 0.3308 (0.3678)	
training:	Epoch: [4][7/204]	Loss 0.3707 (0.3682)	
training:	Epoch: [4][8/204]	Loss 0.3101 (0.3609)	
training:	Epoch: [4][9/204]	Loss 0.2172 (0.3450)	
training:	Epoch: [4][10/204]	Loss 0.3369 (0.3442)	
training:	Epoch: [4][11/204]	Loss 0.3421 (0.3440)	
training:	Epoch: [4][12/204]	Loss 0.4946 (0.3565)	
training:	Epoch: [4][13/204]	Loss 0.3056 (0.3526)	
training:	Epoch: [4][14/204]	Loss 0.3603 (0.3532)	
training:	Epoch: [4][15/204]	Loss 0.5776 (0.3681)	
training:	Epoch: [4][16/204]	Loss 0.6733 (0.3872)	
training:	Epoch: [4][17/204]	Loss 0.3596 (0.3856)	
training:	Epoch: [4][18/204]	Loss 0.6238 (0.3988)	
training:	Epoch: [4][19/204]	Loss 0.3334 (0.3954)	
training:	Epoch: [4][20/204]	Loss 0.3702 (0.3941)	
training:	Epoch: [4][21/204]	Loss 0.5048 (0.3994)	
training:	Epoch: [4][22/204]	Loss 0.4748 (0.4028)	
training:	Epoch: [4][23/204]	Loss 0.3552 (0.4007)	
training:	Epoch: [4][24/204]	Loss 0.2464 (0.3943)	
training:	Epoch: [4][25/204]	Loss 0.3621 (0.3930)	
training:	Epoch: [4][26/204]	Loss 0.3459 (0.3912)	
training:	Epoch: [4][27/204]	Loss 0.3205 (0.3886)	
training:	Epoch: [4][28/204]	Loss 0.3863 (0.3885)	
training:	Epoch: [4][29/204]	Loss 0.5543 (0.3942)	
training:	Epoch: [4][30/204]	Loss 0.3207 (0.3918)	
training:	Epoch: [4][31/204]	Loss 0.3713 (0.3911)	
training:	Epoch: [4][32/204]	Loss 0.5469 (0.3960)	
training:	Epoch: [4][33/204]	Loss 0.3269 (0.3939)	
training:	Epoch: [4][34/204]	Loss 0.2658 (0.3901)	
training:	Epoch: [4][35/204]	Loss 0.5171 (0.3937)	
training:	Epoch: [4][36/204]	Loss 0.3002 (0.3911)	
training:	Epoch: [4][37/204]	Loss 0.4755 (0.3934)	
training:	Epoch: [4][38/204]	Loss 0.3202 (0.3915)	
training:	Epoch: [4][39/204]	Loss 0.3756 (0.3911)	
training:	Epoch: [4][40/204]	Loss 0.3623 (0.3904)	
training:	Epoch: [4][41/204]	Loss 0.3127 (0.3885)	
training:	Epoch: [4][42/204]	Loss 0.2972 (0.3863)	
training:	Epoch: [4][43/204]	Loss 0.4877 (0.3887)	
training:	Epoch: [4][44/204]	Loss 0.3605 (0.3880)	
training:	Epoch: [4][45/204]	Loss 0.3395 (0.3869)	
training:	Epoch: [4][46/204]	Loss 0.2080 (0.3831)	
training:	Epoch: [4][47/204]	Loss 0.4666 (0.3848)	
training:	Epoch: [4][48/204]	Loss 0.3298 (0.3837)	
training:	Epoch: [4][49/204]	Loss 0.3983 (0.3840)	
training:	Epoch: [4][50/204]	Loss 0.5213 (0.3867)	
training:	Epoch: [4][51/204]	Loss 0.2633 (0.3843)	
training:	Epoch: [4][52/204]	Loss 0.4387 (0.3854)	
training:	Epoch: [4][53/204]	Loss 0.3529 (0.3847)	
training:	Epoch: [4][54/204]	Loss 0.4893 (0.3867)	
training:	Epoch: [4][55/204]	Loss 0.3494 (0.3860)	
training:	Epoch: [4][56/204]	Loss 0.3310 (0.3850)	
training:	Epoch: [4][57/204]	Loss 0.4571 (0.3863)	
training:	Epoch: [4][58/204]	Loss 0.4256 (0.3870)	
training:	Epoch: [4][59/204]	Loss 0.3637 (0.3866)	
training:	Epoch: [4][60/204]	Loss 0.3224 (0.3855)	
training:	Epoch: [4][61/204]	Loss 0.3526 (0.3850)	
training:	Epoch: [4][62/204]	Loss 0.3542 (0.3845)	
training:	Epoch: [4][63/204]	Loss 0.2181 (0.3818)	
training:	Epoch: [4][64/204]	Loss 0.2990 (0.3805)	
training:	Epoch: [4][65/204]	Loss 0.4338 (0.3813)	
training:	Epoch: [4][66/204]	Loss 0.4258 (0.3820)	
training:	Epoch: [4][67/204]	Loss 0.3405 (0.3814)	
training:	Epoch: [4][68/204]	Loss 0.3533 (0.3810)	
training:	Epoch: [4][69/204]	Loss 0.5396 (0.3833)	
training:	Epoch: [4][70/204]	Loss 0.3440 (0.3827)	
training:	Epoch: [4][71/204]	Loss 0.4506 (0.3837)	
training:	Epoch: [4][72/204]	Loss 0.2966 (0.3825)	
training:	Epoch: [4][73/204]	Loss 0.3418 (0.3819)	
training:	Epoch: [4][74/204]	Loss 0.3381 (0.3813)	
training:	Epoch: [4][75/204]	Loss 0.5674 (0.3838)	
training:	Epoch: [4][76/204]	Loss 0.4538 (0.3847)	
training:	Epoch: [4][77/204]	Loss 0.2142 (0.3825)	
training:	Epoch: [4][78/204]	Loss 0.2152 (0.3804)	
training:	Epoch: [4][79/204]	Loss 0.2882 (0.3792)	
training:	Epoch: [4][80/204]	Loss 0.3117 (0.3784)	
training:	Epoch: [4][81/204]	Loss 0.3328 (0.3778)	
training:	Epoch: [4][82/204]	Loss 0.5312 (0.3797)	
training:	Epoch: [4][83/204]	Loss 0.2792 (0.3784)	
training:	Epoch: [4][84/204]	Loss 0.3019 (0.3775)	
training:	Epoch: [4][85/204]	Loss 0.4181 (0.3780)	
training:	Epoch: [4][86/204]	Loss 0.3098 (0.3772)	
training:	Epoch: [4][87/204]	Loss 0.2955 (0.3763)	
training:	Epoch: [4][88/204]	Loss 0.6686 (0.3796)	
training:	Epoch: [4][89/204]	Loss 0.4265 (0.3801)	
training:	Epoch: [4][90/204]	Loss 0.2365 (0.3785)	
training:	Epoch: [4][91/204]	Loss 0.2981 (0.3777)	
training:	Epoch: [4][92/204]	Loss 0.2870 (0.3767)	
training:	Epoch: [4][93/204]	Loss 0.3205 (0.3761)	
training:	Epoch: [4][94/204]	Loss 0.5406 (0.3778)	
training:	Epoch: [4][95/204]	Loss 0.4003 (0.3780)	
training:	Epoch: [4][96/204]	Loss 0.2930 (0.3772)	
training:	Epoch: [4][97/204]	Loss 0.5445 (0.3789)	
training:	Epoch: [4][98/204]	Loss 0.3165 (0.3783)	
training:	Epoch: [4][99/204]	Loss 0.3355 (0.3778)	
training:	Epoch: [4][100/204]	Loss 0.3082 (0.3771)	
training:	Epoch: [4][101/204]	Loss 0.2425 (0.3758)	
training:	Epoch: [4][102/204]	Loss 0.3763 (0.3758)	
training:	Epoch: [4][103/204]	Loss 0.3345 (0.3754)	
training:	Epoch: [4][104/204]	Loss 0.5041 (0.3766)	
training:	Epoch: [4][105/204]	Loss 0.4262 (0.3771)	
training:	Epoch: [4][106/204]	Loss 0.4666 (0.3779)	
training:	Epoch: [4][107/204]	Loss 0.3436 (0.3776)	
training:	Epoch: [4][108/204]	Loss 0.3301 (0.3772)	
training:	Epoch: [4][109/204]	Loss 0.2959 (0.3764)	
training:	Epoch: [4][110/204]	Loss 0.3268 (0.3760)	
training:	Epoch: [4][111/204]	Loss 0.4108 (0.3763)	
training:	Epoch: [4][112/204]	Loss 0.3914 (0.3764)	
training:	Epoch: [4][113/204]	Loss 0.3262 (0.3760)	
training:	Epoch: [4][114/204]	Loss 0.3402 (0.3757)	
training:	Epoch: [4][115/204]	Loss 0.2720 (0.3748)	
training:	Epoch: [4][116/204]	Loss 0.4363 (0.3753)	
training:	Epoch: [4][117/204]	Loss 0.2347 (0.3741)	
training:	Epoch: [4][118/204]	Loss 0.4524 (0.3748)	
training:	Epoch: [4][119/204]	Loss 0.4751 (0.3756)	
training:	Epoch: [4][120/204]	Loss 0.6452 (0.3779)	
training:	Epoch: [4][121/204]	Loss 0.4210 (0.3782)	
training:	Epoch: [4][122/204]	Loss 0.1932 (0.3767)	
training:	Epoch: [4][123/204]	Loss 0.3688 (0.3766)	
training:	Epoch: [4][124/204]	Loss 0.4373 (0.3771)	
training:	Epoch: [4][125/204]	Loss 0.3727 (0.3771)	
training:	Epoch: [4][126/204]	Loss 0.3038 (0.3765)	
training:	Epoch: [4][127/204]	Loss 0.4022 (0.3767)	
training:	Epoch: [4][128/204]	Loss 0.3518 (0.3765)	
training:	Epoch: [4][129/204]	Loss 0.3237 (0.3761)	
training:	Epoch: [4][130/204]	Loss 0.3467 (0.3759)	
training:	Epoch: [4][131/204]	Loss 0.3538 (0.3757)	
training:	Epoch: [4][132/204]	Loss 0.3425 (0.3755)	
training:	Epoch: [4][133/204]	Loss 0.4574 (0.3761)	
training:	Epoch: [4][134/204]	Loss 0.3064 (0.3756)	
training:	Epoch: [4][135/204]	Loss 0.3449 (0.3753)	
training:	Epoch: [4][136/204]	Loss 0.4749 (0.3761)	
training:	Epoch: [4][137/204]	Loss 0.4625 (0.3767)	
training:	Epoch: [4][138/204]	Loss 0.2289 (0.3756)	
training:	Epoch: [4][139/204]	Loss 0.3857 (0.3757)	
training:	Epoch: [4][140/204]	Loss 0.2902 (0.3751)	
training:	Epoch: [4][141/204]	Loss 0.5804 (0.3765)	
training:	Epoch: [4][142/204]	Loss 0.3493 (0.3763)	
training:	Epoch: [4][143/204]	Loss 0.5986 (0.3779)	
training:	Epoch: [4][144/204]	Loss 0.4343 (0.3783)	
training:	Epoch: [4][145/204]	Loss 0.3093 (0.3778)	
training:	Epoch: [4][146/204]	Loss 0.3709 (0.3778)	
training:	Epoch: [4][147/204]	Loss 0.3250 (0.3774)	
training:	Epoch: [4][148/204]	Loss 0.3944 (0.3775)	
training:	Epoch: [4][149/204]	Loss 0.2991 (0.3770)	
training:	Epoch: [4][150/204]	Loss 0.3919 (0.3771)	
training:	Epoch: [4][151/204]	Loss 0.4122 (0.3773)	
training:	Epoch: [4][152/204]	Loss 0.5042 (0.3782)	
training:	Epoch: [4][153/204]	Loss 0.2751 (0.3775)	
training:	Epoch: [4][154/204]	Loss 0.3432 (0.3773)	
training:	Epoch: [4][155/204]	Loss 0.3871 (0.3773)	
training:	Epoch: [4][156/204]	Loss 0.3614 (0.3772)	
training:	Epoch: [4][157/204]	Loss 0.2788 (0.3766)	
training:	Epoch: [4][158/204]	Loss 0.4253 (0.3769)	
training:	Epoch: [4][159/204]	Loss 0.2589 (0.3762)	
training:	Epoch: [4][160/204]	Loss 0.3998 (0.3763)	
training:	Epoch: [4][161/204]	Loss 0.4038 (0.3765)	
training:	Epoch: [4][162/204]	Loss 0.3576 (0.3764)	
training:	Epoch: [4][163/204]	Loss 0.3581 (0.3763)	
training:	Epoch: [4][164/204]	Loss 0.3428 (0.3761)	
training:	Epoch: [4][165/204]	Loss 0.3099 (0.3757)	
training:	Epoch: [4][166/204]	Loss 0.5001 (0.3764)	
training:	Epoch: [4][167/204]	Loss 0.5135 (0.3772)	
training:	Epoch: [4][168/204]	Loss 0.4398 (0.3776)	
training:	Epoch: [4][169/204]	Loss 0.5533 (0.3786)	
training:	Epoch: [4][170/204]	Loss 0.4694 (0.3792)	
training:	Epoch: [4][171/204]	Loss 0.4595 (0.3796)	
training:	Epoch: [4][172/204]	Loss 0.4613 (0.3801)	
training:	Epoch: [4][173/204]	Loss 0.4108 (0.3803)	
training:	Epoch: [4][174/204]	Loss 0.4147 (0.3805)	
training:	Epoch: [4][175/204]	Loss 0.2298 (0.3796)	
training:	Epoch: [4][176/204]	Loss 0.4894 (0.3803)	
training:	Epoch: [4][177/204]	Loss 0.3215 (0.3799)	
training:	Epoch: [4][178/204]	Loss 0.3169 (0.3796)	
training:	Epoch: [4][179/204]	Loss 0.2731 (0.3790)	
training:	Epoch: [4][180/204]	Loss 0.3832 (0.3790)	
training:	Epoch: [4][181/204]	Loss 0.2663 (0.3784)	
training:	Epoch: [4][182/204]	Loss 0.4016 (0.3785)	
training:	Epoch: [4][183/204]	Loss 0.6116 (0.3798)	
training:	Epoch: [4][184/204]	Loss 0.3347 (0.3795)	
training:	Epoch: [4][185/204]	Loss 0.3912 (0.3796)	
training:	Epoch: [4][186/204]	Loss 0.6035 (0.3808)	
training:	Epoch: [4][187/204]	Loss 0.2739 (0.3802)	
training:	Epoch: [4][188/204]	Loss 0.3065 (0.3798)	
training:	Epoch: [4][189/204]	Loss 0.2029 (0.3789)	
training:	Epoch: [4][190/204]	Loss 0.4036 (0.3790)	
training:	Epoch: [4][191/204]	Loss 0.4788 (0.3796)	
training:	Epoch: [4][192/204]	Loss 0.3210 (0.3792)	
training:	Epoch: [4][193/204]	Loss 0.2261 (0.3785)	
training:	Epoch: [4][194/204]	Loss 0.5255 (0.3792)	
training:	Epoch: [4][195/204]	Loss 0.5551 (0.3801)	
training:	Epoch: [4][196/204]	Loss 0.6387 (0.3814)	
training:	Epoch: [4][197/204]	Loss 0.3653 (0.3813)	
training:	Epoch: [4][198/204]	Loss 0.3647 (0.3813)	
training:	Epoch: [4][199/204]	Loss 0.2731 (0.3807)	
training:	Epoch: [4][200/204]	Loss 0.3363 (0.3805)	
training:	Epoch: [4][201/204]	Loss 0.3839 (0.3805)	
training:	Epoch: [4][202/204]	Loss 0.3237 (0.3802)	
training:	Epoch: [4][203/204]	Loss 0.1762 (0.3792)	
training:	Epoch: [4][204/204]	Loss 0.2871 (0.3788)	
Training:	 Loss: 0.3782

Training:	 ACC: 0.8648 0.8645 0.8580 0.8715
Validation:	 ACC: 0.8146 0.8143 0.8096 0.8195
Validation:	 Best_BACC: 0.8146 0.8143 0.8096 0.8195
Validation:	 Loss: 0.4122
Pretraining:	Epoch 5/500
----------
training:	Epoch: [5][1/204]	Loss 0.3085 (0.3085)	
training:	Epoch: [5][2/204]	Loss 0.2553 (0.2819)	
training:	Epoch: [5][3/204]	Loss 0.4230 (0.3289)	
training:	Epoch: [5][4/204]	Loss 0.2176 (0.3011)	
training:	Epoch: [5][5/204]	Loss 0.5476 (0.3504)	
training:	Epoch: [5][6/204]	Loss 0.4128 (0.3608)	
training:	Epoch: [5][7/204]	Loss 0.2695 (0.3478)	
training:	Epoch: [5][8/204]	Loss 0.3151 (0.3437)	
training:	Epoch: [5][9/204]	Loss 0.3478 (0.3441)	
training:	Epoch: [5][10/204]	Loss 0.3346 (0.3432)	
training:	Epoch: [5][11/204]	Loss 0.4605 (0.3539)	
training:	Epoch: [5][12/204]	Loss 0.4614 (0.3628)	
training:	Epoch: [5][13/204]	Loss 0.1889 (0.3494)	
training:	Epoch: [5][14/204]	Loss 0.4606 (0.3574)	
training:	Epoch: [5][15/204]	Loss 0.6036 (0.3738)	
training:	Epoch: [5][16/204]	Loss 0.3311 (0.3711)	
training:	Epoch: [5][17/204]	Loss 0.4537 (0.3760)	
training:	Epoch: [5][18/204]	Loss 0.3988 (0.3773)	
training:	Epoch: [5][19/204]	Loss 0.4526 (0.3812)	
training:	Epoch: [5][20/204]	Loss 0.4702 (0.3857)	
training:	Epoch: [5][21/204]	Loss 0.2903 (0.3811)	
training:	Epoch: [5][22/204]	Loss 0.4765 (0.3855)	
training:	Epoch: [5][23/204]	Loss 0.3392 (0.3835)	
training:	Epoch: [5][24/204]	Loss 0.2291 (0.3770)	
training:	Epoch: [5][25/204]	Loss 0.3910 (0.3776)	
training:	Epoch: [5][26/204]	Loss 0.3747 (0.3775)	
training:	Epoch: [5][27/204]	Loss 0.5195 (0.3827)	
training:	Epoch: [5][28/204]	Loss 0.3329 (0.3810)	
training:	Epoch: [5][29/204]	Loss 0.3894 (0.3812)	
training:	Epoch: [5][30/204]	Loss 0.1843 (0.3747)	
training:	Epoch: [5][31/204]	Loss 0.3984 (0.3754)	
training:	Epoch: [5][32/204]	Loss 0.3990 (0.3762)	
training:	Epoch: [5][33/204]	Loss 0.1809 (0.3703)	
training:	Epoch: [5][34/204]	Loss 0.3579 (0.3699)	
training:	Epoch: [5][35/204]	Loss 0.3678 (0.3698)	
training:	Epoch: [5][36/204]	Loss 0.3690 (0.3698)	
training:	Epoch: [5][37/204]	Loss 0.4718 (0.3726)	
training:	Epoch: [5][38/204]	Loss 0.4364 (0.3742)	
training:	Epoch: [5][39/204]	Loss 0.3935 (0.3747)	
training:	Epoch: [5][40/204]	Loss 0.3478 (0.3741)	
training:	Epoch: [5][41/204]	Loss 0.2874 (0.3720)	
training:	Epoch: [5][42/204]	Loss 0.3345 (0.3711)	
training:	Epoch: [5][43/204]	Loss 0.4620 (0.3732)	
training:	Epoch: [5][44/204]	Loss 0.5224 (0.3766)	
training:	Epoch: [5][45/204]	Loss 0.2300 (0.3733)	
training:	Epoch: [5][46/204]	Loss 0.4296 (0.3745)	
training:	Epoch: [5][47/204]	Loss 0.2287 (0.3714)	
training:	Epoch: [5][48/204]	Loss 0.4947 (0.3740)	
training:	Epoch: [5][49/204]	Loss 0.3249 (0.3730)	
training:	Epoch: [5][50/204]	Loss 0.4877 (0.3753)	
training:	Epoch: [5][51/204]	Loss 0.2426 (0.3727)	
training:	Epoch: [5][52/204]	Loss 0.4090 (0.3734)	
training:	Epoch: [5][53/204]	Loss 0.3210 (0.3724)	
training:	Epoch: [5][54/204]	Loss 0.2513 (0.3702)	
training:	Epoch: [5][55/204]	Loss 0.4016 (0.3707)	
training:	Epoch: [5][56/204]	Loss 0.4450 (0.3721)	
training:	Epoch: [5][57/204]	Loss 0.4152 (0.3728)	
training:	Epoch: [5][58/204]	Loss 0.3295 (0.3721)	
training:	Epoch: [5][59/204]	Loss 0.3016 (0.3709)	
training:	Epoch: [5][60/204]	Loss 0.2761 (0.3693)	
training:	Epoch: [5][61/204]	Loss 0.4667 (0.3709)	
training:	Epoch: [5][62/204]	Loss 0.2667 (0.3692)	
training:	Epoch: [5][63/204]	Loss 0.1883 (0.3663)	
training:	Epoch: [5][64/204]	Loss 0.2472 (0.3645)	
training:	Epoch: [5][65/204]	Loss 0.5577 (0.3674)	
training:	Epoch: [5][66/204]	Loss 0.3546 (0.3673)	
training:	Epoch: [5][67/204]	Loss 0.2828 (0.3660)	
training:	Epoch: [5][68/204]	Loss 0.2706 (0.3646)	
training:	Epoch: [5][69/204]	Loss 0.3409 (0.3642)	
training:	Epoch: [5][70/204]	Loss 0.2457 (0.3626)	
training:	Epoch: [5][71/204]	Loss 0.3156 (0.3619)	
training:	Epoch: [5][72/204]	Loss 0.4169 (0.3627)	
training:	Epoch: [5][73/204]	Loss 0.4165 (0.3634)	
training:	Epoch: [5][74/204]	Loss 0.3811 (0.3636)	
training:	Epoch: [5][75/204]	Loss 0.4771 (0.3651)	
training:	Epoch: [5][76/204]	Loss 0.2356 (0.3634)	
training:	Epoch: [5][77/204]	Loss 0.3168 (0.3628)	
training:	Epoch: [5][78/204]	Loss 0.4171 (0.3635)	
training:	Epoch: [5][79/204]	Loss 0.3896 (0.3639)	
training:	Epoch: [5][80/204]	Loss 0.4366 (0.3648)	
training:	Epoch: [5][81/204]	Loss 0.2513 (0.3634)	
training:	Epoch: [5][82/204]	Loss 0.2761 (0.3623)	
training:	Epoch: [5][83/204]	Loss 0.3400 (0.3620)	
training:	Epoch: [5][84/204]	Loss 0.2317 (0.3605)	
training:	Epoch: [5][85/204]	Loss 0.3634 (0.3605)	
training:	Epoch: [5][86/204]	Loss 0.2080 (0.3587)	
training:	Epoch: [5][87/204]	Loss 0.3415 (0.3585)	
training:	Epoch: [5][88/204]	Loss 0.3322 (0.3582)	
training:	Epoch: [5][89/204]	Loss 0.4320 (0.3591)	
training:	Epoch: [5][90/204]	Loss 0.3919 (0.3594)	
training:	Epoch: [5][91/204]	Loss 0.3522 (0.3594)	
training:	Epoch: [5][92/204]	Loss 0.4335 (0.3602)	
training:	Epoch: [5][93/204]	Loss 0.3664 (0.3602)	
training:	Epoch: [5][94/204]	Loss 0.3395 (0.3600)	
training:	Epoch: [5][95/204]	Loss 0.2649 (0.3590)	
training:	Epoch: [5][96/204]	Loss 0.4404 (0.3599)	
training:	Epoch: [5][97/204]	Loss 0.3181 (0.3594)	
training:	Epoch: [5][98/204]	Loss 0.1514 (0.3573)	
training:	Epoch: [5][99/204]	Loss 0.2035 (0.3558)	
training:	Epoch: [5][100/204]	Loss 0.3098 (0.3553)	
training:	Epoch: [5][101/204]	Loss 0.4419 (0.3562)	
training:	Epoch: [5][102/204]	Loss 0.3880 (0.3565)	
training:	Epoch: [5][103/204]	Loss 0.2070 (0.3550)	
training:	Epoch: [5][104/204]	Loss 0.5410 (0.3568)	
training:	Epoch: [5][105/204]	Loss 0.2819 (0.3561)	
training:	Epoch: [5][106/204]	Loss 0.3765 (0.3563)	
training:	Epoch: [5][107/204]	Loss 0.3852 (0.3566)	
training:	Epoch: [5][108/204]	Loss 0.2603 (0.3557)	
training:	Epoch: [5][109/204]	Loss 0.3278 (0.3554)	
training:	Epoch: [5][110/204]	Loss 0.1804 (0.3538)	
training:	Epoch: [5][111/204]	Loss 0.3395 (0.3537)	
training:	Epoch: [5][112/204]	Loss 0.2268 (0.3526)	
training:	Epoch: [5][113/204]	Loss 0.3692 (0.3527)	
training:	Epoch: [5][114/204]	Loss 0.1722 (0.3511)	
training:	Epoch: [5][115/204]	Loss 0.3667 (0.3513)	
training:	Epoch: [5][116/204]	Loss 0.2049 (0.3500)	
training:	Epoch: [5][117/204]	Loss 0.4245 (0.3506)	
training:	Epoch: [5][118/204]	Loss 0.2645 (0.3499)	
training:	Epoch: [5][119/204]	Loss 0.4023 (0.3503)	
training:	Epoch: [5][120/204]	Loss 0.4100 (0.3508)	
training:	Epoch: [5][121/204]	Loss 0.7056 (0.3538)	
training:	Epoch: [5][122/204]	Loss 0.5124 (0.3551)	
training:	Epoch: [5][123/204]	Loss 0.4448 (0.3558)	
training:	Epoch: [5][124/204]	Loss 0.2422 (0.3549)	
training:	Epoch: [5][125/204]	Loss 0.4593 (0.3557)	
training:	Epoch: [5][126/204]	Loss 0.4198 (0.3562)	
training:	Epoch: [5][127/204]	Loss 0.2080 (0.3551)	
training:	Epoch: [5][128/204]	Loss 0.2906 (0.3546)	
training:	Epoch: [5][129/204]	Loss 0.2982 (0.3541)	
training:	Epoch: [5][130/204]	Loss 0.4419 (0.3548)	
training:	Epoch: [5][131/204]	Loss 0.2544 (0.3540)	
training:	Epoch: [5][132/204]	Loss 0.2551 (0.3533)	
training:	Epoch: [5][133/204]	Loss 0.3362 (0.3531)	
training:	Epoch: [5][134/204]	Loss 0.3557 (0.3532)	
training:	Epoch: [5][135/204]	Loss 0.3587 (0.3532)	
training:	Epoch: [5][136/204]	Loss 0.4707 (0.3541)	
training:	Epoch: [5][137/204]	Loss 0.5129 (0.3552)	
training:	Epoch: [5][138/204]	Loss 0.3088 (0.3549)	
training:	Epoch: [5][139/204]	Loss 0.2853 (0.3544)	
training:	Epoch: [5][140/204]	Loss 0.3825 (0.3546)	
training:	Epoch: [5][141/204]	Loss 0.2428 (0.3538)	
training:	Epoch: [5][142/204]	Loss 0.3622 (0.3539)	
training:	Epoch: [5][143/204]	Loss 0.3160 (0.3536)	
training:	Epoch: [5][144/204]	Loss 0.2394 (0.3528)	
training:	Epoch: [5][145/204]	Loss 0.4149 (0.3532)	
training:	Epoch: [5][146/204]	Loss 0.3705 (0.3533)	
training:	Epoch: [5][147/204]	Loss 0.3571 (0.3534)	
training:	Epoch: [5][148/204]	Loss 0.3836 (0.3536)	
training:	Epoch: [5][149/204]	Loss 0.4580 (0.3543)	
training:	Epoch: [5][150/204]	Loss 0.2362 (0.3535)	
training:	Epoch: [5][151/204]	Loss 0.3307 (0.3533)	
training:	Epoch: [5][152/204]	Loss 0.3974 (0.3536)	
training:	Epoch: [5][153/204]	Loss 0.4353 (0.3542)	
training:	Epoch: [5][154/204]	Loss 0.5686 (0.3556)	
training:	Epoch: [5][155/204]	Loss 0.2831 (0.3551)	
training:	Epoch: [5][156/204]	Loss 0.2176 (0.3542)	
training:	Epoch: [5][157/204]	Loss 0.4066 (0.3545)	
training:	Epoch: [5][158/204]	Loss 0.3609 (0.3546)	
training:	Epoch: [5][159/204]	Loss 0.3287 (0.3544)	
training:	Epoch: [5][160/204]	Loss 0.4713 (0.3552)	
training:	Epoch: [5][161/204]	Loss 0.3345 (0.3550)	
training:	Epoch: [5][162/204]	Loss 0.3951 (0.3553)	
training:	Epoch: [5][163/204]	Loss 0.4311 (0.3557)	
training:	Epoch: [5][164/204]	Loss 0.3280 (0.3556)	
training:	Epoch: [5][165/204]	Loss 0.3344 (0.3554)	
training:	Epoch: [5][166/204]	Loss 0.3418 (0.3554)	
training:	Epoch: [5][167/204]	Loss 0.2735 (0.3549)	
training:	Epoch: [5][168/204]	Loss 0.2484 (0.3542)	
training:	Epoch: [5][169/204]	Loss 0.3227 (0.3540)	
training:	Epoch: [5][170/204]	Loss 0.2850 (0.3536)	
training:	Epoch: [5][171/204]	Loss 0.4789 (0.3544)	
training:	Epoch: [5][172/204]	Loss 0.3807 (0.3545)	
training:	Epoch: [5][173/204]	Loss 0.2831 (0.3541)	
training:	Epoch: [5][174/204]	Loss 0.2684 (0.3536)	
training:	Epoch: [5][175/204]	Loss 0.3984 (0.3539)	
training:	Epoch: [5][176/204]	Loss 0.3944 (0.3541)	
training:	Epoch: [5][177/204]	Loss 0.3517 (0.3541)	
training:	Epoch: [5][178/204]	Loss 0.1863 (0.3531)	
training:	Epoch: [5][179/204]	Loss 0.3469 (0.3531)	
training:	Epoch: [5][180/204]	Loss 0.2845 (0.3527)	
training:	Epoch: [5][181/204]	Loss 0.2967 (0.3524)	
training:	Epoch: [5][182/204]	Loss 0.4190 (0.3528)	
training:	Epoch: [5][183/204]	Loss 0.3761 (0.3529)	
training:	Epoch: [5][184/204]	Loss 0.4476 (0.3534)	
training:	Epoch: [5][185/204]	Loss 0.4173 (0.3538)	
training:	Epoch: [5][186/204]	Loss 0.2314 (0.3531)	
training:	Epoch: [5][187/204]	Loss 0.3149 (0.3529)	
training:	Epoch: [5][188/204]	Loss 0.4905 (0.3536)	
training:	Epoch: [5][189/204]	Loss 0.5268 (0.3546)	
training:	Epoch: [5][190/204]	Loss 0.3412 (0.3545)	
training:	Epoch: [5][191/204]	Loss 0.3968 (0.3547)	
training:	Epoch: [5][192/204]	Loss 0.2421 (0.3541)	
training:	Epoch: [5][193/204]	Loss 0.3947 (0.3543)	
training:	Epoch: [5][194/204]	Loss 0.2722 (0.3539)	
training:	Epoch: [5][195/204]	Loss 0.3388 (0.3538)	
training:	Epoch: [5][196/204]	Loss 0.2033 (0.3531)	
training:	Epoch: [5][197/204]	Loss 0.5368 (0.3540)	
training:	Epoch: [5][198/204]	Loss 0.3827 (0.3541)	
training:	Epoch: [5][199/204]	Loss 0.2323 (0.3535)	
training:	Epoch: [5][200/204]	Loss 0.3935 (0.3537)	
training:	Epoch: [5][201/204]	Loss 0.1728 (0.3528)	
training:	Epoch: [5][202/204]	Loss 0.3605 (0.3529)	
training:	Epoch: [5][203/204]	Loss 0.3421 (0.3528)	
training:	Epoch: [5][204/204]	Loss 0.2160 (0.3521)	
Training:	 Loss: 0.3516

Training:	 ACC: 0.8755 0.8755 0.8748 0.8763
Validation:	 ACC: 0.8116 0.8117 0.8127 0.8105
Validation:	 Best_BACC: 0.8146 0.8143 0.8096 0.8195
Validation:	 Loss: 0.4085
Pretraining:	Epoch 6/500
----------
training:	Epoch: [6][1/204]	Loss 0.2331 (0.2331)	
training:	Epoch: [6][2/204]	Loss 0.4464 (0.3397)	
training:	Epoch: [6][3/204]	Loss 0.3851 (0.3549)	
training:	Epoch: [6][4/204]	Loss 0.3705 (0.3588)	
training:	Epoch: [6][5/204]	Loss 0.3976 (0.3665)	
training:	Epoch: [6][6/204]	Loss 0.3042 (0.3562)	
training:	Epoch: [6][7/204]	Loss 0.3260 (0.3518)	
training:	Epoch: [6][8/204]	Loss 0.5047 (0.3709)	
training:	Epoch: [6][9/204]	Loss 0.3897 (0.3730)	
training:	Epoch: [6][10/204]	Loss 0.3248 (0.3682)	
training:	Epoch: [6][11/204]	Loss 0.2954 (0.3616)	
training:	Epoch: [6][12/204]	Loss 0.6543 (0.3860)	
training:	Epoch: [6][13/204]	Loss 0.2902 (0.3786)	
training:	Epoch: [6][14/204]	Loss 0.2761 (0.3713)	
training:	Epoch: [6][15/204]	Loss 0.1696 (0.3578)	
training:	Epoch: [6][16/204]	Loss 0.2973 (0.3541)	
training:	Epoch: [6][17/204]	Loss 0.4626 (0.3604)	
training:	Epoch: [6][18/204]	Loss 0.3415 (0.3594)	
training:	Epoch: [6][19/204]	Loss 0.5255 (0.3681)	
training:	Epoch: [6][20/204]	Loss 0.4083 (0.3702)	
training:	Epoch: [6][21/204]	Loss 0.2475 (0.3643)	
training:	Epoch: [6][22/204]	Loss 0.2753 (0.3603)	
training:	Epoch: [6][23/204]	Loss 0.2632 (0.3560)	
training:	Epoch: [6][24/204]	Loss 0.2989 (0.3537)	
training:	Epoch: [6][25/204]	Loss 0.2630 (0.3500)	
training:	Epoch: [6][26/204]	Loss 0.2823 (0.3474)	
training:	Epoch: [6][27/204]	Loss 0.2625 (0.3443)	
training:	Epoch: [6][28/204]	Loss 0.2977 (0.3426)	
training:	Epoch: [6][29/204]	Loss 0.2411 (0.3391)	
training:	Epoch: [6][30/204]	Loss 0.4475 (0.3427)	
training:	Epoch: [6][31/204]	Loss 0.4381 (0.3458)	
training:	Epoch: [6][32/204]	Loss 0.2046 (0.3414)	
training:	Epoch: [6][33/204]	Loss 0.2663 (0.3391)	
training:	Epoch: [6][34/204]	Loss 0.2790 (0.3373)	
training:	Epoch: [6][35/204]	Loss 0.2615 (0.3352)	
training:	Epoch: [6][36/204]	Loss 0.3549 (0.3357)	
training:	Epoch: [6][37/204]	Loss 0.2881 (0.3344)	
training:	Epoch: [6][38/204]	Loss 0.3934 (0.3360)	
training:	Epoch: [6][39/204]	Loss 0.2659 (0.3342)	
training:	Epoch: [6][40/204]	Loss 0.2618 (0.3324)	
training:	Epoch: [6][41/204]	Loss 0.2005 (0.3292)	
training:	Epoch: [6][42/204]	Loss 0.1223 (0.3242)	
training:	Epoch: [6][43/204]	Loss 0.3090 (0.3239)	
training:	Epoch: [6][44/204]	Loss 0.4264 (0.3262)	
training:	Epoch: [6][45/204]	Loss 0.2628 (0.3248)	
training:	Epoch: [6][46/204]	Loss 0.1966 (0.3220)	
training:	Epoch: [6][47/204]	Loss 0.2579 (0.3207)	
training:	Epoch: [6][48/204]	Loss 0.2692 (0.3196)	
training:	Epoch: [6][49/204]	Loss 0.3707 (0.3206)	
training:	Epoch: [6][50/204]	Loss 0.3027 (0.3203)	
training:	Epoch: [6][51/204]	Loss 0.6146 (0.3260)	
training:	Epoch: [6][52/204]	Loss 0.3324 (0.3262)	
training:	Epoch: [6][53/204]	Loss 0.3009 (0.3257)	
training:	Epoch: [6][54/204]	Loss 0.2663 (0.3246)	
training:	Epoch: [6][55/204]	Loss 0.3586 (0.3252)	
training:	Epoch: [6][56/204]	Loss 0.2679 (0.3242)	
training:	Epoch: [6][57/204]	Loss 0.2154 (0.3223)	
training:	Epoch: [6][58/204]	Loss 0.3206 (0.3222)	
training:	Epoch: [6][59/204]	Loss 0.3157 (0.3221)	
training:	Epoch: [6][60/204]	Loss 0.4929 (0.3250)	
training:	Epoch: [6][61/204]	Loss 0.3311 (0.3251)	
training:	Epoch: [6][62/204]	Loss 0.3216 (0.3250)	
training:	Epoch: [6][63/204]	Loss 0.4476 (0.3270)	
training:	Epoch: [6][64/204]	Loss 0.2558 (0.3259)	
training:	Epoch: [6][65/204]	Loss 0.3477 (0.3262)	
training:	Epoch: [6][66/204]	Loss 0.3656 (0.3268)	
training:	Epoch: [6][67/204]	Loss 0.4176 (0.3281)	
training:	Epoch: [6][68/204]	Loss 0.3862 (0.3290)	
training:	Epoch: [6][69/204]	Loss 0.3538 (0.3294)	
training:	Epoch: [6][70/204]	Loss 0.5690 (0.3328)	
training:	Epoch: [6][71/204]	Loss 0.4084 (0.3338)	
training:	Epoch: [6][72/204]	Loss 0.2710 (0.3330)	
training:	Epoch: [6][73/204]	Loss 0.2074 (0.3313)	
training:	Epoch: [6][74/204]	Loss 0.2684 (0.3304)	
training:	Epoch: [6][75/204]	Loss 0.1972 (0.3286)	
training:	Epoch: [6][76/204]	Loss 0.3173 (0.3285)	
training:	Epoch: [6][77/204]	Loss 0.1819 (0.3266)	
training:	Epoch: [6][78/204]	Loss 0.2176 (0.3252)	
training:	Epoch: [6][79/204]	Loss 0.3445 (0.3254)	
training:	Epoch: [6][80/204]	Loss 0.3102 (0.3252)	
training:	Epoch: [6][81/204]	Loss 0.3529 (0.3256)	
training:	Epoch: [6][82/204]	Loss 0.2210 (0.3243)	
training:	Epoch: [6][83/204]	Loss 0.3337 (0.3244)	
training:	Epoch: [6][84/204]	Loss 0.3108 (0.3243)	
training:	Epoch: [6][85/204]	Loss 0.4157 (0.3253)	
training:	Epoch: [6][86/204]	Loss 0.4751 (0.3271)	
training:	Epoch: [6][87/204]	Loss 0.3299 (0.3271)	
training:	Epoch: [6][88/204]	Loss 0.2182 (0.3259)	
training:	Epoch: [6][89/204]	Loss 0.2692 (0.3252)	
training:	Epoch: [6][90/204]	Loss 0.5165 (0.3274)	
training:	Epoch: [6][91/204]	Loss 0.3948 (0.3281)	
training:	Epoch: [6][92/204]	Loss 0.4569 (0.3295)	
training:	Epoch: [6][93/204]	Loss 0.3129 (0.3293)	
training:	Epoch: [6][94/204]	Loss 0.3055 (0.3291)	
training:	Epoch: [6][95/204]	Loss 0.2574 (0.3283)	
training:	Epoch: [6][96/204]	Loss 0.2951 (0.3280)	
training:	Epoch: [6][97/204]	Loss 0.6752 (0.3315)	
training:	Epoch: [6][98/204]	Loss 0.1797 (0.3300)	
training:	Epoch: [6][99/204]	Loss 0.2562 (0.3292)	
training:	Epoch: [6][100/204]	Loss 0.4100 (0.3301)	
training:	Epoch: [6][101/204]	Loss 0.2744 (0.3295)	
training:	Epoch: [6][102/204]	Loss 0.5455 (0.3316)	
training:	Epoch: [6][103/204]	Loss 0.3878 (0.3322)	
training:	Epoch: [6][104/204]	Loss 0.4113 (0.3329)	
training:	Epoch: [6][105/204]	Loss 0.1942 (0.3316)	
training:	Epoch: [6][106/204]	Loss 0.3441 (0.3317)	
training:	Epoch: [6][107/204]	Loss 0.3130 (0.3315)	
training:	Epoch: [6][108/204]	Loss 0.3344 (0.3316)	
training:	Epoch: [6][109/204]	Loss 0.3052 (0.3313)	
training:	Epoch: [6][110/204]	Loss 0.2725 (0.3308)	
training:	Epoch: [6][111/204]	Loss 0.4502 (0.3319)	
training:	Epoch: [6][112/204]	Loss 0.2256 (0.3309)	
training:	Epoch: [6][113/204]	Loss 0.4984 (0.3324)	
training:	Epoch: [6][114/204]	Loss 0.1695 (0.3310)	
training:	Epoch: [6][115/204]	Loss 0.4042 (0.3316)	
training:	Epoch: [6][116/204]	Loss 0.2297 (0.3307)	
training:	Epoch: [6][117/204]	Loss 0.1550 (0.3292)	
training:	Epoch: [6][118/204]	Loss 0.2236 (0.3283)	
training:	Epoch: [6][119/204]	Loss 0.4983 (0.3298)	
training:	Epoch: [6][120/204]	Loss 0.3202 (0.3297)	
training:	Epoch: [6][121/204]	Loss 0.2381 (0.3289)	
training:	Epoch: [6][122/204]	Loss 0.3665 (0.3292)	
training:	Epoch: [6][123/204]	Loss 0.2757 (0.3288)	
training:	Epoch: [6][124/204]	Loss 0.2972 (0.3286)	
training:	Epoch: [6][125/204]	Loss 0.2767 (0.3281)	
training:	Epoch: [6][126/204]	Loss 0.3124 (0.3280)	
training:	Epoch: [6][127/204]	Loss 0.2784 (0.3276)	
training:	Epoch: [6][128/204]	Loss 0.3978 (0.3282)	
training:	Epoch: [6][129/204]	Loss 0.3009 (0.3280)	
training:	Epoch: [6][130/204]	Loss 0.2326 (0.3272)	
training:	Epoch: [6][131/204]	Loss 0.2543 (0.3267)	
training:	Epoch: [6][132/204]	Loss 0.3513 (0.3269)	
training:	Epoch: [6][133/204]	Loss 0.3742 (0.3272)	
training:	Epoch: [6][134/204]	Loss 0.1939 (0.3262)	
training:	Epoch: [6][135/204]	Loss 0.3339 (0.3263)	
training:	Epoch: [6][136/204]	Loss 0.1933 (0.3253)	
training:	Epoch: [6][137/204]	Loss 0.4135 (0.3259)	
training:	Epoch: [6][138/204]	Loss 0.3205 (0.3259)	
training:	Epoch: [6][139/204]	Loss 0.3390 (0.3260)	
training:	Epoch: [6][140/204]	Loss 0.2790 (0.3257)	
training:	Epoch: [6][141/204]	Loss 0.3847 (0.3261)	
training:	Epoch: [6][142/204]	Loss 0.3319 (0.3261)	
training:	Epoch: [6][143/204]	Loss 0.2597 (0.3257)	
training:	Epoch: [6][144/204]	Loss 0.3574 (0.3259)	
training:	Epoch: [6][145/204]	Loss 0.3905 (0.3263)	
training:	Epoch: [6][146/204]	Loss 0.3006 (0.3261)	
training:	Epoch: [6][147/204]	Loss 0.3693 (0.3264)	
training:	Epoch: [6][148/204]	Loss 0.3600 (0.3267)	
training:	Epoch: [6][149/204]	Loss 0.4961 (0.3278)	
training:	Epoch: [6][150/204]	Loss 0.3209 (0.3278)	
training:	Epoch: [6][151/204]	Loss 0.2454 (0.3272)	
training:	Epoch: [6][152/204]	Loss 0.2787 (0.3269)	
training:	Epoch: [6][153/204]	Loss 0.3628 (0.3271)	
training:	Epoch: [6][154/204]	Loss 0.3773 (0.3274)	
training:	Epoch: [6][155/204]	Loss 0.4782 (0.3284)	
training:	Epoch: [6][156/204]	Loss 0.3863 (0.3288)	
training:	Epoch: [6][157/204]	Loss 0.2160 (0.3281)	
training:	Epoch: [6][158/204]	Loss 0.2722 (0.3277)	
training:	Epoch: [6][159/204]	Loss 0.4408 (0.3284)	
training:	Epoch: [6][160/204]	Loss 0.4035 (0.3289)	
training:	Epoch: [6][161/204]	Loss 0.4291 (0.3295)	
training:	Epoch: [6][162/204]	Loss 0.3402 (0.3296)	
training:	Epoch: [6][163/204]	Loss 0.6278 (0.3314)	
training:	Epoch: [6][164/204]	Loss 0.2981 (0.3312)	
training:	Epoch: [6][165/204]	Loss 0.2724 (0.3309)	
training:	Epoch: [6][166/204]	Loss 0.3839 (0.3312)	
training:	Epoch: [6][167/204]	Loss 0.3591 (0.3313)	
training:	Epoch: [6][168/204]	Loss 0.2793 (0.3310)	
training:	Epoch: [6][169/204]	Loss 0.1253 (0.3298)	
training:	Epoch: [6][170/204]	Loss 0.2612 (0.3294)	
training:	Epoch: [6][171/204]	Loss 0.4502 (0.3301)	
training:	Epoch: [6][172/204]	Loss 0.3622 (0.3303)	
training:	Epoch: [6][173/204]	Loss 0.1986 (0.3295)	
training:	Epoch: [6][174/204]	Loss 0.3951 (0.3299)	
training:	Epoch: [6][175/204]	Loss 0.5164 (0.3310)	
training:	Epoch: [6][176/204]	Loss 0.4387 (0.3316)	
training:	Epoch: [6][177/204]	Loss 0.3502 (0.3317)	
training:	Epoch: [6][178/204]	Loss 0.2773 (0.3314)	
training:	Epoch: [6][179/204]	Loss 0.3241 (0.3314)	
training:	Epoch: [6][180/204]	Loss 0.3817 (0.3316)	
training:	Epoch: [6][181/204]	Loss 0.3787 (0.3319)	
training:	Epoch: [6][182/204]	Loss 0.3650 (0.3321)	
training:	Epoch: [6][183/204]	Loss 0.2023 (0.3314)	
training:	Epoch: [6][184/204]	Loss 0.3076 (0.3312)	
training:	Epoch: [6][185/204]	Loss 0.3248 (0.3312)	
training:	Epoch: [6][186/204]	Loss 0.2356 (0.3307)	
training:	Epoch: [6][187/204]	Loss 0.3090 (0.3306)	
training:	Epoch: [6][188/204]	Loss 0.3894 (0.3309)	
training:	Epoch: [6][189/204]	Loss 0.5171 (0.3319)	
training:	Epoch: [6][190/204]	Loss 0.3866 (0.3322)	
training:	Epoch: [6][191/204]	Loss 0.5591 (0.3334)	
training:	Epoch: [6][192/204]	Loss 0.3973 (0.3337)	
training:	Epoch: [6][193/204]	Loss 0.3611 (0.3338)	
training:	Epoch: [6][194/204]	Loss 0.4210 (0.3343)	
training:	Epoch: [6][195/204]	Loss 0.5793 (0.3355)	
training:	Epoch: [6][196/204]	Loss 0.5124 (0.3364)	
training:	Epoch: [6][197/204]	Loss 0.2870 (0.3362)	
training:	Epoch: [6][198/204]	Loss 0.1669 (0.3353)	
training:	Epoch: [6][199/204]	Loss 0.3072 (0.3352)	
training:	Epoch: [6][200/204]	Loss 0.3591 (0.3353)	
training:	Epoch: [6][201/204]	Loss 0.3481 (0.3354)	
training:	Epoch: [6][202/204]	Loss 0.3301 (0.3353)	
training:	Epoch: [6][203/204]	Loss 0.5676 (0.3365)	
training:	Epoch: [6][204/204]	Loss 0.3883 (0.3367)	
Training:	 Loss: 0.3362

Training:	 ACC: 0.8837 0.8833 0.8730 0.8945
Validation:	 ACC: 0.8154 0.8149 0.8035 0.8274
Validation:	 Best_BACC: 0.8154 0.8149 0.8035 0.8274
Validation:	 Loss: 0.4001
Pretraining:	Epoch 7/500
----------
training:	Epoch: [7][1/204]	Loss 0.3325 (0.3325)	
training:	Epoch: [7][2/204]	Loss 0.3333 (0.3329)	
training:	Epoch: [7][3/204]	Loss 0.4217 (0.3625)	
training:	Epoch: [7][4/204]	Loss 0.3280 (0.3539)	
training:	Epoch: [7][5/204]	Loss 0.2626 (0.3356)	
training:	Epoch: [7][6/204]	Loss 0.3450 (0.3372)	
training:	Epoch: [7][7/204]	Loss 0.2997 (0.3318)	
training:	Epoch: [7][8/204]	Loss 0.2873 (0.3263)	
training:	Epoch: [7][9/204]	Loss 0.4137 (0.3360)	
training:	Epoch: [7][10/204]	Loss 0.2360 (0.3260)	
training:	Epoch: [7][11/204]	Loss 0.3557 (0.3287)	
training:	Epoch: [7][12/204]	Loss 0.2550 (0.3225)	
training:	Epoch: [7][13/204]	Loss 0.3266 (0.3229)	
training:	Epoch: [7][14/204]	Loss 0.1877 (0.3132)	
training:	Epoch: [7][15/204]	Loss 0.2142 (0.3066)	
training:	Epoch: [7][16/204]	Loss 0.3027 (0.3064)	
training:	Epoch: [7][17/204]	Loss 0.4656 (0.3157)	
training:	Epoch: [7][18/204]	Loss 0.2363 (0.3113)	
training:	Epoch: [7][19/204]	Loss 0.3498 (0.3133)	
training:	Epoch: [7][20/204]	Loss 0.7500 (0.3352)	
training:	Epoch: [7][21/204]	Loss 0.2001 (0.3287)	
training:	Epoch: [7][22/204]	Loss 0.2663 (0.3259)	
training:	Epoch: [7][23/204]	Loss 0.4299 (0.3304)	
training:	Epoch: [7][24/204]	Loss 0.4565 (0.3357)	
training:	Epoch: [7][25/204]	Loss 0.3238 (0.3352)	
training:	Epoch: [7][26/204]	Loss 0.3248 (0.3348)	
training:	Epoch: [7][27/204]	Loss 0.3136 (0.3340)	
training:	Epoch: [7][28/204]	Loss 0.2798 (0.3321)	
training:	Epoch: [7][29/204]	Loss 0.3183 (0.3316)	
training:	Epoch: [7][30/204]	Loss 0.4490 (0.3355)	
training:	Epoch: [7][31/204]	Loss 0.2691 (0.3334)	
training:	Epoch: [7][32/204]	Loss 0.4582 (0.3373)	
training:	Epoch: [7][33/204]	Loss 0.1909 (0.3328)	
training:	Epoch: [7][34/204]	Loss 0.3818 (0.3343)	
training:	Epoch: [7][35/204]	Loss 0.2729 (0.3325)	
training:	Epoch: [7][36/204]	Loss 0.3334 (0.3326)	
training:	Epoch: [7][37/204]	Loss 0.3577 (0.3332)	
training:	Epoch: [7][38/204]	Loss 0.2981 (0.3323)	
training:	Epoch: [7][39/204]	Loss 0.3597 (0.3330)	
training:	Epoch: [7][40/204]	Loss 0.3266 (0.3328)	
training:	Epoch: [7][41/204]	Loss 0.2394 (0.3306)	
training:	Epoch: [7][42/204]	Loss 0.2747 (0.3292)	
training:	Epoch: [7][43/204]	Loss 0.3520 (0.3298)	
training:	Epoch: [7][44/204]	Loss 0.3368 (0.3299)	
training:	Epoch: [7][45/204]	Loss 0.2162 (0.3274)	
training:	Epoch: [7][46/204]	Loss 0.3289 (0.3274)	
training:	Epoch: [7][47/204]	Loss 0.2597 (0.3260)	
training:	Epoch: [7][48/204]	Loss 0.3304 (0.3261)	
training:	Epoch: [7][49/204]	Loss 0.4041 (0.3277)	
training:	Epoch: [7][50/204]	Loss 0.2941 (0.3270)	
training:	Epoch: [7][51/204]	Loss 0.2719 (0.3259)	
training:	Epoch: [7][52/204]	Loss 0.2669 (0.3248)	
training:	Epoch: [7][53/204]	Loss 0.2769 (0.3239)	
training:	Epoch: [7][54/204]	Loss 0.6150 (0.3293)	
training:	Epoch: [7][55/204]	Loss 0.4944 (0.3323)	
training:	Epoch: [7][56/204]	Loss 0.1867 (0.3297)	
training:	Epoch: [7][57/204]	Loss 0.3109 (0.3294)	
training:	Epoch: [7][58/204]	Loss 0.3007 (0.3289)	
training:	Epoch: [7][59/204]	Loss 0.1905 (0.3265)	
training:	Epoch: [7][60/204]	Loss 0.1674 (0.3239)	
training:	Epoch: [7][61/204]	Loss 0.3821 (0.3248)	
training:	Epoch: [7][62/204]	Loss 0.2427 (0.3235)	
training:	Epoch: [7][63/204]	Loss 0.2843 (0.3229)	
training:	Epoch: [7][64/204]	Loss 0.2521 (0.3218)	
training:	Epoch: [7][65/204]	Loss 0.2719 (0.3210)	
training:	Epoch: [7][66/204]	Loss 0.3803 (0.3219)	
training:	Epoch: [7][67/204]	Loss 0.2135 (0.3203)	
training:	Epoch: [7][68/204]	Loss 0.2358 (0.3190)	
training:	Epoch: [7][69/204]	Loss 0.4059 (0.3203)	
training:	Epoch: [7][70/204]	Loss 0.2984 (0.3200)	
training:	Epoch: [7][71/204]	Loss 0.1667 (0.3178)	
training:	Epoch: [7][72/204]	Loss 0.1908 (0.3161)	
training:	Epoch: [7][73/204]	Loss 0.3317 (0.3163)	
training:	Epoch: [7][74/204]	Loss 0.2490 (0.3154)	
training:	Epoch: [7][75/204]	Loss 0.1348 (0.3130)	
training:	Epoch: [7][76/204]	Loss 0.1633 (0.3110)	
training:	Epoch: [7][77/204]	Loss 0.4111 (0.3123)	
training:	Epoch: [7][78/204]	Loss 0.4302 (0.3138)	
training:	Epoch: [7][79/204]	Loss 0.3003 (0.3136)	
training:	Epoch: [7][80/204]	Loss 0.3479 (0.3141)	
training:	Epoch: [7][81/204]	Loss 0.4297 (0.3155)	
training:	Epoch: [7][82/204]	Loss 0.4071 (0.3166)	
training:	Epoch: [7][83/204]	Loss 0.2592 (0.3159)	
training:	Epoch: [7][84/204]	Loss 0.2228 (0.3148)	
training:	Epoch: [7][85/204]	Loss 0.3793 (0.3156)	
training:	Epoch: [7][86/204]	Loss 0.1837 (0.3140)	
training:	Epoch: [7][87/204]	Loss 0.3073 (0.3139)	
training:	Epoch: [7][88/204]	Loss 0.3522 (0.3144)	
training:	Epoch: [7][89/204]	Loss 0.2990 (0.3142)	
training:	Epoch: [7][90/204]	Loss 0.4725 (0.3160)	
training:	Epoch: [7][91/204]	Loss 0.3190 (0.3160)	
training:	Epoch: [7][92/204]	Loss 0.2102 (0.3149)	
training:	Epoch: [7][93/204]	Loss 0.1565 (0.3131)	
training:	Epoch: [7][94/204]	Loss 0.3981 (0.3141)	
training:	Epoch: [7][95/204]	Loss 0.3269 (0.3142)	
training:	Epoch: [7][96/204]	Loss 0.2737 (0.3138)	
training:	Epoch: [7][97/204]	Loss 0.2449 (0.3131)	
training:	Epoch: [7][98/204]	Loss 0.2879 (0.3128)	
training:	Epoch: [7][99/204]	Loss 0.4435 (0.3141)	
training:	Epoch: [7][100/204]	Loss 0.2040 (0.3130)	
training:	Epoch: [7][101/204]	Loss 0.2266 (0.3122)	
training:	Epoch: [7][102/204]	Loss 0.2210 (0.3113)	
training:	Epoch: [7][103/204]	Loss 0.4891 (0.3130)	
training:	Epoch: [7][104/204]	Loss 0.2840 (0.3127)	
training:	Epoch: [7][105/204]	Loss 0.1458 (0.3111)	
training:	Epoch: [7][106/204]	Loss 0.4239 (0.3122)	
training:	Epoch: [7][107/204]	Loss 0.4096 (0.3131)	
training:	Epoch: [7][108/204]	Loss 0.3050 (0.3130)	
training:	Epoch: [7][109/204]	Loss 0.4274 (0.3141)	
training:	Epoch: [7][110/204]	Loss 0.2176 (0.3132)	
training:	Epoch: [7][111/204]	Loss 0.3222 (0.3133)	
training:	Epoch: [7][112/204]	Loss 0.3323 (0.3134)	
training:	Epoch: [7][113/204]	Loss 0.2826 (0.3132)	
training:	Epoch: [7][114/204]	Loss 0.1796 (0.3120)	
training:	Epoch: [7][115/204]	Loss 0.2881 (0.3118)	
training:	Epoch: [7][116/204]	Loss 0.3620 (0.3122)	
training:	Epoch: [7][117/204]	Loss 0.3430 (0.3125)	
training:	Epoch: [7][118/204]	Loss 0.4376 (0.3136)	
training:	Epoch: [7][119/204]	Loss 0.2466 (0.3130)	
training:	Epoch: [7][120/204]	Loss 0.2376 (0.3124)	
training:	Epoch: [7][121/204]	Loss 0.3921 (0.3130)	
training:	Epoch: [7][122/204]	Loss 0.2230 (0.3123)	
training:	Epoch: [7][123/204]	Loss 0.1921 (0.3113)	
training:	Epoch: [7][124/204]	Loss 0.4121 (0.3121)	
training:	Epoch: [7][125/204]	Loss 0.2441 (0.3116)	
training:	Epoch: [7][126/204]	Loss 0.2549 (0.3111)	
training:	Epoch: [7][127/204]	Loss 0.6439 (0.3137)	
training:	Epoch: [7][128/204]	Loss 0.2678 (0.3134)	
training:	Epoch: [7][129/204]	Loss 0.3320 (0.3135)	
training:	Epoch: [7][130/204]	Loss 0.3641 (0.3139)	
training:	Epoch: [7][131/204]	Loss 0.5249 (0.3155)	
training:	Epoch: [7][132/204]	Loss 0.2391 (0.3150)	
training:	Epoch: [7][133/204]	Loss 0.3974 (0.3156)	
training:	Epoch: [7][134/204]	Loss 0.3308 (0.3157)	
training:	Epoch: [7][135/204]	Loss 0.4944 (0.3170)	
training:	Epoch: [7][136/204]	Loss 0.3056 (0.3169)	
training:	Epoch: [7][137/204]	Loss 0.2349 (0.3163)	
training:	Epoch: [7][138/204]	Loss 0.1714 (0.3153)	
training:	Epoch: [7][139/204]	Loss 0.3177 (0.3153)	
training:	Epoch: [7][140/204]	Loss 0.3690 (0.3157)	
training:	Epoch: [7][141/204]	Loss 0.3359 (0.3158)	
training:	Epoch: [7][142/204]	Loss 0.2897 (0.3156)	
training:	Epoch: [7][143/204]	Loss 0.2061 (0.3149)	
training:	Epoch: [7][144/204]	Loss 0.3029 (0.3148)	
training:	Epoch: [7][145/204]	Loss 0.2757 (0.3145)	
training:	Epoch: [7][146/204]	Loss 0.4024 (0.3151)	
training:	Epoch: [7][147/204]	Loss 0.3884 (0.3156)	
training:	Epoch: [7][148/204]	Loss 0.4088 (0.3162)	
training:	Epoch: [7][149/204]	Loss 0.3290 (0.3163)	
training:	Epoch: [7][150/204]	Loss 0.4633 (0.3173)	
training:	Epoch: [7][151/204]	Loss 0.3542 (0.3176)	
training:	Epoch: [7][152/204]	Loss 0.2748 (0.3173)	
training:	Epoch: [7][153/204]	Loss 0.2155 (0.3166)	
training:	Epoch: [7][154/204]	Loss 0.4480 (0.3175)	
training:	Epoch: [7][155/204]	Loss 0.3325 (0.3176)	
training:	Epoch: [7][156/204]	Loss 0.3046 (0.3175)	
training:	Epoch: [7][157/204]	Loss 0.2764 (0.3172)	
training:	Epoch: [7][158/204]	Loss 0.4005 (0.3177)	
training:	Epoch: [7][159/204]	Loss 0.3167 (0.3177)	
training:	Epoch: [7][160/204]	Loss 0.4519 (0.3186)	
training:	Epoch: [7][161/204]	Loss 0.2632 (0.3182)	
training:	Epoch: [7][162/204]	Loss 0.2954 (0.3181)	
training:	Epoch: [7][163/204]	Loss 0.2381 (0.3176)	
training:	Epoch: [7][164/204]	Loss 0.2284 (0.3171)	
training:	Epoch: [7][165/204]	Loss 0.2138 (0.3164)	
training:	Epoch: [7][166/204]	Loss 0.2269 (0.3159)	
training:	Epoch: [7][167/204]	Loss 0.2719 (0.3156)	
training:	Epoch: [7][168/204]	Loss 0.5110 (0.3168)	
training:	Epoch: [7][169/204]	Loss 0.0959 (0.3155)	
training:	Epoch: [7][170/204]	Loss 0.3988 (0.3160)	
training:	Epoch: [7][171/204]	Loss 0.3159 (0.3160)	
training:	Epoch: [7][172/204]	Loss 0.2808 (0.3158)	
training:	Epoch: [7][173/204]	Loss 0.2581 (0.3154)	
training:	Epoch: [7][174/204]	Loss 0.3707 (0.3158)	
training:	Epoch: [7][175/204]	Loss 0.2646 (0.3155)	
training:	Epoch: [7][176/204]	Loss 0.3576 (0.3157)	
training:	Epoch: [7][177/204]	Loss 0.5040 (0.3168)	
training:	Epoch: [7][178/204]	Loss 0.4361 (0.3174)	
training:	Epoch: [7][179/204]	Loss 0.2087 (0.3168)	
training:	Epoch: [7][180/204]	Loss 0.3846 (0.3172)	
training:	Epoch: [7][181/204]	Loss 0.4012 (0.3177)	
training:	Epoch: [7][182/204]	Loss 0.3331 (0.3178)	
training:	Epoch: [7][183/204]	Loss 0.4402 (0.3184)	
training:	Epoch: [7][184/204]	Loss 0.3574 (0.3186)	
training:	Epoch: [7][185/204]	Loss 0.6081 (0.3202)	
training:	Epoch: [7][186/204]	Loss 0.2807 (0.3200)	
training:	Epoch: [7][187/204]	Loss 0.2349 (0.3195)	
training:	Epoch: [7][188/204]	Loss 0.3997 (0.3200)	
training:	Epoch: [7][189/204]	Loss 0.3605 (0.3202)	
training:	Epoch: [7][190/204]	Loss 0.3084 (0.3201)	
training:	Epoch: [7][191/204]	Loss 0.3900 (0.3205)	
training:	Epoch: [7][192/204]	Loss 0.2628 (0.3202)	
training:	Epoch: [7][193/204]	Loss 0.1490 (0.3193)	
training:	Epoch: [7][194/204]	Loss 0.2560 (0.3190)	
training:	Epoch: [7][195/204]	Loss 0.2414 (0.3186)	
training:	Epoch: [7][196/204]	Loss 0.4273 (0.3191)	
training:	Epoch: [7][197/204]	Loss 0.2907 (0.3190)	
training:	Epoch: [7][198/204]	Loss 0.3535 (0.3191)	
training:	Epoch: [7][199/204]	Loss 0.2028 (0.3186)	
training:	Epoch: [7][200/204]	Loss 0.2988 (0.3185)	
training:	Epoch: [7][201/204]	Loss 0.3444 (0.3186)	
training:	Epoch: [7][202/204]	Loss 0.2797 (0.3184)	
training:	Epoch: [7][203/204]	Loss 0.5151 (0.3194)	
training:	Epoch: [7][204/204]	Loss 0.1727 (0.3187)	
Training:	 Loss: 0.3182

Training:	 ACC: 0.8912 0.8911 0.8898 0.8925
Validation:	 ACC: 0.8175 0.8175 0.8178 0.8173
Validation:	 Best_BACC: 0.8175 0.8175 0.8178 0.8173
Validation:	 Loss: 0.4097
Pretraining:	Epoch 8/500
----------
training:	Epoch: [8][1/204]	Loss 0.1355 (0.1355)	
training:	Epoch: [8][2/204]	Loss 0.2315 (0.1835)	
training:	Epoch: [8][3/204]	Loss 0.4943 (0.2871)	
training:	Epoch: [8][4/204]	Loss 0.2439 (0.2763)	
training:	Epoch: [8][5/204]	Loss 0.2522 (0.2715)	
training:	Epoch: [8][6/204]	Loss 0.3003 (0.2763)	
training:	Epoch: [8][7/204]	Loss 0.2771 (0.2764)	
training:	Epoch: [8][8/204]	Loss 0.3055 (0.2800)	
training:	Epoch: [8][9/204]	Loss 0.2791 (0.2799)	
training:	Epoch: [8][10/204]	Loss 0.2792 (0.2799)	
training:	Epoch: [8][11/204]	Loss 0.2931 (0.2811)	
training:	Epoch: [8][12/204]	Loss 0.2833 (0.2813)	
training:	Epoch: [8][13/204]	Loss 0.2636 (0.2799)	
training:	Epoch: [8][14/204]	Loss 0.2263 (0.2761)	
training:	Epoch: [8][15/204]	Loss 0.2248 (0.2727)	
training:	Epoch: [8][16/204]	Loss 0.3544 (0.2778)	
training:	Epoch: [8][17/204]	Loss 0.3725 (0.2833)	
training:	Epoch: [8][18/204]	Loss 0.4896 (0.2948)	
training:	Epoch: [8][19/204]	Loss 0.3127 (0.2957)	
training:	Epoch: [8][20/204]	Loss 0.3351 (0.2977)	
training:	Epoch: [8][21/204]	Loss 0.3014 (0.2979)	
training:	Epoch: [8][22/204]	Loss 0.1943 (0.2932)	
training:	Epoch: [8][23/204]	Loss 0.4538 (0.3002)	
training:	Epoch: [8][24/204]	Loss 0.3017 (0.3002)	
training:	Epoch: [8][25/204]	Loss 0.3398 (0.3018)	
training:	Epoch: [8][26/204]	Loss 0.4372 (0.3070)	
training:	Epoch: [8][27/204]	Loss 0.2702 (0.3057)	
training:	Epoch: [8][28/204]	Loss 0.2778 (0.3047)	
training:	Epoch: [8][29/204]	Loss 0.3238 (0.3053)	
training:	Epoch: [8][30/204]	Loss 0.6525 (0.3169)	
training:	Epoch: [8][31/204]	Loss 0.1909 (0.3128)	
training:	Epoch: [8][32/204]	Loss 0.2361 (0.3104)	
training:	Epoch: [8][33/204]	Loss 0.2529 (0.3087)	
training:	Epoch: [8][34/204]	Loss 0.3255 (0.3092)	
training:	Epoch: [8][35/204]	Loss 0.1025 (0.3033)	
training:	Epoch: [8][36/204]	Loss 0.2851 (0.3028)	
training:	Epoch: [8][37/204]	Loss 0.3041 (0.3028)	
training:	Epoch: [8][38/204]	Loss 0.2777 (0.3021)	
training:	Epoch: [8][39/204]	Loss 0.4855 (0.3068)	
training:	Epoch: [8][40/204]	Loss 0.3407 (0.3077)	
training:	Epoch: [8][41/204]	Loss 0.2049 (0.3052)	
training:	Epoch: [8][42/204]	Loss 0.2799 (0.3046)	
training:	Epoch: [8][43/204]	Loss 0.2449 (0.3032)	
training:	Epoch: [8][44/204]	Loss 0.2038 (0.3009)	
training:	Epoch: [8][45/204]	Loss 0.1831 (0.2983)	
training:	Epoch: [8][46/204]	Loss 0.2523 (0.2973)	
training:	Epoch: [8][47/204]	Loss 0.4326 (0.3002)	
training:	Epoch: [8][48/204]	Loss 0.1895 (0.2979)	
training:	Epoch: [8][49/204]	Loss 0.2563 (0.2970)	
training:	Epoch: [8][50/204]	Loss 0.2487 (0.2961)	
training:	Epoch: [8][51/204]	Loss 0.3025 (0.2962)	
training:	Epoch: [8][52/204]	Loss 0.4955 (0.3000)	
training:	Epoch: [8][53/204]	Loss 0.3123 (0.3003)	
training:	Epoch: [8][54/204]	Loss 0.2713 (0.2997)	
training:	Epoch: [8][55/204]	Loss 0.3236 (0.3002)	
training:	Epoch: [8][56/204]	Loss 0.3447 (0.3010)	
training:	Epoch: [8][57/204]	Loss 0.5550 (0.3054)	
training:	Epoch: [8][58/204]	Loss 0.3533 (0.3062)	
training:	Epoch: [8][59/204]	Loss 0.3641 (0.3072)	
training:	Epoch: [8][60/204]	Loss 0.2358 (0.3060)	
training:	Epoch: [8][61/204]	Loss 0.3536 (0.3068)	
training:	Epoch: [8][62/204]	Loss 0.4767 (0.3095)	
training:	Epoch: [8][63/204]	Loss 0.2544 (0.3087)	
training:	Epoch: [8][64/204]	Loss 0.3336 (0.3091)	
training:	Epoch: [8][65/204]	Loss 0.3038 (0.3090)	
training:	Epoch: [8][66/204]	Loss 0.1972 (0.3073)	
training:	Epoch: [8][67/204]	Loss 0.1844 (0.3055)	
training:	Epoch: [8][68/204]	Loss 0.4118 (0.3070)	
training:	Epoch: [8][69/204]	Loss 0.3198 (0.3072)	
training:	Epoch: [8][70/204]	Loss 0.2707 (0.3067)	
training:	Epoch: [8][71/204]	Loss 0.2196 (0.3055)	
training:	Epoch: [8][72/204]	Loss 0.4173 (0.3070)	
training:	Epoch: [8][73/204]	Loss 0.3626 (0.3078)	
training:	Epoch: [8][74/204]	Loss 0.2352 (0.3068)	
training:	Epoch: [8][75/204]	Loss 0.5392 (0.3099)	
training:	Epoch: [8][76/204]	Loss 0.2019 (0.3085)	
training:	Epoch: [8][77/204]	Loss 0.3186 (0.3086)	
training:	Epoch: [8][78/204]	Loss 0.2812 (0.3082)	
training:	Epoch: [8][79/204]	Loss 0.3001 (0.3081)	
training:	Epoch: [8][80/204]	Loss 0.1459 (0.3061)	
training:	Epoch: [8][81/204]	Loss 0.2925 (0.3060)	
training:	Epoch: [8][82/204]	Loss 0.1488 (0.3040)	
training:	Epoch: [8][83/204]	Loss 0.2531 (0.3034)	
training:	Epoch: [8][84/204]	Loss 0.3370 (0.3038)	
training:	Epoch: [8][85/204]	Loss 0.3462 (0.3043)	
training:	Epoch: [8][86/204]	Loss 0.2289 (0.3034)	
training:	Epoch: [8][87/204]	Loss 0.1821 (0.3020)	
training:	Epoch: [8][88/204]	Loss 0.1904 (0.3008)	
training:	Epoch: [8][89/204]	Loss 0.2798 (0.3005)	
training:	Epoch: [8][90/204]	Loss 0.3337 (0.3009)	
training:	Epoch: [8][91/204]	Loss 0.2983 (0.3009)	
training:	Epoch: [8][92/204]	Loss 0.3734 (0.3017)	
training:	Epoch: [8][93/204]	Loss 0.2174 (0.3008)	
training:	Epoch: [8][94/204]	Loss 0.1832 (0.2995)	
training:	Epoch: [8][95/204]	Loss 0.3088 (0.2996)	
training:	Epoch: [8][96/204]	Loss 0.4076 (0.3007)	
training:	Epoch: [8][97/204]	Loss 0.3103 (0.3008)	
training:	Epoch: [8][98/204]	Loss 0.2697 (0.3005)	
training:	Epoch: [8][99/204]	Loss 0.2828 (0.3003)	
training:	Epoch: [8][100/204]	Loss 0.2557 (0.2999)	
training:	Epoch: [8][101/204]	Loss 0.2882 (0.2998)	
training:	Epoch: [8][102/204]	Loss 0.4975 (0.3017)	
training:	Epoch: [8][103/204]	Loss 0.4360 (0.3030)	
training:	Epoch: [8][104/204]	Loss 0.2840 (0.3028)	
training:	Epoch: [8][105/204]	Loss 0.3232 (0.3030)	
training:	Epoch: [8][106/204]	Loss 0.3576 (0.3035)	
training:	Epoch: [8][107/204]	Loss 0.3546 (0.3040)	
training:	Epoch: [8][108/204]	Loss 0.1348 (0.3025)	
training:	Epoch: [8][109/204]	Loss 0.3086 (0.3025)	
training:	Epoch: [8][110/204]	Loss 0.1334 (0.3010)	
training:	Epoch: [8][111/204]	Loss 0.2713 (0.3007)	
training:	Epoch: [8][112/204]	Loss 0.5392 (0.3028)	
training:	Epoch: [8][113/204]	Loss 0.2968 (0.3028)	
training:	Epoch: [8][114/204]	Loss 0.2996 (0.3028)	
training:	Epoch: [8][115/204]	Loss 0.3307 (0.3030)	
training:	Epoch: [8][116/204]	Loss 0.3103 (0.3031)	
training:	Epoch: [8][117/204]	Loss 0.3449 (0.3034)	
training:	Epoch: [8][118/204]	Loss 0.3197 (0.3036)	
training:	Epoch: [8][119/204]	Loss 0.2575 (0.3032)	
training:	Epoch: [8][120/204]	Loss 0.4089 (0.3040)	
training:	Epoch: [8][121/204]	Loss 0.2140 (0.3033)	
training:	Epoch: [8][122/204]	Loss 0.4045 (0.3041)	
training:	Epoch: [8][123/204]	Loss 0.1533 (0.3029)	
training:	Epoch: [8][124/204]	Loss 0.3967 (0.3037)	
training:	Epoch: [8][125/204]	Loss 0.1527 (0.3025)	
training:	Epoch: [8][126/204]	Loss 0.2318 (0.3019)	
training:	Epoch: [8][127/204]	Loss 0.5657 (0.3040)	
training:	Epoch: [8][128/204]	Loss 0.4162 (0.3048)	
training:	Epoch: [8][129/204]	Loss 0.2659 (0.3045)	
training:	Epoch: [8][130/204]	Loss 0.4022 (0.3053)	
training:	Epoch: [8][131/204]	Loss 0.3497 (0.3056)	
training:	Epoch: [8][132/204]	Loss 0.3150 (0.3057)	
training:	Epoch: [8][133/204]	Loss 0.2008 (0.3049)	
training:	Epoch: [8][134/204]	Loss 0.2543 (0.3045)	
training:	Epoch: [8][135/204]	Loss 0.2219 (0.3039)	
training:	Epoch: [8][136/204]	Loss 0.5109 (0.3055)	
training:	Epoch: [8][137/204]	Loss 0.4415 (0.3064)	
training:	Epoch: [8][138/204]	Loss 0.2257 (0.3059)	
training:	Epoch: [8][139/204]	Loss 0.2719 (0.3056)	
training:	Epoch: [8][140/204]	Loss 0.2812 (0.3054)	
training:	Epoch: [8][141/204]	Loss 0.4042 (0.3061)	
training:	Epoch: [8][142/204]	Loss 0.3507 (0.3065)	
training:	Epoch: [8][143/204]	Loss 0.2537 (0.3061)	
training:	Epoch: [8][144/204]	Loss 0.4116 (0.3068)	
training:	Epoch: [8][145/204]	Loss 0.4261 (0.3076)	
training:	Epoch: [8][146/204]	Loss 0.2441 (0.3072)	
training:	Epoch: [8][147/204]	Loss 0.3759 (0.3077)	
training:	Epoch: [8][148/204]	Loss 0.2869 (0.3075)	
training:	Epoch: [8][149/204]	Loss 0.3002 (0.3075)	
training:	Epoch: [8][150/204]	Loss 0.2654 (0.3072)	
training:	Epoch: [8][151/204]	Loss 0.2366 (0.3067)	
training:	Epoch: [8][152/204]	Loss 0.2453 (0.3063)	
training:	Epoch: [8][153/204]	Loss 0.3147 (0.3064)	
training:	Epoch: [8][154/204]	Loss 0.2248 (0.3059)	
training:	Epoch: [8][155/204]	Loss 0.2559 (0.3055)	
training:	Epoch: [8][156/204]	Loss 0.2435 (0.3051)	
training:	Epoch: [8][157/204]	Loss 0.2521 (0.3048)	
training:	Epoch: [8][158/204]	Loss 0.4448 (0.3057)	
training:	Epoch: [8][159/204]	Loss 0.2963 (0.3056)	
training:	Epoch: [8][160/204]	Loss 0.4582 (0.3066)	
training:	Epoch: [8][161/204]	Loss 0.6130 (0.3085)	
training:	Epoch: [8][162/204]	Loss 0.2312 (0.3080)	
training:	Epoch: [8][163/204]	Loss 0.2482 (0.3076)	
training:	Epoch: [8][164/204]	Loss 0.3423 (0.3079)	
training:	Epoch: [8][165/204]	Loss 0.2314 (0.3074)	
training:	Epoch: [8][166/204]	Loss 0.3782 (0.3078)	
training:	Epoch: [8][167/204]	Loss 0.2706 (0.3076)	
training:	Epoch: [8][168/204]	Loss 0.2746 (0.3074)	
training:	Epoch: [8][169/204]	Loss 0.3156 (0.3074)	
training:	Epoch: [8][170/204]	Loss 0.1216 (0.3064)	
training:	Epoch: [8][171/204]	Loss 0.2512 (0.3060)	
training:	Epoch: [8][172/204]	Loss 0.2598 (0.3058)	
training:	Epoch: [8][173/204]	Loss 0.3196 (0.3058)	
training:	Epoch: [8][174/204]	Loss 0.2436 (0.3055)	
training:	Epoch: [8][175/204]	Loss 0.3585 (0.3058)	
training:	Epoch: [8][176/204]	Loss 0.3360 (0.3060)	
training:	Epoch: [8][177/204]	Loss 0.4142 (0.3066)	
training:	Epoch: [8][178/204]	Loss 0.2324 (0.3062)	
training:	Epoch: [8][179/204]	Loss 0.2606 (0.3059)	
training:	Epoch: [8][180/204]	Loss 0.5228 (0.3071)	
training:	Epoch: [8][181/204]	Loss 0.1506 (0.3062)	
training:	Epoch: [8][182/204]	Loss 0.4381 (0.3070)	
training:	Epoch: [8][183/204]	Loss 0.2630 (0.3067)	
training:	Epoch: [8][184/204]	Loss 0.2225 (0.3063)	
training:	Epoch: [8][185/204]	Loss 0.3500 (0.3065)	
training:	Epoch: [8][186/204]	Loss 0.1365 (0.3056)	
training:	Epoch: [8][187/204]	Loss 0.3010 (0.3056)	
training:	Epoch: [8][188/204]	Loss 0.1938 (0.3050)	
training:	Epoch: [8][189/204]	Loss 0.2402 (0.3046)	
training:	Epoch: [8][190/204]	Loss 0.4459 (0.3054)	
training:	Epoch: [8][191/204]	Loss 0.3672 (0.3057)	
training:	Epoch: [8][192/204]	Loss 0.1754 (0.3050)	
training:	Epoch: [8][193/204]	Loss 0.3988 (0.3055)	
training:	Epoch: [8][194/204]	Loss 0.3141 (0.3055)	
training:	Epoch: [8][195/204]	Loss 0.3923 (0.3060)	
training:	Epoch: [8][196/204]	Loss 0.1601 (0.3052)	
training:	Epoch: [8][197/204]	Loss 0.2976 (0.3052)	
training:	Epoch: [8][198/204]	Loss 0.2523 (0.3049)	
training:	Epoch: [8][199/204]	Loss 0.1889 (0.3044)	
training:	Epoch: [8][200/204]	Loss 0.2258 (0.3040)	
training:	Epoch: [8][201/204]	Loss 0.2350 (0.3036)	
training:	Epoch: [8][202/204]	Loss 0.2801 (0.3035)	
training:	Epoch: [8][203/204]	Loss 0.3294 (0.3036)	
training:	Epoch: [8][204/204]	Loss 0.3996 (0.3041)	
Training:	 Loss: 0.3036

Training:	 ACC: 0.9005 0.9007 0.9062 0.8948
Validation:	 ACC: 0.8169 0.8175 0.8321 0.8016
Validation:	 Best_BACC: 0.8175 0.8175 0.8178 0.8173
Validation:	 Loss: 0.4204
Pretraining:	Epoch 9/500
----------
training:	Epoch: [9][1/204]	Loss 0.2693 (0.2693)	
training:	Epoch: [9][2/204]	Loss 0.3750 (0.3221)	
training:	Epoch: [9][3/204]	Loss 0.3192 (0.3212)	
training:	Epoch: [9][4/204]	Loss 0.0896 (0.2633)	
training:	Epoch: [9][5/204]	Loss 0.1891 (0.2485)	
training:	Epoch: [9][6/204]	Loss 0.2029 (0.2409)	
training:	Epoch: [9][7/204]	Loss 0.2028 (0.2354)	
training:	Epoch: [9][8/204]	Loss 0.4010 (0.2561)	
training:	Epoch: [9][9/204]	Loss 0.3973 (0.2718)	
training:	Epoch: [9][10/204]	Loss 0.3780 (0.2824)	
training:	Epoch: [9][11/204]	Loss 0.2132 (0.2761)	
training:	Epoch: [9][12/204]	Loss 0.2996 (0.2781)	
training:	Epoch: [9][13/204]	Loss 0.4171 (0.2888)	
training:	Epoch: [9][14/204]	Loss 0.2930 (0.2891)	
training:	Epoch: [9][15/204]	Loss 0.2108 (0.2839)	
training:	Epoch: [9][16/204]	Loss 0.3344 (0.2870)	
training:	Epoch: [9][17/204]	Loss 0.2796 (0.2866)	
training:	Epoch: [9][18/204]	Loss 0.3069 (0.2877)	
training:	Epoch: [9][19/204]	Loss 0.3578 (0.2914)	
training:	Epoch: [9][20/204]	Loss 0.1961 (0.2866)	
training:	Epoch: [9][21/204]	Loss 0.2238 (0.2836)	
training:	Epoch: [9][22/204]	Loss 0.4230 (0.2900)	
training:	Epoch: [9][23/204]	Loss 0.2114 (0.2866)	
training:	Epoch: [9][24/204]	Loss 0.4078 (0.2916)	
training:	Epoch: [9][25/204]	Loss 0.3288 (0.2931)	
training:	Epoch: [9][26/204]	Loss 0.2005 (0.2895)	
training:	Epoch: [9][27/204]	Loss 0.2892 (0.2895)	
training:	Epoch: [9][28/204]	Loss 0.3958 (0.2933)	
training:	Epoch: [9][29/204]	Loss 0.5064 (0.3007)	
training:	Epoch: [9][30/204]	Loss 0.4541 (0.3058)	
training:	Epoch: [9][31/204]	Loss 0.1835 (0.3018)	
training:	Epoch: [9][32/204]	Loss 0.1439 (0.2969)	
training:	Epoch: [9][33/204]	Loss 0.3541 (0.2986)	
training:	Epoch: [9][34/204]	Loss 0.3845 (0.3012)	
training:	Epoch: [9][35/204]	Loss 0.3133 (0.3015)	
training:	Epoch: [9][36/204]	Loss 0.3030 (0.3016)	
training:	Epoch: [9][37/204]	Loss 0.2031 (0.2989)	
training:	Epoch: [9][38/204]	Loss 0.2356 (0.2972)	
training:	Epoch: [9][39/204]	Loss 0.2351 (0.2956)	
training:	Epoch: [9][40/204]	Loss 0.2155 (0.2936)	
training:	Epoch: [9][41/204]	Loss 0.5473 (0.2998)	
training:	Epoch: [9][42/204]	Loss 0.4175 (0.3026)	
training:	Epoch: [9][43/204]	Loss 0.3340 (0.3033)	
training:	Epoch: [9][44/204]	Loss 0.3828 (0.3052)	
training:	Epoch: [9][45/204]	Loss 0.1210 (0.3011)	
training:	Epoch: [9][46/204]	Loss 0.3501 (0.3021)	
training:	Epoch: [9][47/204]	Loss 0.2383 (0.3008)	
training:	Epoch: [9][48/204]	Loss 0.2049 (0.2988)	
training:	Epoch: [9][49/204]	Loss 0.1150 (0.2950)	
training:	Epoch: [9][50/204]	Loss 0.3433 (0.2960)	
training:	Epoch: [9][51/204]	Loss 0.3257 (0.2966)	
training:	Epoch: [9][52/204]	Loss 0.3325 (0.2973)	
training:	Epoch: [9][53/204]	Loss 0.2599 (0.2966)	
training:	Epoch: [9][54/204]	Loss 0.1411 (0.2937)	
training:	Epoch: [9][55/204]	Loss 0.1374 (0.2908)	
training:	Epoch: [9][56/204]	Loss 0.2823 (0.2907)	
training:	Epoch: [9][57/204]	Loss 0.4423 (0.2933)	
training:	Epoch: [9][58/204]	Loss 0.4025 (0.2952)	
training:	Epoch: [9][59/204]	Loss 0.1481 (0.2927)	
training:	Epoch: [9][60/204]	Loss 0.1946 (0.2911)	
training:	Epoch: [9][61/204]	Loss 0.5501 (0.2953)	
training:	Epoch: [9][62/204]	Loss 0.2706 (0.2949)	
training:	Epoch: [9][63/204]	Loss 0.1949 (0.2934)	
training:	Epoch: [9][64/204]	Loss 0.2174 (0.2922)	
training:	Epoch: [9][65/204]	Loss 0.1870 (0.2905)	
training:	Epoch: [9][66/204]	Loss 0.3532 (0.2915)	
training:	Epoch: [9][67/204]	Loss 0.2625 (0.2911)	
training:	Epoch: [9][68/204]	Loss 0.3975 (0.2926)	
training:	Epoch: [9][69/204]	Loss 0.2258 (0.2917)	
training:	Epoch: [9][70/204]	Loss 0.2662 (0.2913)	
training:	Epoch: [9][71/204]	Loss 0.3206 (0.2917)	
training:	Epoch: [9][72/204]	Loss 0.2728 (0.2914)	
training:	Epoch: [9][73/204]	Loss 0.2239 (0.2905)	
training:	Epoch: [9][74/204]	Loss 0.2216 (0.2896)	
training:	Epoch: [9][75/204]	Loss 0.4242 (0.2914)	
training:	Epoch: [9][76/204]	Loss 0.3199 (0.2918)	
training:	Epoch: [9][77/204]	Loss 0.2424 (0.2911)	
training:	Epoch: [9][78/204]	Loss 0.3486 (0.2919)	
training:	Epoch: [9][79/204]	Loss 0.3016 (0.2920)	
training:	Epoch: [9][80/204]	Loss 0.5201 (0.2948)	
training:	Epoch: [9][81/204]	Loss 0.2666 (0.2945)	
training:	Epoch: [9][82/204]	Loss 0.2819 (0.2943)	
training:	Epoch: [9][83/204]	Loss 0.2503 (0.2938)	
training:	Epoch: [9][84/204]	Loss 0.2969 (0.2938)	
training:	Epoch: [9][85/204]	Loss 0.2531 (0.2934)	
training:	Epoch: [9][86/204]	Loss 0.3076 (0.2935)	
training:	Epoch: [9][87/204]	Loss 0.4138 (0.2949)	
training:	Epoch: [9][88/204]	Loss 0.2657 (0.2946)	
training:	Epoch: [9][89/204]	Loss 0.3625 (0.2953)	
training:	Epoch: [9][90/204]	Loss 0.2135 (0.2944)	
training:	Epoch: [9][91/204]	Loss 0.2444 (0.2939)	
training:	Epoch: [9][92/204]	Loss 0.1872 (0.2927)	
training:	Epoch: [9][93/204]	Loss 0.1946 (0.2917)	
training:	Epoch: [9][94/204]	Loss 0.3514 (0.2923)	
training:	Epoch: [9][95/204]	Loss 0.1532 (0.2908)	
training:	Epoch: [9][96/204]	Loss 0.2356 (0.2903)	
training:	Epoch: [9][97/204]	Loss 0.2172 (0.2895)	
training:	Epoch: [9][98/204]	Loss 0.2471 (0.2891)	
training:	Epoch: [9][99/204]	Loss 0.3860 (0.2901)	
training:	Epoch: [9][100/204]	Loss 0.1401 (0.2886)	
training:	Epoch: [9][101/204]	Loss 0.2739 (0.2884)	
training:	Epoch: [9][102/204]	Loss 0.4199 (0.2897)	
training:	Epoch: [9][103/204]	Loss 0.3082 (0.2899)	
training:	Epoch: [9][104/204]	Loss 0.1935 (0.2890)	
training:	Epoch: [9][105/204]	Loss 0.1793 (0.2879)	
training:	Epoch: [9][106/204]	Loss 0.2106 (0.2872)	
training:	Epoch: [9][107/204]	Loss 0.4258 (0.2885)	
training:	Epoch: [9][108/204]	Loss 0.3790 (0.2893)	
training:	Epoch: [9][109/204]	Loss 0.2798 (0.2892)	
training:	Epoch: [9][110/204]	Loss 0.2025 (0.2884)	
training:	Epoch: [9][111/204]	Loss 0.3066 (0.2886)	
training:	Epoch: [9][112/204]	Loss 0.4508 (0.2900)	
training:	Epoch: [9][113/204]	Loss 0.3932 (0.2910)	
training:	Epoch: [9][114/204]	Loss 0.1825 (0.2900)	
training:	Epoch: [9][115/204]	Loss 0.3790 (0.2908)	
training:	Epoch: [9][116/204]	Loss 0.1599 (0.2897)	
training:	Epoch: [9][117/204]	Loss 0.2090 (0.2890)	
training:	Epoch: [9][118/204]	Loss 0.2690 (0.2888)	
training:	Epoch: [9][119/204]	Loss 0.2340 (0.2883)	
training:	Epoch: [9][120/204]	Loss 0.2143 (0.2877)	
training:	Epoch: [9][121/204]	Loss 0.3301 (0.2881)	
training:	Epoch: [9][122/204]	Loss 0.2966 (0.2881)	
training:	Epoch: [9][123/204]	Loss 0.1980 (0.2874)	
training:	Epoch: [9][124/204]	Loss 0.4801 (0.2890)	
training:	Epoch: [9][125/204]	Loss 0.1998 (0.2882)	
training:	Epoch: [9][126/204]	Loss 0.2203 (0.2877)	
training:	Epoch: [9][127/204]	Loss 0.2167 (0.2871)	
training:	Epoch: [9][128/204]	Loss 0.3159 (0.2874)	
training:	Epoch: [9][129/204]	Loss 0.3138 (0.2876)	
training:	Epoch: [9][130/204]	Loss 0.2383 (0.2872)	
training:	Epoch: [9][131/204]	Loss 0.3046 (0.2873)	
training:	Epoch: [9][132/204]	Loss 0.4231 (0.2884)	
training:	Epoch: [9][133/204]	Loss 0.3465 (0.2888)	
training:	Epoch: [9][134/204]	Loss 0.1856 (0.2880)	
training:	Epoch: [9][135/204]	Loss 0.2168 (0.2875)	
training:	Epoch: [9][136/204]	Loss 0.2980 (0.2876)	
training:	Epoch: [9][137/204]	Loss 0.3051 (0.2877)	
training:	Epoch: [9][138/204]	Loss 0.2022 (0.2871)	
training:	Epoch: [9][139/204]	Loss 0.2897 (0.2871)	
training:	Epoch: [9][140/204]	Loss 0.2230 (0.2866)	
training:	Epoch: [9][141/204]	Loss 0.4163 (0.2876)	
training:	Epoch: [9][142/204]	Loss 0.4035 (0.2884)	
training:	Epoch: [9][143/204]	Loss 0.2341 (0.2880)	
training:	Epoch: [9][144/204]	Loss 0.5606 (0.2899)	
training:	Epoch: [9][145/204]	Loss 0.2982 (0.2900)	
training:	Epoch: [9][146/204]	Loss 0.3316 (0.2902)	
training:	Epoch: [9][147/204]	Loss 0.3059 (0.2903)	
training:	Epoch: [9][148/204]	Loss 0.2079 (0.2898)	
training:	Epoch: [9][149/204]	Loss 0.0942 (0.2885)	
training:	Epoch: [9][150/204]	Loss 0.5005 (0.2899)	
training:	Epoch: [9][151/204]	Loss 0.4025 (0.2906)	
training:	Epoch: [9][152/204]	Loss 0.3393 (0.2910)	
training:	Epoch: [9][153/204]	Loss 0.2495 (0.2907)	
training:	Epoch: [9][154/204]	Loss 0.4081 (0.2914)	
training:	Epoch: [9][155/204]	Loss 0.2041 (0.2909)	
training:	Epoch: [9][156/204]	Loss 0.3623 (0.2913)	
training:	Epoch: [9][157/204]	Loss 0.3682 (0.2918)	
training:	Epoch: [9][158/204]	Loss 0.2444 (0.2915)	
training:	Epoch: [9][159/204]	Loss 0.1782 (0.2908)	
training:	Epoch: [9][160/204]	Loss 0.2208 (0.2904)	
training:	Epoch: [9][161/204]	Loss 0.3439 (0.2907)	
training:	Epoch: [9][162/204]	Loss 0.4174 (0.2915)	
training:	Epoch: [9][163/204]	Loss 0.2958 (0.2915)	
training:	Epoch: [9][164/204]	Loss 0.3439 (0.2918)	
training:	Epoch: [9][165/204]	Loss 0.1884 (0.2912)	
training:	Epoch: [9][166/204]	Loss 0.3136 (0.2913)	
training:	Epoch: [9][167/204]	Loss 0.4318 (0.2922)	
training:	Epoch: [9][168/204]	Loss 0.2799 (0.2921)	
training:	Epoch: [9][169/204]	Loss 0.3510 (0.2925)	
training:	Epoch: [9][170/204]	Loss 0.2137 (0.2920)	
training:	Epoch: [9][171/204]	Loss 0.3065 (0.2921)	
training:	Epoch: [9][172/204]	Loss 0.2359 (0.2918)	
training:	Epoch: [9][173/204]	Loss 0.1578 (0.2910)	
training:	Epoch: [9][174/204]	Loss 0.2501 (0.2907)	
training:	Epoch: [9][175/204]	Loss 0.2430 (0.2905)	
training:	Epoch: [9][176/204]	Loss 0.2150 (0.2900)	
training:	Epoch: [9][177/204]	Loss 0.1721 (0.2894)	
training:	Epoch: [9][178/204]	Loss 0.2501 (0.2892)	
training:	Epoch: [9][179/204]	Loss 0.2437 (0.2889)	
training:	Epoch: [9][180/204]	Loss 0.2562 (0.2887)	
training:	Epoch: [9][181/204]	Loss 0.1539 (0.2880)	
training:	Epoch: [9][182/204]	Loss 0.4845 (0.2891)	
training:	Epoch: [9][183/204]	Loss 0.4495 (0.2899)	
training:	Epoch: [9][184/204]	Loss 0.2721 (0.2898)	
training:	Epoch: [9][185/204]	Loss 0.1344 (0.2890)	
training:	Epoch: [9][186/204]	Loss 0.3290 (0.2892)	
training:	Epoch: [9][187/204]	Loss 0.3009 (0.2893)	
training:	Epoch: [9][188/204]	Loss 0.2484 (0.2891)	
training:	Epoch: [9][189/204]	Loss 0.3686 (0.2895)	
training:	Epoch: [9][190/204]	Loss 0.1206 (0.2886)	
training:	Epoch: [9][191/204]	Loss 0.1716 (0.2880)	
training:	Epoch: [9][192/204]	Loss 0.1875 (0.2875)	
training:	Epoch: [9][193/204]	Loss 0.2084 (0.2870)	
training:	Epoch: [9][194/204]	Loss 0.5292 (0.2883)	
training:	Epoch: [9][195/204]	Loss 0.5650 (0.2897)	
training:	Epoch: [9][196/204]	Loss 0.2732 (0.2896)	
training:	Epoch: [9][197/204]	Loss 0.2316 (0.2893)	
training:	Epoch: [9][198/204]	Loss 0.3462 (0.2896)	
training:	Epoch: [9][199/204]	Loss 0.1820 (0.2891)	
training:	Epoch: [9][200/204]	Loss 0.3980 (0.2896)	
training:	Epoch: [9][201/204]	Loss 0.2334 (0.2893)	
training:	Epoch: [9][202/204]	Loss 0.4757 (0.2903)	
training:	Epoch: [9][203/204]	Loss 0.3720 (0.2907)	
training:	Epoch: [9][204/204]	Loss 0.3544 (0.2910)	
Training:	 Loss: 0.2905

Training:	 ACC: 0.9055 0.9064 0.9280 0.8830
Validation:	 ACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.4280
Pretraining:	Epoch 10/500
----------
training:	Epoch: [10][1/204]	Loss 0.2690 (0.2690)	
training:	Epoch: [10][2/204]	Loss 0.2508 (0.2599)	
training:	Epoch: [10][3/204]	Loss 0.2293 (0.2497)	
training:	Epoch: [10][4/204]	Loss 0.3593 (0.2771)	
training:	Epoch: [10][5/204]	Loss 0.0741 (0.2365)	
training:	Epoch: [10][6/204]	Loss 0.2426 (0.2375)	
training:	Epoch: [10][7/204]	Loss 0.1907 (0.2308)	
training:	Epoch: [10][8/204]	Loss 0.0982 (0.2142)	
training:	Epoch: [10][9/204]	Loss 0.2523 (0.2185)	
training:	Epoch: [10][10/204]	Loss 0.3174 (0.2284)	
training:	Epoch: [10][11/204]	Loss 0.4655 (0.2499)	
training:	Epoch: [10][12/204]	Loss 0.2676 (0.2514)	
training:	Epoch: [10][13/204]	Loss 0.3905 (0.2621)	
training:	Epoch: [10][14/204]	Loss 0.3756 (0.2702)	
training:	Epoch: [10][15/204]	Loss 0.1242 (0.2605)	
training:	Epoch: [10][16/204]	Loss 0.2027 (0.2568)	
training:	Epoch: [10][17/204]	Loss 0.3358 (0.2615)	
training:	Epoch: [10][18/204]	Loss 0.1594 (0.2558)	
training:	Epoch: [10][19/204]	Loss 0.2556 (0.2558)	
training:	Epoch: [10][20/204]	Loss 0.1781 (0.2519)	
training:	Epoch: [10][21/204]	Loss 0.2582 (0.2522)	
training:	Epoch: [10][22/204]	Loss 0.1791 (0.2489)	
training:	Epoch: [10][23/204]	Loss 0.2908 (0.2507)	
training:	Epoch: [10][24/204]	Loss 0.3460 (0.2547)	
training:	Epoch: [10][25/204]	Loss 0.2831 (0.2558)	
training:	Epoch: [10][26/204]	Loss 0.2521 (0.2557)	
training:	Epoch: [10][27/204]	Loss 0.1731 (0.2526)	
training:	Epoch: [10][28/204]	Loss 0.2035 (0.2509)	
training:	Epoch: [10][29/204]	Loss 0.3765 (0.2552)	
training:	Epoch: [10][30/204]	Loss 0.2081 (0.2536)	
training:	Epoch: [10][31/204]	Loss 0.2206 (0.2526)	
training:	Epoch: [10][32/204]	Loss 0.1092 (0.2481)	
training:	Epoch: [10][33/204]	Loss 0.3378 (0.2508)	
training:	Epoch: [10][34/204]	Loss 0.1851 (0.2489)	
training:	Epoch: [10][35/204]	Loss 0.2242 (0.2482)	
training:	Epoch: [10][36/204]	Loss 0.4725 (0.2544)	
training:	Epoch: [10][37/204]	Loss 0.0944 (0.2501)	
training:	Epoch: [10][38/204]	Loss 0.2637 (0.2504)	
training:	Epoch: [10][39/204]	Loss 0.1624 (0.2482)	
training:	Epoch: [10][40/204]	Loss 0.3066 (0.2496)	
training:	Epoch: [10][41/204]	Loss 0.2244 (0.2490)	
training:	Epoch: [10][42/204]	Loss 0.1882 (0.2476)	
training:	Epoch: [10][43/204]	Loss 0.3164 (0.2492)	
training:	Epoch: [10][44/204]	Loss 0.1670 (0.2473)	
training:	Epoch: [10][45/204]	Loss 0.2261 (0.2468)	
training:	Epoch: [10][46/204]	Loss 0.3449 (0.2490)	
training:	Epoch: [10][47/204]	Loss 0.2393 (0.2488)	
training:	Epoch: [10][48/204]	Loss 0.3351 (0.2506)	
training:	Epoch: [10][49/204]	Loss 0.3975 (0.2536)	
training:	Epoch: [10][50/204]	Loss 0.3255 (0.2550)	
training:	Epoch: [10][51/204]	Loss 0.2930 (0.2557)	
training:	Epoch: [10][52/204]	Loss 0.1144 (0.2530)	
training:	Epoch: [10][53/204]	Loss 0.2712 (0.2534)	
training:	Epoch: [10][54/204]	Loss 0.2271 (0.2529)	
training:	Epoch: [10][55/204]	Loss 0.1630 (0.2512)	
training:	Epoch: [10][56/204]	Loss 0.3206 (0.2525)	
training:	Epoch: [10][57/204]	Loss 0.4585 (0.2561)	
training:	Epoch: [10][58/204]	Loss 0.2879 (0.2566)	
training:	Epoch: [10][59/204]	Loss 0.1284 (0.2545)	
training:	Epoch: [10][60/204]	Loss 0.0945 (0.2518)	
training:	Epoch: [10][61/204]	Loss 0.3753 (0.2538)	
training:	Epoch: [10][62/204]	Loss 0.3241 (0.2550)	
training:	Epoch: [10][63/204]	Loss 0.3706 (0.2568)	
training:	Epoch: [10][64/204]	Loss 0.2962 (0.2574)	
training:	Epoch: [10][65/204]	Loss 0.1970 (0.2565)	
training:	Epoch: [10][66/204]	Loss 0.3486 (0.2579)	
training:	Epoch: [10][67/204]	Loss 0.1337 (0.2560)	
training:	Epoch: [10][68/204]	Loss 0.2740 (0.2563)	
training:	Epoch: [10][69/204]	Loss 0.4671 (0.2593)	
training:	Epoch: [10][70/204]	Loss 0.3599 (0.2608)	
training:	Epoch: [10][71/204]	Loss 0.1951 (0.2599)	
training:	Epoch: [10][72/204]	Loss 0.1118 (0.2578)	
training:	Epoch: [10][73/204]	Loss 0.3512 (0.2591)	
training:	Epoch: [10][74/204]	Loss 0.5304 (0.2627)	
training:	Epoch: [10][75/204]	Loss 0.1756 (0.2616)	
training:	Epoch: [10][76/204]	Loss 0.5693 (0.2656)	
training:	Epoch: [10][77/204]	Loss 0.0672 (0.2631)	
training:	Epoch: [10][78/204]	Loss 0.3960 (0.2648)	
training:	Epoch: [10][79/204]	Loss 0.3815 (0.2662)	
training:	Epoch: [10][80/204]	Loss 0.3772 (0.2676)	
training:	Epoch: [10][81/204]	Loss 0.1330 (0.2660)	
training:	Epoch: [10][82/204]	Loss 0.1257 (0.2643)	
training:	Epoch: [10][83/204]	Loss 0.1431 (0.2628)	
training:	Epoch: [10][84/204]	Loss 0.3136 (0.2634)	
training:	Epoch: [10][85/204]	Loss 0.2676 (0.2635)	
training:	Epoch: [10][86/204]	Loss 0.2623 (0.2634)	
training:	Epoch: [10][87/204]	Loss 0.3984 (0.2650)	
training:	Epoch: [10][88/204]	Loss 0.2935 (0.2653)	
training:	Epoch: [10][89/204]	Loss 0.3326 (0.2661)	
training:	Epoch: [10][90/204]	Loss 0.4770 (0.2684)	
training:	Epoch: [10][91/204]	Loss 0.4080 (0.2699)	
training:	Epoch: [10][92/204]	Loss 0.1563 (0.2687)	
training:	Epoch: [10][93/204]	Loss 0.2228 (0.2682)	
training:	Epoch: [10][94/204]	Loss 0.1604 (0.2671)	
training:	Epoch: [10][95/204]	Loss 0.1374 (0.2657)	
training:	Epoch: [10][96/204]	Loss 0.1678 (0.2647)	
training:	Epoch: [10][97/204]	Loss 0.3248 (0.2653)	
training:	Epoch: [10][98/204]	Loss 0.1169 (0.2638)	
training:	Epoch: [10][99/204]	Loss 0.2679 (0.2638)	
training:	Epoch: [10][100/204]	Loss 0.3186 (0.2644)	
training:	Epoch: [10][101/204]	Loss 0.2616 (0.2644)	
training:	Epoch: [10][102/204]	Loss 0.2231 (0.2639)	
training:	Epoch: [10][103/204]	Loss 0.4732 (0.2660)	
training:	Epoch: [10][104/204]	Loss 0.1749 (0.2651)	
training:	Epoch: [10][105/204]	Loss 0.2548 (0.2650)	
training:	Epoch: [10][106/204]	Loss 0.4440 (0.2667)	
training:	Epoch: [10][107/204]	Loss 0.2576 (0.2666)	
training:	Epoch: [10][108/204]	Loss 0.3451 (0.2673)	
training:	Epoch: [10][109/204]	Loss 0.2508 (0.2672)	
training:	Epoch: [10][110/204]	Loss 0.4626 (0.2690)	
training:	Epoch: [10][111/204]	Loss 0.4265 (0.2704)	
training:	Epoch: [10][112/204]	Loss 0.2704 (0.2704)	
training:	Epoch: [10][113/204]	Loss 0.3832 (0.2714)	
training:	Epoch: [10][114/204]	Loss 0.4743 (0.2732)	
training:	Epoch: [10][115/204]	Loss 0.1885 (0.2724)	
training:	Epoch: [10][116/204]	Loss 0.3449 (0.2730)	
training:	Epoch: [10][117/204]	Loss 0.2877 (0.2732)	
training:	Epoch: [10][118/204]	Loss 0.2568 (0.2730)	
training:	Epoch: [10][119/204]	Loss 0.3149 (0.2734)	
training:	Epoch: [10][120/204]	Loss 0.3969 (0.2744)	
training:	Epoch: [10][121/204]	Loss 0.1782 (0.2736)	
training:	Epoch: [10][122/204]	Loss 0.2099 (0.2731)	
training:	Epoch: [10][123/204]	Loss 0.2793 (0.2731)	
training:	Epoch: [10][124/204]	Loss 0.1642 (0.2723)	
training:	Epoch: [10][125/204]	Loss 0.5219 (0.2743)	
training:	Epoch: [10][126/204]	Loss 0.1228 (0.2731)	
training:	Epoch: [10][127/204]	Loss 0.2140 (0.2726)	
training:	Epoch: [10][128/204]	Loss 0.3191 (0.2730)	
training:	Epoch: [10][129/204]	Loss 0.4399 (0.2743)	
training:	Epoch: [10][130/204]	Loss 0.1053 (0.2730)	
training:	Epoch: [10][131/204]	Loss 0.1088 (0.2717)	
training:	Epoch: [10][132/204]	Loss 0.1401 (0.2707)	
training:	Epoch: [10][133/204]	Loss 0.4273 (0.2719)	
training:	Epoch: [10][134/204]	Loss 0.1928 (0.2713)	
training:	Epoch: [10][135/204]	Loss 0.2238 (0.2709)	
training:	Epoch: [10][136/204]	Loss 0.3070 (0.2712)	
training:	Epoch: [10][137/204]	Loss 0.0837 (0.2698)	
training:	Epoch: [10][138/204]	Loss 0.2851 (0.2700)	
training:	Epoch: [10][139/204]	Loss 0.1832 (0.2693)	
training:	Epoch: [10][140/204]	Loss 0.3087 (0.2696)	
training:	Epoch: [10][141/204]	Loss 0.2492 (0.2695)	
training:	Epoch: [10][142/204]	Loss 0.3274 (0.2699)	
training:	Epoch: [10][143/204]	Loss 0.1850 (0.2693)	
training:	Epoch: [10][144/204]	Loss 0.1639 (0.2685)	
training:	Epoch: [10][145/204]	Loss 0.3026 (0.2688)	
training:	Epoch: [10][146/204]	Loss 0.2946 (0.2690)	
training:	Epoch: [10][147/204]	Loss 0.2808 (0.2690)	
training:	Epoch: [10][148/204]	Loss 0.2084 (0.2686)	
training:	Epoch: [10][149/204]	Loss 0.2446 (0.2685)	
training:	Epoch: [10][150/204]	Loss 0.3558 (0.2691)	
training:	Epoch: [10][151/204]	Loss 0.4569 (0.2703)	
training:	Epoch: [10][152/204]	Loss 0.2801 (0.2704)	
training:	Epoch: [10][153/204]	Loss 0.3326 (0.2708)	
training:	Epoch: [10][154/204]	Loss 0.2716 (0.2708)	
training:	Epoch: [10][155/204]	Loss 0.5509 (0.2726)	
training:	Epoch: [10][156/204]	Loss 0.1417 (0.2717)	
training:	Epoch: [10][157/204]	Loss 0.1641 (0.2711)	
training:	Epoch: [10][158/204]	Loss 0.1171 (0.2701)	
training:	Epoch: [10][159/204]	Loss 0.3282 (0.2704)	
training:	Epoch: [10][160/204]	Loss 0.2405 (0.2703)	
training:	Epoch: [10][161/204]	Loss 0.3247 (0.2706)	
training:	Epoch: [10][162/204]	Loss 0.3848 (0.2713)	
training:	Epoch: [10][163/204]	Loss 0.1391 (0.2705)	
training:	Epoch: [10][164/204]	Loss 0.3540 (0.2710)	
training:	Epoch: [10][165/204]	Loss 0.2474 (0.2709)	
training:	Epoch: [10][166/204]	Loss 0.2396 (0.2707)	
training:	Epoch: [10][167/204]	Loss 0.1840 (0.2702)	
training:	Epoch: [10][168/204]	Loss 0.3781 (0.2708)	
training:	Epoch: [10][169/204]	Loss 0.3102 (0.2710)	
training:	Epoch: [10][170/204]	Loss 0.3474 (0.2715)	
training:	Epoch: [10][171/204]	Loss 0.1445 (0.2707)	
training:	Epoch: [10][172/204]	Loss 0.1756 (0.2702)	
training:	Epoch: [10][173/204]	Loss 0.2462 (0.2700)	
training:	Epoch: [10][174/204]	Loss 0.3358 (0.2704)	
training:	Epoch: [10][175/204]	Loss 0.5016 (0.2717)	
training:	Epoch: [10][176/204]	Loss 0.2635 (0.2717)	
training:	Epoch: [10][177/204]	Loss 0.3722 (0.2723)	
training:	Epoch: [10][178/204]	Loss 0.1706 (0.2717)	
training:	Epoch: [10][179/204]	Loss 0.1638 (0.2711)	
training:	Epoch: [10][180/204]	Loss 0.2057 (0.2707)	
training:	Epoch: [10][181/204]	Loss 0.1636 (0.2701)	
training:	Epoch: [10][182/204]	Loss 0.1119 (0.2693)	
training:	Epoch: [10][183/204]	Loss 0.2923 (0.2694)	
training:	Epoch: [10][184/204]	Loss 0.2559 (0.2693)	
training:	Epoch: [10][185/204]	Loss 0.3580 (0.2698)	
training:	Epoch: [10][186/204]	Loss 0.4170 (0.2706)	
training:	Epoch: [10][187/204]	Loss 0.3655 (0.2711)	
training:	Epoch: [10][188/204]	Loss 0.1840 (0.2706)	
training:	Epoch: [10][189/204]	Loss 0.2036 (0.2703)	
training:	Epoch: [10][190/204]	Loss 0.4505 (0.2712)	
training:	Epoch: [10][191/204]	Loss 0.3921 (0.2719)	
training:	Epoch: [10][192/204]	Loss 0.4518 (0.2728)	
training:	Epoch: [10][193/204]	Loss 0.3735 (0.2733)	
training:	Epoch: [10][194/204]	Loss 0.2190 (0.2730)	
training:	Epoch: [10][195/204]	Loss 0.1197 (0.2722)	
training:	Epoch: [10][196/204]	Loss 0.3894 (0.2728)	
training:	Epoch: [10][197/204]	Loss 0.1626 (0.2723)	
training:	Epoch: [10][198/204]	Loss 0.2051 (0.2719)	
training:	Epoch: [10][199/204]	Loss 0.2040 (0.2716)	
training:	Epoch: [10][200/204]	Loss 0.2079 (0.2713)	
training:	Epoch: [10][201/204]	Loss 0.0980 (0.2704)	
training:	Epoch: [10][202/204]	Loss 0.3039 (0.2706)	
training:	Epoch: [10][203/204]	Loss 0.4370 (0.2714)	
training:	Epoch: [10][204/204]	Loss 0.3082 (0.2716)	
Training:	 Loss: 0.2712

Training:	 ACC: 0.9224 0.9223 0.9192 0.9257
Validation:	 ACC: 0.8155 0.8159 0.8250 0.8061
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.4385
Pretraining:	Epoch 11/500
----------
training:	Epoch: [11][1/204]	Loss 0.2540 (0.2540)	
training:	Epoch: [11][2/204]	Loss 0.2468 (0.2504)	
training:	Epoch: [11][3/204]	Loss 0.3465 (0.2824)	
training:	Epoch: [11][4/204]	Loss 0.2901 (0.2844)	
training:	Epoch: [11][5/204]	Loss 0.1614 (0.2598)	
training:	Epoch: [11][6/204]	Loss 0.1192 (0.2363)	
training:	Epoch: [11][7/204]	Loss 0.2959 (0.2448)	
training:	Epoch: [11][8/204]	Loss 0.2626 (0.2471)	
training:	Epoch: [11][9/204]	Loss 0.3913 (0.2631)	
training:	Epoch: [11][10/204]	Loss 0.1489 (0.2517)	
training:	Epoch: [11][11/204]	Loss 0.5406 (0.2779)	
training:	Epoch: [11][12/204]	Loss 0.2317 (0.2741)	
training:	Epoch: [11][13/204]	Loss 0.2788 (0.2744)	
training:	Epoch: [11][14/204]	Loss 0.2963 (0.2760)	
training:	Epoch: [11][15/204]	Loss 0.2674 (0.2754)	
training:	Epoch: [11][16/204]	Loss 0.2390 (0.2732)	
training:	Epoch: [11][17/204]	Loss 0.1986 (0.2688)	
training:	Epoch: [11][18/204]	Loss 0.3307 (0.2722)	
training:	Epoch: [11][19/204]	Loss 0.1451 (0.2655)	
training:	Epoch: [11][20/204]	Loss 0.2421 (0.2644)	
training:	Epoch: [11][21/204]	Loss 0.2542 (0.2639)	
training:	Epoch: [11][22/204]	Loss 0.4043 (0.2703)	
training:	Epoch: [11][23/204]	Loss 0.1431 (0.2647)	
training:	Epoch: [11][24/204]	Loss 0.1354 (0.2593)	
training:	Epoch: [11][25/204]	Loss 0.2176 (0.2577)	
training:	Epoch: [11][26/204]	Loss 0.1711 (0.2543)	
training:	Epoch: [11][27/204]	Loss 0.3193 (0.2567)	
training:	Epoch: [11][28/204]	Loss 0.1890 (0.2543)	
training:	Epoch: [11][29/204]	Loss 0.4267 (0.2603)	
training:	Epoch: [11][30/204]	Loss 0.2053 (0.2584)	
training:	Epoch: [11][31/204]	Loss 0.2905 (0.2595)	
training:	Epoch: [11][32/204]	Loss 0.1993 (0.2576)	
training:	Epoch: [11][33/204]	Loss 0.2228 (0.2565)	
training:	Epoch: [11][34/204]	Loss 0.3349 (0.2588)	
training:	Epoch: [11][35/204]	Loss 0.1818 (0.2566)	
training:	Epoch: [11][36/204]	Loss 0.1318 (0.2532)	
training:	Epoch: [11][37/204]	Loss 0.0841 (0.2486)	
training:	Epoch: [11][38/204]	Loss 0.1384 (0.2457)	
training:	Epoch: [11][39/204]	Loss 0.2594 (0.2460)	
training:	Epoch: [11][40/204]	Loss 0.2087 (0.2451)	
training:	Epoch: [11][41/204]	Loss 0.4781 (0.2508)	
training:	Epoch: [11][42/204]	Loss 0.0912 (0.2470)	
training:	Epoch: [11][43/204]	Loss 0.2847 (0.2479)	
training:	Epoch: [11][44/204]	Loss 0.3411 (0.2500)	
training:	Epoch: [11][45/204]	Loss 0.2332 (0.2496)	
training:	Epoch: [11][46/204]	Loss 0.2713 (0.2501)	
training:	Epoch: [11][47/204]	Loss 0.2324 (0.2497)	
training:	Epoch: [11][48/204]	Loss 0.2552 (0.2498)	
training:	Epoch: [11][49/204]	Loss 0.1946 (0.2487)	
training:	Epoch: [11][50/204]	Loss 0.2320 (0.2484)	
training:	Epoch: [11][51/204]	Loss 0.3188 (0.2497)	
training:	Epoch: [11][52/204]	Loss 0.1744 (0.2483)	
training:	Epoch: [11][53/204]	Loss 0.1957 (0.2473)	
training:	Epoch: [11][54/204]	Loss 0.2151 (0.2467)	
training:	Epoch: [11][55/204]	Loss 0.1807 (0.2455)	
training:	Epoch: [11][56/204]	Loss 0.2683 (0.2459)	
training:	Epoch: [11][57/204]	Loss 0.2122 (0.2453)	
training:	Epoch: [11][58/204]	Loss 0.3115 (0.2465)	
training:	Epoch: [11][59/204]	Loss 0.2483 (0.2465)	
training:	Epoch: [11][60/204]	Loss 0.0772 (0.2437)	
training:	Epoch: [11][61/204]	Loss 0.3998 (0.2462)	
training:	Epoch: [11][62/204]	Loss 0.2482 (0.2463)	
training:	Epoch: [11][63/204]	Loss 0.4847 (0.2501)	
training:	Epoch: [11][64/204]	Loss 0.2568 (0.2502)	
training:	Epoch: [11][65/204]	Loss 0.0945 (0.2478)	
training:	Epoch: [11][66/204]	Loss 0.3110 (0.2487)	
training:	Epoch: [11][67/204]	Loss 0.0938 (0.2464)	
training:	Epoch: [11][68/204]	Loss 0.2559 (0.2465)	
training:	Epoch: [11][69/204]	Loss 0.2052 (0.2459)	
training:	Epoch: [11][70/204]	Loss 0.2725 (0.2463)	
training:	Epoch: [11][71/204]	Loss 0.3365 (0.2476)	
training:	Epoch: [11][72/204]	Loss 0.1139 (0.2457)	
training:	Epoch: [11][73/204]	Loss 0.1316 (0.2442)	
training:	Epoch: [11][74/204]	Loss 0.4888 (0.2475)	
training:	Epoch: [11][75/204]	Loss 0.4351 (0.2500)	
training:	Epoch: [11][76/204]	Loss 0.3082 (0.2508)	
training:	Epoch: [11][77/204]	Loss 0.2199 (0.2504)	
training:	Epoch: [11][78/204]	Loss 0.2602 (0.2505)	
training:	Epoch: [11][79/204]	Loss 0.3248 (0.2514)	
training:	Epoch: [11][80/204]	Loss 0.1789 (0.2505)	
training:	Epoch: [11][81/204]	Loss 0.3754 (0.2521)	
training:	Epoch: [11][82/204]	Loss 0.2702 (0.2523)	
training:	Epoch: [11][83/204]	Loss 0.2810 (0.2526)	
training:	Epoch: [11][84/204]	Loss 0.1365 (0.2512)	
training:	Epoch: [11][85/204]	Loss 0.3658 (0.2526)	
training:	Epoch: [11][86/204]	Loss 0.3260 (0.2534)	
training:	Epoch: [11][87/204]	Loss 0.1270 (0.2520)	
training:	Epoch: [11][88/204]	Loss 0.2886 (0.2524)	
training:	Epoch: [11][89/204]	Loss 0.2982 (0.2529)	
training:	Epoch: [11][90/204]	Loss 0.3287 (0.2538)	
training:	Epoch: [11][91/204]	Loss 0.2021 (0.2532)	
training:	Epoch: [11][92/204]	Loss 0.2776 (0.2535)	
training:	Epoch: [11][93/204]	Loss 0.1389 (0.2522)	
training:	Epoch: [11][94/204]	Loss 0.2940 (0.2527)	
training:	Epoch: [11][95/204]	Loss 0.0983 (0.2510)	
training:	Epoch: [11][96/204]	Loss 0.4117 (0.2527)	
training:	Epoch: [11][97/204]	Loss 0.2384 (0.2526)	
training:	Epoch: [11][98/204]	Loss 0.3291 (0.2534)	
training:	Epoch: [11][99/204]	Loss 0.3197 (0.2540)	
training:	Epoch: [11][100/204]	Loss 0.3811 (0.2553)	
training:	Epoch: [11][101/204]	Loss 0.2957 (0.2557)	
training:	Epoch: [11][102/204]	Loss 0.1257 (0.2544)	
training:	Epoch: [11][103/204]	Loss 0.1034 (0.2530)	
training:	Epoch: [11][104/204]	Loss 0.2696 (0.2531)	
training:	Epoch: [11][105/204]	Loss 0.0725 (0.2514)	
training:	Epoch: [11][106/204]	Loss 0.1888 (0.2508)	
training:	Epoch: [11][107/204]	Loss 0.1455 (0.2498)	
training:	Epoch: [11][108/204]	Loss 0.2972 (0.2503)	
training:	Epoch: [11][109/204]	Loss 0.1186 (0.2490)	
training:	Epoch: [11][110/204]	Loss 0.2662 (0.2492)	
training:	Epoch: [11][111/204]	Loss 0.2276 (0.2490)	
training:	Epoch: [11][112/204]	Loss 0.2804 (0.2493)	
training:	Epoch: [11][113/204]	Loss 0.1422 (0.2483)	
training:	Epoch: [11][114/204]	Loss 0.1522 (0.2475)	
training:	Epoch: [11][115/204]	Loss 0.2338 (0.2474)	
training:	Epoch: [11][116/204]	Loss 0.2195 (0.2471)	
training:	Epoch: [11][117/204]	Loss 0.4240 (0.2487)	
training:	Epoch: [11][118/204]	Loss 0.1529 (0.2478)	
training:	Epoch: [11][119/204]	Loss 0.3062 (0.2483)	
training:	Epoch: [11][120/204]	Loss 0.2319 (0.2482)	
training:	Epoch: [11][121/204]	Loss 0.3751 (0.2492)	
training:	Epoch: [11][122/204]	Loss 0.2131 (0.2489)	
training:	Epoch: [11][123/204]	Loss 0.4430 (0.2505)	
training:	Epoch: [11][124/204]	Loss 0.3281 (0.2511)	
training:	Epoch: [11][125/204]	Loss 0.3576 (0.2520)	
training:	Epoch: [11][126/204]	Loss 0.0735 (0.2506)	
training:	Epoch: [11][127/204]	Loss 0.1565 (0.2498)	
training:	Epoch: [11][128/204]	Loss 0.4884 (0.2517)	
training:	Epoch: [11][129/204]	Loss 0.2691 (0.2518)	
training:	Epoch: [11][130/204]	Loss 0.2174 (0.2516)	
training:	Epoch: [11][131/204]	Loss 0.1693 (0.2509)	
training:	Epoch: [11][132/204]	Loss 0.2718 (0.2511)	
training:	Epoch: [11][133/204]	Loss 0.1644 (0.2505)	
training:	Epoch: [11][134/204]	Loss 0.1134 (0.2494)	
training:	Epoch: [11][135/204]	Loss 0.4511 (0.2509)	
training:	Epoch: [11][136/204]	Loss 0.4726 (0.2526)	
training:	Epoch: [11][137/204]	Loss 0.2571 (0.2526)	
training:	Epoch: [11][138/204]	Loss 0.4484 (0.2540)	
training:	Epoch: [11][139/204]	Loss 0.2147 (0.2537)	
training:	Epoch: [11][140/204]	Loss 0.3254 (0.2542)	
training:	Epoch: [11][141/204]	Loss 0.3534 (0.2549)	
training:	Epoch: [11][142/204]	Loss 0.1561 (0.2542)	
training:	Epoch: [11][143/204]	Loss 0.4044 (0.2553)	
training:	Epoch: [11][144/204]	Loss 0.2024 (0.2549)	
training:	Epoch: [11][145/204]	Loss 0.1444 (0.2542)	
training:	Epoch: [11][146/204]	Loss 0.1115 (0.2532)	
training:	Epoch: [11][147/204]	Loss 0.1124 (0.2522)	
training:	Epoch: [11][148/204]	Loss 0.3585 (0.2529)	
training:	Epoch: [11][149/204]	Loss 0.2183 (0.2527)	
training:	Epoch: [11][150/204]	Loss 0.3104 (0.2531)	
training:	Epoch: [11][151/204]	Loss 0.2349 (0.2530)	
training:	Epoch: [11][152/204]	Loss 0.1812 (0.2525)	
training:	Epoch: [11][153/204]	Loss 0.2962 (0.2528)	
training:	Epoch: [11][154/204]	Loss 0.1722 (0.2523)	
training:	Epoch: [11][155/204]	Loss 0.1631 (0.2517)	
training:	Epoch: [11][156/204]	Loss 0.1021 (0.2507)	
training:	Epoch: [11][157/204]	Loss 0.1318 (0.2500)	
training:	Epoch: [11][158/204]	Loss 0.3654 (0.2507)	
training:	Epoch: [11][159/204]	Loss 0.2335 (0.2506)	
training:	Epoch: [11][160/204]	Loss 0.2380 (0.2505)	
training:	Epoch: [11][161/204]	Loss 0.3723 (0.2513)	
training:	Epoch: [11][162/204]	Loss 0.0866 (0.2503)	
training:	Epoch: [11][163/204]	Loss 0.2736 (0.2504)	
training:	Epoch: [11][164/204]	Loss 0.3076 (0.2508)	
training:	Epoch: [11][165/204]	Loss 0.1507 (0.2501)	
training:	Epoch: [11][166/204]	Loss 0.2213 (0.2500)	
training:	Epoch: [11][167/204]	Loss 0.5676 (0.2519)	
training:	Epoch: [11][168/204]	Loss 0.2143 (0.2517)	
training:	Epoch: [11][169/204]	Loss 0.4425 (0.2528)	
training:	Epoch: [11][170/204]	Loss 0.3883 (0.2536)	
training:	Epoch: [11][171/204]	Loss 0.3863 (0.2544)	
training:	Epoch: [11][172/204]	Loss 0.2056 (0.2541)	
training:	Epoch: [11][173/204]	Loss 0.4735 (0.2553)	
training:	Epoch: [11][174/204]	Loss 0.1286 (0.2546)	
training:	Epoch: [11][175/204]	Loss 0.2504 (0.2546)	
training:	Epoch: [11][176/204]	Loss 0.2223 (0.2544)	
training:	Epoch: [11][177/204]	Loss 0.2526 (0.2544)	
training:	Epoch: [11][178/204]	Loss 0.1905 (0.2540)	
training:	Epoch: [11][179/204]	Loss 0.2694 (0.2541)	
training:	Epoch: [11][180/204]	Loss 0.2100 (0.2539)	
training:	Epoch: [11][181/204]	Loss 0.1665 (0.2534)	
training:	Epoch: [11][182/204]	Loss 0.2631 (0.2534)	
training:	Epoch: [11][183/204]	Loss 0.2422 (0.2534)	
training:	Epoch: [11][184/204]	Loss 0.2164 (0.2532)	
training:	Epoch: [11][185/204]	Loss 0.2127 (0.2530)	
training:	Epoch: [11][186/204]	Loss 0.3388 (0.2534)	
training:	Epoch: [11][187/204]	Loss 0.2929 (0.2536)	
training:	Epoch: [11][188/204]	Loss 0.2016 (0.2534)	
training:	Epoch: [11][189/204]	Loss 0.2052 (0.2531)	
training:	Epoch: [11][190/204]	Loss 0.2065 (0.2529)	
training:	Epoch: [11][191/204]	Loss 0.1952 (0.2526)	
training:	Epoch: [11][192/204]	Loss 0.1315 (0.2519)	
training:	Epoch: [11][193/204]	Loss 0.3472 (0.2524)	
training:	Epoch: [11][194/204]	Loss 0.3014 (0.2527)	
training:	Epoch: [11][195/204]	Loss 0.1520 (0.2522)	
training:	Epoch: [11][196/204]	Loss 0.2126 (0.2520)	
training:	Epoch: [11][197/204]	Loss 0.1726 (0.2516)	
training:	Epoch: [11][198/204]	Loss 0.3107 (0.2519)	
training:	Epoch: [11][199/204]	Loss 0.3822 (0.2525)	
training:	Epoch: [11][200/204]	Loss 0.1699 (0.2521)	
training:	Epoch: [11][201/204]	Loss 0.4881 (0.2533)	
training:	Epoch: [11][202/204]	Loss 0.2076 (0.2530)	
training:	Epoch: [11][203/204]	Loss 0.1006 (0.2523)	
training:	Epoch: [11][204/204]	Loss 0.2233 (0.2521)	
Training:	 Loss: 0.2518

Training:	 ACC: 0.9337 0.9338 0.9353 0.9321
Validation:	 ACC: 0.8189 0.8197 0.8373 0.8004
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.4579
Pretraining:	Epoch 12/500
----------
training:	Epoch: [12][1/204]	Loss 0.3544 (0.3544)	
training:	Epoch: [12][2/204]	Loss 0.3078 (0.3311)	
training:	Epoch: [12][3/204]	Loss 0.2722 (0.3115)	
training:	Epoch: [12][4/204]	Loss 0.2886 (0.3058)	
training:	Epoch: [12][5/204]	Loss 0.2064 (0.2859)	
training:	Epoch: [12][6/204]	Loss 0.2337 (0.2772)	
training:	Epoch: [12][7/204]	Loss 0.0990 (0.2517)	
training:	Epoch: [12][8/204]	Loss 0.2740 (0.2545)	
training:	Epoch: [12][9/204]	Loss 0.3086 (0.2605)	
training:	Epoch: [12][10/204]	Loss 0.1348 (0.2480)	
training:	Epoch: [12][11/204]	Loss 0.2500 (0.2481)	
training:	Epoch: [12][12/204]	Loss 0.3599 (0.2575)	
training:	Epoch: [12][13/204]	Loss 0.2103 (0.2538)	
training:	Epoch: [12][14/204]	Loss 0.1550 (0.2468)	
training:	Epoch: [12][15/204]	Loss 0.2921 (0.2498)	
training:	Epoch: [12][16/204]	Loss 0.1337 (0.2425)	
training:	Epoch: [12][17/204]	Loss 0.1308 (0.2360)	
training:	Epoch: [12][18/204]	Loss 0.1656 (0.2321)	
training:	Epoch: [12][19/204]	Loss 0.2843 (0.2348)	
training:	Epoch: [12][20/204]	Loss 0.2345 (0.2348)	
training:	Epoch: [12][21/204]	Loss 0.1012 (0.2284)	
training:	Epoch: [12][22/204]	Loss 0.1153 (0.2233)	
training:	Epoch: [12][23/204]	Loss 0.1373 (0.2196)	
training:	Epoch: [12][24/204]	Loss 0.1628 (0.2172)	
training:	Epoch: [12][25/204]	Loss 0.4011 (0.2245)	
training:	Epoch: [12][26/204]	Loss 0.0694 (0.2186)	
training:	Epoch: [12][27/204]	Loss 0.2492 (0.2197)	
training:	Epoch: [12][28/204]	Loss 0.2004 (0.2190)	
training:	Epoch: [12][29/204]	Loss 0.2086 (0.2187)	
training:	Epoch: [12][30/204]	Loss 0.2008 (0.2181)	
training:	Epoch: [12][31/204]	Loss 0.1753 (0.2167)	
training:	Epoch: [12][32/204]	Loss 0.1706 (0.2153)	
training:	Epoch: [12][33/204]	Loss 0.4244 (0.2216)	
training:	Epoch: [12][34/204]	Loss 0.1732 (0.2202)	
training:	Epoch: [12][35/204]	Loss 0.1465 (0.2181)	
training:	Epoch: [12][36/204]	Loss 0.2088 (0.2178)	
training:	Epoch: [12][37/204]	Loss 0.3539 (0.2215)	
training:	Epoch: [12][38/204]	Loss 0.1542 (0.2197)	
training:	Epoch: [12][39/204]	Loss 0.4490 (0.2256)	
training:	Epoch: [12][40/204]	Loss 0.1965 (0.2249)	
training:	Epoch: [12][41/204]	Loss 0.3000 (0.2267)	
training:	Epoch: [12][42/204]	Loss 0.1449 (0.2248)	
training:	Epoch: [12][43/204]	Loss 0.2387 (0.2251)	
training:	Epoch: [12][44/204]	Loss 0.1907 (0.2243)	
training:	Epoch: [12][45/204]	Loss 0.3819 (0.2278)	
training:	Epoch: [12][46/204]	Loss 0.2227 (0.2277)	
training:	Epoch: [12][47/204]	Loss 0.2601 (0.2284)	
training:	Epoch: [12][48/204]	Loss 0.1104 (0.2259)	
training:	Epoch: [12][49/204]	Loss 0.1736 (0.2249)	
training:	Epoch: [12][50/204]	Loss 0.2703 (0.2258)	
training:	Epoch: [12][51/204]	Loss 0.4049 (0.2293)	
training:	Epoch: [12][52/204]	Loss 0.1073 (0.2269)	
training:	Epoch: [12][53/204]	Loss 0.2093 (0.2266)	
training:	Epoch: [12][54/204]	Loss 0.2382 (0.2268)	
training:	Epoch: [12][55/204]	Loss 0.2053 (0.2264)	
training:	Epoch: [12][56/204]	Loss 0.2285 (0.2265)	
training:	Epoch: [12][57/204]	Loss 0.3346 (0.2284)	
training:	Epoch: [12][58/204]	Loss 0.2111 (0.2281)	
training:	Epoch: [12][59/204]	Loss 0.1215 (0.2263)	
training:	Epoch: [12][60/204]	Loss 0.1425 (0.2249)	
training:	Epoch: [12][61/204]	Loss 0.1700 (0.2240)	
training:	Epoch: [12][62/204]	Loss 0.1481 (0.2227)	
training:	Epoch: [12][63/204]	Loss 0.2323 (0.2229)	
training:	Epoch: [12][64/204]	Loss 0.1168 (0.2212)	
training:	Epoch: [12][65/204]	Loss 0.3035 (0.2225)	
training:	Epoch: [12][66/204]	Loss 0.0906 (0.2205)	
training:	Epoch: [12][67/204]	Loss 0.3598 (0.2226)	
training:	Epoch: [12][68/204]	Loss 0.2844 (0.2235)	
training:	Epoch: [12][69/204]	Loss 0.1836 (0.2229)	
training:	Epoch: [12][70/204]	Loss 0.1424 (0.2218)	
training:	Epoch: [12][71/204]	Loss 0.0993 (0.2200)	
training:	Epoch: [12][72/204]	Loss 0.2205 (0.2200)	
training:	Epoch: [12][73/204]	Loss 0.2161 (0.2200)	
training:	Epoch: [12][74/204]	Loss 0.3843 (0.2222)	
training:	Epoch: [12][75/204]	Loss 0.1133 (0.2207)	
training:	Epoch: [12][76/204]	Loss 0.1766 (0.2202)	
training:	Epoch: [12][77/204]	Loss 0.0923 (0.2185)	
training:	Epoch: [12][78/204]	Loss 0.1298 (0.2174)	
training:	Epoch: [12][79/204]	Loss 0.5588 (0.2217)	
training:	Epoch: [12][80/204]	Loss 0.1474 (0.2208)	
training:	Epoch: [12][81/204]	Loss 0.2112 (0.2206)	
training:	Epoch: [12][82/204]	Loss 0.3542 (0.2223)	
training:	Epoch: [12][83/204]	Loss 0.2313 (0.2224)	
training:	Epoch: [12][84/204]	Loss 0.1729 (0.2218)	
training:	Epoch: [12][85/204]	Loss 0.2733 (0.2224)	
training:	Epoch: [12][86/204]	Loss 0.0886 (0.2208)	
training:	Epoch: [12][87/204]	Loss 0.2719 (0.2214)	
training:	Epoch: [12][88/204]	Loss 0.1067 (0.2201)	
training:	Epoch: [12][89/204]	Loss 0.3749 (0.2219)	
training:	Epoch: [12][90/204]	Loss 0.1677 (0.2213)	
training:	Epoch: [12][91/204]	Loss 0.0892 (0.2198)	
training:	Epoch: [12][92/204]	Loss 0.1747 (0.2193)	
training:	Epoch: [12][93/204]	Loss 0.1741 (0.2188)	
training:	Epoch: [12][94/204]	Loss 0.1472 (0.2181)	
training:	Epoch: [12][95/204]	Loss 0.0954 (0.2168)	
training:	Epoch: [12][96/204]	Loss 0.3110 (0.2178)	
training:	Epoch: [12][97/204]	Loss 0.3380 (0.2190)	
training:	Epoch: [12][98/204]	Loss 0.0796 (0.2176)	
training:	Epoch: [12][99/204]	Loss 0.1410 (0.2168)	
training:	Epoch: [12][100/204]	Loss 0.1424 (0.2161)	
training:	Epoch: [12][101/204]	Loss 0.6902 (0.2208)	
training:	Epoch: [12][102/204]	Loss 0.1837 (0.2204)	
training:	Epoch: [12][103/204]	Loss 0.1624 (0.2198)	
training:	Epoch: [12][104/204]	Loss 0.1747 (0.2194)	
training:	Epoch: [12][105/204]	Loss 0.2287 (0.2195)	
training:	Epoch: [12][106/204]	Loss 0.3010 (0.2203)	
training:	Epoch: [12][107/204]	Loss 0.3048 (0.2210)	
training:	Epoch: [12][108/204]	Loss 0.1780 (0.2206)	
training:	Epoch: [12][109/204]	Loss 0.4470 (0.2227)	
training:	Epoch: [12][110/204]	Loss 0.2941 (0.2234)	
training:	Epoch: [12][111/204]	Loss 0.1533 (0.2227)	
training:	Epoch: [12][112/204]	Loss 0.1480 (0.2221)	
training:	Epoch: [12][113/204]	Loss 0.3420 (0.2231)	
training:	Epoch: [12][114/204]	Loss 0.3116 (0.2239)	
training:	Epoch: [12][115/204]	Loss 0.3117 (0.2247)	
training:	Epoch: [12][116/204]	Loss 0.3045 (0.2254)	
training:	Epoch: [12][117/204]	Loss 0.0511 (0.2239)	
training:	Epoch: [12][118/204]	Loss 0.1717 (0.2234)	
training:	Epoch: [12][119/204]	Loss 0.3415 (0.2244)	
training:	Epoch: [12][120/204]	Loss 0.1380 (0.2237)	
training:	Epoch: [12][121/204]	Loss 0.1491 (0.2231)	
training:	Epoch: [12][122/204]	Loss 0.1442 (0.2224)	
training:	Epoch: [12][123/204]	Loss 0.1404 (0.2218)	
training:	Epoch: [12][124/204]	Loss 0.3610 (0.2229)	
training:	Epoch: [12][125/204]	Loss 0.3696 (0.2241)	
training:	Epoch: [12][126/204]	Loss 0.0950 (0.2230)	
training:	Epoch: [12][127/204]	Loss 0.3373 (0.2239)	
training:	Epoch: [12][128/204]	Loss 0.2963 (0.2245)	
training:	Epoch: [12][129/204]	Loss 0.4376 (0.2262)	
training:	Epoch: [12][130/204]	Loss 0.2078 (0.2260)	
training:	Epoch: [12][131/204]	Loss 0.2055 (0.2259)	
training:	Epoch: [12][132/204]	Loss 0.1414 (0.2252)	
training:	Epoch: [12][133/204]	Loss 0.2967 (0.2258)	
training:	Epoch: [12][134/204]	Loss 0.2994 (0.2263)	
training:	Epoch: [12][135/204]	Loss 0.1061 (0.2254)	
training:	Epoch: [12][136/204]	Loss 0.1103 (0.2246)	
training:	Epoch: [12][137/204]	Loss 0.0912 (0.2236)	
training:	Epoch: [12][138/204]	Loss 0.4602 (0.2253)	
training:	Epoch: [12][139/204]	Loss 0.2640 (0.2256)	
training:	Epoch: [12][140/204]	Loss 0.3865 (0.2267)	
training:	Epoch: [12][141/204]	Loss 0.1207 (0.2260)	
training:	Epoch: [12][142/204]	Loss 0.2440 (0.2261)	
training:	Epoch: [12][143/204]	Loss 0.0985 (0.2252)	
training:	Epoch: [12][144/204]	Loss 0.2307 (0.2253)	
training:	Epoch: [12][145/204]	Loss 0.2506 (0.2254)	
training:	Epoch: [12][146/204]	Loss 0.3586 (0.2264)	
training:	Epoch: [12][147/204]	Loss 0.2284 (0.2264)	
training:	Epoch: [12][148/204]	Loss 0.0614 (0.2253)	
training:	Epoch: [12][149/204]	Loss 0.4953 (0.2271)	
training:	Epoch: [12][150/204]	Loss 0.2676 (0.2273)	
training:	Epoch: [12][151/204]	Loss 0.1777 (0.2270)	
training:	Epoch: [12][152/204]	Loss 0.2479 (0.2271)	
training:	Epoch: [12][153/204]	Loss 0.0691 (0.2261)	
training:	Epoch: [12][154/204]	Loss 0.1282 (0.2255)	
training:	Epoch: [12][155/204]	Loss 0.1429 (0.2249)	
training:	Epoch: [12][156/204]	Loss 0.1134 (0.2242)	
training:	Epoch: [12][157/204]	Loss 0.2085 (0.2241)	
training:	Epoch: [12][158/204]	Loss 0.2572 (0.2243)	
training:	Epoch: [12][159/204]	Loss 0.3424 (0.2251)	
training:	Epoch: [12][160/204]	Loss 0.4224 (0.2263)	
training:	Epoch: [12][161/204]	Loss 0.2419 (0.2264)	
training:	Epoch: [12][162/204]	Loss 0.2649 (0.2266)	
training:	Epoch: [12][163/204]	Loss 0.3995 (0.2277)	
training:	Epoch: [12][164/204]	Loss 0.1848 (0.2274)	
training:	Epoch: [12][165/204]	Loss 0.1993 (0.2273)	
training:	Epoch: [12][166/204]	Loss 0.3603 (0.2281)	
training:	Epoch: [12][167/204]	Loss 0.2243 (0.2281)	
training:	Epoch: [12][168/204]	Loss 0.2638 (0.2283)	
training:	Epoch: [12][169/204]	Loss 0.2095 (0.2282)	
training:	Epoch: [12][170/204]	Loss 0.2992 (0.2286)	
training:	Epoch: [12][171/204]	Loss 0.1262 (0.2280)	
training:	Epoch: [12][172/204]	Loss 0.2866 (0.2283)	
training:	Epoch: [12][173/204]	Loss 0.3051 (0.2288)	
training:	Epoch: [12][174/204]	Loss 0.1360 (0.2282)	
training:	Epoch: [12][175/204]	Loss 0.2466 (0.2283)	
training:	Epoch: [12][176/204]	Loss 0.3082 (0.2288)	
training:	Epoch: [12][177/204]	Loss 0.2212 (0.2287)	
training:	Epoch: [12][178/204]	Loss 0.0815 (0.2279)	
training:	Epoch: [12][179/204]	Loss 0.4370 (0.2291)	
training:	Epoch: [12][180/204]	Loss 0.2371 (0.2291)	
training:	Epoch: [12][181/204]	Loss 0.0720 (0.2283)	
training:	Epoch: [12][182/204]	Loss 0.0758 (0.2274)	
training:	Epoch: [12][183/204]	Loss 0.2637 (0.2276)	
training:	Epoch: [12][184/204]	Loss 0.2159 (0.2276)	
training:	Epoch: [12][185/204]	Loss 0.2332 (0.2276)	
training:	Epoch: [12][186/204]	Loss 0.2163 (0.2275)	
training:	Epoch: [12][187/204]	Loss 0.1932 (0.2273)	
training:	Epoch: [12][188/204]	Loss 0.0702 (0.2265)	
training:	Epoch: [12][189/204]	Loss 0.2577 (0.2267)	
training:	Epoch: [12][190/204]	Loss 0.2565 (0.2268)	
training:	Epoch: [12][191/204]	Loss 0.1657 (0.2265)	
training:	Epoch: [12][192/204]	Loss 0.0880 (0.2258)	
training:	Epoch: [12][193/204]	Loss 0.2254 (0.2258)	
training:	Epoch: [12][194/204]	Loss 0.2761 (0.2260)	
training:	Epoch: [12][195/204]	Loss 0.2643 (0.2262)	
training:	Epoch: [12][196/204]	Loss 0.1613 (0.2259)	
training:	Epoch: [12][197/204]	Loss 0.4770 (0.2272)	
training:	Epoch: [12][198/204]	Loss 0.2930 (0.2275)	
training:	Epoch: [12][199/204]	Loss 0.3931 (0.2283)	
training:	Epoch: [12][200/204]	Loss 0.1899 (0.2282)	
training:	Epoch: [12][201/204]	Loss 0.1956 (0.2280)	
training:	Epoch: [12][202/204]	Loss 0.2087 (0.2279)	
training:	Epoch: [12][203/204]	Loss 0.1590 (0.2276)	
training:	Epoch: [12][204/204]	Loss 0.2573 (0.2277)	
Training:	 Loss: 0.2274

Training:	 ACC: 0.9373 0.9361 0.9068 0.9678
Validation:	 ACC: 0.8105 0.8090 0.7769 0.8442
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.4747
Pretraining:	Epoch 13/500
----------
training:	Epoch: [13][1/204]	Loss 0.2864 (0.2864)	
training:	Epoch: [13][2/204]	Loss 0.1493 (0.2179)	
training:	Epoch: [13][3/204]	Loss 0.1863 (0.2073)	
training:	Epoch: [13][4/204]	Loss 0.1381 (0.1900)	
training:	Epoch: [13][5/204]	Loss 0.2605 (0.2041)	
training:	Epoch: [13][6/204]	Loss 0.1313 (0.1920)	
training:	Epoch: [13][7/204]	Loss 0.4401 (0.2274)	
training:	Epoch: [13][8/204]	Loss 0.3322 (0.2405)	
training:	Epoch: [13][9/204]	Loss 0.1620 (0.2318)	
training:	Epoch: [13][10/204]	Loss 0.1379 (0.2224)	
training:	Epoch: [13][11/204]	Loss 0.1403 (0.2149)	
training:	Epoch: [13][12/204]	Loss 0.1733 (0.2115)	
training:	Epoch: [13][13/204]	Loss 0.3117 (0.2192)	
training:	Epoch: [13][14/204]	Loss 0.1793 (0.2163)	
training:	Epoch: [13][15/204]	Loss 0.1607 (0.2126)	
training:	Epoch: [13][16/204]	Loss 0.2788 (0.2168)	
training:	Epoch: [13][17/204]	Loss 0.2573 (0.2191)	
training:	Epoch: [13][18/204]	Loss 0.3253 (0.2250)	
training:	Epoch: [13][19/204]	Loss 0.4112 (0.2348)	
training:	Epoch: [13][20/204]	Loss 0.1858 (0.2324)	
training:	Epoch: [13][21/204]	Loss 0.1465 (0.2283)	
training:	Epoch: [13][22/204]	Loss 0.2894 (0.2311)	
training:	Epoch: [13][23/204]	Loss 0.2162 (0.2304)	
training:	Epoch: [13][24/204]	Loss 0.3477 (0.2353)	
training:	Epoch: [13][25/204]	Loss 0.2275 (0.2350)	
training:	Epoch: [13][26/204]	Loss 0.1953 (0.2335)	
training:	Epoch: [13][27/204]	Loss 0.1335 (0.2298)	
training:	Epoch: [13][28/204]	Loss 0.2464 (0.2304)	
training:	Epoch: [13][29/204]	Loss 0.0990 (0.2258)	
training:	Epoch: [13][30/204]	Loss 0.2927 (0.2281)	
training:	Epoch: [13][31/204]	Loss 0.3152 (0.2309)	
training:	Epoch: [13][32/204]	Loss 0.1854 (0.2295)	
training:	Epoch: [13][33/204]	Loss 0.1877 (0.2282)	
training:	Epoch: [13][34/204]	Loss 0.2807 (0.2297)	
training:	Epoch: [13][35/204]	Loss 0.2456 (0.2302)	
training:	Epoch: [13][36/204]	Loss 0.2162 (0.2298)	
training:	Epoch: [13][37/204]	Loss 0.1137 (0.2267)	
training:	Epoch: [13][38/204]	Loss 0.0785 (0.2228)	
training:	Epoch: [13][39/204]	Loss 0.0808 (0.2191)	
training:	Epoch: [13][40/204]	Loss 0.2126 (0.2190)	
training:	Epoch: [13][41/204]	Loss 0.2034 (0.2186)	
training:	Epoch: [13][42/204]	Loss 0.2483 (0.2193)	
training:	Epoch: [13][43/204]	Loss 0.3444 (0.2222)	
training:	Epoch: [13][44/204]	Loss 0.1372 (0.2203)	
training:	Epoch: [13][45/204]	Loss 0.1855 (0.2195)	
training:	Epoch: [13][46/204]	Loss 0.2729 (0.2206)	
training:	Epoch: [13][47/204]	Loss 0.3131 (0.2226)	
training:	Epoch: [13][48/204]	Loss 0.1408 (0.2209)	
training:	Epoch: [13][49/204]	Loss 0.1291 (0.2190)	
training:	Epoch: [13][50/204]	Loss 0.0736 (0.2161)	
training:	Epoch: [13][51/204]	Loss 0.2455 (0.2167)	
training:	Epoch: [13][52/204]	Loss 0.3051 (0.2184)	
training:	Epoch: [13][53/204]	Loss 0.3335 (0.2206)	
training:	Epoch: [13][54/204]	Loss 0.2128 (0.2204)	
training:	Epoch: [13][55/204]	Loss 0.2121 (0.2203)	
training:	Epoch: [13][56/204]	Loss 0.0683 (0.2176)	
training:	Epoch: [13][57/204]	Loss 0.1532 (0.2164)	
training:	Epoch: [13][58/204]	Loss 0.3675 (0.2190)	
training:	Epoch: [13][59/204]	Loss 0.1848 (0.2185)	
training:	Epoch: [13][60/204]	Loss 0.1396 (0.2171)	
training:	Epoch: [13][61/204]	Loss 0.3595 (0.2195)	
training:	Epoch: [13][62/204]	Loss 0.2800 (0.2205)	
training:	Epoch: [13][63/204]	Loss 0.1618 (0.2195)	
training:	Epoch: [13][64/204]	Loss 0.2189 (0.2195)	
training:	Epoch: [13][65/204]	Loss 0.3516 (0.2215)	
training:	Epoch: [13][66/204]	Loss 0.0906 (0.2196)	
training:	Epoch: [13][67/204]	Loss 0.3323 (0.2212)	
training:	Epoch: [13][68/204]	Loss 0.0850 (0.2192)	
training:	Epoch: [13][69/204]	Loss 0.3112 (0.2206)	
training:	Epoch: [13][70/204]	Loss 0.3866 (0.2229)	
training:	Epoch: [13][71/204]	Loss 0.1891 (0.2225)	
training:	Epoch: [13][72/204]	Loss 0.2318 (0.2226)	
training:	Epoch: [13][73/204]	Loss 0.3325 (0.2241)	
training:	Epoch: [13][74/204]	Loss 0.1312 (0.2229)	
training:	Epoch: [13][75/204]	Loss 0.1932 (0.2225)	
training:	Epoch: [13][76/204]	Loss 0.1099 (0.2210)	
training:	Epoch: [13][77/204]	Loss 0.1612 (0.2202)	
training:	Epoch: [13][78/204]	Loss 0.2893 (0.2211)	
training:	Epoch: [13][79/204]	Loss 0.2634 (0.2216)	
training:	Epoch: [13][80/204]	Loss 0.1743 (0.2210)	
training:	Epoch: [13][81/204]	Loss 0.1792 (0.2205)	
training:	Epoch: [13][82/204]	Loss 0.1910 (0.2202)	
training:	Epoch: [13][83/204]	Loss 0.1854 (0.2197)	
training:	Epoch: [13][84/204]	Loss 0.2177 (0.2197)	
training:	Epoch: [13][85/204]	Loss 0.0720 (0.2180)	
training:	Epoch: [13][86/204]	Loss 0.1088 (0.2167)	
training:	Epoch: [13][87/204]	Loss 0.2870 (0.2175)	
training:	Epoch: [13][88/204]	Loss 0.1591 (0.2168)	
training:	Epoch: [13][89/204]	Loss 0.2222 (0.2169)	
training:	Epoch: [13][90/204]	Loss 0.2196 (0.2169)	
training:	Epoch: [13][91/204]	Loss 0.2747 (0.2176)	
training:	Epoch: [13][92/204]	Loss 0.3200 (0.2187)	
training:	Epoch: [13][93/204]	Loss 0.1870 (0.2183)	
training:	Epoch: [13][94/204]	Loss 0.1226 (0.2173)	
training:	Epoch: [13][95/204]	Loss 0.1809 (0.2169)	
training:	Epoch: [13][96/204]	Loss 0.2285 (0.2171)	
training:	Epoch: [13][97/204]	Loss 0.2172 (0.2171)	
training:	Epoch: [13][98/204]	Loss 0.2522 (0.2174)	
training:	Epoch: [13][99/204]	Loss 0.1107 (0.2163)	
training:	Epoch: [13][100/204]	Loss 0.3559 (0.2177)	
training:	Epoch: [13][101/204]	Loss 0.0819 (0.2164)	
training:	Epoch: [13][102/204]	Loss 0.2559 (0.2168)	
training:	Epoch: [13][103/204]	Loss 0.2321 (0.2169)	
training:	Epoch: [13][104/204]	Loss 0.3692 (0.2184)	
training:	Epoch: [13][105/204]	Loss 0.2417 (0.2186)	
training:	Epoch: [13][106/204]	Loss 0.1874 (0.2183)	
training:	Epoch: [13][107/204]	Loss 0.2085 (0.2182)	
training:	Epoch: [13][108/204]	Loss 0.2712 (0.2187)	
training:	Epoch: [13][109/204]	Loss 0.1733 (0.2183)	
training:	Epoch: [13][110/204]	Loss 0.1120 (0.2173)	
training:	Epoch: [13][111/204]	Loss 0.1455 (0.2167)	
training:	Epoch: [13][112/204]	Loss 0.4435 (0.2187)	
training:	Epoch: [13][113/204]	Loss 0.2019 (0.2186)	
training:	Epoch: [13][114/204]	Loss 0.1290 (0.2178)	
training:	Epoch: [13][115/204]	Loss 0.1388 (0.2171)	
training:	Epoch: [13][116/204]	Loss 0.1751 (0.2167)	
training:	Epoch: [13][117/204]	Loss 0.2172 (0.2167)	
training:	Epoch: [13][118/204]	Loss 0.2155 (0.2167)	
training:	Epoch: [13][119/204]	Loss 0.3020 (0.2174)	
training:	Epoch: [13][120/204]	Loss 0.2431 (0.2177)	
training:	Epoch: [13][121/204]	Loss 0.1466 (0.2171)	
training:	Epoch: [13][122/204]	Loss 0.3427 (0.2181)	
training:	Epoch: [13][123/204]	Loss 0.1091 (0.2172)	
training:	Epoch: [13][124/204]	Loss 0.1353 (0.2166)	
training:	Epoch: [13][125/204]	Loss 0.1787 (0.2163)	
training:	Epoch: [13][126/204]	Loss 0.2114 (0.2162)	
training:	Epoch: [13][127/204]	Loss 0.2076 (0.2161)	
training:	Epoch: [13][128/204]	Loss 0.3548 (0.2172)	
training:	Epoch: [13][129/204]	Loss 0.1781 (0.2169)	
training:	Epoch: [13][130/204]	Loss 0.1324 (0.2163)	
training:	Epoch: [13][131/204]	Loss 0.1180 (0.2155)	
training:	Epoch: [13][132/204]	Loss 0.2205 (0.2156)	
training:	Epoch: [13][133/204]	Loss 0.1703 (0.2152)	
training:	Epoch: [13][134/204]	Loss 0.1992 (0.2151)	
training:	Epoch: [13][135/204]	Loss 0.2334 (0.2152)	
training:	Epoch: [13][136/204]	Loss 0.1090 (0.2145)	
training:	Epoch: [13][137/204]	Loss 0.2737 (0.2149)	
training:	Epoch: [13][138/204]	Loss 0.1121 (0.2141)	
training:	Epoch: [13][139/204]	Loss 0.0961 (0.2133)	
training:	Epoch: [13][140/204]	Loss 0.0703 (0.2123)	
training:	Epoch: [13][141/204]	Loss 0.1463 (0.2118)	
training:	Epoch: [13][142/204]	Loss 0.2054 (0.2118)	
training:	Epoch: [13][143/204]	Loss 0.1333 (0.2112)	
training:	Epoch: [13][144/204]	Loss 0.1026 (0.2105)	
training:	Epoch: [13][145/204]	Loss 0.2237 (0.2105)	
training:	Epoch: [13][146/204]	Loss 0.3025 (0.2112)	
training:	Epoch: [13][147/204]	Loss 0.0973 (0.2104)	
training:	Epoch: [13][148/204]	Loss 0.1605 (0.2101)	
training:	Epoch: [13][149/204]	Loss 0.2436 (0.2103)	
training:	Epoch: [13][150/204]	Loss 0.3141 (0.2110)	
training:	Epoch: [13][151/204]	Loss 0.0869 (0.2102)	
training:	Epoch: [13][152/204]	Loss 0.1371 (0.2097)	
training:	Epoch: [13][153/204]	Loss 0.2163 (0.2097)	
training:	Epoch: [13][154/204]	Loss 0.0692 (0.2088)	
training:	Epoch: [13][155/204]	Loss 0.2057 (0.2088)	
training:	Epoch: [13][156/204]	Loss 0.0581 (0.2078)	
training:	Epoch: [13][157/204]	Loss 0.0544 (0.2068)	
training:	Epoch: [13][158/204]	Loss 0.0968 (0.2061)	
training:	Epoch: [13][159/204]	Loss 0.1022 (0.2055)	
training:	Epoch: [13][160/204]	Loss 0.0892 (0.2048)	
training:	Epoch: [13][161/204]	Loss 0.1045 (0.2041)	
training:	Epoch: [13][162/204]	Loss 0.2290 (0.2043)	
training:	Epoch: [13][163/204]	Loss 0.1958 (0.2042)	
training:	Epoch: [13][164/204]	Loss 0.3896 (0.2054)	
training:	Epoch: [13][165/204]	Loss 0.0699 (0.2046)	
training:	Epoch: [13][166/204]	Loss 0.5704 (0.2068)	
training:	Epoch: [13][167/204]	Loss 0.1406 (0.2064)	
training:	Epoch: [13][168/204]	Loss 0.2740 (0.2068)	
training:	Epoch: [13][169/204]	Loss 0.2405 (0.2070)	
training:	Epoch: [13][170/204]	Loss 0.1337 (0.2065)	
training:	Epoch: [13][171/204]	Loss 0.0986 (0.2059)	
training:	Epoch: [13][172/204]	Loss 0.1955 (0.2058)	
training:	Epoch: [13][173/204]	Loss 0.1729 (0.2057)	
training:	Epoch: [13][174/204]	Loss 0.2577 (0.2060)	
training:	Epoch: [13][175/204]	Loss 0.2589 (0.2063)	
training:	Epoch: [13][176/204]	Loss 0.1180 (0.2058)	
training:	Epoch: [13][177/204]	Loss 0.1815 (0.2056)	
training:	Epoch: [13][178/204]	Loss 0.2177 (0.2057)	
training:	Epoch: [13][179/204]	Loss 0.3295 (0.2064)	
training:	Epoch: [13][180/204]	Loss 0.1460 (0.2060)	
training:	Epoch: [13][181/204]	Loss 0.0844 (0.2054)	
training:	Epoch: [13][182/204]	Loss 0.2365 (0.2055)	
training:	Epoch: [13][183/204]	Loss 0.1376 (0.2052)	
training:	Epoch: [13][184/204]	Loss 0.0920 (0.2046)	
training:	Epoch: [13][185/204]	Loss 0.1391 (0.2042)	
training:	Epoch: [13][186/204]	Loss 0.1552 (0.2039)	
training:	Epoch: [13][187/204]	Loss 0.2345 (0.2041)	
training:	Epoch: [13][188/204]	Loss 0.3119 (0.2047)	
training:	Epoch: [13][189/204]	Loss 0.0613 (0.2039)	
training:	Epoch: [13][190/204]	Loss 0.3213 (0.2045)	
training:	Epoch: [13][191/204]	Loss 0.2705 (0.2049)	
training:	Epoch: [13][192/204]	Loss 0.0439 (0.2040)	
training:	Epoch: [13][193/204]	Loss 0.1160 (0.2036)	
training:	Epoch: [13][194/204]	Loss 0.2221 (0.2037)	
training:	Epoch: [13][195/204]	Loss 0.0893 (0.2031)	
training:	Epoch: [13][196/204]	Loss 0.2268 (0.2032)	
training:	Epoch: [13][197/204]	Loss 0.2224 (0.2033)	
training:	Epoch: [13][198/204]	Loss 0.2300 (0.2034)	
training:	Epoch: [13][199/204]	Loss 0.2413 (0.2036)	
training:	Epoch: [13][200/204]	Loss 0.2274 (0.2038)	
training:	Epoch: [13][201/204]	Loss 0.1762 (0.2036)	
training:	Epoch: [13][202/204]	Loss 0.2764 (0.2040)	
training:	Epoch: [13][203/204]	Loss 0.2174 (0.2040)	
training:	Epoch: [13][204/204]	Loss 0.1777 (0.2039)	
Training:	 Loss: 0.2036

Training:	 ACC: 0.9555 0.9553 0.9515 0.9595
Validation:	 ACC: 0.8092 0.8101 0.8291 0.7892
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.5041
Pretraining:	Epoch 14/500
----------
training:	Epoch: [14][1/204]	Loss 0.0536 (0.0536)	
training:	Epoch: [14][2/204]	Loss 0.2152 (0.1344)	
training:	Epoch: [14][3/204]	Loss 0.0522 (0.1070)	
training:	Epoch: [14][4/204]	Loss 0.1782 (0.1248)	
training:	Epoch: [14][5/204]	Loss 0.2224 (0.1443)	
training:	Epoch: [14][6/204]	Loss 0.1778 (0.1499)	
training:	Epoch: [14][7/204]	Loss 0.1905 (0.1557)	
training:	Epoch: [14][8/204]	Loss 0.2846 (0.1718)	
training:	Epoch: [14][9/204]	Loss 0.2031 (0.1753)	
training:	Epoch: [14][10/204]	Loss 0.1285 (0.1706)	
training:	Epoch: [14][11/204]	Loss 0.1378 (0.1676)	
training:	Epoch: [14][12/204]	Loss 0.0829 (0.1606)	
training:	Epoch: [14][13/204]	Loss 0.2785 (0.1696)	
training:	Epoch: [14][14/204]	Loss 0.1121 (0.1655)	
training:	Epoch: [14][15/204]	Loss 0.2733 (0.1727)	
training:	Epoch: [14][16/204]	Loss 0.0809 (0.1670)	
training:	Epoch: [14][17/204]	Loss 0.0481 (0.1600)	
training:	Epoch: [14][18/204]	Loss 0.2611 (0.1656)	
training:	Epoch: [14][19/204]	Loss 0.2021 (0.1675)	
training:	Epoch: [14][20/204]	Loss 0.2915 (0.1737)	
training:	Epoch: [14][21/204]	Loss 0.0843 (0.1695)	
training:	Epoch: [14][22/204]	Loss 0.1544 (0.1688)	
training:	Epoch: [14][23/204]	Loss 0.3193 (0.1753)	
training:	Epoch: [14][24/204]	Loss 0.1148 (0.1728)	
training:	Epoch: [14][25/204]	Loss 0.3377 (0.1794)	
training:	Epoch: [14][26/204]	Loss 0.0509 (0.1744)	
training:	Epoch: [14][27/204]	Loss 0.1982 (0.1753)	
training:	Epoch: [14][28/204]	Loss 0.3129 (0.1802)	
training:	Epoch: [14][29/204]	Loss 0.1202 (0.1782)	
training:	Epoch: [14][30/204]	Loss 0.1624 (0.1776)	
training:	Epoch: [14][31/204]	Loss 0.1850 (0.1779)	
training:	Epoch: [14][32/204]	Loss 0.1337 (0.1765)	
training:	Epoch: [14][33/204]	Loss 0.1773 (0.1765)	
training:	Epoch: [14][34/204]	Loss 0.1581 (0.1760)	
training:	Epoch: [14][35/204]	Loss 0.1130 (0.1742)	
training:	Epoch: [14][36/204]	Loss 0.1337 (0.1731)	
training:	Epoch: [14][37/204]	Loss 0.1085 (0.1713)	
training:	Epoch: [14][38/204]	Loss 0.1242 (0.1701)	
training:	Epoch: [14][39/204]	Loss 0.0746 (0.1676)	
training:	Epoch: [14][40/204]	Loss 0.0955 (0.1658)	
training:	Epoch: [14][41/204]	Loss 0.1035 (0.1643)	
training:	Epoch: [14][42/204]	Loss 0.2726 (0.1669)	
training:	Epoch: [14][43/204]	Loss 0.2190 (0.1681)	
training:	Epoch: [14][44/204]	Loss 0.3014 (0.1711)	
training:	Epoch: [14][45/204]	Loss 0.1974 (0.1717)	
training:	Epoch: [14][46/204]	Loss 0.0598 (0.1693)	
training:	Epoch: [14][47/204]	Loss 0.3618 (0.1734)	
training:	Epoch: [14][48/204]	Loss 0.1234 (0.1723)	
training:	Epoch: [14][49/204]	Loss 0.0623 (0.1701)	
training:	Epoch: [14][50/204]	Loss 0.1755 (0.1702)	
training:	Epoch: [14][51/204]	Loss 0.2055 (0.1709)	
training:	Epoch: [14][52/204]	Loss 0.1697 (0.1709)	
training:	Epoch: [14][53/204]	Loss 0.3135 (0.1736)	
training:	Epoch: [14][54/204]	Loss 0.3083 (0.1761)	
training:	Epoch: [14][55/204]	Loss 0.1122 (0.1749)	
training:	Epoch: [14][56/204]	Loss 0.3748 (0.1785)	
training:	Epoch: [14][57/204]	Loss 0.0500 (0.1762)	
training:	Epoch: [14][58/204]	Loss 0.0440 (0.1739)	
training:	Epoch: [14][59/204]	Loss 0.0912 (0.1725)	
training:	Epoch: [14][60/204]	Loss 0.0704 (0.1708)	
training:	Epoch: [14][61/204]	Loss 0.1948 (0.1712)	
training:	Epoch: [14][62/204]	Loss 0.1840 (0.1714)	
training:	Epoch: [14][63/204]	Loss 0.3421 (0.1741)	
training:	Epoch: [14][64/204]	Loss 0.1851 (0.1743)	
training:	Epoch: [14][65/204]	Loss 0.2588 (0.1756)	
training:	Epoch: [14][66/204]	Loss 0.1353 (0.1750)	
training:	Epoch: [14][67/204]	Loss 0.2054 (0.1754)	
training:	Epoch: [14][68/204]	Loss 0.1151 (0.1746)	
training:	Epoch: [14][69/204]	Loss 0.0708 (0.1731)	
training:	Epoch: [14][70/204]	Loss 0.2099 (0.1736)	
training:	Epoch: [14][71/204]	Loss 0.3775 (0.1765)	
training:	Epoch: [14][72/204]	Loss 0.2047 (0.1768)	
training:	Epoch: [14][73/204]	Loss 0.2853 (0.1783)	
training:	Epoch: [14][74/204]	Loss 0.1720 (0.1782)	
training:	Epoch: [14][75/204]	Loss 0.1104 (0.1773)	
training:	Epoch: [14][76/204]	Loss 0.0868 (0.1761)	
training:	Epoch: [14][77/204]	Loss 0.1576 (0.1759)	
training:	Epoch: [14][78/204]	Loss 0.1144 (0.1751)	
training:	Epoch: [14][79/204]	Loss 0.1760 (0.1751)	
training:	Epoch: [14][80/204]	Loss 0.0974 (0.1742)	
training:	Epoch: [14][81/204]	Loss 0.0610 (0.1728)	
training:	Epoch: [14][82/204]	Loss 0.1472 (0.1724)	
training:	Epoch: [14][83/204]	Loss 0.1283 (0.1719)	
training:	Epoch: [14][84/204]	Loss 0.0538 (0.1705)	
training:	Epoch: [14][85/204]	Loss 0.1315 (0.1701)	
training:	Epoch: [14][86/204]	Loss 0.0604 (0.1688)	
training:	Epoch: [14][87/204]	Loss 0.0531 (0.1674)	
training:	Epoch: [14][88/204]	Loss 0.1184 (0.1669)	
training:	Epoch: [14][89/204]	Loss 0.0808 (0.1659)	
training:	Epoch: [14][90/204]	Loss 0.2000 (0.1663)	
training:	Epoch: [14][91/204]	Loss 0.0968 (0.1655)	
training:	Epoch: [14][92/204]	Loss 0.1987 (0.1659)	
training:	Epoch: [14][93/204]	Loss 0.0474 (0.1646)	
training:	Epoch: [14][94/204]	Loss 0.2062 (0.1651)	
training:	Epoch: [14][95/204]	Loss 0.3324 (0.1668)	
training:	Epoch: [14][96/204]	Loss 0.2693 (0.1679)	
training:	Epoch: [14][97/204]	Loss 0.1758 (0.1680)	
training:	Epoch: [14][98/204]	Loss 0.1895 (0.1682)	
training:	Epoch: [14][99/204]	Loss 0.1462 (0.1680)	
training:	Epoch: [14][100/204]	Loss 0.2127 (0.1684)	
training:	Epoch: [14][101/204]	Loss 0.0840 (0.1676)	
training:	Epoch: [14][102/204]	Loss 0.2753 (0.1686)	
training:	Epoch: [14][103/204]	Loss 0.2368 (0.1693)	
training:	Epoch: [14][104/204]	Loss 0.1490 (0.1691)	
training:	Epoch: [14][105/204]	Loss 0.2394 (0.1698)	
training:	Epoch: [14][106/204]	Loss 0.1353 (0.1695)	
training:	Epoch: [14][107/204]	Loss 0.1281 (0.1691)	
training:	Epoch: [14][108/204]	Loss 0.2238 (0.1696)	
training:	Epoch: [14][109/204]	Loss 0.3387 (0.1711)	
training:	Epoch: [14][110/204]	Loss 0.2631 (0.1720)	
training:	Epoch: [14][111/204]	Loss 0.1846 (0.1721)	
training:	Epoch: [14][112/204]	Loss 0.2272 (0.1726)	
training:	Epoch: [14][113/204]	Loss 0.0941 (0.1719)	
training:	Epoch: [14][114/204]	Loss 0.1515 (0.1717)	
training:	Epoch: [14][115/204]	Loss 0.3239 (0.1730)	
training:	Epoch: [14][116/204]	Loss 0.2530 (0.1737)	
training:	Epoch: [14][117/204]	Loss 0.1425 (0.1734)	
training:	Epoch: [14][118/204]	Loss 0.1663 (0.1734)	
training:	Epoch: [14][119/204]	Loss 0.1333 (0.1730)	
training:	Epoch: [14][120/204]	Loss 0.1048 (0.1725)	
training:	Epoch: [14][121/204]	Loss 0.0605 (0.1715)	
training:	Epoch: [14][122/204]	Loss 0.2765 (0.1724)	
training:	Epoch: [14][123/204]	Loss 0.0694 (0.1716)	
training:	Epoch: [14][124/204]	Loss 0.1303 (0.1712)	
training:	Epoch: [14][125/204]	Loss 0.1828 (0.1713)	
training:	Epoch: [14][126/204]	Loss 0.2336 (0.1718)	
training:	Epoch: [14][127/204]	Loss 0.4131 (0.1737)	
training:	Epoch: [14][128/204]	Loss 0.0835 (0.1730)	
training:	Epoch: [14][129/204]	Loss 0.0825 (0.1723)	
training:	Epoch: [14][130/204]	Loss 0.2213 (0.1727)	
training:	Epoch: [14][131/204]	Loss 0.1097 (0.1722)	
training:	Epoch: [14][132/204]	Loss 0.1351 (0.1719)	
training:	Epoch: [14][133/204]	Loss 0.1033 (0.1714)	
training:	Epoch: [14][134/204]	Loss 0.2202 (0.1718)	
training:	Epoch: [14][135/204]	Loss 0.4028 (0.1735)	
training:	Epoch: [14][136/204]	Loss 0.2293 (0.1739)	
training:	Epoch: [14][137/204]	Loss 0.0885 (0.1733)	
training:	Epoch: [14][138/204]	Loss 0.2251 (0.1737)	
training:	Epoch: [14][139/204]	Loss 0.1436 (0.1734)	
training:	Epoch: [14][140/204]	Loss 0.1481 (0.1733)	
training:	Epoch: [14][141/204]	Loss 0.2023 (0.1735)	
training:	Epoch: [14][142/204]	Loss 0.0446 (0.1726)	
training:	Epoch: [14][143/204]	Loss 0.1734 (0.1726)	
training:	Epoch: [14][144/204]	Loss 0.1060 (0.1721)	
training:	Epoch: [14][145/204]	Loss 0.0941 (0.1716)	
training:	Epoch: [14][146/204]	Loss 0.0782 (0.1709)	
training:	Epoch: [14][147/204]	Loss 0.2025 (0.1711)	
training:	Epoch: [14][148/204]	Loss 0.1087 (0.1707)	
training:	Epoch: [14][149/204]	Loss 0.0891 (0.1702)	
training:	Epoch: [14][150/204]	Loss 0.2035 (0.1704)	
training:	Epoch: [14][151/204]	Loss 0.2684 (0.1710)	
training:	Epoch: [14][152/204]	Loss 0.2638 (0.1717)	
training:	Epoch: [14][153/204]	Loss 0.2096 (0.1719)	
training:	Epoch: [14][154/204]	Loss 0.0873 (0.1714)	
training:	Epoch: [14][155/204]	Loss 0.3411 (0.1724)	
training:	Epoch: [14][156/204]	Loss 0.0914 (0.1719)	
training:	Epoch: [14][157/204]	Loss 0.0398 (0.1711)	
training:	Epoch: [14][158/204]	Loss 0.1782 (0.1711)	
training:	Epoch: [14][159/204]	Loss 0.0728 (0.1705)	
training:	Epoch: [14][160/204]	Loss 0.4005 (0.1719)	
training:	Epoch: [14][161/204]	Loss 0.1631 (0.1719)	
training:	Epoch: [14][162/204]	Loss 0.1874 (0.1720)	
training:	Epoch: [14][163/204]	Loss 0.1882 (0.1721)	
training:	Epoch: [14][164/204]	Loss 0.1592 (0.1720)	
training:	Epoch: [14][165/204]	Loss 0.1028 (0.1716)	
training:	Epoch: [14][166/204]	Loss 0.0608 (0.1709)	
training:	Epoch: [14][167/204]	Loss 0.1314 (0.1707)	
training:	Epoch: [14][168/204]	Loss 0.2183 (0.1710)	
training:	Epoch: [14][169/204]	Loss 0.0645 (0.1703)	
training:	Epoch: [14][170/204]	Loss 0.0679 (0.1697)	
training:	Epoch: [14][171/204]	Loss 0.4824 (0.1716)	
training:	Epoch: [14][172/204]	Loss 0.2456 (0.1720)	
training:	Epoch: [14][173/204]	Loss 0.0833 (0.1715)	
training:	Epoch: [14][174/204]	Loss 0.2275 (0.1718)	
training:	Epoch: [14][175/204]	Loss 0.1361 (0.1716)	
training:	Epoch: [14][176/204]	Loss 0.0939 (0.1712)	
training:	Epoch: [14][177/204]	Loss 0.3433 (0.1721)	
training:	Epoch: [14][178/204]	Loss 0.1853 (0.1722)	
training:	Epoch: [14][179/204]	Loss 0.1237 (0.1719)	
training:	Epoch: [14][180/204]	Loss 0.0612 (0.1713)	
training:	Epoch: [14][181/204]	Loss 0.3338 (0.1722)	
training:	Epoch: [14][182/204]	Loss 0.1515 (0.1721)	
training:	Epoch: [14][183/204]	Loss 0.1678 (0.1721)	
training:	Epoch: [14][184/204]	Loss 0.1634 (0.1720)	
training:	Epoch: [14][185/204]	Loss 0.0541 (0.1714)	
training:	Epoch: [14][186/204]	Loss 0.1118 (0.1711)	
training:	Epoch: [14][187/204]	Loss 0.2816 (0.1717)	
training:	Epoch: [14][188/204]	Loss 0.1780 (0.1717)	
training:	Epoch: [14][189/204]	Loss 0.1754 (0.1717)	
training:	Epoch: [14][190/204]	Loss 0.3939 (0.1729)	
training:	Epoch: [14][191/204]	Loss 0.1646 (0.1728)	
training:	Epoch: [14][192/204]	Loss 0.2111 (0.1730)	
training:	Epoch: [14][193/204]	Loss 0.0863 (0.1726)	
training:	Epoch: [14][194/204]	Loss 0.1150 (0.1723)	
training:	Epoch: [14][195/204]	Loss 0.0975 (0.1719)	
training:	Epoch: [14][196/204]	Loss 0.0892 (0.1715)	
training:	Epoch: [14][197/204]	Loss 0.2219 (0.1717)	
training:	Epoch: [14][198/204]	Loss 0.1018 (0.1714)	
training:	Epoch: [14][199/204]	Loss 0.4618 (0.1729)	
training:	Epoch: [14][200/204]	Loss 0.3208 (0.1736)	
training:	Epoch: [14][201/204]	Loss 0.1678 (0.1736)	
training:	Epoch: [14][202/204]	Loss 0.0906 (0.1732)	
training:	Epoch: [14][203/204]	Loss 0.0711 (0.1727)	
training:	Epoch: [14][204/204]	Loss 0.0935 (0.1723)	
Training:	 Loss: 0.1720

Training:	 ACC: 0.9671 0.9668 0.9600 0.9742
Validation:	 ACC: 0.8051 0.8058 0.8209 0.7892
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.5396
Pretraining:	Epoch 15/500
----------
training:	Epoch: [15][1/204]	Loss 0.0495 (0.0495)	
training:	Epoch: [15][2/204]	Loss 0.1637 (0.1066)	
training:	Epoch: [15][3/204]	Loss 0.0805 (0.0979)	
training:	Epoch: [15][4/204]	Loss 0.0929 (0.0967)	
training:	Epoch: [15][5/204]	Loss 0.1575 (0.1088)	
training:	Epoch: [15][6/204]	Loss 0.0536 (0.0996)	
training:	Epoch: [15][7/204]	Loss 0.1336 (0.1045)	
training:	Epoch: [15][8/204]	Loss 0.1230 (0.1068)	
training:	Epoch: [15][9/204]	Loss 0.0644 (0.1021)	
training:	Epoch: [15][10/204]	Loss 0.0957 (0.1014)	
training:	Epoch: [15][11/204]	Loss 0.0421 (0.0960)	
training:	Epoch: [15][12/204]	Loss 0.3433 (0.1167)	
training:	Epoch: [15][13/204]	Loss 0.1522 (0.1194)	
training:	Epoch: [15][14/204]	Loss 0.2638 (0.1297)	
training:	Epoch: [15][15/204]	Loss 0.1548 (0.1314)	
training:	Epoch: [15][16/204]	Loss 0.1789 (0.1343)	
training:	Epoch: [15][17/204]	Loss 0.2290 (0.1399)	
training:	Epoch: [15][18/204]	Loss 0.2046 (0.1435)	
training:	Epoch: [15][19/204]	Loss 0.1413 (0.1434)	
training:	Epoch: [15][20/204]	Loss 0.2454 (0.1485)	
training:	Epoch: [15][21/204]	Loss 0.1897 (0.1504)	
training:	Epoch: [15][22/204]	Loss 0.2337 (0.1542)	
training:	Epoch: [15][23/204]	Loss 0.0710 (0.1506)	
training:	Epoch: [15][24/204]	Loss 0.0498 (0.1464)	
training:	Epoch: [15][25/204]	Loss 0.2077 (0.1489)	
training:	Epoch: [15][26/204]	Loss 0.1527 (0.1490)	
training:	Epoch: [15][27/204]	Loss 0.1541 (0.1492)	
training:	Epoch: [15][28/204]	Loss 0.1628 (0.1497)	
training:	Epoch: [15][29/204]	Loss 0.0668 (0.1468)	
training:	Epoch: [15][30/204]	Loss 0.0429 (0.1434)	
training:	Epoch: [15][31/204]	Loss 0.1671 (0.1441)	
training:	Epoch: [15][32/204]	Loss 0.0629 (0.1416)	
training:	Epoch: [15][33/204]	Loss 0.2638 (0.1453)	
training:	Epoch: [15][34/204]	Loss 0.0544 (0.1426)	
training:	Epoch: [15][35/204]	Loss 0.1791 (0.1437)	
training:	Epoch: [15][36/204]	Loss 0.3612 (0.1497)	
training:	Epoch: [15][37/204]	Loss 0.0601 (0.1473)	
training:	Epoch: [15][38/204]	Loss 0.2825 (0.1508)	
training:	Epoch: [15][39/204]	Loss 0.2417 (0.1532)	
training:	Epoch: [15][40/204]	Loss 0.2662 (0.1560)	
training:	Epoch: [15][41/204]	Loss 0.2104 (0.1573)	
training:	Epoch: [15][42/204]	Loss 0.0588 (0.1550)	
training:	Epoch: [15][43/204]	Loss 0.2935 (0.1582)	
training:	Epoch: [15][44/204]	Loss 0.1624 (0.1583)	
training:	Epoch: [15][45/204]	Loss 0.0689 (0.1563)	
training:	Epoch: [15][46/204]	Loss 0.1005 (0.1551)	
training:	Epoch: [15][47/204]	Loss 0.1115 (0.1542)	
training:	Epoch: [15][48/204]	Loss 0.3573 (0.1584)	
training:	Epoch: [15][49/204]	Loss 0.0953 (0.1571)	
training:	Epoch: [15][50/204]	Loss 0.1246 (0.1565)	
training:	Epoch: [15][51/204]	Loss 0.3422 (0.1601)	
training:	Epoch: [15][52/204]	Loss 0.0724 (0.1584)	
training:	Epoch: [15][53/204]	Loss 0.0460 (0.1563)	
training:	Epoch: [15][54/204]	Loss 0.1708 (0.1566)	
training:	Epoch: [15][55/204]	Loss 0.0590 (0.1548)	
training:	Epoch: [15][56/204]	Loss 0.1509 (0.1547)	
training:	Epoch: [15][57/204]	Loss 0.1012 (0.1538)	
training:	Epoch: [15][58/204]	Loss 0.0699 (0.1523)	
training:	Epoch: [15][59/204]	Loss 0.0526 (0.1506)	
training:	Epoch: [15][60/204]	Loss 0.2708 (0.1526)	
training:	Epoch: [15][61/204]	Loss 0.2755 (0.1547)	
training:	Epoch: [15][62/204]	Loss 0.2273 (0.1558)	
training:	Epoch: [15][63/204]	Loss 0.0726 (0.1545)	
training:	Epoch: [15][64/204]	Loss 0.0505 (0.1529)	
training:	Epoch: [15][65/204]	Loss 0.0808 (0.1518)	
training:	Epoch: [15][66/204]	Loss 0.0563 (0.1503)	
training:	Epoch: [15][67/204]	Loss 0.0444 (0.1487)	
training:	Epoch: [15][68/204]	Loss 0.0514 (0.1473)	
training:	Epoch: [15][69/204]	Loss 0.1593 (0.1475)	
training:	Epoch: [15][70/204]	Loss 0.0787 (0.1465)	
training:	Epoch: [15][71/204]	Loss 0.0894 (0.1457)	
training:	Epoch: [15][72/204]	Loss 0.2175 (0.1467)	
training:	Epoch: [15][73/204]	Loss 0.2456 (0.1481)	
training:	Epoch: [15][74/204]	Loss 0.1434 (0.1480)	
training:	Epoch: [15][75/204]	Loss 0.1504 (0.1480)	
training:	Epoch: [15][76/204]	Loss 0.0424 (0.1466)	
training:	Epoch: [15][77/204]	Loss 0.0320 (0.1451)	
training:	Epoch: [15][78/204]	Loss 0.0554 (0.1440)	
training:	Epoch: [15][79/204]	Loss 0.2407 (0.1452)	
training:	Epoch: [15][80/204]	Loss 0.0686 (0.1443)	
training:	Epoch: [15][81/204]	Loss 0.1286 (0.1441)	
training:	Epoch: [15][82/204]	Loss 0.0902 (0.1434)	
training:	Epoch: [15][83/204]	Loss 0.2757 (0.1450)	
training:	Epoch: [15][84/204]	Loss 0.0524 (0.1439)	
training:	Epoch: [15][85/204]	Loss 0.0750 (0.1431)	
training:	Epoch: [15][86/204]	Loss 0.0695 (0.1422)	
training:	Epoch: [15][87/204]	Loss 0.0956 (0.1417)	
training:	Epoch: [15][88/204]	Loss 0.3166 (0.1437)	
training:	Epoch: [15][89/204]	Loss 0.0499 (0.1426)	
training:	Epoch: [15][90/204]	Loss 0.0695 (0.1418)	
training:	Epoch: [15][91/204]	Loss 0.0347 (0.1406)	
training:	Epoch: [15][92/204]	Loss 0.0799 (0.1400)	
training:	Epoch: [15][93/204]	Loss 0.1367 (0.1399)	
training:	Epoch: [15][94/204]	Loss 0.1919 (0.1405)	
training:	Epoch: [15][95/204]	Loss 0.1245 (0.1403)	
training:	Epoch: [15][96/204]	Loss 0.2771 (0.1418)	
training:	Epoch: [15][97/204]	Loss 0.2088 (0.1424)	
training:	Epoch: [15][98/204]	Loss 0.0680 (0.1417)	
training:	Epoch: [15][99/204]	Loss 0.1881 (0.1422)	
training:	Epoch: [15][100/204]	Loss 0.1689 (0.1424)	
training:	Epoch: [15][101/204]	Loss 0.0999 (0.1420)	
training:	Epoch: [15][102/204]	Loss 0.1148 (0.1417)	
training:	Epoch: [15][103/204]	Loss 0.1174 (0.1415)	
training:	Epoch: [15][104/204]	Loss 0.0747 (0.1409)	
training:	Epoch: [15][105/204]	Loss 0.0500 (0.1400)	
training:	Epoch: [15][106/204]	Loss 0.2697 (0.1412)	
training:	Epoch: [15][107/204]	Loss 0.1347 (0.1412)	
training:	Epoch: [15][108/204]	Loss 0.0574 (0.1404)	
training:	Epoch: [15][109/204]	Loss 0.2361 (0.1413)	
training:	Epoch: [15][110/204]	Loss 0.2592 (0.1423)	
training:	Epoch: [15][111/204]	Loss 0.2745 (0.1435)	
training:	Epoch: [15][112/204]	Loss 0.1587 (0.1437)	
training:	Epoch: [15][113/204]	Loss 0.0899 (0.1432)	
training:	Epoch: [15][114/204]	Loss 0.2830 (0.1444)	
training:	Epoch: [15][115/204]	Loss 0.0839 (0.1439)	
training:	Epoch: [15][116/204]	Loss 0.3052 (0.1453)	
training:	Epoch: [15][117/204]	Loss 0.1435 (0.1453)	
training:	Epoch: [15][118/204]	Loss 0.0623 (0.1446)	
training:	Epoch: [15][119/204]	Loss 0.2402 (0.1454)	
training:	Epoch: [15][120/204]	Loss 0.0440 (0.1445)	
training:	Epoch: [15][121/204]	Loss 0.0657 (0.1439)	
training:	Epoch: [15][122/204]	Loss 0.2572 (0.1448)	
training:	Epoch: [15][123/204]	Loss 0.3765 (0.1467)	
training:	Epoch: [15][124/204]	Loss 0.0429 (0.1458)	
training:	Epoch: [15][125/204]	Loss 0.2125 (0.1464)	
training:	Epoch: [15][126/204]	Loss 0.0787 (0.1458)	
training:	Epoch: [15][127/204]	Loss 0.1003 (0.1455)	
training:	Epoch: [15][128/204]	Loss 0.0549 (0.1448)	
training:	Epoch: [15][129/204]	Loss 0.1634 (0.1449)	
training:	Epoch: [15][130/204]	Loss 0.1129 (0.1447)	
training:	Epoch: [15][131/204]	Loss 0.0840 (0.1442)	
training:	Epoch: [15][132/204]	Loss 0.2244 (0.1448)	
training:	Epoch: [15][133/204]	Loss 0.0749 (0.1443)	
training:	Epoch: [15][134/204]	Loss 0.1664 (0.1445)	
training:	Epoch: [15][135/204]	Loss 0.0773 (0.1440)	
training:	Epoch: [15][136/204]	Loss 0.2561 (0.1448)	
training:	Epoch: [15][137/204]	Loss 0.0656 (0.1442)	
training:	Epoch: [15][138/204]	Loss 0.1053 (0.1439)	
training:	Epoch: [15][139/204]	Loss 0.1546 (0.1440)	
training:	Epoch: [15][140/204]	Loss 0.2546 (0.1448)	
training:	Epoch: [15][141/204]	Loss 0.1648 (0.1449)	
training:	Epoch: [15][142/204]	Loss 0.3969 (0.1467)	
training:	Epoch: [15][143/204]	Loss 0.1350 (0.1466)	
training:	Epoch: [15][144/204]	Loss 0.0922 (0.1462)	
training:	Epoch: [15][145/204]	Loss 0.1648 (0.1464)	
training:	Epoch: [15][146/204]	Loss 0.2106 (0.1468)	
training:	Epoch: [15][147/204]	Loss 0.2814 (0.1477)	
training:	Epoch: [15][148/204]	Loss 0.0985 (0.1474)	
training:	Epoch: [15][149/204]	Loss 0.0324 (0.1466)	
training:	Epoch: [15][150/204]	Loss 0.2000 (0.1470)	
training:	Epoch: [15][151/204]	Loss 0.0602 (0.1464)	
training:	Epoch: [15][152/204]	Loss 0.1738 (0.1466)	
training:	Epoch: [15][153/204]	Loss 0.0576 (0.1460)	
training:	Epoch: [15][154/204]	Loss 0.0877 (0.1456)	
training:	Epoch: [15][155/204]	Loss 0.1992 (0.1460)	
training:	Epoch: [15][156/204]	Loss 0.1543 (0.1460)	
training:	Epoch: [15][157/204]	Loss 0.1998 (0.1464)	
training:	Epoch: [15][158/204]	Loss 0.2145 (0.1468)	
training:	Epoch: [15][159/204]	Loss 0.1610 (0.1469)	
training:	Epoch: [15][160/204]	Loss 0.0848 (0.1465)	
training:	Epoch: [15][161/204]	Loss 0.0320 (0.1458)	
training:	Epoch: [15][162/204]	Loss 0.1336 (0.1457)	
training:	Epoch: [15][163/204]	Loss 0.1895 (0.1460)	
training:	Epoch: [15][164/204]	Loss 0.0392 (0.1453)	
training:	Epoch: [15][165/204]	Loss 0.1045 (0.1451)	
training:	Epoch: [15][166/204]	Loss 0.0635 (0.1446)	
training:	Epoch: [15][167/204]	Loss 0.1736 (0.1448)	
training:	Epoch: [15][168/204]	Loss 0.4142 (0.1464)	
training:	Epoch: [15][169/204]	Loss 0.1906 (0.1466)	
training:	Epoch: [15][170/204]	Loss 0.1641 (0.1467)	
training:	Epoch: [15][171/204]	Loss 0.0816 (0.1463)	
training:	Epoch: [15][172/204]	Loss 0.0376 (0.1457)	
training:	Epoch: [15][173/204]	Loss 0.1470 (0.1457)	
training:	Epoch: [15][174/204]	Loss 0.1410 (0.1457)	
training:	Epoch: [15][175/204]	Loss 0.2102 (0.1461)	
training:	Epoch: [15][176/204]	Loss 0.1153 (0.1459)	
training:	Epoch: [15][177/204]	Loss 0.2774 (0.1466)	
training:	Epoch: [15][178/204]	Loss 0.0680 (0.1462)	
training:	Epoch: [15][179/204]	Loss 0.2280 (0.1466)	
training:	Epoch: [15][180/204]	Loss 0.0524 (0.1461)	
training:	Epoch: [15][181/204]	Loss 0.1187 (0.1460)	
training:	Epoch: [15][182/204]	Loss 0.0982 (0.1457)	
training:	Epoch: [15][183/204]	Loss 0.2771 (0.1464)	
training:	Epoch: [15][184/204]	Loss 0.0694 (0.1460)	
training:	Epoch: [15][185/204]	Loss 0.2568 (0.1466)	
training:	Epoch: [15][186/204]	Loss 0.1792 (0.1468)	
training:	Epoch: [15][187/204]	Loss 0.3039 (0.1476)	
training:	Epoch: [15][188/204]	Loss 0.1482 (0.1476)	
training:	Epoch: [15][189/204]	Loss 0.1849 (0.1478)	
training:	Epoch: [15][190/204]	Loss 0.1947 (0.1481)	
training:	Epoch: [15][191/204]	Loss 0.1996 (0.1483)	
training:	Epoch: [15][192/204]	Loss 0.1550 (0.1484)	
training:	Epoch: [15][193/204]	Loss 0.0328 (0.1478)	
training:	Epoch: [15][194/204]	Loss 0.0632 (0.1473)	
training:	Epoch: [15][195/204]	Loss 0.0375 (0.1468)	
training:	Epoch: [15][196/204]	Loss 0.1549 (0.1468)	
training:	Epoch: [15][197/204]	Loss 0.3213 (0.1477)	
training:	Epoch: [15][198/204]	Loss 0.1018 (0.1475)	
training:	Epoch: [15][199/204]	Loss 0.1887 (0.1477)	
training:	Epoch: [15][200/204]	Loss 0.3647 (0.1488)	
training:	Epoch: [15][201/204]	Loss 0.1531 (0.1488)	
training:	Epoch: [15][202/204]	Loss 0.3823 (0.1499)	
training:	Epoch: [15][203/204]	Loss 0.0578 (0.1495)	
training:	Epoch: [15][204/204]	Loss 0.1618 (0.1495)	
Training:	 Loss: 0.1493

Training:	 ACC: 0.9756 0.9755 0.9727 0.9786
Validation:	 ACC: 0.7966 0.7978 0.8219 0.7713
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.5800
Pretraining:	Epoch 16/500
----------
training:	Epoch: [16][1/204]	Loss 0.2681 (0.2681)	
training:	Epoch: [16][2/204]	Loss 0.0485 (0.1583)	
training:	Epoch: [16][3/204]	Loss 0.2811 (0.1992)	
training:	Epoch: [16][4/204]	Loss 0.1213 (0.1798)	
training:	Epoch: [16][5/204]	Loss 0.0658 (0.1570)	
training:	Epoch: [16][6/204]	Loss 0.0536 (0.1397)	
training:	Epoch: [16][7/204]	Loss 0.1579 (0.1423)	
training:	Epoch: [16][8/204]	Loss 0.1026 (0.1374)	
training:	Epoch: [16][9/204]	Loss 0.1429 (0.1380)	
training:	Epoch: [16][10/204]	Loss 0.0356 (0.1278)	
training:	Epoch: [16][11/204]	Loss 0.0781 (0.1232)	
training:	Epoch: [16][12/204]	Loss 0.0487 (0.1170)	
training:	Epoch: [16][13/204]	Loss 0.1088 (0.1164)	
training:	Epoch: [16][14/204]	Loss 0.0789 (0.1137)	
training:	Epoch: [16][15/204]	Loss 0.0583 (0.1100)	
training:	Epoch: [16][16/204]	Loss 0.0664 (0.1073)	
training:	Epoch: [16][17/204]	Loss 0.1258 (0.1084)	
training:	Epoch: [16][18/204]	Loss 0.1551 (0.1110)	
training:	Epoch: [16][19/204]	Loss 0.1879 (0.1150)	
training:	Epoch: [16][20/204]	Loss 0.0370 (0.1111)	
training:	Epoch: [16][21/204]	Loss 0.1736 (0.1141)	
training:	Epoch: [16][22/204]	Loss 0.1495 (0.1157)	
training:	Epoch: [16][23/204]	Loss 0.0320 (0.1121)	
training:	Epoch: [16][24/204]	Loss 0.2761 (0.1189)	
training:	Epoch: [16][25/204]	Loss 0.3580 (0.1285)	
training:	Epoch: [16][26/204]	Loss 0.1406 (0.1289)	
training:	Epoch: [16][27/204]	Loss 0.3451 (0.1369)	
training:	Epoch: [16][28/204]	Loss 0.2071 (0.1394)	
training:	Epoch: [16][29/204]	Loss 0.0371 (0.1359)	
training:	Epoch: [16][30/204]	Loss 0.0430 (0.1328)	
training:	Epoch: [16][31/204]	Loss 0.3722 (0.1405)	
training:	Epoch: [16][32/204]	Loss 0.0371 (0.1373)	
training:	Epoch: [16][33/204]	Loss 0.0792 (0.1355)	
training:	Epoch: [16][34/204]	Loss 0.0374 (0.1327)	
training:	Epoch: [16][35/204]	Loss 0.0448 (0.1301)	
training:	Epoch: [16][36/204]	Loss 0.1501 (0.1307)	
training:	Epoch: [16][37/204]	Loss 0.0665 (0.1290)	
training:	Epoch: [16][38/204]	Loss 0.0823 (0.1277)	
training:	Epoch: [16][39/204]	Loss 0.1607 (0.1286)	
training:	Epoch: [16][40/204]	Loss 0.0514 (0.1267)	
training:	Epoch: [16][41/204]	Loss 0.0398 (0.1245)	
training:	Epoch: [16][42/204]	Loss 0.1208 (0.1244)	
training:	Epoch: [16][43/204]	Loss 0.1656 (0.1254)	
training:	Epoch: [16][44/204]	Loss 0.0814 (0.1244)	
training:	Epoch: [16][45/204]	Loss 0.1500 (0.1250)	
training:	Epoch: [16][46/204]	Loss 0.0671 (0.1237)	
training:	Epoch: [16][47/204]	Loss 0.1939 (0.1252)	
training:	Epoch: [16][48/204]	Loss 0.0509 (0.1237)	
training:	Epoch: [16][49/204]	Loss 0.0598 (0.1224)	
training:	Epoch: [16][50/204]	Loss 0.0437 (0.1208)	
training:	Epoch: [16][51/204]	Loss 0.0624 (0.1196)	
training:	Epoch: [16][52/204]	Loss 0.1423 (0.1201)	
training:	Epoch: [16][53/204]	Loss 0.1839 (0.1213)	
training:	Epoch: [16][54/204]	Loss 0.1710 (0.1222)	
training:	Epoch: [16][55/204]	Loss 0.1624 (0.1229)	
training:	Epoch: [16][56/204]	Loss 0.0394 (0.1214)	
training:	Epoch: [16][57/204]	Loss 0.1458 (0.1219)	
training:	Epoch: [16][58/204]	Loss 0.1401 (0.1222)	
training:	Epoch: [16][59/204]	Loss 0.0546 (0.1210)	
training:	Epoch: [16][60/204]	Loss 0.1644 (0.1218)	
training:	Epoch: [16][61/204]	Loss 0.2122 (0.1232)	
training:	Epoch: [16][62/204]	Loss 0.1529 (0.1237)	
training:	Epoch: [16][63/204]	Loss 0.1540 (0.1242)	
training:	Epoch: [16][64/204]	Loss 0.2810 (0.1266)	
training:	Epoch: [16][65/204]	Loss 0.0922 (0.1261)	
training:	Epoch: [16][66/204]	Loss 0.2372 (0.1278)	
training:	Epoch: [16][67/204]	Loss 0.0572 (0.1267)	
training:	Epoch: [16][68/204]	Loss 0.1488 (0.1271)	
training:	Epoch: [16][69/204]	Loss 0.1933 (0.1280)	
training:	Epoch: [16][70/204]	Loss 0.0479 (0.1269)	
training:	Epoch: [16][71/204]	Loss 0.1784 (0.1276)	
training:	Epoch: [16][72/204]	Loss 0.0364 (0.1263)	
training:	Epoch: [16][73/204]	Loss 0.0399 (0.1252)	
training:	Epoch: [16][74/204]	Loss 0.1616 (0.1257)	
training:	Epoch: [16][75/204]	Loss 0.0495 (0.1246)	
training:	Epoch: [16][76/204]	Loss 0.1519 (0.1250)	
training:	Epoch: [16][77/204]	Loss 0.0448 (0.1240)	
training:	Epoch: [16][78/204]	Loss 0.1524 (0.1243)	
training:	Epoch: [16][79/204]	Loss 0.0377 (0.1232)	
training:	Epoch: [16][80/204]	Loss 0.0579 (0.1224)	
training:	Epoch: [16][81/204]	Loss 0.1816 (0.1231)	
training:	Epoch: [16][82/204]	Loss 0.1431 (0.1234)	
training:	Epoch: [16][83/204]	Loss 0.1630 (0.1239)	
training:	Epoch: [16][84/204]	Loss 0.0916 (0.1235)	
training:	Epoch: [16][85/204]	Loss 0.1518 (0.1238)	
training:	Epoch: [16][86/204]	Loss 0.1458 (0.1241)	
training:	Epoch: [16][87/204]	Loss 0.0685 (0.1234)	
training:	Epoch: [16][88/204]	Loss 0.0361 (0.1224)	
training:	Epoch: [16][89/204]	Loss 0.0928 (0.1221)	
training:	Epoch: [16][90/204]	Loss 0.1120 (0.1220)	
training:	Epoch: [16][91/204]	Loss 0.0903 (0.1216)	
training:	Epoch: [16][92/204]	Loss 0.1993 (0.1225)	
training:	Epoch: [16][93/204]	Loss 0.0390 (0.1216)	
training:	Epoch: [16][94/204]	Loss 0.1207 (0.1216)	
training:	Epoch: [16][95/204]	Loss 0.0301 (0.1206)	
training:	Epoch: [16][96/204]	Loss 0.0745 (0.1201)	
training:	Epoch: [16][97/204]	Loss 0.1856 (0.1208)	
training:	Epoch: [16][98/204]	Loss 0.0653 (0.1202)	
training:	Epoch: [16][99/204]	Loss 0.0702 (0.1197)	
training:	Epoch: [16][100/204]	Loss 0.0475 (0.1190)	
training:	Epoch: [16][101/204]	Loss 0.1269 (0.1191)	
training:	Epoch: [16][102/204]	Loss 0.1583 (0.1195)	
training:	Epoch: [16][103/204]	Loss 0.0462 (0.1188)	
training:	Epoch: [16][104/204]	Loss 0.2667 (0.1202)	
training:	Epoch: [16][105/204]	Loss 0.1868 (0.1208)	
training:	Epoch: [16][106/204]	Loss 0.2555 (0.1221)	
training:	Epoch: [16][107/204]	Loss 0.0351 (0.1213)	
training:	Epoch: [16][108/204]	Loss 0.2576 (0.1225)	
training:	Epoch: [16][109/204]	Loss 0.1868 (0.1231)	
training:	Epoch: [16][110/204]	Loss 0.0571 (0.1225)	
training:	Epoch: [16][111/204]	Loss 0.4337 (0.1253)	
training:	Epoch: [16][112/204]	Loss 0.2980 (0.1269)	
training:	Epoch: [16][113/204]	Loss 0.0511 (0.1262)	
training:	Epoch: [16][114/204]	Loss 0.2497 (0.1273)	
training:	Epoch: [16][115/204]	Loss 0.1780 (0.1277)	
training:	Epoch: [16][116/204]	Loss 0.2552 (0.1288)	
training:	Epoch: [16][117/204]	Loss 0.0973 (0.1286)	
training:	Epoch: [16][118/204]	Loss 0.1535 (0.1288)	
training:	Epoch: [16][119/204]	Loss 0.0625 (0.1282)	
training:	Epoch: [16][120/204]	Loss 0.0343 (0.1274)	
training:	Epoch: [16][121/204]	Loss 0.0481 (0.1268)	
training:	Epoch: [16][122/204]	Loss 0.2845 (0.1281)	
training:	Epoch: [16][123/204]	Loss 0.3519 (0.1299)	
training:	Epoch: [16][124/204]	Loss 0.1568 (0.1301)	
training:	Epoch: [16][125/204]	Loss 0.2317 (0.1309)	
training:	Epoch: [16][126/204]	Loss 0.1438 (0.1310)	
training:	Epoch: [16][127/204]	Loss 0.2482 (0.1319)	
training:	Epoch: [16][128/204]	Loss 0.0999 (0.1317)	
training:	Epoch: [16][129/204]	Loss 0.0845 (0.1313)	
training:	Epoch: [16][130/204]	Loss 0.0464 (0.1307)	
training:	Epoch: [16][131/204]	Loss 0.1375 (0.1307)	
training:	Epoch: [16][132/204]	Loss 0.1611 (0.1310)	
training:	Epoch: [16][133/204]	Loss 0.0347 (0.1302)	
training:	Epoch: [16][134/204]	Loss 0.0812 (0.1299)	
training:	Epoch: [16][135/204]	Loss 0.0693 (0.1294)	
training:	Epoch: [16][136/204]	Loss 0.2452 (0.1303)	
training:	Epoch: [16][137/204]	Loss 0.0603 (0.1298)	
training:	Epoch: [16][138/204]	Loss 0.2935 (0.1309)	
training:	Epoch: [16][139/204]	Loss 0.0602 (0.1304)	
training:	Epoch: [16][140/204]	Loss 0.0587 (0.1299)	
training:	Epoch: [16][141/204]	Loss 0.2665 (0.1309)	
training:	Epoch: [16][142/204]	Loss 0.1644 (0.1311)	
training:	Epoch: [16][143/204]	Loss 0.0607 (0.1306)	
training:	Epoch: [16][144/204]	Loss 0.1124 (0.1305)	
training:	Epoch: [16][145/204]	Loss 0.1655 (0.1307)	
training:	Epoch: [16][146/204]	Loss 0.0713 (0.1303)	
training:	Epoch: [16][147/204]	Loss 0.2762 (0.1313)	
training:	Epoch: [16][148/204]	Loss 0.0572 (0.1308)	
training:	Epoch: [16][149/204]	Loss 0.0634 (0.1304)	
training:	Epoch: [16][150/204]	Loss 0.0600 (0.1299)	
training:	Epoch: [16][151/204]	Loss 0.1316 (0.1299)	
training:	Epoch: [16][152/204]	Loss 0.1572 (0.1301)	
training:	Epoch: [16][153/204]	Loss 0.0458 (0.1296)	
training:	Epoch: [16][154/204]	Loss 0.1720 (0.1298)	
training:	Epoch: [16][155/204]	Loss 0.1521 (0.1300)	
training:	Epoch: [16][156/204]	Loss 0.0912 (0.1297)	
training:	Epoch: [16][157/204]	Loss 0.1038 (0.1296)	
training:	Epoch: [16][158/204]	Loss 0.1590 (0.1297)	
training:	Epoch: [16][159/204]	Loss 0.0377 (0.1292)	
training:	Epoch: [16][160/204]	Loss 0.0392 (0.1286)	
training:	Epoch: [16][161/204]	Loss 0.1480 (0.1287)	
training:	Epoch: [16][162/204]	Loss 0.1028 (0.1286)	
training:	Epoch: [16][163/204]	Loss 0.0617 (0.1282)	
training:	Epoch: [16][164/204]	Loss 0.1405 (0.1282)	
training:	Epoch: [16][165/204]	Loss 0.1505 (0.1284)	
training:	Epoch: [16][166/204]	Loss 0.0586 (0.1279)	
training:	Epoch: [16][167/204]	Loss 0.0548 (0.1275)	
training:	Epoch: [16][168/204]	Loss 0.1572 (0.1277)	
training:	Epoch: [16][169/204]	Loss 0.0366 (0.1271)	
training:	Epoch: [16][170/204]	Loss 0.0471 (0.1267)	
training:	Epoch: [16][171/204]	Loss 0.0336 (0.1261)	
training:	Epoch: [16][172/204]	Loss 0.3343 (0.1273)	
training:	Epoch: [16][173/204]	Loss 0.2792 (0.1282)	
training:	Epoch: [16][174/204]	Loss 0.1478 (0.1283)	
training:	Epoch: [16][175/204]	Loss 0.2108 (0.1288)	
training:	Epoch: [16][176/204]	Loss 0.1465 (0.1289)	
training:	Epoch: [16][177/204]	Loss 0.1161 (0.1288)	
training:	Epoch: [16][178/204]	Loss 0.2653 (0.1296)	
training:	Epoch: [16][179/204]	Loss 0.1663 (0.1298)	
training:	Epoch: [16][180/204]	Loss 0.1923 (0.1301)	
training:	Epoch: [16][181/204]	Loss 0.0422 (0.1297)	
training:	Epoch: [16][182/204]	Loss 0.1447 (0.1297)	
training:	Epoch: [16][183/204]	Loss 0.1419 (0.1298)	
training:	Epoch: [16][184/204]	Loss 0.0813 (0.1295)	
training:	Epoch: [16][185/204]	Loss 0.1410 (0.1296)	
training:	Epoch: [16][186/204]	Loss 0.1173 (0.1295)	
training:	Epoch: [16][187/204]	Loss 0.0459 (0.1291)	
training:	Epoch: [16][188/204]	Loss 0.0383 (0.1286)	
training:	Epoch: [16][189/204]	Loss 0.2688 (0.1294)	
training:	Epoch: [16][190/204]	Loss 0.1011 (0.1292)	
training:	Epoch: [16][191/204]	Loss 0.0430 (0.1288)	
training:	Epoch: [16][192/204]	Loss 0.0447 (0.1283)	
training:	Epoch: [16][193/204]	Loss 0.1467 (0.1284)	
training:	Epoch: [16][194/204]	Loss 0.0398 (0.1280)	
training:	Epoch: [16][195/204]	Loss 0.0804 (0.1277)	
training:	Epoch: [16][196/204]	Loss 0.1668 (0.1279)	
training:	Epoch: [16][197/204]	Loss 0.1722 (0.1281)	
training:	Epoch: [16][198/204]	Loss 0.0378 (0.1277)	
training:	Epoch: [16][199/204]	Loss 0.1764 (0.1279)	
training:	Epoch: [16][200/204]	Loss 0.1474 (0.1280)	
training:	Epoch: [16][201/204]	Loss 0.0503 (0.1276)	
training:	Epoch: [16][202/204]	Loss 0.0360 (0.1272)	
training:	Epoch: [16][203/204]	Loss 0.0304 (0.1267)	
training:	Epoch: [16][204/204]	Loss 0.0999 (0.1266)	
Training:	 Loss: 0.1264

Training:	 ACC: 0.9778 0.9775 0.9700 0.9857
Validation:	 ACC: 0.7992 0.7994 0.8035 0.7948
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.6208
Pretraining:	Epoch 17/500
----------
training:	Epoch: [17][1/204]	Loss 0.0433 (0.0433)	
training:	Epoch: [17][2/204]	Loss 0.0344 (0.0389)	
training:	Epoch: [17][3/204]	Loss 0.2307 (0.1028)	
training:	Epoch: [17][4/204]	Loss 0.1372 (0.1114)	
training:	Epoch: [17][5/204]	Loss 0.0332 (0.0958)	
training:	Epoch: [17][6/204]	Loss 0.2669 (0.1243)	
training:	Epoch: [17][7/204]	Loss 0.1575 (0.1290)	
training:	Epoch: [17][8/204]	Loss 0.0319 (0.1169)	
training:	Epoch: [17][9/204]	Loss 0.0738 (0.1121)	
training:	Epoch: [17][10/204]	Loss 0.0449 (0.1054)	
training:	Epoch: [17][11/204]	Loss 0.0376 (0.0992)	
training:	Epoch: [17][12/204]	Loss 0.0528 (0.0953)	
training:	Epoch: [17][13/204]	Loss 0.1534 (0.0998)	
training:	Epoch: [17][14/204]	Loss 0.0363 (0.0953)	
training:	Epoch: [17][15/204]	Loss 0.0296 (0.0909)	
training:	Epoch: [17][16/204]	Loss 0.0362 (0.0875)	
training:	Epoch: [17][17/204]	Loss 0.1571 (0.0916)	
training:	Epoch: [17][18/204]	Loss 0.1477 (0.0947)	
training:	Epoch: [17][19/204]	Loss 0.0319 (0.0914)	
training:	Epoch: [17][20/204]	Loss 0.1693 (0.0953)	
training:	Epoch: [17][21/204]	Loss 0.0295 (0.0922)	
training:	Epoch: [17][22/204]	Loss 0.1432 (0.0945)	
training:	Epoch: [17][23/204]	Loss 0.1290 (0.0960)	
training:	Epoch: [17][24/204]	Loss 0.2558 (0.1026)	
training:	Epoch: [17][25/204]	Loss 0.0417 (0.1002)	
training:	Epoch: [17][26/204]	Loss 0.0261 (0.0974)	
training:	Epoch: [17][27/204]	Loss 0.1105 (0.0978)	
training:	Epoch: [17][28/204]	Loss 0.0488 (0.0961)	
training:	Epoch: [17][29/204]	Loss 0.1422 (0.0977)	
training:	Epoch: [17][30/204]	Loss 0.1904 (0.1008)	
training:	Epoch: [17][31/204]	Loss 0.0328 (0.0986)	
training:	Epoch: [17][32/204]	Loss 0.0276 (0.0964)	
training:	Epoch: [17][33/204]	Loss 0.1612 (0.0983)	
training:	Epoch: [17][34/204]	Loss 0.0281 (0.0963)	
training:	Epoch: [17][35/204]	Loss 0.1402 (0.0975)	
training:	Epoch: [17][36/204]	Loss 0.0453 (0.0961)	
training:	Epoch: [17][37/204]	Loss 0.1658 (0.0979)	
training:	Epoch: [17][38/204]	Loss 0.0323 (0.0962)	
training:	Epoch: [17][39/204]	Loss 0.1332 (0.0972)	
training:	Epoch: [17][40/204]	Loss 0.1382 (0.0982)	
training:	Epoch: [17][41/204]	Loss 0.1751 (0.1001)	
training:	Epoch: [17][42/204]	Loss 0.1643 (0.1016)	
training:	Epoch: [17][43/204]	Loss 0.0382 (0.1001)	
training:	Epoch: [17][44/204]	Loss 0.1583 (0.1014)	
training:	Epoch: [17][45/204]	Loss 0.1454 (0.1024)	
training:	Epoch: [17][46/204]	Loss 0.0793 (0.1019)	
training:	Epoch: [17][47/204]	Loss 0.0507 (0.1008)	
training:	Epoch: [17][48/204]	Loss 0.0382 (0.0995)	
training:	Epoch: [17][49/204]	Loss 0.0439 (0.0984)	
training:	Epoch: [17][50/204]	Loss 0.0300 (0.0970)	
training:	Epoch: [17][51/204]	Loss 0.3252 (0.1015)	
training:	Epoch: [17][52/204]	Loss 0.3330 (0.1059)	
training:	Epoch: [17][53/204]	Loss 0.0359 (0.1046)	
training:	Epoch: [17][54/204]	Loss 0.1058 (0.1046)	
training:	Epoch: [17][55/204]	Loss 0.0627 (0.1039)	
training:	Epoch: [17][56/204]	Loss 0.0569 (0.1030)	
training:	Epoch: [17][57/204]	Loss 0.0292 (0.1018)	
training:	Epoch: [17][58/204]	Loss 0.2831 (0.1049)	
training:	Epoch: [17][59/204]	Loss 0.0884 (0.1046)	
training:	Epoch: [17][60/204]	Loss 0.0348 (0.1034)	
training:	Epoch: [17][61/204]	Loss 0.0278 (0.1022)	
training:	Epoch: [17][62/204]	Loss 0.0263 (0.1010)	
training:	Epoch: [17][63/204]	Loss 0.0802 (0.1006)	
training:	Epoch: [17][64/204]	Loss 0.0360 (0.0996)	
training:	Epoch: [17][65/204]	Loss 0.0482 (0.0988)	
training:	Epoch: [17][66/204]	Loss 0.1456 (0.0995)	
training:	Epoch: [17][67/204]	Loss 0.2722 (0.1021)	
training:	Epoch: [17][68/204]	Loss 0.2905 (0.1049)	
training:	Epoch: [17][69/204]	Loss 0.1751 (0.1059)	
training:	Epoch: [17][70/204]	Loss 0.2699 (0.1083)	
training:	Epoch: [17][71/204]	Loss 0.1481 (0.1088)	
training:	Epoch: [17][72/204]	Loss 0.1397 (0.1092)	
training:	Epoch: [17][73/204]	Loss 0.1576 (0.1099)	
training:	Epoch: [17][74/204]	Loss 0.1612 (0.1106)	
training:	Epoch: [17][75/204]	Loss 0.0330 (0.1096)	
training:	Epoch: [17][76/204]	Loss 0.0330 (0.1086)	
training:	Epoch: [17][77/204]	Loss 0.1577 (0.1092)	
training:	Epoch: [17][78/204]	Loss 0.1362 (0.1095)	
training:	Epoch: [17][79/204]	Loss 0.2911 (0.1118)	
training:	Epoch: [17][80/204]	Loss 0.2716 (0.1138)	
training:	Epoch: [17][81/204]	Loss 0.1393 (0.1142)	
training:	Epoch: [17][82/204]	Loss 0.2779 (0.1161)	
training:	Epoch: [17][83/204]	Loss 0.0518 (0.1154)	
training:	Epoch: [17][84/204]	Loss 0.1390 (0.1157)	
training:	Epoch: [17][85/204]	Loss 0.1537 (0.1161)	
training:	Epoch: [17][86/204]	Loss 0.1489 (0.1165)	
training:	Epoch: [17][87/204]	Loss 0.0285 (0.1155)	
training:	Epoch: [17][88/204]	Loss 0.1460 (0.1158)	
training:	Epoch: [17][89/204]	Loss 0.0877 (0.1155)	
training:	Epoch: [17][90/204]	Loss 0.0670 (0.1150)	
training:	Epoch: [17][91/204]	Loss 0.1062 (0.1149)	
training:	Epoch: [17][92/204]	Loss 0.0361 (0.1140)	
training:	Epoch: [17][93/204]	Loss 0.1680 (0.1146)	
training:	Epoch: [17][94/204]	Loss 0.2029 (0.1155)	
training:	Epoch: [17][95/204]	Loss 0.0509 (0.1149)	
training:	Epoch: [17][96/204]	Loss 0.1428 (0.1151)	
training:	Epoch: [17][97/204]	Loss 0.1526 (0.1155)	
training:	Epoch: [17][98/204]	Loss 0.0344 (0.1147)	
training:	Epoch: [17][99/204]	Loss 0.0428 (0.1140)	
training:	Epoch: [17][100/204]	Loss 0.1417 (0.1143)	
training:	Epoch: [17][101/204]	Loss 0.0374 (0.1135)	
training:	Epoch: [17][102/204]	Loss 0.1536 (0.1139)	
training:	Epoch: [17][103/204]	Loss 0.0540 (0.1133)	
training:	Epoch: [17][104/204]	Loss 0.0352 (0.1126)	
training:	Epoch: [17][105/204]	Loss 0.2445 (0.1138)	
training:	Epoch: [17][106/204]	Loss 0.1733 (0.1144)	
training:	Epoch: [17][107/204]	Loss 0.1728 (0.1149)	
training:	Epoch: [17][108/204]	Loss 0.0299 (0.1141)	
training:	Epoch: [17][109/204]	Loss 0.0497 (0.1135)	
training:	Epoch: [17][110/204]	Loss 0.1642 (0.1140)	
training:	Epoch: [17][111/204]	Loss 0.1022 (0.1139)	
training:	Epoch: [17][112/204]	Loss 0.2809 (0.1154)	
training:	Epoch: [17][113/204]	Loss 0.1377 (0.1156)	
training:	Epoch: [17][114/204]	Loss 0.0466 (0.1150)	
training:	Epoch: [17][115/204]	Loss 0.0348 (0.1143)	
training:	Epoch: [17][116/204]	Loss 0.0619 (0.1138)	
training:	Epoch: [17][117/204]	Loss 0.1243 (0.1139)	
training:	Epoch: [17][118/204]	Loss 0.0349 (0.1132)	
training:	Epoch: [17][119/204]	Loss 0.0414 (0.1126)	
training:	Epoch: [17][120/204]	Loss 0.0332 (0.1120)	
training:	Epoch: [17][121/204]	Loss 0.0385 (0.1114)	
training:	Epoch: [17][122/204]	Loss 0.0287 (0.1107)	
training:	Epoch: [17][123/204]	Loss 0.0388 (0.1101)	
training:	Epoch: [17][124/204]	Loss 0.1697 (0.1106)	
training:	Epoch: [17][125/204]	Loss 0.0651 (0.1102)	
training:	Epoch: [17][126/204]	Loss 0.3603 (0.1122)	
training:	Epoch: [17][127/204]	Loss 0.0386 (0.1116)	
training:	Epoch: [17][128/204]	Loss 0.1313 (0.1118)	
training:	Epoch: [17][129/204]	Loss 0.0671 (0.1114)	
training:	Epoch: [17][130/204]	Loss 0.1286 (0.1116)	
training:	Epoch: [17][131/204]	Loss 0.1449 (0.1118)	
training:	Epoch: [17][132/204]	Loss 0.0411 (0.1113)	
training:	Epoch: [17][133/204]	Loss 0.2873 (0.1126)	
training:	Epoch: [17][134/204]	Loss 0.0305 (0.1120)	
training:	Epoch: [17][135/204]	Loss 0.2112 (0.1127)	
training:	Epoch: [17][136/204]	Loss 0.3610 (0.1146)	
training:	Epoch: [17][137/204]	Loss 0.1866 (0.1151)	
training:	Epoch: [17][138/204]	Loss 0.0355 (0.1145)	
training:	Epoch: [17][139/204]	Loss 0.0294 (0.1139)	
training:	Epoch: [17][140/204]	Loss 0.0602 (0.1135)	
training:	Epoch: [17][141/204]	Loss 0.1768 (0.1140)	
training:	Epoch: [17][142/204]	Loss 0.0469 (0.1135)	
training:	Epoch: [17][143/204]	Loss 0.1138 (0.1135)	
training:	Epoch: [17][144/204]	Loss 0.0404 (0.1130)	
training:	Epoch: [17][145/204]	Loss 0.0684 (0.1127)	
training:	Epoch: [17][146/204]	Loss 0.1787 (0.1131)	
training:	Epoch: [17][147/204]	Loss 0.1093 (0.1131)	
training:	Epoch: [17][148/204]	Loss 0.0376 (0.1126)	
training:	Epoch: [17][149/204]	Loss 0.0659 (0.1123)	
training:	Epoch: [17][150/204]	Loss 0.2974 (0.1135)	
training:	Epoch: [17][151/204]	Loss 0.0432 (0.1131)	
training:	Epoch: [17][152/204]	Loss 0.0550 (0.1127)	
training:	Epoch: [17][153/204]	Loss 0.0369 (0.1122)	
training:	Epoch: [17][154/204]	Loss 0.0399 (0.1117)	
training:	Epoch: [17][155/204]	Loss 0.0366 (0.1112)	
training:	Epoch: [17][156/204]	Loss 0.0387 (0.1108)	
training:	Epoch: [17][157/204]	Loss 0.0797 (0.1106)	
training:	Epoch: [17][158/204]	Loss 0.0501 (0.1102)	
training:	Epoch: [17][159/204]	Loss 0.1215 (0.1102)	
training:	Epoch: [17][160/204]	Loss 0.0348 (0.1098)	
training:	Epoch: [17][161/204]	Loss 0.0570 (0.1094)	
training:	Epoch: [17][162/204]	Loss 0.2607 (0.1104)	
training:	Epoch: [17][163/204]	Loss 0.0440 (0.1100)	
training:	Epoch: [17][164/204]	Loss 0.2360 (0.1107)	
training:	Epoch: [17][165/204]	Loss 0.0547 (0.1104)	
training:	Epoch: [17][166/204]	Loss 0.0305 (0.1099)	
training:	Epoch: [17][167/204]	Loss 0.0824 (0.1098)	
training:	Epoch: [17][168/204]	Loss 0.1154 (0.1098)	
training:	Epoch: [17][169/204]	Loss 0.0384 (0.1094)	
training:	Epoch: [17][170/204]	Loss 0.0331 (0.1089)	
training:	Epoch: [17][171/204]	Loss 0.0354 (0.1085)	
training:	Epoch: [17][172/204]	Loss 0.1094 (0.1085)	
training:	Epoch: [17][173/204]	Loss 0.1398 (0.1087)	
training:	Epoch: [17][174/204]	Loss 0.0245 (0.1082)	
training:	Epoch: [17][175/204]	Loss 0.0274 (0.1077)	
training:	Epoch: [17][176/204]	Loss 0.1760 (0.1081)	
training:	Epoch: [17][177/204]	Loss 0.0388 (0.1077)	
training:	Epoch: [17][178/204]	Loss 0.1224 (0.1078)	
training:	Epoch: [17][179/204]	Loss 0.0394 (0.1074)	
training:	Epoch: [17][180/204]	Loss 0.0281 (0.1070)	
training:	Epoch: [17][181/204]	Loss 0.1462 (0.1072)	
training:	Epoch: [17][182/204]	Loss 0.2552 (0.1080)	
training:	Epoch: [17][183/204]	Loss 0.0774 (0.1078)	
training:	Epoch: [17][184/204]	Loss 0.0530 (0.1075)	
training:	Epoch: [17][185/204]	Loss 0.1841 (0.1080)	
training:	Epoch: [17][186/204]	Loss 0.1987 (0.1085)	
training:	Epoch: [17][187/204]	Loss 0.1899 (0.1089)	
training:	Epoch: [17][188/204]	Loss 0.0799 (0.1087)	
training:	Epoch: [17][189/204]	Loss 0.1414 (0.1089)	
training:	Epoch: [17][190/204]	Loss 0.0731 (0.1087)	
training:	Epoch: [17][191/204]	Loss 0.0272 (0.1083)	
training:	Epoch: [17][192/204]	Loss 0.1597 (0.1086)	
training:	Epoch: [17][193/204]	Loss 0.0271 (0.1081)	
training:	Epoch: [17][194/204]	Loss 0.0303 (0.1077)	
training:	Epoch: [17][195/204]	Loss 0.1421 (0.1079)	
training:	Epoch: [17][196/204]	Loss 0.1307 (0.1080)	
training:	Epoch: [17][197/204]	Loss 0.1707 (0.1083)	
training:	Epoch: [17][198/204]	Loss 0.1659 (0.1086)	
training:	Epoch: [17][199/204]	Loss 0.0849 (0.1085)	
training:	Epoch: [17][200/204]	Loss 0.0436 (0.1082)	
training:	Epoch: [17][201/204]	Loss 0.1526 (0.1084)	
training:	Epoch: [17][202/204]	Loss 0.2147 (0.1089)	
training:	Epoch: [17][203/204]	Loss 0.1403 (0.1091)	
training:	Epoch: [17][204/204]	Loss 0.0276 (0.1087)	
Training:	 Loss: 0.1085

Training:	 ACC: 0.9819 0.9818 0.9782 0.9857
Validation:	 ACC: 0.7995 0.8010 0.8321 0.7668
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.6538
Pretraining:	Epoch 18/500
----------
training:	Epoch: [18][1/204]	Loss 0.0316 (0.0316)	
training:	Epoch: [18][2/204]	Loss 0.1536 (0.0926)	
training:	Epoch: [18][3/204]	Loss 0.1078 (0.0976)	
training:	Epoch: [18][4/204]	Loss 0.1439 (0.1092)	
training:	Epoch: [18][5/204]	Loss 0.0300 (0.0933)	
training:	Epoch: [18][6/204]	Loss 0.1480 (0.1025)	
training:	Epoch: [18][7/204]	Loss 0.1486 (0.1090)	
training:	Epoch: [18][8/204]	Loss 0.1475 (0.1138)	
training:	Epoch: [18][9/204]	Loss 0.0313 (0.1047)	
training:	Epoch: [18][10/204]	Loss 0.1518 (0.1094)	
training:	Epoch: [18][11/204]	Loss 0.1390 (0.1121)	
training:	Epoch: [18][12/204]	Loss 0.2175 (0.1209)	
training:	Epoch: [18][13/204]	Loss 0.0237 (0.1134)	
training:	Epoch: [18][14/204]	Loss 0.0298 (0.1074)	
training:	Epoch: [18][15/204]	Loss 0.0455 (0.1033)	
training:	Epoch: [18][16/204]	Loss 0.1719 (0.1076)	
training:	Epoch: [18][17/204]	Loss 0.0277 (0.1029)	
training:	Epoch: [18][18/204]	Loss 0.1914 (0.1078)	
training:	Epoch: [18][19/204]	Loss 0.0244 (0.1034)	
training:	Epoch: [18][20/204]	Loss 0.0438 (0.1004)	
training:	Epoch: [18][21/204]	Loss 0.0253 (0.0969)	
training:	Epoch: [18][22/204]	Loss 0.0396 (0.0943)	
training:	Epoch: [18][23/204]	Loss 0.0315 (0.0915)	
training:	Epoch: [18][24/204]	Loss 0.0249 (0.0888)	
training:	Epoch: [18][25/204]	Loss 0.0464 (0.0871)	
training:	Epoch: [18][26/204]	Loss 0.0558 (0.0859)	
training:	Epoch: [18][27/204]	Loss 0.1161 (0.0870)	
training:	Epoch: [18][28/204]	Loss 0.1483 (0.0892)	
training:	Epoch: [18][29/204]	Loss 0.0622 (0.0882)	
training:	Epoch: [18][30/204]	Loss 0.0647 (0.0874)	
training:	Epoch: [18][31/204]	Loss 0.0227 (0.0854)	
training:	Epoch: [18][32/204]	Loss 0.0373 (0.0839)	
training:	Epoch: [18][33/204]	Loss 0.0949 (0.0842)	
training:	Epoch: [18][34/204]	Loss 0.0855 (0.0842)	
training:	Epoch: [18][35/204]	Loss 0.1490 (0.0861)	
training:	Epoch: [18][36/204]	Loss 0.2769 (0.0914)	
training:	Epoch: [18][37/204]	Loss 0.0245 (0.0896)	
training:	Epoch: [18][38/204]	Loss 0.0384 (0.0882)	
training:	Epoch: [18][39/204]	Loss 0.2306 (0.0919)	
training:	Epoch: [18][40/204]	Loss 0.2015 (0.0946)	
training:	Epoch: [18][41/204]	Loss 0.0247 (0.0929)	
training:	Epoch: [18][42/204]	Loss 0.0262 (0.0913)	
training:	Epoch: [18][43/204]	Loss 0.1456 (0.0926)	
training:	Epoch: [18][44/204]	Loss 0.0327 (0.0912)	
training:	Epoch: [18][45/204]	Loss 0.1594 (0.0927)	
training:	Epoch: [18][46/204]	Loss 0.1504 (0.0940)	
training:	Epoch: [18][47/204]	Loss 0.0842 (0.0938)	
training:	Epoch: [18][48/204]	Loss 0.1508 (0.0950)	
training:	Epoch: [18][49/204]	Loss 0.1517 (0.0961)	
training:	Epoch: [18][50/204]	Loss 0.1683 (0.0976)	
training:	Epoch: [18][51/204]	Loss 0.1520 (0.0986)	
training:	Epoch: [18][52/204]	Loss 0.0332 (0.0974)	
training:	Epoch: [18][53/204]	Loss 0.0242 (0.0960)	
training:	Epoch: [18][54/204]	Loss 0.3307 (0.1004)	
training:	Epoch: [18][55/204]	Loss 0.0234 (0.0990)	
training:	Epoch: [18][56/204]	Loss 0.0513 (0.0981)	
training:	Epoch: [18][57/204]	Loss 0.1978 (0.0999)	
training:	Epoch: [18][58/204]	Loss 0.0967 (0.0998)	
training:	Epoch: [18][59/204]	Loss 0.1468 (0.1006)	
training:	Epoch: [18][60/204]	Loss 0.0843 (0.1003)	
training:	Epoch: [18][61/204]	Loss 0.2571 (0.1029)	
training:	Epoch: [18][62/204]	Loss 0.1387 (0.1035)	
training:	Epoch: [18][63/204]	Loss 0.1511 (0.1042)	
training:	Epoch: [18][64/204]	Loss 0.0666 (0.1036)	
training:	Epoch: [18][65/204]	Loss 0.2563 (0.1060)	
training:	Epoch: [18][66/204]	Loss 0.0625 (0.1053)	
training:	Epoch: [18][67/204]	Loss 0.1504 (0.1060)	
training:	Epoch: [18][68/204]	Loss 0.1418 (0.1065)	
training:	Epoch: [18][69/204]	Loss 0.1342 (0.1069)	
training:	Epoch: [18][70/204]	Loss 0.0220 (0.1057)	
training:	Epoch: [18][71/204]	Loss 0.1431 (0.1062)	
training:	Epoch: [18][72/204]	Loss 0.1392 (0.1067)	
training:	Epoch: [18][73/204]	Loss 0.1710 (0.1076)	
training:	Epoch: [18][74/204]	Loss 0.0377 (0.1066)	
training:	Epoch: [18][75/204]	Loss 0.1404 (0.1071)	
training:	Epoch: [18][76/204]	Loss 0.0325 (0.1061)	
training:	Epoch: [18][77/204]	Loss 0.2351 (0.1078)	
training:	Epoch: [18][78/204]	Loss 0.1498 (0.1083)	
training:	Epoch: [18][79/204]	Loss 0.1534 (0.1089)	
training:	Epoch: [18][80/204]	Loss 0.0468 (0.1081)	
training:	Epoch: [18][81/204]	Loss 0.1636 (0.1088)	
training:	Epoch: [18][82/204]	Loss 0.1628 (0.1095)	
training:	Epoch: [18][83/204]	Loss 0.0277 (0.1085)	
training:	Epoch: [18][84/204]	Loss 0.0473 (0.1077)	
training:	Epoch: [18][85/204]	Loss 0.0329 (0.1069)	
training:	Epoch: [18][86/204]	Loss 0.0366 (0.1060)	
training:	Epoch: [18][87/204]	Loss 0.1422 (0.1065)	
training:	Epoch: [18][88/204]	Loss 0.0357 (0.1057)	
training:	Epoch: [18][89/204]	Loss 0.1360 (0.1060)	
training:	Epoch: [18][90/204]	Loss 0.0276 (0.1051)	
training:	Epoch: [18][91/204]	Loss 0.0531 (0.1046)	
training:	Epoch: [18][92/204]	Loss 0.1448 (0.1050)	
training:	Epoch: [18][93/204]	Loss 0.0234 (0.1041)	
training:	Epoch: [18][94/204]	Loss 0.1801 (0.1049)	
training:	Epoch: [18][95/204]	Loss 0.0277 (0.1041)	
training:	Epoch: [18][96/204]	Loss 0.0436 (0.1035)	
training:	Epoch: [18][97/204]	Loss 0.0244 (0.1027)	
training:	Epoch: [18][98/204]	Loss 0.0661 (0.1023)	
training:	Epoch: [18][99/204]	Loss 0.1353 (0.1026)	
training:	Epoch: [18][100/204]	Loss 0.0273 (0.1019)	
training:	Epoch: [18][101/204]	Loss 0.0259 (0.1011)	
training:	Epoch: [18][102/204]	Loss 0.4438 (0.1045)	
training:	Epoch: [18][103/204]	Loss 0.0275 (0.1037)	
training:	Epoch: [18][104/204]	Loss 0.0249 (0.1030)	
training:	Epoch: [18][105/204]	Loss 0.0339 (0.1023)	
training:	Epoch: [18][106/204]	Loss 0.0318 (0.1017)	
training:	Epoch: [18][107/204]	Loss 0.1854 (0.1024)	
training:	Epoch: [18][108/204]	Loss 0.2290 (0.1036)	
training:	Epoch: [18][109/204]	Loss 0.1177 (0.1037)	
training:	Epoch: [18][110/204]	Loss 0.0577 (0.1033)	
training:	Epoch: [18][111/204]	Loss 0.0410 (0.1028)	
training:	Epoch: [18][112/204]	Loss 0.1833 (0.1035)	
training:	Epoch: [18][113/204]	Loss 0.1980 (0.1043)	
training:	Epoch: [18][114/204]	Loss 0.0920 (0.1042)	
training:	Epoch: [18][115/204]	Loss 0.1711 (0.1048)	
training:	Epoch: [18][116/204]	Loss 0.0320 (0.1042)	
training:	Epoch: [18][117/204]	Loss 0.1615 (0.1046)	
training:	Epoch: [18][118/204]	Loss 0.1589 (0.1051)	
training:	Epoch: [18][119/204]	Loss 0.1563 (0.1055)	
training:	Epoch: [18][120/204]	Loss 0.2170 (0.1065)	
training:	Epoch: [18][121/204]	Loss 0.1605 (0.1069)	
training:	Epoch: [18][122/204]	Loss 0.1543 (0.1073)	
training:	Epoch: [18][123/204]	Loss 0.0342 (0.1067)	
training:	Epoch: [18][124/204]	Loss 0.0379 (0.1062)	
training:	Epoch: [18][125/204]	Loss 0.1536 (0.1065)	
training:	Epoch: [18][126/204]	Loss 0.2181 (0.1074)	
training:	Epoch: [18][127/204]	Loss 0.0280 (0.1068)	
training:	Epoch: [18][128/204]	Loss 0.1527 (0.1072)	
training:	Epoch: [18][129/204]	Loss 0.0268 (0.1065)	
training:	Epoch: [18][130/204]	Loss 0.1347 (0.1067)	
training:	Epoch: [18][131/204]	Loss 0.1514 (0.1071)	
training:	Epoch: [18][132/204]	Loss 0.0254 (0.1065)	
training:	Epoch: [18][133/204]	Loss 0.0746 (0.1062)	
training:	Epoch: [18][134/204]	Loss 0.2727 (0.1075)	
training:	Epoch: [18][135/204]	Loss 0.1556 (0.1078)	
training:	Epoch: [18][136/204]	Loss 0.0677 (0.1075)	
training:	Epoch: [18][137/204]	Loss 0.0730 (0.1073)	
training:	Epoch: [18][138/204]	Loss 0.1121 (0.1073)	
training:	Epoch: [18][139/204]	Loss 0.0692 (0.1070)	
training:	Epoch: [18][140/204]	Loss 0.0697 (0.1068)	
training:	Epoch: [18][141/204]	Loss 0.1331 (0.1070)	
training:	Epoch: [18][142/204]	Loss 0.1376 (0.1072)	
training:	Epoch: [18][143/204]	Loss 0.1376 (0.1074)	
training:	Epoch: [18][144/204]	Loss 0.0270 (0.1068)	
training:	Epoch: [18][145/204]	Loss 0.0257 (0.1063)	
training:	Epoch: [18][146/204]	Loss 0.2489 (0.1072)	
training:	Epoch: [18][147/204]	Loss 0.0246 (0.1067)	
training:	Epoch: [18][148/204]	Loss 0.1110 (0.1067)	
training:	Epoch: [18][149/204]	Loss 0.1466 (0.1070)	
training:	Epoch: [18][150/204]	Loss 0.0387 (0.1065)	
training:	Epoch: [18][151/204]	Loss 0.2058 (0.1072)	
training:	Epoch: [18][152/204]	Loss 0.1477 (0.1075)	
training:	Epoch: [18][153/204]	Loss 0.1367 (0.1076)	
training:	Epoch: [18][154/204]	Loss 0.0346 (0.1072)	
training:	Epoch: [18][155/204]	Loss 0.1409 (0.1074)	
training:	Epoch: [18][156/204]	Loss 0.0216 (0.1068)	
training:	Epoch: [18][157/204]	Loss 0.1633 (0.1072)	
training:	Epoch: [18][158/204]	Loss 0.0283 (0.1067)	
training:	Epoch: [18][159/204]	Loss 0.0355 (0.1063)	
training:	Epoch: [18][160/204]	Loss 0.2601 (0.1072)	
training:	Epoch: [18][161/204]	Loss 0.0344 (0.1068)	
training:	Epoch: [18][162/204]	Loss 0.0331 (0.1063)	
training:	Epoch: [18][163/204]	Loss 0.0250 (0.1058)	
training:	Epoch: [18][164/204]	Loss 0.1017 (0.1058)	
training:	Epoch: [18][165/204]	Loss 0.1304 (0.1059)	
training:	Epoch: [18][166/204]	Loss 0.2558 (0.1068)	
training:	Epoch: [18][167/204]	Loss 0.0226 (0.1063)	
training:	Epoch: [18][168/204]	Loss 0.2761 (0.1073)	
training:	Epoch: [18][169/204]	Loss 0.1266 (0.1075)	
training:	Epoch: [18][170/204]	Loss 0.2574 (0.1083)	
training:	Epoch: [18][171/204]	Loss 0.0240 (0.1078)	
training:	Epoch: [18][172/204]	Loss 0.0423 (0.1075)	
training:	Epoch: [18][173/204]	Loss 0.0685 (0.1072)	
training:	Epoch: [18][174/204]	Loss 0.1446 (0.1075)	
training:	Epoch: [18][175/204]	Loss 0.0600 (0.1072)	
training:	Epoch: [18][176/204]	Loss 0.0291 (0.1067)	
training:	Epoch: [18][177/204]	Loss 0.0767 (0.1066)	
training:	Epoch: [18][178/204]	Loss 0.0254 (0.1061)	
training:	Epoch: [18][179/204]	Loss 0.1395 (0.1063)	
training:	Epoch: [18][180/204]	Loss 0.0530 (0.1060)	
training:	Epoch: [18][181/204]	Loss 0.1637 (0.1063)	
training:	Epoch: [18][182/204]	Loss 0.0441 (0.1060)	
training:	Epoch: [18][183/204]	Loss 0.0323 (0.1056)	
training:	Epoch: [18][184/204]	Loss 0.1452 (0.1058)	
training:	Epoch: [18][185/204]	Loss 0.0324 (0.1054)	
training:	Epoch: [18][186/204]	Loss 0.0370 (0.1050)	
training:	Epoch: [18][187/204]	Loss 0.1376 (0.1052)	
training:	Epoch: [18][188/204]	Loss 0.0232 (0.1048)	
training:	Epoch: [18][189/204]	Loss 0.0234 (0.1043)	
training:	Epoch: [18][190/204]	Loss 0.0248 (0.1039)	
training:	Epoch: [18][191/204]	Loss 0.0352 (0.1036)	
training:	Epoch: [18][192/204]	Loss 0.0339 (0.1032)	
training:	Epoch: [18][193/204]	Loss 0.0392 (0.1029)	
training:	Epoch: [18][194/204]	Loss 0.1296 (0.1030)	
training:	Epoch: [18][195/204]	Loss 0.0216 (0.1026)	
training:	Epoch: [18][196/204]	Loss 0.1376 (0.1028)	
training:	Epoch: [18][197/204]	Loss 0.1416 (0.1030)	
training:	Epoch: [18][198/204]	Loss 0.1663 (0.1033)	
training:	Epoch: [18][199/204]	Loss 0.0722 (0.1031)	
training:	Epoch: [18][200/204]	Loss 0.0318 (0.1028)	
training:	Epoch: [18][201/204]	Loss 0.0499 (0.1025)	
training:	Epoch: [18][202/204]	Loss 0.0300 (0.1021)	
training:	Epoch: [18][203/204]	Loss 0.1016 (0.1021)	
training:	Epoch: [18][204/204]	Loss 0.2298 (0.1028)	
Training:	 Loss: 0.1026

Training:	 ACC: 0.9841 0.9839 0.9803 0.9879
Validation:	 ACC: 0.7945 0.7956 0.8188 0.7702
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.6767
Pretraining:	Epoch 19/500
----------
training:	Epoch: [19][1/204]	Loss 0.0328 (0.0328)	
training:	Epoch: [19][2/204]	Loss 0.0732 (0.0530)	
training:	Epoch: [19][3/204]	Loss 0.0783 (0.0614)	
training:	Epoch: [19][4/204]	Loss 0.0237 (0.0520)	
training:	Epoch: [19][5/204]	Loss 0.0259 (0.0468)	
training:	Epoch: [19][6/204]	Loss 0.2693 (0.0839)	
training:	Epoch: [19][7/204]	Loss 0.0272 (0.0758)	
training:	Epoch: [19][8/204]	Loss 0.0324 (0.0704)	
training:	Epoch: [19][9/204]	Loss 0.1490 (0.0791)	
training:	Epoch: [19][10/204]	Loss 0.1356 (0.0847)	
training:	Epoch: [19][11/204]	Loss 0.0273 (0.0795)	
training:	Epoch: [19][12/204]	Loss 0.1525 (0.0856)	
training:	Epoch: [19][13/204]	Loss 0.0246 (0.0809)	
training:	Epoch: [19][14/204]	Loss 0.0226 (0.0768)	
training:	Epoch: [19][15/204]	Loss 0.0228 (0.0732)	
training:	Epoch: [19][16/204]	Loss 0.1058 (0.0752)	
training:	Epoch: [19][17/204]	Loss 0.0227 (0.0721)	
training:	Epoch: [19][18/204]	Loss 0.0335 (0.0700)	
training:	Epoch: [19][19/204]	Loss 0.0225 (0.0675)	
training:	Epoch: [19][20/204]	Loss 0.1509 (0.0716)	
training:	Epoch: [19][21/204]	Loss 0.0283 (0.0696)	
training:	Epoch: [19][22/204]	Loss 0.0266 (0.0676)	
training:	Epoch: [19][23/204]	Loss 0.0221 (0.0656)	
training:	Epoch: [19][24/204]	Loss 0.0270 (0.0640)	
training:	Epoch: [19][25/204]	Loss 0.1473 (0.0674)	
training:	Epoch: [19][26/204]	Loss 0.0764 (0.0677)	
training:	Epoch: [19][27/204]	Loss 0.0528 (0.0672)	
training:	Epoch: [19][28/204]	Loss 0.0238 (0.0656)	
training:	Epoch: [19][29/204]	Loss 0.0242 (0.0642)	
training:	Epoch: [19][30/204]	Loss 0.0229 (0.0628)	
training:	Epoch: [19][31/204]	Loss 0.0727 (0.0631)	
training:	Epoch: [19][32/204]	Loss 0.3389 (0.0717)	
training:	Epoch: [19][33/204]	Loss 0.1195 (0.0732)	
training:	Epoch: [19][34/204]	Loss 0.0240 (0.0717)	
training:	Epoch: [19][35/204]	Loss 0.0202 (0.0703)	
training:	Epoch: [19][36/204]	Loss 0.2192 (0.0744)	
training:	Epoch: [19][37/204]	Loss 0.1203 (0.0757)	
training:	Epoch: [19][38/204]	Loss 0.0222 (0.0742)	
training:	Epoch: [19][39/204]	Loss 0.1505 (0.0762)	
training:	Epoch: [19][40/204]	Loss 0.0437 (0.0754)	
training:	Epoch: [19][41/204]	Loss 0.0226 (0.0741)	
training:	Epoch: [19][42/204]	Loss 0.0459 (0.0734)	
training:	Epoch: [19][43/204]	Loss 0.0520 (0.0729)	
training:	Epoch: [19][44/204]	Loss 0.2057 (0.0759)	
training:	Epoch: [19][45/204]	Loss 0.0335 (0.0750)	
training:	Epoch: [19][46/204]	Loss 0.0292 (0.0740)	
training:	Epoch: [19][47/204]	Loss 0.0224 (0.0729)	
training:	Epoch: [19][48/204]	Loss 0.0220 (0.0718)	
training:	Epoch: [19][49/204]	Loss 0.0273 (0.0709)	
training:	Epoch: [19][50/204]	Loss 0.1530 (0.0726)	
training:	Epoch: [19][51/204]	Loss 0.0272 (0.0717)	
training:	Epoch: [19][52/204]	Loss 0.1392 (0.0730)	
training:	Epoch: [19][53/204]	Loss 0.0417 (0.0724)	
training:	Epoch: [19][54/204]	Loss 0.2566 (0.0758)	
training:	Epoch: [19][55/204]	Loss 0.0318 (0.0750)	
training:	Epoch: [19][56/204]	Loss 0.1460 (0.0763)	
training:	Epoch: [19][57/204]	Loss 0.1492 (0.0776)	
training:	Epoch: [19][58/204]	Loss 0.0997 (0.0779)	
training:	Epoch: [19][59/204]	Loss 0.0220 (0.0770)	
training:	Epoch: [19][60/204]	Loss 0.0249 (0.0761)	
training:	Epoch: [19][61/204]	Loss 0.0323 (0.0754)	
training:	Epoch: [19][62/204]	Loss 0.0210 (0.0745)	
training:	Epoch: [19][63/204]	Loss 0.0394 (0.0740)	
training:	Epoch: [19][64/204]	Loss 0.1468 (0.0751)	
training:	Epoch: [19][65/204]	Loss 0.0687 (0.0750)	
training:	Epoch: [19][66/204]	Loss 0.1407 (0.0760)	
training:	Epoch: [19][67/204]	Loss 0.1502 (0.0771)	
training:	Epoch: [19][68/204]	Loss 0.1408 (0.0780)	
training:	Epoch: [19][69/204]	Loss 0.1366 (0.0789)	
training:	Epoch: [19][70/204]	Loss 0.1154 (0.0794)	
training:	Epoch: [19][71/204]	Loss 0.0412 (0.0789)	
training:	Epoch: [19][72/204]	Loss 0.0217 (0.0781)	
training:	Epoch: [19][73/204]	Loss 0.0207 (0.0773)	
training:	Epoch: [19][74/204]	Loss 0.0248 (0.0766)	
training:	Epoch: [19][75/204]	Loss 0.0214 (0.0759)	
training:	Epoch: [19][76/204]	Loss 0.0301 (0.0753)	
training:	Epoch: [19][77/204]	Loss 0.0224 (0.0746)	
training:	Epoch: [19][78/204]	Loss 0.1452 (0.0755)	
training:	Epoch: [19][79/204]	Loss 0.0270 (0.0749)	
training:	Epoch: [19][80/204]	Loss 0.0405 (0.0744)	
training:	Epoch: [19][81/204]	Loss 0.0326 (0.0739)	
training:	Epoch: [19][82/204]	Loss 0.0214 (0.0733)	
training:	Epoch: [19][83/204]	Loss 0.0327 (0.0728)	
training:	Epoch: [19][84/204]	Loss 0.1427 (0.0736)	
training:	Epoch: [19][85/204]	Loss 0.1390 (0.0744)	
training:	Epoch: [19][86/204]	Loss 0.0259 (0.0738)	
training:	Epoch: [19][87/204]	Loss 0.3909 (0.0775)	
training:	Epoch: [19][88/204]	Loss 0.1025 (0.0778)	
training:	Epoch: [19][89/204]	Loss 0.2627 (0.0798)	
training:	Epoch: [19][90/204]	Loss 0.0429 (0.0794)	
training:	Epoch: [19][91/204]	Loss 0.0232 (0.0788)	
training:	Epoch: [19][92/204]	Loss 0.0257 (0.0782)	
training:	Epoch: [19][93/204]	Loss 0.0235 (0.0776)	
training:	Epoch: [19][94/204]	Loss 0.0215 (0.0770)	
training:	Epoch: [19][95/204]	Loss 0.0274 (0.0765)	
training:	Epoch: [19][96/204]	Loss 0.0217 (0.0759)	
training:	Epoch: [19][97/204]	Loss 0.2705 (0.0779)	
training:	Epoch: [19][98/204]	Loss 0.0209 (0.0774)	
training:	Epoch: [19][99/204]	Loss 0.0451 (0.0770)	
training:	Epoch: [19][100/204]	Loss 0.1451 (0.0777)	
training:	Epoch: [19][101/204]	Loss 0.1918 (0.0789)	
training:	Epoch: [19][102/204]	Loss 0.1583 (0.0796)	
training:	Epoch: [19][103/204]	Loss 0.0190 (0.0790)	
training:	Epoch: [19][104/204]	Loss 0.0386 (0.0787)	
training:	Epoch: [19][105/204]	Loss 0.0221 (0.0781)	
training:	Epoch: [19][106/204]	Loss 0.1471 (0.0788)	
training:	Epoch: [19][107/204]	Loss 0.1088 (0.0790)	
training:	Epoch: [19][108/204]	Loss 0.0243 (0.0785)	
training:	Epoch: [19][109/204]	Loss 0.1394 (0.0791)	
training:	Epoch: [19][110/204]	Loss 0.1534 (0.0798)	
training:	Epoch: [19][111/204]	Loss 0.1400 (0.0803)	
training:	Epoch: [19][112/204]	Loss 0.0236 (0.0798)	
training:	Epoch: [19][113/204]	Loss 0.0451 (0.0795)	
training:	Epoch: [19][114/204]	Loss 0.1368 (0.0800)	
training:	Epoch: [19][115/204]	Loss 0.2525 (0.0815)	
training:	Epoch: [19][116/204]	Loss 0.0325 (0.0811)	
training:	Epoch: [19][117/204]	Loss 0.0266 (0.0806)	
training:	Epoch: [19][118/204]	Loss 0.2915 (0.0824)	
training:	Epoch: [19][119/204]	Loss 0.0935 (0.0825)	
training:	Epoch: [19][120/204]	Loss 0.0261 (0.0820)	
training:	Epoch: [19][121/204]	Loss 0.1672 (0.0827)	
training:	Epoch: [19][122/204]	Loss 0.0331 (0.0823)	
training:	Epoch: [19][123/204]	Loss 0.0244 (0.0819)	
training:	Epoch: [19][124/204]	Loss 0.2625 (0.0833)	
training:	Epoch: [19][125/204]	Loss 0.1882 (0.0841)	
training:	Epoch: [19][126/204]	Loss 0.0261 (0.0837)	
training:	Epoch: [19][127/204]	Loss 0.1352 (0.0841)	
training:	Epoch: [19][128/204]	Loss 0.0342 (0.0837)	
training:	Epoch: [19][129/204]	Loss 0.1030 (0.0839)	
training:	Epoch: [19][130/204]	Loss 0.0303 (0.0834)	
training:	Epoch: [19][131/204]	Loss 0.1557 (0.0840)	
training:	Epoch: [19][132/204]	Loss 0.1366 (0.0844)	
training:	Epoch: [19][133/204]	Loss 0.0214 (0.0839)	
training:	Epoch: [19][134/204]	Loss 0.0558 (0.0837)	
training:	Epoch: [19][135/204]	Loss 0.2696 (0.0851)	
training:	Epoch: [19][136/204]	Loss 0.0783 (0.0850)	
training:	Epoch: [19][137/204]	Loss 0.1424 (0.0855)	
training:	Epoch: [19][138/204]	Loss 0.0246 (0.0850)	
training:	Epoch: [19][139/204]	Loss 0.1388 (0.0854)	
training:	Epoch: [19][140/204]	Loss 0.1548 (0.0859)	
training:	Epoch: [19][141/204]	Loss 0.0634 (0.0857)	
training:	Epoch: [19][142/204]	Loss 0.1162 (0.0860)	
training:	Epoch: [19][143/204]	Loss 0.1133 (0.0861)	
training:	Epoch: [19][144/204]	Loss 0.0303 (0.0858)	
training:	Epoch: [19][145/204]	Loss 0.0205 (0.0853)	
training:	Epoch: [19][146/204]	Loss 0.2922 (0.0867)	
training:	Epoch: [19][147/204]	Loss 0.0230 (0.0863)	
training:	Epoch: [19][148/204]	Loss 0.0408 (0.0860)	
training:	Epoch: [19][149/204]	Loss 0.1779 (0.0866)	
training:	Epoch: [19][150/204]	Loss 0.0919 (0.0866)	
training:	Epoch: [19][151/204]	Loss 0.0398 (0.0863)	
training:	Epoch: [19][152/204]	Loss 0.0430 (0.0860)	
training:	Epoch: [19][153/204]	Loss 0.1549 (0.0865)	
training:	Epoch: [19][154/204]	Loss 0.0282 (0.0861)	
training:	Epoch: [19][155/204]	Loss 0.2307 (0.0870)	
training:	Epoch: [19][156/204]	Loss 0.1457 (0.0874)	
training:	Epoch: [19][157/204]	Loss 0.0706 (0.0873)	
training:	Epoch: [19][158/204]	Loss 0.1317 (0.0876)	
training:	Epoch: [19][159/204]	Loss 0.0902 (0.0876)	
training:	Epoch: [19][160/204]	Loss 0.0483 (0.0874)	
training:	Epoch: [19][161/204]	Loss 0.0255 (0.0870)	
training:	Epoch: [19][162/204]	Loss 0.1748 (0.0875)	
training:	Epoch: [19][163/204]	Loss 0.0589 (0.0873)	
training:	Epoch: [19][164/204]	Loss 0.0287 (0.0870)	
training:	Epoch: [19][165/204]	Loss 0.1547 (0.0874)	
training:	Epoch: [19][166/204]	Loss 0.1475 (0.0878)	
training:	Epoch: [19][167/204]	Loss 0.1386 (0.0881)	
training:	Epoch: [19][168/204]	Loss 0.3908 (0.0899)	
training:	Epoch: [19][169/204]	Loss 0.1565 (0.0903)	
training:	Epoch: [19][170/204]	Loss 0.0243 (0.0899)	
training:	Epoch: [19][171/204]	Loss 0.1949 (0.0905)	
training:	Epoch: [19][172/204]	Loss 0.2304 (0.0913)	
training:	Epoch: [19][173/204]	Loss 0.3547 (0.0928)	
training:	Epoch: [19][174/204]	Loss 0.2076 (0.0935)	
training:	Epoch: [19][175/204]	Loss 0.0205 (0.0931)	
training:	Epoch: [19][176/204]	Loss 0.1543 (0.0934)	
training:	Epoch: [19][177/204]	Loss 0.0219 (0.0930)	
training:	Epoch: [19][178/204]	Loss 0.1214 (0.0932)	
training:	Epoch: [19][179/204]	Loss 0.0305 (0.0928)	
training:	Epoch: [19][180/204]	Loss 0.0209 (0.0924)	
training:	Epoch: [19][181/204]	Loss 0.0277 (0.0921)	
training:	Epoch: [19][182/204]	Loss 0.1504 (0.0924)	
training:	Epoch: [19][183/204]	Loss 0.1837 (0.0929)	
training:	Epoch: [19][184/204]	Loss 0.0389 (0.0926)	
training:	Epoch: [19][185/204]	Loss 0.1033 (0.0926)	
training:	Epoch: [19][186/204]	Loss 0.1475 (0.0929)	
training:	Epoch: [19][187/204]	Loss 0.0289 (0.0926)	
training:	Epoch: [19][188/204]	Loss 0.0255 (0.0922)	
training:	Epoch: [19][189/204]	Loss 0.0718 (0.0921)	
training:	Epoch: [19][190/204]	Loss 0.0430 (0.0919)	
training:	Epoch: [19][191/204]	Loss 0.0219 (0.0915)	
training:	Epoch: [19][192/204]	Loss 0.0333 (0.0912)	
training:	Epoch: [19][193/204]	Loss 0.2169 (0.0919)	
training:	Epoch: [19][194/204]	Loss 0.0605 (0.0917)	
training:	Epoch: [19][195/204]	Loss 0.1535 (0.0920)	
training:	Epoch: [19][196/204]	Loss 0.1484 (0.0923)	
training:	Epoch: [19][197/204]	Loss 0.2693 (0.0932)	
training:	Epoch: [19][198/204]	Loss 0.1515 (0.0935)	
training:	Epoch: [19][199/204]	Loss 0.0850 (0.0934)	
training:	Epoch: [19][200/204]	Loss 0.2585 (0.0943)	
training:	Epoch: [19][201/204]	Loss 0.0252 (0.0939)	
training:	Epoch: [19][202/204]	Loss 0.0242 (0.0936)	
training:	Epoch: [19][203/204]	Loss 0.0228 (0.0932)	
training:	Epoch: [19][204/204]	Loss 0.0204 (0.0929)	
Training:	 Loss: 0.0927

Training:	 ACC: 0.9850 0.9849 0.9827 0.9872
Validation:	 ACC: 0.7928 0.7945 0.8301 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.7066
Pretraining:	Epoch 20/500
----------
training:	Epoch: [20][1/204]	Loss 0.1448 (0.1448)	
training:	Epoch: [20][2/204]	Loss 0.0215 (0.0832)	
training:	Epoch: [20][3/204]	Loss 0.1371 (0.1012)	
training:	Epoch: [20][4/204]	Loss 0.1529 (0.1141)	
training:	Epoch: [20][5/204]	Loss 0.0199 (0.0953)	
training:	Epoch: [20][6/204]	Loss 0.1366 (0.1021)	
training:	Epoch: [20][7/204]	Loss 0.0336 (0.0923)	
training:	Epoch: [20][8/204]	Loss 0.0374 (0.0855)	
training:	Epoch: [20][9/204]	Loss 0.1565 (0.0934)	
training:	Epoch: [20][10/204]	Loss 0.0328 (0.0873)	
training:	Epoch: [20][11/204]	Loss 0.2219 (0.0996)	
training:	Epoch: [20][12/204]	Loss 0.1115 (0.1005)	
training:	Epoch: [20][13/204]	Loss 0.1371 (0.1034)	
training:	Epoch: [20][14/204]	Loss 0.0209 (0.0975)	
training:	Epoch: [20][15/204]	Loss 0.1498 (0.1010)	
training:	Epoch: [20][16/204]	Loss 0.0209 (0.0960)	
training:	Epoch: [20][17/204]	Loss 0.2512 (0.1051)	
training:	Epoch: [20][18/204]	Loss 0.0199 (0.1004)	
training:	Epoch: [20][19/204]	Loss 0.0286 (0.0966)	
training:	Epoch: [20][20/204]	Loss 0.0230 (0.0929)	
training:	Epoch: [20][21/204]	Loss 0.0202 (0.0894)	
training:	Epoch: [20][22/204]	Loss 0.0335 (0.0869)	
training:	Epoch: [20][23/204]	Loss 0.0200 (0.0840)	
training:	Epoch: [20][24/204]	Loss 0.0208 (0.0814)	
training:	Epoch: [20][25/204]	Loss 0.1501 (0.0841)	
training:	Epoch: [20][26/204]	Loss 0.0208 (0.0817)	
training:	Epoch: [20][27/204]	Loss 0.0228 (0.0795)	
training:	Epoch: [20][28/204]	Loss 0.0191 (0.0773)	
training:	Epoch: [20][29/204]	Loss 0.1461 (0.0797)	
training:	Epoch: [20][30/204]	Loss 0.1603 (0.0824)	
training:	Epoch: [20][31/204]	Loss 0.0232 (0.0805)	
training:	Epoch: [20][32/204]	Loss 0.0402 (0.0792)	
training:	Epoch: [20][33/204]	Loss 0.1560 (0.0816)	
training:	Epoch: [20][34/204]	Loss 0.0549 (0.0808)	
training:	Epoch: [20][35/204]	Loss 0.2677 (0.0861)	
training:	Epoch: [20][36/204]	Loss 0.0630 (0.0855)	
training:	Epoch: [20][37/204]	Loss 0.1393 (0.0869)	
training:	Epoch: [20][38/204]	Loss 0.1317 (0.0881)	
training:	Epoch: [20][39/204]	Loss 0.0243 (0.0865)	
training:	Epoch: [20][40/204]	Loss 0.1336 (0.0876)	
training:	Epoch: [20][41/204]	Loss 0.1313 (0.0887)	
training:	Epoch: [20][42/204]	Loss 0.0306 (0.0873)	
training:	Epoch: [20][43/204]	Loss 0.0225 (0.0858)	
training:	Epoch: [20][44/204]	Loss 0.1486 (0.0872)	
training:	Epoch: [20][45/204]	Loss 0.0260 (0.0859)	
training:	Epoch: [20][46/204]	Loss 0.1516 (0.0873)	
training:	Epoch: [20][47/204]	Loss 0.2575 (0.0909)	
training:	Epoch: [20][48/204]	Loss 0.1368 (0.0919)	
training:	Epoch: [20][49/204]	Loss 0.2683 (0.0955)	
training:	Epoch: [20][50/204]	Loss 0.0246 (0.0941)	
training:	Epoch: [20][51/204]	Loss 0.0249 (0.0927)	
training:	Epoch: [20][52/204]	Loss 0.0855 (0.0926)	
training:	Epoch: [20][53/204]	Loss 0.0418 (0.0916)	
training:	Epoch: [20][54/204]	Loss 0.4256 (0.0978)	
training:	Epoch: [20][55/204]	Loss 0.2754 (0.1010)	
training:	Epoch: [20][56/204]	Loss 0.0202 (0.0996)	
training:	Epoch: [20][57/204]	Loss 0.0266 (0.0983)	
training:	Epoch: [20][58/204]	Loss 0.1843 (0.0998)	
training:	Epoch: [20][59/204]	Loss 0.0350 (0.0987)	
training:	Epoch: [20][60/204]	Loss 0.0336 (0.0976)	
training:	Epoch: [20][61/204]	Loss 0.0254 (0.0964)	
training:	Epoch: [20][62/204]	Loss 0.1620 (0.0975)	
training:	Epoch: [20][63/204]	Loss 0.0238 (0.0963)	
training:	Epoch: [20][64/204]	Loss 0.0253 (0.0952)	
training:	Epoch: [20][65/204]	Loss 0.0217 (0.0941)	
training:	Epoch: [20][66/204]	Loss 0.1867 (0.0955)	
training:	Epoch: [20][67/204]	Loss 0.0252 (0.0944)	
training:	Epoch: [20][68/204]	Loss 0.0271 (0.0934)	
training:	Epoch: [20][69/204]	Loss 0.0209 (0.0924)	
training:	Epoch: [20][70/204]	Loss 0.1007 (0.0925)	
training:	Epoch: [20][71/204]	Loss 0.0225 (0.0915)	
training:	Epoch: [20][72/204]	Loss 0.1342 (0.0921)	
training:	Epoch: [20][73/204]	Loss 0.0343 (0.0913)	
training:	Epoch: [20][74/204]	Loss 0.0241 (0.0904)	
training:	Epoch: [20][75/204]	Loss 0.0956 (0.0905)	
training:	Epoch: [20][76/204]	Loss 0.0204 (0.0896)	
training:	Epoch: [20][77/204]	Loss 0.0238 (0.0887)	
training:	Epoch: [20][78/204]	Loss 0.0267 (0.0879)	
training:	Epoch: [20][79/204]	Loss 0.2732 (0.0903)	
training:	Epoch: [20][80/204]	Loss 0.1423 (0.0909)	
training:	Epoch: [20][81/204]	Loss 0.0344 (0.0902)	
training:	Epoch: [20][82/204]	Loss 0.0307 (0.0895)	
training:	Epoch: [20][83/204]	Loss 0.1406 (0.0901)	
training:	Epoch: [20][84/204]	Loss 0.0253 (0.0893)	
training:	Epoch: [20][85/204]	Loss 0.0681 (0.0891)	
training:	Epoch: [20][86/204]	Loss 0.0312 (0.0884)	
training:	Epoch: [20][87/204]	Loss 0.0576 (0.0880)	
training:	Epoch: [20][88/204]	Loss 0.0232 (0.0873)	
training:	Epoch: [20][89/204]	Loss 0.0545 (0.0869)	
training:	Epoch: [20][90/204]	Loss 0.1511 (0.0877)	
training:	Epoch: [20][91/204]	Loss 0.0250 (0.0870)	
training:	Epoch: [20][92/204]	Loss 0.0354 (0.0864)	
training:	Epoch: [20][93/204]	Loss 0.0201 (0.0857)	
training:	Epoch: [20][94/204]	Loss 0.0223 (0.0850)	
training:	Epoch: [20][95/204]	Loss 0.1453 (0.0857)	
training:	Epoch: [20][96/204]	Loss 0.2873 (0.0878)	
training:	Epoch: [20][97/204]	Loss 0.0461 (0.0873)	
training:	Epoch: [20][98/204]	Loss 0.0216 (0.0867)	
training:	Epoch: [20][99/204]	Loss 0.0199 (0.0860)	
training:	Epoch: [20][100/204]	Loss 0.0211 (0.0853)	
training:	Epoch: [20][101/204]	Loss 0.1153 (0.0856)	
training:	Epoch: [20][102/204]	Loss 0.0379 (0.0852)	
training:	Epoch: [20][103/204]	Loss 0.1587 (0.0859)	
training:	Epoch: [20][104/204]	Loss 0.1397 (0.0864)	
training:	Epoch: [20][105/204]	Loss 0.3847 (0.0892)	
training:	Epoch: [20][106/204]	Loss 0.0279 (0.0887)	
training:	Epoch: [20][107/204]	Loss 0.0262 (0.0881)	
training:	Epoch: [20][108/204]	Loss 0.0737 (0.0879)	
training:	Epoch: [20][109/204]	Loss 0.0353 (0.0875)	
training:	Epoch: [20][110/204]	Loss 0.1510 (0.0880)	
training:	Epoch: [20][111/204]	Loss 0.0200 (0.0874)	
training:	Epoch: [20][112/204]	Loss 0.0186 (0.0868)	
training:	Epoch: [20][113/204]	Loss 0.0201 (0.0862)	
training:	Epoch: [20][114/204]	Loss 0.1578 (0.0868)	
training:	Epoch: [20][115/204]	Loss 0.0384 (0.0864)	
training:	Epoch: [20][116/204]	Loss 0.0255 (0.0859)	
training:	Epoch: [20][117/204]	Loss 0.0217 (0.0853)	
training:	Epoch: [20][118/204]	Loss 0.0256 (0.0848)	
training:	Epoch: [20][119/204]	Loss 0.2158 (0.0859)	
training:	Epoch: [20][120/204]	Loss 0.0235 (0.0854)	
training:	Epoch: [20][121/204]	Loss 0.1524 (0.0860)	
training:	Epoch: [20][122/204]	Loss 0.0390 (0.0856)	
training:	Epoch: [20][123/204]	Loss 0.1136 (0.0858)	
training:	Epoch: [20][124/204]	Loss 0.0196 (0.0853)	
training:	Epoch: [20][125/204]	Loss 0.1509 (0.0858)	
training:	Epoch: [20][126/204]	Loss 0.1180 (0.0861)	
training:	Epoch: [20][127/204]	Loss 0.0231 (0.0856)	
training:	Epoch: [20][128/204]	Loss 0.0474 (0.0853)	
training:	Epoch: [20][129/204]	Loss 0.1078 (0.0854)	
training:	Epoch: [20][130/204]	Loss 0.0479 (0.0852)	
training:	Epoch: [20][131/204]	Loss 0.0240 (0.0847)	
training:	Epoch: [20][132/204]	Loss 0.0693 (0.0846)	
training:	Epoch: [20][133/204]	Loss 0.1230 (0.0849)	
training:	Epoch: [20][134/204]	Loss 0.0216 (0.0844)	
training:	Epoch: [20][135/204]	Loss 0.0262 (0.0840)	
training:	Epoch: [20][136/204]	Loss 0.0670 (0.0838)	
training:	Epoch: [20][137/204]	Loss 0.1026 (0.0840)	
training:	Epoch: [20][138/204]	Loss 0.0241 (0.0835)	
training:	Epoch: [20][139/204]	Loss 0.0217 (0.0831)	
training:	Epoch: [20][140/204]	Loss 0.1499 (0.0836)	
training:	Epoch: [20][141/204]	Loss 0.2697 (0.0849)	
training:	Epoch: [20][142/204]	Loss 0.0578 (0.0847)	
training:	Epoch: [20][143/204]	Loss 0.1681 (0.0853)	
training:	Epoch: [20][144/204]	Loss 0.0209 (0.0848)	
training:	Epoch: [20][145/204]	Loss 0.0190 (0.0844)	
training:	Epoch: [20][146/204]	Loss 0.0225 (0.0840)	
training:	Epoch: [20][147/204]	Loss 0.1399 (0.0843)	
training:	Epoch: [20][148/204]	Loss 0.0309 (0.0840)	
training:	Epoch: [20][149/204]	Loss 0.0182 (0.0835)	
training:	Epoch: [20][150/204]	Loss 0.0197 (0.0831)	
training:	Epoch: [20][151/204]	Loss 0.2725 (0.0844)	
training:	Epoch: [20][152/204]	Loss 0.0313 (0.0840)	
training:	Epoch: [20][153/204]	Loss 0.0279 (0.0836)	
training:	Epoch: [20][154/204]	Loss 0.0328 (0.0833)	
training:	Epoch: [20][155/204]	Loss 0.0268 (0.0829)	
training:	Epoch: [20][156/204]	Loss 0.0328 (0.0826)	
training:	Epoch: [20][157/204]	Loss 0.0297 (0.0823)	
training:	Epoch: [20][158/204]	Loss 0.0355 (0.0820)	
training:	Epoch: [20][159/204]	Loss 0.0351 (0.0817)	
training:	Epoch: [20][160/204]	Loss 0.0442 (0.0815)	
training:	Epoch: [20][161/204]	Loss 0.0234 (0.0811)	
training:	Epoch: [20][162/204]	Loss 0.0203 (0.0807)	
training:	Epoch: [20][163/204]	Loss 0.2735 (0.0819)	
training:	Epoch: [20][164/204]	Loss 0.0268 (0.0816)	
training:	Epoch: [20][165/204]	Loss 0.0215 (0.0812)	
training:	Epoch: [20][166/204]	Loss 0.0529 (0.0810)	
training:	Epoch: [20][167/204]	Loss 0.2562 (0.0821)	
training:	Epoch: [20][168/204]	Loss 0.1459 (0.0825)	
training:	Epoch: [20][169/204]	Loss 0.0298 (0.0822)	
training:	Epoch: [20][170/204]	Loss 0.1491 (0.0826)	
training:	Epoch: [20][171/204]	Loss 0.0255 (0.0822)	
training:	Epoch: [20][172/204]	Loss 0.0262 (0.0819)	
training:	Epoch: [20][173/204]	Loss 0.1426 (0.0822)	
training:	Epoch: [20][174/204]	Loss 0.0220 (0.0819)	
training:	Epoch: [20][175/204]	Loss 0.0193 (0.0815)	
training:	Epoch: [20][176/204]	Loss 0.0233 (0.0812)	
training:	Epoch: [20][177/204]	Loss 0.2774 (0.0823)	
training:	Epoch: [20][178/204]	Loss 0.0248 (0.0820)	
training:	Epoch: [20][179/204]	Loss 0.0787 (0.0820)	
training:	Epoch: [20][180/204]	Loss 0.0210 (0.0816)	
training:	Epoch: [20][181/204]	Loss 0.1351 (0.0819)	
training:	Epoch: [20][182/204]	Loss 0.0200 (0.0816)	
training:	Epoch: [20][183/204]	Loss 0.0226 (0.0813)	
training:	Epoch: [20][184/204]	Loss 0.0202 (0.0809)	
training:	Epoch: [20][185/204]	Loss 0.0204 (0.0806)	
training:	Epoch: [20][186/204]	Loss 0.0397 (0.0804)	
training:	Epoch: [20][187/204]	Loss 0.0332 (0.0801)	
training:	Epoch: [20][188/204]	Loss 0.0190 (0.0798)	
training:	Epoch: [20][189/204]	Loss 0.1389 (0.0801)	
training:	Epoch: [20][190/204]	Loss 0.0244 (0.0798)	
training:	Epoch: [20][191/204]	Loss 0.0725 (0.0798)	
training:	Epoch: [20][192/204]	Loss 0.2913 (0.0809)	
training:	Epoch: [20][193/204]	Loss 0.1397 (0.0812)	
training:	Epoch: [20][194/204]	Loss 0.0206 (0.0809)	
training:	Epoch: [20][195/204]	Loss 0.0197 (0.0806)	
training:	Epoch: [20][196/204]	Loss 0.1566 (0.0810)	
training:	Epoch: [20][197/204]	Loss 0.0553 (0.0808)	
training:	Epoch: [20][198/204]	Loss 0.0268 (0.0806)	
training:	Epoch: [20][199/204]	Loss 0.3174 (0.0817)	
training:	Epoch: [20][200/204]	Loss 0.0213 (0.0814)	
training:	Epoch: [20][201/204]	Loss 0.0227 (0.0812)	
training:	Epoch: [20][202/204]	Loss 0.0273 (0.0809)	
training:	Epoch: [20][203/204]	Loss 0.0188 (0.0806)	
training:	Epoch: [20][204/204]	Loss 0.1242 (0.0808)	
Training:	 Loss: 0.0807

Training:	 ACC: 0.9865 0.9864 0.9830 0.9901
Validation:	 ACC: 0.7928 0.7935 0.8066 0.7791
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.7266
Pretraining:	Epoch 21/500
----------
training:	Epoch: [21][1/204]	Loss 0.0174 (0.0174)	
training:	Epoch: [21][2/204]	Loss 0.0194 (0.0184)	
training:	Epoch: [21][3/204]	Loss 0.0188 (0.0185)	
training:	Epoch: [21][4/204]	Loss 0.0196 (0.0188)	
training:	Epoch: [21][5/204]	Loss 0.1516 (0.0453)	
training:	Epoch: [21][6/204]	Loss 0.0274 (0.0424)	
training:	Epoch: [21][7/204]	Loss 0.1566 (0.0587)	
training:	Epoch: [21][8/204]	Loss 0.0195 (0.0538)	
training:	Epoch: [21][9/204]	Loss 0.0234 (0.0504)	
training:	Epoch: [21][10/204]	Loss 0.0200 (0.0474)	
training:	Epoch: [21][11/204]	Loss 0.1480 (0.0565)	
training:	Epoch: [21][12/204]	Loss 0.1226 (0.0620)	
training:	Epoch: [21][13/204]	Loss 0.1391 (0.0680)	
training:	Epoch: [21][14/204]	Loss 0.0188 (0.0644)	
training:	Epoch: [21][15/204]	Loss 0.1416 (0.0696)	
training:	Epoch: [21][16/204]	Loss 0.1575 (0.0751)	
training:	Epoch: [21][17/204]	Loss 0.0172 (0.0717)	
training:	Epoch: [21][18/204]	Loss 0.1368 (0.0753)	
training:	Epoch: [21][19/204]	Loss 0.1703 (0.0803)	
training:	Epoch: [21][20/204]	Loss 0.0405 (0.0783)	
training:	Epoch: [21][21/204]	Loss 0.0192 (0.0755)	
training:	Epoch: [21][22/204]	Loss 0.0402 (0.0739)	
training:	Epoch: [21][23/204]	Loss 0.0199 (0.0715)	
training:	Epoch: [21][24/204]	Loss 0.1437 (0.0745)	
training:	Epoch: [21][25/204]	Loss 0.1347 (0.0770)	
training:	Epoch: [21][26/204]	Loss 0.1052 (0.0780)	
training:	Epoch: [21][27/204]	Loss 0.0214 (0.0759)	
training:	Epoch: [21][28/204]	Loss 0.1503 (0.0786)	
training:	Epoch: [21][29/204]	Loss 0.0199 (0.0766)	
training:	Epoch: [21][30/204]	Loss 0.0198 (0.0747)	
training:	Epoch: [21][31/204]	Loss 0.1403 (0.0768)	
training:	Epoch: [21][32/204]	Loss 0.0206 (0.0750)	
training:	Epoch: [21][33/204]	Loss 0.0225 (0.0734)	
training:	Epoch: [21][34/204]	Loss 0.2814 (0.0796)	
training:	Epoch: [21][35/204]	Loss 0.0212 (0.0779)	
training:	Epoch: [21][36/204]	Loss 0.0297 (0.0766)	
training:	Epoch: [21][37/204]	Loss 0.0171 (0.0749)	
training:	Epoch: [21][38/204]	Loss 0.1430 (0.0767)	
training:	Epoch: [21][39/204]	Loss 0.1399 (0.0784)	
training:	Epoch: [21][40/204]	Loss 0.0186 (0.0769)	
training:	Epoch: [21][41/204]	Loss 0.0188 (0.0755)	
training:	Epoch: [21][42/204]	Loss 0.1443 (0.0771)	
training:	Epoch: [21][43/204]	Loss 0.0224 (0.0758)	
training:	Epoch: [21][44/204]	Loss 0.0815 (0.0759)	
training:	Epoch: [21][45/204]	Loss 0.0219 (0.0747)	
training:	Epoch: [21][46/204]	Loss 0.4248 (0.0824)	
training:	Epoch: [21][47/204]	Loss 0.0209 (0.0810)	
training:	Epoch: [21][48/204]	Loss 0.0271 (0.0799)	
training:	Epoch: [21][49/204]	Loss 0.0187 (0.0787)	
training:	Epoch: [21][50/204]	Loss 0.0214 (0.0775)	
training:	Epoch: [21][51/204]	Loss 0.0181 (0.0764)	
training:	Epoch: [21][52/204]	Loss 0.0256 (0.0754)	
training:	Epoch: [21][53/204]	Loss 0.0182 (0.0743)	
training:	Epoch: [21][54/204]	Loss 0.1386 (0.0755)	
training:	Epoch: [21][55/204]	Loss 0.0173 (0.0744)	
training:	Epoch: [21][56/204]	Loss 0.2809 (0.0781)	
training:	Epoch: [21][57/204]	Loss 0.2645 (0.0814)	
training:	Epoch: [21][58/204]	Loss 0.0248 (0.0804)	
training:	Epoch: [21][59/204]	Loss 0.0245 (0.0795)	
training:	Epoch: [21][60/204]	Loss 0.0201 (0.0785)	
training:	Epoch: [21][61/204]	Loss 0.0163 (0.0775)	
training:	Epoch: [21][62/204]	Loss 0.2720 (0.0806)	
training:	Epoch: [21][63/204]	Loss 0.0534 (0.0802)	
training:	Epoch: [21][64/204]	Loss 0.0189 (0.0792)	
training:	Epoch: [21][65/204]	Loss 0.0285 (0.0784)	
training:	Epoch: [21][66/204]	Loss 0.0198 (0.0775)	
training:	Epoch: [21][67/204]	Loss 0.1230 (0.0782)	
training:	Epoch: [21][68/204]	Loss 0.0208 (0.0774)	
training:	Epoch: [21][69/204]	Loss 0.1522 (0.0785)	
training:	Epoch: [21][70/204]	Loss 0.0173 (0.0776)	
training:	Epoch: [21][71/204]	Loss 0.0239 (0.0768)	
training:	Epoch: [21][72/204]	Loss 0.2840 (0.0797)	
training:	Epoch: [21][73/204]	Loss 0.0206 (0.0789)	
training:	Epoch: [21][74/204]	Loss 0.0183 (0.0781)	
training:	Epoch: [21][75/204]	Loss 0.1375 (0.0789)	
training:	Epoch: [21][76/204]	Loss 0.0307 (0.0782)	
training:	Epoch: [21][77/204]	Loss 0.0426 (0.0778)	
training:	Epoch: [21][78/204]	Loss 0.0232 (0.0771)	
training:	Epoch: [21][79/204]	Loss 0.0185 (0.0763)	
training:	Epoch: [21][80/204]	Loss 0.0161 (0.0756)	
training:	Epoch: [21][81/204]	Loss 0.0256 (0.0750)	
training:	Epoch: [21][82/204]	Loss 0.1487 (0.0759)	
training:	Epoch: [21][83/204]	Loss 0.0786 (0.0759)	
training:	Epoch: [21][84/204]	Loss 0.0235 (0.0753)	
training:	Epoch: [21][85/204]	Loss 0.0244 (0.0747)	
training:	Epoch: [21][86/204]	Loss 0.2219 (0.0764)	
training:	Epoch: [21][87/204]	Loss 0.1515 (0.0772)	
training:	Epoch: [21][88/204]	Loss 0.0269 (0.0767)	
training:	Epoch: [21][89/204]	Loss 0.0228 (0.0761)	
training:	Epoch: [21][90/204]	Loss 0.0336 (0.0756)	
training:	Epoch: [21][91/204]	Loss 0.0160 (0.0749)	
training:	Epoch: [21][92/204]	Loss 0.0202 (0.0743)	
training:	Epoch: [21][93/204]	Loss 0.0185 (0.0737)	
training:	Epoch: [21][94/204]	Loss 0.1319 (0.0744)	
training:	Epoch: [21][95/204]	Loss 0.1523 (0.0752)	
training:	Epoch: [21][96/204]	Loss 0.0224 (0.0746)	
training:	Epoch: [21][97/204]	Loss 0.0168 (0.0740)	
training:	Epoch: [21][98/204]	Loss 0.1715 (0.0750)	
training:	Epoch: [21][99/204]	Loss 0.0193 (0.0745)	
training:	Epoch: [21][100/204]	Loss 0.0201 (0.0739)	
training:	Epoch: [21][101/204]	Loss 0.1386 (0.0746)	
training:	Epoch: [21][102/204]	Loss 0.1490 (0.0753)	
training:	Epoch: [21][103/204]	Loss 0.0190 (0.0748)	
training:	Epoch: [21][104/204]	Loss 0.0192 (0.0742)	
training:	Epoch: [21][105/204]	Loss 0.0192 (0.0737)	
training:	Epoch: [21][106/204]	Loss 0.0203 (0.0732)	
training:	Epoch: [21][107/204]	Loss 0.1448 (0.0739)	
training:	Epoch: [21][108/204]	Loss 0.1922 (0.0750)	
training:	Epoch: [21][109/204]	Loss 0.0200 (0.0745)	
training:	Epoch: [21][110/204]	Loss 0.0308 (0.0741)	
training:	Epoch: [21][111/204]	Loss 0.0245 (0.0736)	
training:	Epoch: [21][112/204]	Loss 0.0233 (0.0732)	
training:	Epoch: [21][113/204]	Loss 0.1421 (0.0738)	
training:	Epoch: [21][114/204]	Loss 0.0208 (0.0733)	
training:	Epoch: [21][115/204]	Loss 0.1430 (0.0739)	
training:	Epoch: [21][116/204]	Loss 0.1752 (0.0748)	
training:	Epoch: [21][117/204]	Loss 0.0212 (0.0743)	
training:	Epoch: [21][118/204]	Loss 0.1594 (0.0750)	
training:	Epoch: [21][119/204]	Loss 0.0187 (0.0746)	
training:	Epoch: [21][120/204]	Loss 0.1286 (0.0750)	
training:	Epoch: [21][121/204]	Loss 0.0230 (0.0746)	
training:	Epoch: [21][122/204]	Loss 0.1405 (0.0751)	
training:	Epoch: [21][123/204]	Loss 0.0621 (0.0750)	
training:	Epoch: [21][124/204]	Loss 0.0248 (0.0746)	
training:	Epoch: [21][125/204]	Loss 0.1379 (0.0751)	
training:	Epoch: [21][126/204]	Loss 0.0265 (0.0747)	
training:	Epoch: [21][127/204]	Loss 0.0220 (0.0743)	
training:	Epoch: [21][128/204]	Loss 0.0211 (0.0739)	
training:	Epoch: [21][129/204]	Loss 0.0184 (0.0735)	
training:	Epoch: [21][130/204]	Loss 0.0239 (0.0731)	
training:	Epoch: [21][131/204]	Loss 0.0179 (0.0727)	
training:	Epoch: [21][132/204]	Loss 0.1719 (0.0734)	
training:	Epoch: [21][133/204]	Loss 0.1436 (0.0740)	
training:	Epoch: [21][134/204]	Loss 0.0180 (0.0735)	
training:	Epoch: [21][135/204]	Loss 0.0593 (0.0734)	
training:	Epoch: [21][136/204]	Loss 0.1494 (0.0740)	
training:	Epoch: [21][137/204]	Loss 0.1382 (0.0745)	
training:	Epoch: [21][138/204]	Loss 0.0204 (0.0741)	
training:	Epoch: [21][139/204]	Loss 0.0447 (0.0739)	
training:	Epoch: [21][140/204]	Loss 0.0222 (0.0735)	
training:	Epoch: [21][141/204]	Loss 0.0198 (0.0731)	
training:	Epoch: [21][142/204]	Loss 0.0194 (0.0727)	
training:	Epoch: [21][143/204]	Loss 0.1567 (0.0733)	
training:	Epoch: [21][144/204]	Loss 0.0202 (0.0730)	
training:	Epoch: [21][145/204]	Loss 0.0184 (0.0726)	
training:	Epoch: [21][146/204]	Loss 0.1431 (0.0731)	
training:	Epoch: [21][147/204]	Loss 0.1426 (0.0735)	
training:	Epoch: [21][148/204]	Loss 0.0177 (0.0732)	
training:	Epoch: [21][149/204]	Loss 0.1520 (0.0737)	
training:	Epoch: [21][150/204]	Loss 0.0207 (0.0733)	
training:	Epoch: [21][151/204]	Loss 0.0188 (0.0730)	
training:	Epoch: [21][152/204]	Loss 0.1531 (0.0735)	
training:	Epoch: [21][153/204]	Loss 0.1511 (0.0740)	
training:	Epoch: [21][154/204]	Loss 0.1303 (0.0744)	
training:	Epoch: [21][155/204]	Loss 0.0174 (0.0740)	
training:	Epoch: [21][156/204]	Loss 0.0230 (0.0737)	
training:	Epoch: [21][157/204]	Loss 0.1415 (0.0741)	
training:	Epoch: [21][158/204]	Loss 0.2804 (0.0754)	
training:	Epoch: [21][159/204]	Loss 0.0166 (0.0750)	
training:	Epoch: [21][160/204]	Loss 0.0173 (0.0747)	
training:	Epoch: [21][161/204]	Loss 0.0239 (0.0744)	
training:	Epoch: [21][162/204]	Loss 0.0168 (0.0740)	
training:	Epoch: [21][163/204]	Loss 0.0190 (0.0737)	
training:	Epoch: [21][164/204]	Loss 0.1550 (0.0742)	
training:	Epoch: [21][165/204]	Loss 0.1510 (0.0746)	
training:	Epoch: [21][166/204]	Loss 0.0980 (0.0748)	
training:	Epoch: [21][167/204]	Loss 0.0194 (0.0744)	
training:	Epoch: [21][168/204]	Loss 0.0166 (0.0741)	
training:	Epoch: [21][169/204]	Loss 0.0188 (0.0738)	
training:	Epoch: [21][170/204]	Loss 0.1400 (0.0742)	
training:	Epoch: [21][171/204]	Loss 0.0198 (0.0738)	
training:	Epoch: [21][172/204]	Loss 0.1375 (0.0742)	
training:	Epoch: [21][173/204]	Loss 0.0195 (0.0739)	
training:	Epoch: [21][174/204]	Loss 0.0231 (0.0736)	
training:	Epoch: [21][175/204]	Loss 0.0345 (0.0734)	
training:	Epoch: [21][176/204]	Loss 0.1362 (0.0737)	
training:	Epoch: [21][177/204]	Loss 0.0192 (0.0734)	
training:	Epoch: [21][178/204]	Loss 0.1021 (0.0736)	
training:	Epoch: [21][179/204]	Loss 0.1075 (0.0738)	
training:	Epoch: [21][180/204]	Loss 0.0158 (0.0735)	
training:	Epoch: [21][181/204]	Loss 0.0241 (0.0732)	
training:	Epoch: [21][182/204]	Loss 0.0751 (0.0732)	
training:	Epoch: [21][183/204]	Loss 0.1466 (0.0736)	
training:	Epoch: [21][184/204]	Loss 0.0167 (0.0733)	
training:	Epoch: [21][185/204]	Loss 0.1597 (0.0738)	
training:	Epoch: [21][186/204]	Loss 0.1419 (0.0741)	
training:	Epoch: [21][187/204]	Loss 0.0166 (0.0738)	
training:	Epoch: [21][188/204]	Loss 0.0391 (0.0736)	
training:	Epoch: [21][189/204]	Loss 0.0182 (0.0733)	
training:	Epoch: [21][190/204]	Loss 0.0178 (0.0730)	
training:	Epoch: [21][191/204]	Loss 0.1490 (0.0734)	
training:	Epoch: [21][192/204]	Loss 0.0182 (0.0732)	
training:	Epoch: [21][193/204]	Loss 0.3893 (0.0748)	
training:	Epoch: [21][194/204]	Loss 0.0189 (0.0745)	
training:	Epoch: [21][195/204]	Loss 0.1399 (0.0748)	
training:	Epoch: [21][196/204]	Loss 0.0341 (0.0746)	
training:	Epoch: [21][197/204]	Loss 0.0169 (0.0743)	
training:	Epoch: [21][198/204]	Loss 0.1193 (0.0746)	
training:	Epoch: [21][199/204]	Loss 0.1635 (0.0750)	
training:	Epoch: [21][200/204]	Loss 0.0183 (0.0747)	
training:	Epoch: [21][201/204]	Loss 0.3213 (0.0760)	
training:	Epoch: [21][202/204]	Loss 0.0164 (0.0757)	
training:	Epoch: [21][203/204]	Loss 0.0169 (0.0754)	
training:	Epoch: [21][204/204]	Loss 0.0193 (0.0751)	
Training:	 Loss: 0.0750

Training:	 ACC: 0.9874 0.9873 0.9847 0.9901
Validation:	 ACC: 0.7883 0.7887 0.7963 0.7803
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.7475
Pretraining:	Epoch 22/500
----------
training:	Epoch: [22][1/204]	Loss 0.0193 (0.0193)	
training:	Epoch: [22][2/204]	Loss 0.1367 (0.0780)	
training:	Epoch: [22][3/204]	Loss 0.1500 (0.1020)	
training:	Epoch: [22][4/204]	Loss 0.0528 (0.0897)	
training:	Epoch: [22][5/204]	Loss 0.0580 (0.0834)	
training:	Epoch: [22][6/204]	Loss 0.0972 (0.0857)	
training:	Epoch: [22][7/204]	Loss 0.0188 (0.0761)	
training:	Epoch: [22][8/204]	Loss 0.1329 (0.0832)	
training:	Epoch: [22][9/204]	Loss 0.0176 (0.0759)	
training:	Epoch: [22][10/204]	Loss 0.1578 (0.0841)	
training:	Epoch: [22][11/204]	Loss 0.0202 (0.0783)	
training:	Epoch: [22][12/204]	Loss 0.2403 (0.0918)	
training:	Epoch: [22][13/204]	Loss 0.0218 (0.0864)	
training:	Epoch: [22][14/204]	Loss 0.0255 (0.0821)	
training:	Epoch: [22][15/204]	Loss 0.0245 (0.0782)	
training:	Epoch: [22][16/204]	Loss 0.0519 (0.0766)	
training:	Epoch: [22][17/204]	Loss 0.0236 (0.0735)	
training:	Epoch: [22][18/204]	Loss 0.0593 (0.0727)	
training:	Epoch: [22][19/204]	Loss 0.0267 (0.0703)	
training:	Epoch: [22][20/204]	Loss 0.1766 (0.0756)	
training:	Epoch: [22][21/204]	Loss 0.0555 (0.0746)	
training:	Epoch: [22][22/204]	Loss 0.0300 (0.0726)	
training:	Epoch: [22][23/204]	Loss 0.0242 (0.0705)	
training:	Epoch: [22][24/204]	Loss 0.1573 (0.0741)	
training:	Epoch: [22][25/204]	Loss 0.0868 (0.0746)	
training:	Epoch: [22][26/204]	Loss 0.0887 (0.0752)	
training:	Epoch: [22][27/204]	Loss 0.0242 (0.0733)	
training:	Epoch: [22][28/204]	Loss 0.0199 (0.0714)	
training:	Epoch: [22][29/204]	Loss 0.0215 (0.0696)	
training:	Epoch: [22][30/204]	Loss 0.0374 (0.0686)	
training:	Epoch: [22][31/204]	Loss 0.0212 (0.0670)	
training:	Epoch: [22][32/204]	Loss 0.1037 (0.0682)	
training:	Epoch: [22][33/204]	Loss 0.1395 (0.0703)	
training:	Epoch: [22][34/204]	Loss 0.0228 (0.0689)	
training:	Epoch: [22][35/204]	Loss 0.2211 (0.0733)	
training:	Epoch: [22][36/204]	Loss 0.0746 (0.0733)	
training:	Epoch: [22][37/204]	Loss 0.2791 (0.0789)	
training:	Epoch: [22][38/204]	Loss 0.1526 (0.0808)	
training:	Epoch: [22][39/204]	Loss 0.0215 (0.0793)	
training:	Epoch: [22][40/204]	Loss 0.0152 (0.0777)	
training:	Epoch: [22][41/204]	Loss 0.1585 (0.0797)	
training:	Epoch: [22][42/204]	Loss 0.2759 (0.0844)	
training:	Epoch: [22][43/204]	Loss 0.0287 (0.0831)	
training:	Epoch: [22][44/204]	Loss 0.0228 (0.0817)	
training:	Epoch: [22][45/204]	Loss 0.2497 (0.0854)	
training:	Epoch: [22][46/204]	Loss 0.0196 (0.0840)	
training:	Epoch: [22][47/204]	Loss 0.0169 (0.0826)	
training:	Epoch: [22][48/204]	Loss 0.2358 (0.0858)	
training:	Epoch: [22][49/204]	Loss 0.0197 (0.0844)	
training:	Epoch: [22][50/204]	Loss 0.0162 (0.0830)	
training:	Epoch: [22][51/204]	Loss 0.0202 (0.0818)	
training:	Epoch: [22][52/204]	Loss 0.0172 (0.0806)	
training:	Epoch: [22][53/204]	Loss 0.0177 (0.0794)	
training:	Epoch: [22][54/204]	Loss 0.0206 (0.0783)	
training:	Epoch: [22][55/204]	Loss 0.0246 (0.0773)	
training:	Epoch: [22][56/204]	Loss 0.0181 (0.0763)	
training:	Epoch: [22][57/204]	Loss 0.0163 (0.0752)	
training:	Epoch: [22][58/204]	Loss 0.0181 (0.0742)	
training:	Epoch: [22][59/204]	Loss 0.1451 (0.0754)	
training:	Epoch: [22][60/204]	Loss 0.1490 (0.0766)	
training:	Epoch: [22][61/204]	Loss 0.0165 (0.0757)	
training:	Epoch: [22][62/204]	Loss 0.0952 (0.0760)	
training:	Epoch: [22][63/204]	Loss 0.0182 (0.0751)	
training:	Epoch: [22][64/204]	Loss 0.0323 (0.0744)	
training:	Epoch: [22][65/204]	Loss 0.0216 (0.0736)	
training:	Epoch: [22][66/204]	Loss 0.0283 (0.0729)	
training:	Epoch: [22][67/204]	Loss 0.0220 (0.0721)	
training:	Epoch: [22][68/204]	Loss 0.1355 (0.0731)	
training:	Epoch: [22][69/204]	Loss 0.0162 (0.0722)	
training:	Epoch: [22][70/204]	Loss 0.0191 (0.0715)	
training:	Epoch: [22][71/204]	Loss 0.0217 (0.0708)	
training:	Epoch: [22][72/204]	Loss 0.1356 (0.0717)	
training:	Epoch: [22][73/204]	Loss 0.2750 (0.0745)	
training:	Epoch: [22][74/204]	Loss 0.0678 (0.0744)	
training:	Epoch: [22][75/204]	Loss 0.0166 (0.0736)	
training:	Epoch: [22][76/204]	Loss 0.0184 (0.0729)	
training:	Epoch: [22][77/204]	Loss 0.2573 (0.0753)	
training:	Epoch: [22][78/204]	Loss 0.1563 (0.0763)	
training:	Epoch: [22][79/204]	Loss 0.3022 (0.0792)	
training:	Epoch: [22][80/204]	Loss 0.0325 (0.0786)	
training:	Epoch: [22][81/204]	Loss 0.1218 (0.0791)	
training:	Epoch: [22][82/204]	Loss 0.1749 (0.0803)	
training:	Epoch: [22][83/204]	Loss 0.1460 (0.0811)	
training:	Epoch: [22][84/204]	Loss 0.2669 (0.0833)	
training:	Epoch: [22][85/204]	Loss 0.0244 (0.0826)	
training:	Epoch: [22][86/204]	Loss 0.0227 (0.0819)	
training:	Epoch: [22][87/204]	Loss 0.0192 (0.0812)	
training:	Epoch: [22][88/204]	Loss 0.1549 (0.0820)	
training:	Epoch: [22][89/204]	Loss 0.1540 (0.0828)	
training:	Epoch: [22][90/204]	Loss 0.0191 (0.0821)	
training:	Epoch: [22][91/204]	Loss 0.0173 (0.0814)	
training:	Epoch: [22][92/204]	Loss 0.0167 (0.0807)	
training:	Epoch: [22][93/204]	Loss 0.2653 (0.0827)	
training:	Epoch: [22][94/204]	Loss 0.0167 (0.0820)	
training:	Epoch: [22][95/204]	Loss 0.0183 (0.0813)	
training:	Epoch: [22][96/204]	Loss 0.1741 (0.0823)	
training:	Epoch: [22][97/204]	Loss 0.0176 (0.0816)	
training:	Epoch: [22][98/204]	Loss 0.1436 (0.0822)	
training:	Epoch: [22][99/204]	Loss 0.0204 (0.0816)	
training:	Epoch: [22][100/204]	Loss 0.0182 (0.0810)	
training:	Epoch: [22][101/204]	Loss 0.0189 (0.0804)	
training:	Epoch: [22][102/204]	Loss 0.0169 (0.0798)	
training:	Epoch: [22][103/204]	Loss 0.1421 (0.0804)	
training:	Epoch: [22][104/204]	Loss 0.0180 (0.0798)	
training:	Epoch: [22][105/204]	Loss 0.1546 (0.0805)	
training:	Epoch: [22][106/204]	Loss 0.0185 (0.0799)	
training:	Epoch: [22][107/204]	Loss 0.0195 (0.0793)	
training:	Epoch: [22][108/204]	Loss 0.0263 (0.0788)	
training:	Epoch: [22][109/204]	Loss 0.0244 (0.0783)	
training:	Epoch: [22][110/204]	Loss 0.0177 (0.0778)	
training:	Epoch: [22][111/204]	Loss 0.0214 (0.0773)	
training:	Epoch: [22][112/204]	Loss 0.0175 (0.0767)	
training:	Epoch: [22][113/204]	Loss 0.0224 (0.0763)	
training:	Epoch: [22][114/204]	Loss 0.1402 (0.0768)	
training:	Epoch: [22][115/204]	Loss 0.0184 (0.0763)	
training:	Epoch: [22][116/204]	Loss 0.1582 (0.0770)	
training:	Epoch: [22][117/204]	Loss 0.0154 (0.0765)	
training:	Epoch: [22][118/204]	Loss 0.0177 (0.0760)	
training:	Epoch: [22][119/204]	Loss 0.0231 (0.0755)	
training:	Epoch: [22][120/204]	Loss 0.0154 (0.0750)	
training:	Epoch: [22][121/204]	Loss 0.1561 (0.0757)	
training:	Epoch: [22][122/204]	Loss 0.0187 (0.0752)	
training:	Epoch: [22][123/204]	Loss 0.2588 (0.0767)	
training:	Epoch: [22][124/204]	Loss 0.1596 (0.0774)	
training:	Epoch: [22][125/204]	Loss 0.0171 (0.0769)	
training:	Epoch: [22][126/204]	Loss 0.0268 (0.0765)	
training:	Epoch: [22][127/204]	Loss 0.0422 (0.0763)	
training:	Epoch: [22][128/204]	Loss 0.1389 (0.0767)	
training:	Epoch: [22][129/204]	Loss 0.0200 (0.0763)	
training:	Epoch: [22][130/204]	Loss 0.0171 (0.0759)	
training:	Epoch: [22][131/204]	Loss 0.0174 (0.0754)	
training:	Epoch: [22][132/204]	Loss 0.0170 (0.0750)	
training:	Epoch: [22][133/204]	Loss 0.1542 (0.0756)	
training:	Epoch: [22][134/204]	Loss 0.0163 (0.0751)	
training:	Epoch: [22][135/204]	Loss 0.0159 (0.0747)	
training:	Epoch: [22][136/204]	Loss 0.0157 (0.0742)	
training:	Epoch: [22][137/204]	Loss 0.1425 (0.0747)	
training:	Epoch: [22][138/204]	Loss 0.0168 (0.0743)	
training:	Epoch: [22][139/204]	Loss 0.1634 (0.0750)	
training:	Epoch: [22][140/204]	Loss 0.0163 (0.0745)	
training:	Epoch: [22][141/204]	Loss 0.0158 (0.0741)	
training:	Epoch: [22][142/204]	Loss 0.0169 (0.0737)	
training:	Epoch: [22][143/204]	Loss 0.0175 (0.0733)	
training:	Epoch: [22][144/204]	Loss 0.0155 (0.0729)	
training:	Epoch: [22][145/204]	Loss 0.0168 (0.0725)	
training:	Epoch: [22][146/204]	Loss 0.2979 (0.0741)	
training:	Epoch: [22][147/204]	Loss 0.0195 (0.0737)	
training:	Epoch: [22][148/204]	Loss 0.0150 (0.0733)	
training:	Epoch: [22][149/204]	Loss 0.1271 (0.0737)	
training:	Epoch: [22][150/204]	Loss 0.0189 (0.0733)	
training:	Epoch: [22][151/204]	Loss 0.0165 (0.0729)	
training:	Epoch: [22][152/204]	Loss 0.0239 (0.0726)	
training:	Epoch: [22][153/204]	Loss 0.1391 (0.0731)	
training:	Epoch: [22][154/204]	Loss 0.0225 (0.0727)	
training:	Epoch: [22][155/204]	Loss 0.0345 (0.0725)	
training:	Epoch: [22][156/204]	Loss 0.2784 (0.0738)	
training:	Epoch: [22][157/204]	Loss 0.1424 (0.0742)	
training:	Epoch: [22][158/204]	Loss 0.0188 (0.0739)	
training:	Epoch: [22][159/204]	Loss 0.0204 (0.0735)	
training:	Epoch: [22][160/204]	Loss 0.1647 (0.0741)	
training:	Epoch: [22][161/204]	Loss 0.0241 (0.0738)	
training:	Epoch: [22][162/204]	Loss 0.1359 (0.0742)	
training:	Epoch: [22][163/204]	Loss 0.0210 (0.0739)	
training:	Epoch: [22][164/204]	Loss 0.0157 (0.0735)	
training:	Epoch: [22][165/204]	Loss 0.0171 (0.0732)	
training:	Epoch: [22][166/204]	Loss 0.1548 (0.0737)	
training:	Epoch: [22][167/204]	Loss 0.0247 (0.0734)	
training:	Epoch: [22][168/204]	Loss 0.0251 (0.0731)	
training:	Epoch: [22][169/204]	Loss 0.1452 (0.0735)	
training:	Epoch: [22][170/204]	Loss 0.0160 (0.0732)	
training:	Epoch: [22][171/204]	Loss 0.0171 (0.0728)	
training:	Epoch: [22][172/204]	Loss 0.1543 (0.0733)	
training:	Epoch: [22][173/204]	Loss 0.0170 (0.0730)	
training:	Epoch: [22][174/204]	Loss 0.0264 (0.0727)	
training:	Epoch: [22][175/204]	Loss 0.0751 (0.0727)	
training:	Epoch: [22][176/204]	Loss 0.0335 (0.0725)	
training:	Epoch: [22][177/204]	Loss 0.2671 (0.0736)	
training:	Epoch: [22][178/204]	Loss 0.0159 (0.0733)	
training:	Epoch: [22][179/204]	Loss 0.0320 (0.0731)	
training:	Epoch: [22][180/204]	Loss 0.0163 (0.0727)	
training:	Epoch: [22][181/204]	Loss 0.0157 (0.0724)	
training:	Epoch: [22][182/204]	Loss 0.0162 (0.0721)	
training:	Epoch: [22][183/204]	Loss 0.0154 (0.0718)	
training:	Epoch: [22][184/204]	Loss 0.0168 (0.0715)	
training:	Epoch: [22][185/204]	Loss 0.1452 (0.0719)	
training:	Epoch: [22][186/204]	Loss 0.0459 (0.0718)	
training:	Epoch: [22][187/204]	Loss 0.1552 (0.0722)	
training:	Epoch: [22][188/204]	Loss 0.0154 (0.0719)	
training:	Epoch: [22][189/204]	Loss 0.0168 (0.0716)	
training:	Epoch: [22][190/204]	Loss 0.1456 (0.0720)	
training:	Epoch: [22][191/204]	Loss 0.0196 (0.0717)	
training:	Epoch: [22][192/204]	Loss 0.0211 (0.0715)	
training:	Epoch: [22][193/204]	Loss 0.2313 (0.0723)	
training:	Epoch: [22][194/204]	Loss 0.1548 (0.0727)	
training:	Epoch: [22][195/204]	Loss 0.1549 (0.0731)	
training:	Epoch: [22][196/204]	Loss 0.0169 (0.0729)	
training:	Epoch: [22][197/204]	Loss 0.1400 (0.0732)	
training:	Epoch: [22][198/204]	Loss 0.1656 (0.0737)	
training:	Epoch: [22][199/204]	Loss 0.0162 (0.0734)	
training:	Epoch: [22][200/204]	Loss 0.0953 (0.0735)	
training:	Epoch: [22][201/204]	Loss 0.0193 (0.0732)	
training:	Epoch: [22][202/204]	Loss 0.0162 (0.0729)	
training:	Epoch: [22][203/204]	Loss 0.0160 (0.0727)	
training:	Epoch: [22][204/204]	Loss 0.0302 (0.0724)	
Training:	 Loss: 0.0723

Training:	 ACC: 0.9884 0.9884 0.9868 0.9901
Validation:	 ACC: 0.7906 0.7924 0.8311 0.7500
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.7700
Pretraining:	Epoch 23/500
----------
training:	Epoch: [23][1/204]	Loss 0.0153 (0.0153)	
training:	Epoch: [23][2/204]	Loss 0.0182 (0.0167)	
training:	Epoch: [23][3/204]	Loss 0.0200 (0.0178)	
training:	Epoch: [23][4/204]	Loss 0.1504 (0.0510)	
training:	Epoch: [23][5/204]	Loss 0.0150 (0.0438)	
training:	Epoch: [23][6/204]	Loss 0.0188 (0.0396)	
training:	Epoch: [23][7/204]	Loss 0.0163 (0.0363)	
training:	Epoch: [23][8/204]	Loss 0.0224 (0.0345)	
training:	Epoch: [23][9/204]	Loss 0.0176 (0.0327)	
training:	Epoch: [23][10/204]	Loss 0.0172 (0.0311)	
training:	Epoch: [23][11/204]	Loss 0.1466 (0.0416)	
training:	Epoch: [23][12/204]	Loss 0.1356 (0.0494)	
training:	Epoch: [23][13/204]	Loss 0.1643 (0.0583)	
training:	Epoch: [23][14/204]	Loss 0.0167 (0.0553)	
training:	Epoch: [23][15/204]	Loss 0.0199 (0.0529)	
training:	Epoch: [23][16/204]	Loss 0.0193 (0.0508)	
training:	Epoch: [23][17/204]	Loss 0.0883 (0.0530)	
training:	Epoch: [23][18/204]	Loss 0.0164 (0.0510)	
training:	Epoch: [23][19/204]	Loss 0.0180 (0.0493)	
training:	Epoch: [23][20/204]	Loss 0.0219 (0.0479)	
training:	Epoch: [23][21/204]	Loss 0.1376 (0.0522)	
training:	Epoch: [23][22/204]	Loss 0.0190 (0.0507)	
training:	Epoch: [23][23/204]	Loss 0.0167 (0.0492)	
training:	Epoch: [23][24/204]	Loss 0.2844 (0.0590)	
training:	Epoch: [23][25/204]	Loss 0.0198 (0.0574)	
training:	Epoch: [23][26/204]	Loss 0.1790 (0.0621)	
training:	Epoch: [23][27/204]	Loss 0.0177 (0.0605)	
training:	Epoch: [23][28/204]	Loss 0.0146 (0.0588)	
training:	Epoch: [23][29/204]	Loss 0.0151 (0.0573)	
training:	Epoch: [23][30/204]	Loss 0.2641 (0.0642)	
training:	Epoch: [23][31/204]	Loss 0.0223 (0.0629)	
training:	Epoch: [23][32/204]	Loss 0.1622 (0.0660)	
training:	Epoch: [23][33/204]	Loss 0.0197 (0.0646)	
training:	Epoch: [23][34/204]	Loss 0.2843 (0.0710)	
training:	Epoch: [23][35/204]	Loss 0.0183 (0.0695)	
training:	Epoch: [23][36/204]	Loss 0.0195 (0.0681)	
training:	Epoch: [23][37/204]	Loss 0.0154 (0.0667)	
training:	Epoch: [23][38/204]	Loss 0.0176 (0.0654)	
training:	Epoch: [23][39/204]	Loss 0.0165 (0.0642)	
training:	Epoch: [23][40/204]	Loss 0.1413 (0.0661)	
training:	Epoch: [23][41/204]	Loss 0.0164 (0.0649)	
training:	Epoch: [23][42/204]	Loss 0.0154 (0.0637)	
training:	Epoch: [23][43/204]	Loss 0.0167 (0.0626)	
training:	Epoch: [23][44/204]	Loss 0.0161 (0.0615)	
training:	Epoch: [23][45/204]	Loss 0.0188 (0.0606)	
training:	Epoch: [23][46/204]	Loss 0.0177 (0.0597)	
training:	Epoch: [23][47/204]	Loss 0.0161 (0.0587)	
training:	Epoch: [23][48/204]	Loss 0.1496 (0.0606)	
training:	Epoch: [23][49/204]	Loss 0.2888 (0.0653)	
training:	Epoch: [23][50/204]	Loss 0.0160 (0.0643)	
training:	Epoch: [23][51/204]	Loss 0.0180 (0.0634)	
training:	Epoch: [23][52/204]	Loss 0.0295 (0.0627)	
training:	Epoch: [23][53/204]	Loss 0.0151 (0.0618)	
training:	Epoch: [23][54/204]	Loss 0.1576 (0.0636)	
training:	Epoch: [23][55/204]	Loss 0.1541 (0.0653)	
training:	Epoch: [23][56/204]	Loss 0.0216 (0.0645)	
training:	Epoch: [23][57/204]	Loss 0.0154 (0.0636)	
training:	Epoch: [23][58/204]	Loss 0.0190 (0.0629)	
training:	Epoch: [23][59/204]	Loss 0.1597 (0.0645)	
training:	Epoch: [23][60/204]	Loss 0.0162 (0.0637)	
training:	Epoch: [23][61/204]	Loss 0.0160 (0.0629)	
training:	Epoch: [23][62/204]	Loss 0.0170 (0.0622)	
training:	Epoch: [23][63/204]	Loss 0.0183 (0.0615)	
training:	Epoch: [23][64/204]	Loss 0.0161 (0.0608)	
training:	Epoch: [23][65/204]	Loss 0.0157 (0.0601)	
training:	Epoch: [23][66/204]	Loss 0.0169 (0.0594)	
training:	Epoch: [23][67/204]	Loss 0.0223 (0.0589)	
training:	Epoch: [23][68/204]	Loss 0.0173 (0.0582)	
training:	Epoch: [23][69/204]	Loss 0.1508 (0.0596)	
training:	Epoch: [23][70/204]	Loss 0.0180 (0.0590)	
training:	Epoch: [23][71/204]	Loss 0.0146 (0.0584)	
training:	Epoch: [23][72/204]	Loss 0.2688 (0.0613)	
training:	Epoch: [23][73/204]	Loss 0.0180 (0.0607)	
training:	Epoch: [23][74/204]	Loss 0.0463 (0.0605)	
training:	Epoch: [23][75/204]	Loss 0.2708 (0.0633)	
training:	Epoch: [23][76/204]	Loss 0.0171 (0.0627)	
training:	Epoch: [23][77/204]	Loss 0.0156 (0.0621)	
training:	Epoch: [23][78/204]	Loss 0.1572 (0.0633)	
training:	Epoch: [23][79/204]	Loss 0.0144 (0.0627)	
training:	Epoch: [23][80/204]	Loss 0.1468 (0.0637)	
training:	Epoch: [23][81/204]	Loss 0.0147 (0.0631)	
training:	Epoch: [23][82/204]	Loss 0.0192 (0.0626)	
training:	Epoch: [23][83/204]	Loss 0.0524 (0.0625)	
training:	Epoch: [23][84/204]	Loss 0.0151 (0.0619)	
training:	Epoch: [23][85/204]	Loss 0.0482 (0.0618)	
training:	Epoch: [23][86/204]	Loss 0.0157 (0.0612)	
training:	Epoch: [23][87/204]	Loss 0.1545 (0.0623)	
training:	Epoch: [23][88/204]	Loss 0.0956 (0.0627)	
training:	Epoch: [23][89/204]	Loss 0.0160 (0.0621)	
training:	Epoch: [23][90/204]	Loss 0.0149 (0.0616)	
training:	Epoch: [23][91/204]	Loss 0.0164 (0.0611)	
training:	Epoch: [23][92/204]	Loss 0.0162 (0.0606)	
training:	Epoch: [23][93/204]	Loss 0.1437 (0.0615)	
training:	Epoch: [23][94/204]	Loss 0.0161 (0.0610)	
training:	Epoch: [23][95/204]	Loss 0.0155 (0.0606)	
training:	Epoch: [23][96/204]	Loss 0.0158 (0.0601)	
training:	Epoch: [23][97/204]	Loss 0.0153 (0.0596)	
training:	Epoch: [23][98/204]	Loss 0.1365 (0.0604)	
training:	Epoch: [23][99/204]	Loss 0.0245 (0.0601)	
training:	Epoch: [23][100/204]	Loss 0.0676 (0.0601)	
training:	Epoch: [23][101/204]	Loss 0.0169 (0.0597)	
training:	Epoch: [23][102/204]	Loss 0.0168 (0.0593)	
training:	Epoch: [23][103/204]	Loss 0.0203 (0.0589)	
training:	Epoch: [23][104/204]	Loss 0.1360 (0.0596)	
training:	Epoch: [23][105/204]	Loss 0.3424 (0.0623)	
training:	Epoch: [23][106/204]	Loss 0.2661 (0.0643)	
training:	Epoch: [23][107/204]	Loss 0.0370 (0.0640)	
training:	Epoch: [23][108/204]	Loss 0.0148 (0.0635)	
training:	Epoch: [23][109/204]	Loss 0.0232 (0.0632)	
training:	Epoch: [23][110/204]	Loss 0.0728 (0.0633)	
training:	Epoch: [23][111/204]	Loss 0.1445 (0.0640)	
training:	Epoch: [23][112/204]	Loss 0.0283 (0.0637)	
training:	Epoch: [23][113/204]	Loss 0.0172 (0.0633)	
training:	Epoch: [23][114/204]	Loss 0.0152 (0.0628)	
training:	Epoch: [23][115/204]	Loss 0.1389 (0.0635)	
training:	Epoch: [23][116/204]	Loss 0.0193 (0.0631)	
training:	Epoch: [23][117/204]	Loss 0.1904 (0.0642)	
training:	Epoch: [23][118/204]	Loss 0.0983 (0.0645)	
training:	Epoch: [23][119/204]	Loss 0.2763 (0.0663)	
training:	Epoch: [23][120/204]	Loss 0.0636 (0.0663)	
training:	Epoch: [23][121/204]	Loss 0.0157 (0.0658)	
training:	Epoch: [23][122/204]	Loss 0.0184 (0.0655)	
training:	Epoch: [23][123/204]	Loss 0.0166 (0.0651)	
training:	Epoch: [23][124/204]	Loss 0.0216 (0.0647)	
training:	Epoch: [23][125/204]	Loss 0.0160 (0.0643)	
training:	Epoch: [23][126/204]	Loss 0.0142 (0.0639)	
training:	Epoch: [23][127/204]	Loss 0.0230 (0.0636)	
training:	Epoch: [23][128/204]	Loss 0.0170 (0.0632)	
training:	Epoch: [23][129/204]	Loss 0.0167 (0.0629)	
training:	Epoch: [23][130/204]	Loss 0.0149 (0.0625)	
training:	Epoch: [23][131/204]	Loss 0.2241 (0.0637)	
training:	Epoch: [23][132/204]	Loss 0.0133 (0.0634)	
training:	Epoch: [23][133/204]	Loss 0.0180 (0.0630)	
training:	Epoch: [23][134/204]	Loss 0.0359 (0.0628)	
training:	Epoch: [23][135/204]	Loss 0.0200 (0.0625)	
training:	Epoch: [23][136/204]	Loss 0.0146 (0.0621)	
training:	Epoch: [23][137/204]	Loss 0.0181 (0.0618)	
training:	Epoch: [23][138/204]	Loss 0.0327 (0.0616)	
training:	Epoch: [23][139/204]	Loss 0.0147 (0.0613)	
training:	Epoch: [23][140/204]	Loss 0.0169 (0.0610)	
training:	Epoch: [23][141/204]	Loss 0.0157 (0.0606)	
training:	Epoch: [23][142/204]	Loss 0.0180 (0.0603)	
training:	Epoch: [23][143/204]	Loss 0.0558 (0.0603)	
training:	Epoch: [23][144/204]	Loss 0.0154 (0.0600)	
training:	Epoch: [23][145/204]	Loss 0.0165 (0.0597)	
training:	Epoch: [23][146/204]	Loss 0.0146 (0.0594)	
training:	Epoch: [23][147/204]	Loss 0.0168 (0.0591)	
training:	Epoch: [23][148/204]	Loss 0.0345 (0.0589)	
training:	Epoch: [23][149/204]	Loss 0.0143 (0.0586)	
training:	Epoch: [23][150/204]	Loss 0.0173 (0.0584)	
training:	Epoch: [23][151/204]	Loss 0.0155 (0.0581)	
training:	Epoch: [23][152/204]	Loss 0.0143 (0.0578)	
training:	Epoch: [23][153/204]	Loss 0.0146 (0.0575)	
training:	Epoch: [23][154/204]	Loss 0.0148 (0.0572)	
training:	Epoch: [23][155/204]	Loss 0.1413 (0.0578)	
training:	Epoch: [23][156/204]	Loss 0.0164 (0.0575)	
training:	Epoch: [23][157/204]	Loss 0.1416 (0.0580)	
training:	Epoch: [23][158/204]	Loss 0.0147 (0.0578)	
training:	Epoch: [23][159/204]	Loss 0.0203 (0.0575)	
training:	Epoch: [23][160/204]	Loss 0.0380 (0.0574)	
training:	Epoch: [23][161/204]	Loss 0.0163 (0.0571)	
training:	Epoch: [23][162/204]	Loss 0.1589 (0.0578)	
training:	Epoch: [23][163/204]	Loss 0.2911 (0.0592)	
training:	Epoch: [23][164/204]	Loss 0.0149 (0.0589)	
training:	Epoch: [23][165/204]	Loss 0.0160 (0.0587)	
training:	Epoch: [23][166/204]	Loss 0.2822 (0.0600)	
training:	Epoch: [23][167/204]	Loss 0.1446 (0.0605)	
training:	Epoch: [23][168/204]	Loss 0.0164 (0.0603)	
training:	Epoch: [23][169/204]	Loss 0.0165 (0.0600)	
training:	Epoch: [23][170/204]	Loss 0.1029 (0.0603)	
training:	Epoch: [23][171/204]	Loss 0.2816 (0.0616)	
training:	Epoch: [23][172/204]	Loss 0.1574 (0.0621)	
training:	Epoch: [23][173/204]	Loss 0.1401 (0.0626)	
training:	Epoch: [23][174/204]	Loss 0.0155 (0.0623)	
training:	Epoch: [23][175/204]	Loss 0.0149 (0.0620)	
training:	Epoch: [23][176/204]	Loss 0.0172 (0.0618)	
training:	Epoch: [23][177/204]	Loss 0.0170 (0.0615)	
training:	Epoch: [23][178/204]	Loss 0.0173 (0.0613)	
training:	Epoch: [23][179/204]	Loss 0.1536 (0.0618)	
training:	Epoch: [23][180/204]	Loss 0.0211 (0.0616)	
training:	Epoch: [23][181/204]	Loss 0.0141 (0.0613)	
training:	Epoch: [23][182/204]	Loss 0.1512 (0.0618)	
training:	Epoch: [23][183/204]	Loss 0.0159 (0.0615)	
training:	Epoch: [23][184/204]	Loss 0.3952 (0.0633)	
training:	Epoch: [23][185/204]	Loss 0.0158 (0.0631)	
training:	Epoch: [23][186/204]	Loss 0.0212 (0.0629)	
training:	Epoch: [23][187/204]	Loss 0.0169 (0.0626)	
training:	Epoch: [23][188/204]	Loss 0.2704 (0.0637)	
training:	Epoch: [23][189/204]	Loss 0.1542 (0.0642)	
training:	Epoch: [23][190/204]	Loss 0.1437 (0.0646)	
training:	Epoch: [23][191/204]	Loss 0.1443 (0.0650)	
training:	Epoch: [23][192/204]	Loss 0.1609 (0.0655)	
training:	Epoch: [23][193/204]	Loss 0.0149 (0.0653)	
training:	Epoch: [23][194/204]	Loss 0.1374 (0.0656)	
training:	Epoch: [23][195/204]	Loss 0.0149 (0.0654)	
training:	Epoch: [23][196/204]	Loss 0.0146 (0.0651)	
training:	Epoch: [23][197/204]	Loss 0.2541 (0.0661)	
training:	Epoch: [23][198/204]	Loss 0.0215 (0.0659)	
training:	Epoch: [23][199/204]	Loss 0.2757 (0.0669)	
training:	Epoch: [23][200/204]	Loss 0.0164 (0.0667)	
training:	Epoch: [23][201/204]	Loss 0.0168 (0.0664)	
training:	Epoch: [23][202/204]	Loss 0.0145 (0.0662)	
training:	Epoch: [23][203/204]	Loss 0.2353 (0.0670)	
training:	Epoch: [23][204/204]	Loss 0.2887 (0.0681)	
Training:	 Loss: 0.0680

Training:	 ACC: 0.9886 0.9885 0.9874 0.9898
Validation:	 ACC: 0.7850 0.7865 0.8188 0.7511
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.7831
Pretraining:	Epoch 24/500
----------
training:	Epoch: [24][1/204]	Loss 0.1557 (0.1557)	
training:	Epoch: [24][2/204]	Loss 0.1262 (0.1409)	
training:	Epoch: [24][3/204]	Loss 0.0156 (0.0992)	
training:	Epoch: [24][4/204]	Loss 0.0343 (0.0829)	
training:	Epoch: [24][5/204]	Loss 0.0197 (0.0703)	
training:	Epoch: [24][6/204]	Loss 0.0133 (0.0608)	
training:	Epoch: [24][7/204]	Loss 0.0165 (0.0545)	
training:	Epoch: [24][8/204]	Loss 0.0164 (0.0497)	
training:	Epoch: [24][9/204]	Loss 0.0150 (0.0458)	
training:	Epoch: [24][10/204]	Loss 0.0156 (0.0428)	
training:	Epoch: [24][11/204]	Loss 0.0159 (0.0404)	
training:	Epoch: [24][12/204]	Loss 0.0326 (0.0397)	
training:	Epoch: [24][13/204]	Loss 0.0159 (0.0379)	
training:	Epoch: [24][14/204]	Loss 0.1532 (0.0461)	
training:	Epoch: [24][15/204]	Loss 0.0148 (0.0440)	
training:	Epoch: [24][16/204]	Loss 0.1363 (0.0498)	
training:	Epoch: [24][17/204]	Loss 0.1483 (0.0556)	
training:	Epoch: [24][18/204]	Loss 0.2716 (0.0676)	
training:	Epoch: [24][19/204]	Loss 0.0147 (0.0648)	
training:	Epoch: [24][20/204]	Loss 0.0159 (0.0624)	
training:	Epoch: [24][21/204]	Loss 0.0184 (0.0603)	
training:	Epoch: [24][22/204]	Loss 0.0191 (0.0584)	
training:	Epoch: [24][23/204]	Loss 0.0307 (0.0572)	
training:	Epoch: [24][24/204]	Loss 0.0159 (0.0555)	
training:	Epoch: [24][25/204]	Loss 0.0181 (0.0540)	
training:	Epoch: [24][26/204]	Loss 0.2670 (0.0622)	
training:	Epoch: [24][27/204]	Loss 0.1598 (0.0658)	
training:	Epoch: [24][28/204]	Loss 0.0234 (0.0643)	
training:	Epoch: [24][29/204]	Loss 0.1504 (0.0673)	
training:	Epoch: [24][30/204]	Loss 0.0561 (0.0669)	
training:	Epoch: [24][31/204]	Loss 0.0188 (0.0653)	
training:	Epoch: [24][32/204]	Loss 0.2928 (0.0724)	
training:	Epoch: [24][33/204]	Loss 0.0571 (0.0720)	
training:	Epoch: [24][34/204]	Loss 0.0249 (0.0706)	
training:	Epoch: [24][35/204]	Loss 0.0138 (0.0690)	
training:	Epoch: [24][36/204]	Loss 0.0144 (0.0675)	
training:	Epoch: [24][37/204]	Loss 0.0140 (0.0660)	
training:	Epoch: [24][38/204]	Loss 0.0146 (0.0647)	
training:	Epoch: [24][39/204]	Loss 0.0172 (0.0634)	
training:	Epoch: [24][40/204]	Loss 0.1515 (0.0656)	
training:	Epoch: [24][41/204]	Loss 0.1329 (0.0673)	
training:	Epoch: [24][42/204]	Loss 0.1567 (0.0694)	
training:	Epoch: [24][43/204]	Loss 0.0153 (0.0682)	
training:	Epoch: [24][44/204]	Loss 0.0163 (0.0670)	
training:	Epoch: [24][45/204]	Loss 0.0211 (0.0660)	
training:	Epoch: [24][46/204]	Loss 0.0176 (0.0649)	
training:	Epoch: [24][47/204]	Loss 0.1087 (0.0658)	
training:	Epoch: [24][48/204]	Loss 0.1434 (0.0675)	
training:	Epoch: [24][49/204]	Loss 0.0167 (0.0664)	
training:	Epoch: [24][50/204]	Loss 0.1410 (0.0679)	
training:	Epoch: [24][51/204]	Loss 0.0147 (0.0669)	
training:	Epoch: [24][52/204]	Loss 0.1496 (0.0685)	
training:	Epoch: [24][53/204]	Loss 0.1520 (0.0700)	
training:	Epoch: [24][54/204]	Loss 0.2592 (0.0735)	
training:	Epoch: [24][55/204]	Loss 0.0520 (0.0731)	
training:	Epoch: [24][56/204]	Loss 0.1474 (0.0745)	
training:	Epoch: [24][57/204]	Loss 0.0364 (0.0738)	
training:	Epoch: [24][58/204]	Loss 0.2342 (0.0766)	
training:	Epoch: [24][59/204]	Loss 0.0168 (0.0756)	
training:	Epoch: [24][60/204]	Loss 0.0917 (0.0758)	
training:	Epoch: [24][61/204]	Loss 0.1513 (0.0771)	
training:	Epoch: [24][62/204]	Loss 0.0210 (0.0762)	
training:	Epoch: [24][63/204]	Loss 0.1453 (0.0773)	
training:	Epoch: [24][64/204]	Loss 0.0244 (0.0764)	
training:	Epoch: [24][65/204]	Loss 0.0171 (0.0755)	
training:	Epoch: [24][66/204]	Loss 0.1438 (0.0766)	
training:	Epoch: [24][67/204]	Loss 0.0182 (0.0757)	
training:	Epoch: [24][68/204]	Loss 0.0145 (0.0748)	
training:	Epoch: [24][69/204]	Loss 0.0159 (0.0739)	
training:	Epoch: [24][70/204]	Loss 0.0648 (0.0738)	
training:	Epoch: [24][71/204]	Loss 0.0150 (0.0730)	
training:	Epoch: [24][72/204]	Loss 0.2805 (0.0759)	
training:	Epoch: [24][73/204]	Loss 0.1350 (0.0767)	
training:	Epoch: [24][74/204]	Loss 0.0166 (0.0759)	
training:	Epoch: [24][75/204]	Loss 0.0155 (0.0750)	
training:	Epoch: [24][76/204]	Loss 0.0160 (0.0743)	
training:	Epoch: [24][77/204]	Loss 0.0159 (0.0735)	
training:	Epoch: [24][78/204]	Loss 0.0212 (0.0728)	
training:	Epoch: [24][79/204]	Loss 0.0364 (0.0724)	
training:	Epoch: [24][80/204]	Loss 0.1442 (0.0733)	
training:	Epoch: [24][81/204]	Loss 0.4233 (0.0776)	
training:	Epoch: [24][82/204]	Loss 0.0273 (0.0770)	
training:	Epoch: [24][83/204]	Loss 0.1009 (0.0773)	
training:	Epoch: [24][84/204]	Loss 0.0329 (0.0767)	
training:	Epoch: [24][85/204]	Loss 0.1715 (0.0779)	
training:	Epoch: [24][86/204]	Loss 0.1842 (0.0791)	
training:	Epoch: [24][87/204]	Loss 0.0223 (0.0784)	
training:	Epoch: [24][88/204]	Loss 0.1337 (0.0791)	
training:	Epoch: [24][89/204]	Loss 0.0293 (0.0785)	
training:	Epoch: [24][90/204]	Loss 0.1832 (0.0797)	
training:	Epoch: [24][91/204]	Loss 0.0586 (0.0794)	
training:	Epoch: [24][92/204]	Loss 0.1835 (0.0806)	
training:	Epoch: [24][93/204]	Loss 0.0564 (0.0803)	
training:	Epoch: [24][94/204]	Loss 0.0145 (0.0796)	
training:	Epoch: [24][95/204]	Loss 0.2807 (0.0817)	
training:	Epoch: [24][96/204]	Loss 0.0180 (0.0811)	
training:	Epoch: [24][97/204]	Loss 0.0445 (0.0807)	
training:	Epoch: [24][98/204]	Loss 0.0231 (0.0801)	
training:	Epoch: [24][99/204]	Loss 0.0159 (0.0795)	
training:	Epoch: [24][100/204]	Loss 0.0155 (0.0788)	
training:	Epoch: [24][101/204]	Loss 0.2851 (0.0809)	
training:	Epoch: [24][102/204]	Loss 0.0626 (0.0807)	
training:	Epoch: [24][103/204]	Loss 0.0161 (0.0800)	
training:	Epoch: [24][104/204]	Loss 0.0158 (0.0794)	
training:	Epoch: [24][105/204]	Loss 0.0410 (0.0791)	
training:	Epoch: [24][106/204]	Loss 0.0156 (0.0785)	
training:	Epoch: [24][107/204]	Loss 0.0216 (0.0779)	
training:	Epoch: [24][108/204]	Loss 0.0148 (0.0774)	
training:	Epoch: [24][109/204]	Loss 0.0484 (0.0771)	
training:	Epoch: [24][110/204]	Loss 0.0163 (0.0765)	
training:	Epoch: [24][111/204]	Loss 0.1546 (0.0772)	
training:	Epoch: [24][112/204]	Loss 0.0292 (0.0768)	
training:	Epoch: [24][113/204]	Loss 0.0154 (0.0763)	
training:	Epoch: [24][114/204]	Loss 0.0167 (0.0757)	
training:	Epoch: [24][115/204]	Loss 0.1118 (0.0761)	
training:	Epoch: [24][116/204]	Loss 0.0519 (0.0758)	
training:	Epoch: [24][117/204]	Loss 0.1378 (0.0764)	
training:	Epoch: [24][118/204]	Loss 0.0177 (0.0759)	
training:	Epoch: [24][119/204]	Loss 0.0150 (0.0754)	
training:	Epoch: [24][120/204]	Loss 0.0174 (0.0749)	
training:	Epoch: [24][121/204]	Loss 0.0198 (0.0744)	
training:	Epoch: [24][122/204]	Loss 0.0151 (0.0739)	
training:	Epoch: [24][123/204]	Loss 0.0263 (0.0736)	
training:	Epoch: [24][124/204]	Loss 0.0176 (0.0731)	
training:	Epoch: [24][125/204]	Loss 0.0168 (0.0727)	
training:	Epoch: [24][126/204]	Loss 0.0139 (0.0722)	
training:	Epoch: [24][127/204]	Loss 0.0158 (0.0717)	
training:	Epoch: [24][128/204]	Loss 0.0415 (0.0715)	
training:	Epoch: [24][129/204]	Loss 0.0171 (0.0711)	
training:	Epoch: [24][130/204]	Loss 0.1630 (0.0718)	
training:	Epoch: [24][131/204]	Loss 0.0271 (0.0715)	
training:	Epoch: [24][132/204]	Loss 0.0160 (0.0710)	
training:	Epoch: [24][133/204]	Loss 0.1520 (0.0716)	
training:	Epoch: [24][134/204]	Loss 0.0151 (0.0712)	
training:	Epoch: [24][135/204]	Loss 0.0141 (0.0708)	
training:	Epoch: [24][136/204]	Loss 0.1537 (0.0714)	
training:	Epoch: [24][137/204]	Loss 0.1387 (0.0719)	
training:	Epoch: [24][138/204]	Loss 0.1416 (0.0724)	
training:	Epoch: [24][139/204]	Loss 0.1505 (0.0730)	
training:	Epoch: [24][140/204]	Loss 0.0153 (0.0726)	
training:	Epoch: [24][141/204]	Loss 0.1453 (0.0731)	
training:	Epoch: [24][142/204]	Loss 0.0155 (0.0727)	
training:	Epoch: [24][143/204]	Loss 0.0153 (0.0723)	
training:	Epoch: [24][144/204]	Loss 0.0168 (0.0719)	
training:	Epoch: [24][145/204]	Loss 0.0552 (0.0718)	
training:	Epoch: [24][146/204]	Loss 0.0188 (0.0714)	
training:	Epoch: [24][147/204]	Loss 0.0270 (0.0711)	
training:	Epoch: [24][148/204]	Loss 0.0177 (0.0707)	
training:	Epoch: [24][149/204]	Loss 0.0604 (0.0707)	
training:	Epoch: [24][150/204]	Loss 0.0142 (0.0703)	
training:	Epoch: [24][151/204]	Loss 0.0152 (0.0699)	
training:	Epoch: [24][152/204]	Loss 0.0155 (0.0696)	
training:	Epoch: [24][153/204]	Loss 0.1418 (0.0700)	
training:	Epoch: [24][154/204]	Loss 0.0157 (0.0697)	
training:	Epoch: [24][155/204]	Loss 0.0150 (0.0693)	
training:	Epoch: [24][156/204]	Loss 0.1487 (0.0698)	
training:	Epoch: [24][157/204]	Loss 0.0148 (0.0695)	
training:	Epoch: [24][158/204]	Loss 0.0246 (0.0692)	
training:	Epoch: [24][159/204]	Loss 0.1458 (0.0697)	
training:	Epoch: [24][160/204]	Loss 0.0148 (0.0693)	
training:	Epoch: [24][161/204]	Loss 0.1499 (0.0698)	
training:	Epoch: [24][162/204]	Loss 0.0149 (0.0695)	
training:	Epoch: [24][163/204]	Loss 0.1771 (0.0702)	
training:	Epoch: [24][164/204]	Loss 0.1559 (0.0707)	
training:	Epoch: [24][165/204]	Loss 0.1331 (0.0711)	
training:	Epoch: [24][166/204]	Loss 0.0157 (0.0707)	
training:	Epoch: [24][167/204]	Loss 0.0170 (0.0704)	
training:	Epoch: [24][168/204]	Loss 0.0216 (0.0701)	
training:	Epoch: [24][169/204]	Loss 0.1416 (0.0705)	
training:	Epoch: [24][170/204]	Loss 0.1450 (0.0710)	
training:	Epoch: [24][171/204]	Loss 0.0743 (0.0710)	
training:	Epoch: [24][172/204]	Loss 0.0147 (0.0707)	
training:	Epoch: [24][173/204]	Loss 0.0135 (0.0703)	
training:	Epoch: [24][174/204]	Loss 0.0144 (0.0700)	
training:	Epoch: [24][175/204]	Loss 0.0231 (0.0698)	
training:	Epoch: [24][176/204]	Loss 0.1355 (0.0701)	
training:	Epoch: [24][177/204]	Loss 0.0259 (0.0699)	
training:	Epoch: [24][178/204]	Loss 0.0143 (0.0696)	
training:	Epoch: [24][179/204]	Loss 0.0158 (0.0693)	
training:	Epoch: [24][180/204]	Loss 0.0162 (0.0690)	
training:	Epoch: [24][181/204]	Loss 0.1434 (0.0694)	
training:	Epoch: [24][182/204]	Loss 0.2972 (0.0706)	
training:	Epoch: [24][183/204]	Loss 0.1502 (0.0711)	
training:	Epoch: [24][184/204]	Loss 0.0152 (0.0708)	
training:	Epoch: [24][185/204]	Loss 0.0150 (0.0705)	
training:	Epoch: [24][186/204]	Loss 0.0181 (0.0702)	
training:	Epoch: [24][187/204]	Loss 0.0199 (0.0699)	
training:	Epoch: [24][188/204]	Loss 0.0220 (0.0697)	
training:	Epoch: [24][189/204]	Loss 0.0170 (0.0694)	
training:	Epoch: [24][190/204]	Loss 0.1272 (0.0697)	
training:	Epoch: [24][191/204]	Loss 0.3038 (0.0709)	
training:	Epoch: [24][192/204]	Loss 0.0156 (0.0706)	
training:	Epoch: [24][193/204]	Loss 0.0155 (0.0703)	
training:	Epoch: [24][194/204]	Loss 0.0182 (0.0701)	
training:	Epoch: [24][195/204]	Loss 0.0156 (0.0698)	
training:	Epoch: [24][196/204]	Loss 0.1373 (0.0701)	
training:	Epoch: [24][197/204]	Loss 0.1444 (0.0705)	
training:	Epoch: [24][198/204]	Loss 0.0158 (0.0702)	
training:	Epoch: [24][199/204]	Loss 0.0541 (0.0702)	
training:	Epoch: [24][200/204]	Loss 0.1546 (0.0706)	
training:	Epoch: [24][201/204]	Loss 0.0145 (0.0703)	
training:	Epoch: [24][202/204]	Loss 0.0146 (0.0700)	
training:	Epoch: [24][203/204]	Loss 0.1551 (0.0704)	
training:	Epoch: [24][204/204]	Loss 0.0151 (0.0702)	
Training:	 Loss: 0.0701

Training:	 ACC: 0.9876 0.9875 0.9850 0.9901
Validation:	 ACC: 0.7843 0.7838 0.7748 0.7937
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8010
Pretraining:	Epoch 25/500
----------
training:	Epoch: [25][1/204]	Loss 0.0155 (0.0155)	
training:	Epoch: [25][2/204]	Loss 0.0347 (0.0251)	
training:	Epoch: [25][3/204]	Loss 0.0143 (0.0215)	
training:	Epoch: [25][4/204]	Loss 0.0343 (0.0247)	
training:	Epoch: [25][5/204]	Loss 0.2896 (0.0777)	
training:	Epoch: [25][6/204]	Loss 0.1471 (0.0892)	
training:	Epoch: [25][7/204]	Loss 0.1697 (0.1007)	
training:	Epoch: [25][8/204]	Loss 0.0142 (0.0899)	
training:	Epoch: [25][9/204]	Loss 0.0156 (0.0817)	
training:	Epoch: [25][10/204]	Loss 0.1110 (0.0846)	
training:	Epoch: [25][11/204]	Loss 0.1412 (0.0897)	
training:	Epoch: [25][12/204]	Loss 0.0175 (0.0837)	
training:	Epoch: [25][13/204]	Loss 0.0157 (0.0785)	
training:	Epoch: [25][14/204]	Loss 0.0149 (0.0739)	
training:	Epoch: [25][15/204]	Loss 0.1312 (0.0778)	
training:	Epoch: [25][16/204]	Loss 0.0164 (0.0739)	
training:	Epoch: [25][17/204]	Loss 0.1520 (0.0785)	
training:	Epoch: [25][18/204]	Loss 0.0168 (0.0751)	
training:	Epoch: [25][19/204]	Loss 0.0170 (0.0720)	
training:	Epoch: [25][20/204]	Loss 0.2625 (0.0816)	
training:	Epoch: [25][21/204]	Loss 0.0171 (0.0785)	
training:	Epoch: [25][22/204]	Loss 0.2602 (0.0867)	
training:	Epoch: [25][23/204]	Loss 0.0136 (0.0836)	
training:	Epoch: [25][24/204]	Loss 0.0149 (0.0807)	
training:	Epoch: [25][25/204]	Loss 0.0165 (0.0781)	
training:	Epoch: [25][26/204]	Loss 0.0153 (0.0757)	
training:	Epoch: [25][27/204]	Loss 0.0159 (0.0735)	
training:	Epoch: [25][28/204]	Loss 0.0328 (0.0721)	
training:	Epoch: [25][29/204]	Loss 0.0138 (0.0700)	
training:	Epoch: [25][30/204]	Loss 0.0153 (0.0682)	
training:	Epoch: [25][31/204]	Loss 0.0211 (0.0667)	
training:	Epoch: [25][32/204]	Loss 0.0160 (0.0651)	
training:	Epoch: [25][33/204]	Loss 0.0149 (0.0636)	
training:	Epoch: [25][34/204]	Loss 0.0228 (0.0624)	
training:	Epoch: [25][35/204]	Loss 0.1507 (0.0649)	
training:	Epoch: [25][36/204]	Loss 0.1506 (0.0673)	
training:	Epoch: [25][37/204]	Loss 0.0167 (0.0659)	
training:	Epoch: [25][38/204]	Loss 0.0142 (0.0646)	
training:	Epoch: [25][39/204]	Loss 0.0140 (0.0633)	
training:	Epoch: [25][40/204]	Loss 0.0154 (0.0621)	
training:	Epoch: [25][41/204]	Loss 0.0228 (0.0611)	
training:	Epoch: [25][42/204]	Loss 0.0173 (0.0601)	
training:	Epoch: [25][43/204]	Loss 0.2652 (0.0648)	
training:	Epoch: [25][44/204]	Loss 0.0299 (0.0641)	
training:	Epoch: [25][45/204]	Loss 0.0159 (0.0630)	
training:	Epoch: [25][46/204]	Loss 0.0151 (0.0619)	
training:	Epoch: [25][47/204]	Loss 0.0152 (0.0609)	
training:	Epoch: [25][48/204]	Loss 0.0145 (0.0600)	
training:	Epoch: [25][49/204]	Loss 0.0157 (0.0591)	
training:	Epoch: [25][50/204]	Loss 0.0159 (0.0582)	
training:	Epoch: [25][51/204]	Loss 0.0269 (0.0576)	
training:	Epoch: [25][52/204]	Loss 0.0140 (0.0568)	
training:	Epoch: [25][53/204]	Loss 0.0153 (0.0560)	
training:	Epoch: [25][54/204]	Loss 0.3526 (0.0615)	
training:	Epoch: [25][55/204]	Loss 0.1415 (0.0629)	
training:	Epoch: [25][56/204]	Loss 0.0142 (0.0621)	
training:	Epoch: [25][57/204]	Loss 0.0153 (0.0612)	
training:	Epoch: [25][58/204]	Loss 0.0145 (0.0604)	
training:	Epoch: [25][59/204]	Loss 0.1451 (0.0619)	
training:	Epoch: [25][60/204]	Loss 0.0162 (0.0611)	
training:	Epoch: [25][61/204]	Loss 0.0247 (0.0605)	
training:	Epoch: [25][62/204]	Loss 0.0151 (0.0598)	
training:	Epoch: [25][63/204]	Loss 0.0167 (0.0591)	
training:	Epoch: [25][64/204]	Loss 0.1598 (0.0607)	
training:	Epoch: [25][65/204]	Loss 0.0172 (0.0600)	
training:	Epoch: [25][66/204]	Loss 0.0134 (0.0593)	
training:	Epoch: [25][67/204]	Loss 0.0150 (0.0586)	
training:	Epoch: [25][68/204]	Loss 0.0179 (0.0580)	
training:	Epoch: [25][69/204]	Loss 0.0137 (0.0574)	
training:	Epoch: [25][70/204]	Loss 0.1607 (0.0589)	
training:	Epoch: [25][71/204]	Loss 0.0144 (0.0582)	
training:	Epoch: [25][72/204]	Loss 0.0195 (0.0577)	
training:	Epoch: [25][73/204]	Loss 0.1364 (0.0588)	
training:	Epoch: [25][74/204]	Loss 0.0147 (0.0582)	
training:	Epoch: [25][75/204]	Loss 0.0165 (0.0576)	
training:	Epoch: [25][76/204]	Loss 0.0149 (0.0571)	
training:	Epoch: [25][77/204]	Loss 0.0150 (0.0565)	
training:	Epoch: [25][78/204]	Loss 0.1570 (0.0578)	
training:	Epoch: [25][79/204]	Loss 0.1516 (0.0590)	
training:	Epoch: [25][80/204]	Loss 0.0171 (0.0585)	
training:	Epoch: [25][81/204]	Loss 0.1390 (0.0595)	
training:	Epoch: [25][82/204]	Loss 0.2871 (0.0622)	
training:	Epoch: [25][83/204]	Loss 0.0308 (0.0619)	
training:	Epoch: [25][84/204]	Loss 0.1582 (0.0630)	
training:	Epoch: [25][85/204]	Loss 0.0172 (0.0625)	
training:	Epoch: [25][86/204]	Loss 0.0129 (0.0619)	
training:	Epoch: [25][87/204]	Loss 0.0148 (0.0614)	
training:	Epoch: [25][88/204]	Loss 0.0150 (0.0608)	
training:	Epoch: [25][89/204]	Loss 0.0135 (0.0603)	
training:	Epoch: [25][90/204]	Loss 0.1402 (0.0612)	
training:	Epoch: [25][91/204]	Loss 0.0383 (0.0609)	
training:	Epoch: [25][92/204]	Loss 0.0134 (0.0604)	
training:	Epoch: [25][93/204]	Loss 0.1457 (0.0613)	
training:	Epoch: [25][94/204]	Loss 0.0158 (0.0608)	
training:	Epoch: [25][95/204]	Loss 0.0173 (0.0604)	
training:	Epoch: [25][96/204]	Loss 0.1519 (0.0613)	
training:	Epoch: [25][97/204]	Loss 0.1599 (0.0624)	
training:	Epoch: [25][98/204]	Loss 0.0142 (0.0619)	
training:	Epoch: [25][99/204]	Loss 0.0276 (0.0615)	
training:	Epoch: [25][100/204]	Loss 0.1489 (0.0624)	
training:	Epoch: [25][101/204]	Loss 0.0146 (0.0619)	
training:	Epoch: [25][102/204]	Loss 0.1468 (0.0628)	
training:	Epoch: [25][103/204]	Loss 0.0141 (0.0623)	
training:	Epoch: [25][104/204]	Loss 0.1442 (0.0631)	
training:	Epoch: [25][105/204]	Loss 0.0157 (0.0626)	
training:	Epoch: [25][106/204]	Loss 0.1537 (0.0635)	
training:	Epoch: [25][107/204]	Loss 0.0184 (0.0631)	
training:	Epoch: [25][108/204]	Loss 0.0148 (0.0626)	
training:	Epoch: [25][109/204]	Loss 0.0159 (0.0622)	
training:	Epoch: [25][110/204]	Loss 0.0134 (0.0617)	
training:	Epoch: [25][111/204]	Loss 0.0138 (0.0613)	
training:	Epoch: [25][112/204]	Loss 0.0140 (0.0609)	
training:	Epoch: [25][113/204]	Loss 0.0237 (0.0606)	
training:	Epoch: [25][114/204]	Loss 0.4109 (0.0636)	
training:	Epoch: [25][115/204]	Loss 0.0148 (0.0632)	
training:	Epoch: [25][116/204]	Loss 0.0158 (0.0628)	
training:	Epoch: [25][117/204]	Loss 0.0168 (0.0624)	
training:	Epoch: [25][118/204]	Loss 0.1405 (0.0631)	
training:	Epoch: [25][119/204]	Loss 0.0144 (0.0627)	
training:	Epoch: [25][120/204]	Loss 0.1421 (0.0633)	
training:	Epoch: [25][121/204]	Loss 0.0168 (0.0629)	
training:	Epoch: [25][122/204]	Loss 0.1457 (0.0636)	
training:	Epoch: [25][123/204]	Loss 0.2861 (0.0654)	
training:	Epoch: [25][124/204]	Loss 0.0158 (0.0650)	
training:	Epoch: [25][125/204]	Loss 0.0142 (0.0646)	
training:	Epoch: [25][126/204]	Loss 0.0149 (0.0642)	
training:	Epoch: [25][127/204]	Loss 0.0140 (0.0638)	
training:	Epoch: [25][128/204]	Loss 0.1342 (0.0644)	
training:	Epoch: [25][129/204]	Loss 0.0137 (0.0640)	
training:	Epoch: [25][130/204]	Loss 0.0144 (0.0636)	
training:	Epoch: [25][131/204]	Loss 0.0172 (0.0632)	
training:	Epoch: [25][132/204]	Loss 0.1499 (0.0639)	
training:	Epoch: [25][133/204]	Loss 0.0218 (0.0636)	
training:	Epoch: [25][134/204]	Loss 0.0132 (0.0632)	
training:	Epoch: [25][135/204]	Loss 0.0135 (0.0628)	
training:	Epoch: [25][136/204]	Loss 0.0272 (0.0626)	
training:	Epoch: [25][137/204]	Loss 0.0144 (0.0622)	
training:	Epoch: [25][138/204]	Loss 0.0429 (0.0621)	
training:	Epoch: [25][139/204]	Loss 0.2725 (0.0636)	
training:	Epoch: [25][140/204]	Loss 0.0137 (0.0632)	
training:	Epoch: [25][141/204]	Loss 0.1559 (0.0639)	
training:	Epoch: [25][142/204]	Loss 0.0183 (0.0636)	
training:	Epoch: [25][143/204]	Loss 0.0150 (0.0632)	
training:	Epoch: [25][144/204]	Loss 0.0135 (0.0629)	
training:	Epoch: [25][145/204]	Loss 0.1466 (0.0635)	
training:	Epoch: [25][146/204]	Loss 0.0136 (0.0631)	
training:	Epoch: [25][147/204]	Loss 0.0149 (0.0628)	
training:	Epoch: [25][148/204]	Loss 0.0149 (0.0625)	
training:	Epoch: [25][149/204]	Loss 0.1514 (0.0631)	
training:	Epoch: [25][150/204]	Loss 0.0133 (0.0627)	
training:	Epoch: [25][151/204]	Loss 0.1529 (0.0633)	
training:	Epoch: [25][152/204]	Loss 0.0145 (0.0630)	
training:	Epoch: [25][153/204]	Loss 0.0162 (0.0627)	
training:	Epoch: [25][154/204]	Loss 0.1806 (0.0635)	
training:	Epoch: [25][155/204]	Loss 0.0150 (0.0632)	
training:	Epoch: [25][156/204]	Loss 0.0149 (0.0629)	
training:	Epoch: [25][157/204]	Loss 0.0141 (0.0625)	
training:	Epoch: [25][158/204]	Loss 0.0152 (0.0622)	
training:	Epoch: [25][159/204]	Loss 0.0167 (0.0620)	
training:	Epoch: [25][160/204]	Loss 0.0182 (0.0617)	
training:	Epoch: [25][161/204]	Loss 0.0147 (0.0614)	
training:	Epoch: [25][162/204]	Loss 0.0588 (0.0614)	
training:	Epoch: [25][163/204]	Loss 0.0154 (0.0611)	
training:	Epoch: [25][164/204]	Loss 0.0153 (0.0608)	
training:	Epoch: [25][165/204]	Loss 0.0146 (0.0605)	
training:	Epoch: [25][166/204]	Loss 0.0140 (0.0603)	
training:	Epoch: [25][167/204]	Loss 0.0465 (0.0602)	
training:	Epoch: [25][168/204]	Loss 0.2803 (0.0615)	
training:	Epoch: [25][169/204]	Loss 0.0184 (0.0612)	
training:	Epoch: [25][170/204]	Loss 0.0142 (0.0610)	
training:	Epoch: [25][171/204]	Loss 0.1424 (0.0614)	
training:	Epoch: [25][172/204]	Loss 0.1561 (0.0620)	
training:	Epoch: [25][173/204]	Loss 0.0176 (0.0617)	
training:	Epoch: [25][174/204]	Loss 0.1520 (0.0622)	
training:	Epoch: [25][175/204]	Loss 0.0140 (0.0620)	
training:	Epoch: [25][176/204]	Loss 0.1694 (0.0626)	
training:	Epoch: [25][177/204]	Loss 0.0769 (0.0627)	
training:	Epoch: [25][178/204]	Loss 0.0152 (0.0624)	
training:	Epoch: [25][179/204]	Loss 0.1573 (0.0629)	
training:	Epoch: [25][180/204]	Loss 0.0152 (0.0627)	
training:	Epoch: [25][181/204]	Loss 0.1527 (0.0632)	
training:	Epoch: [25][182/204]	Loss 0.1318 (0.0635)	
training:	Epoch: [25][183/204]	Loss 0.3013 (0.0648)	
training:	Epoch: [25][184/204]	Loss 0.0148 (0.0646)	
training:	Epoch: [25][185/204]	Loss 0.0144 (0.0643)	
training:	Epoch: [25][186/204]	Loss 0.2620 (0.0653)	
training:	Epoch: [25][187/204]	Loss 0.0158 (0.0651)	
training:	Epoch: [25][188/204]	Loss 0.0175 (0.0648)	
training:	Epoch: [25][189/204]	Loss 0.0550 (0.0648)	
training:	Epoch: [25][190/204]	Loss 0.0158 (0.0645)	
training:	Epoch: [25][191/204]	Loss 0.0243 (0.0643)	
training:	Epoch: [25][192/204]	Loss 0.0135 (0.0640)	
training:	Epoch: [25][193/204]	Loss 0.0158 (0.0638)	
training:	Epoch: [25][194/204]	Loss 0.1447 (0.0642)	
training:	Epoch: [25][195/204]	Loss 0.0149 (0.0640)	
training:	Epoch: [25][196/204]	Loss 0.0223 (0.0637)	
training:	Epoch: [25][197/204]	Loss 0.0153 (0.0635)	
training:	Epoch: [25][198/204]	Loss 0.1388 (0.0639)	
training:	Epoch: [25][199/204]	Loss 0.0170 (0.0636)	
training:	Epoch: [25][200/204]	Loss 0.2192 (0.0644)	
training:	Epoch: [25][201/204]	Loss 0.0173 (0.0642)	
training:	Epoch: [25][202/204]	Loss 0.1384 (0.0646)	
training:	Epoch: [25][203/204]	Loss 0.0141 (0.0643)	
training:	Epoch: [25][204/204]	Loss 0.0153 (0.0641)	
Training:	 Loss: 0.0640

Training:	 ACC: 0.9890 0.9890 0.9879 0.9901
Validation:	 ACC: 0.7862 0.7865 0.7932 0.7791
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8129
Pretraining:	Epoch 26/500
----------
training:	Epoch: [26][1/204]	Loss 0.0151 (0.0151)	
training:	Epoch: [26][2/204]	Loss 0.0142 (0.0146)	
training:	Epoch: [26][3/204]	Loss 0.0154 (0.0149)	
training:	Epoch: [26][4/204]	Loss 0.0138 (0.0146)	
training:	Epoch: [26][5/204]	Loss 0.0138 (0.0145)	
training:	Epoch: [26][6/204]	Loss 0.0135 (0.0143)	
training:	Epoch: [26][7/204]	Loss 0.0143 (0.0143)	
training:	Epoch: [26][8/204]	Loss 0.0134 (0.0142)	
training:	Epoch: [26][9/204]	Loss 0.1471 (0.0290)	
training:	Epoch: [26][10/204]	Loss 0.1545 (0.0415)	
training:	Epoch: [26][11/204]	Loss 0.0147 (0.0391)	
training:	Epoch: [26][12/204]	Loss 0.0141 (0.0370)	
training:	Epoch: [26][13/204]	Loss 0.1432 (0.0452)	
training:	Epoch: [26][14/204]	Loss 0.0143 (0.0430)	
training:	Epoch: [26][15/204]	Loss 0.0136 (0.0410)	
training:	Epoch: [26][16/204]	Loss 0.0157 (0.0394)	
training:	Epoch: [26][17/204]	Loss 0.2841 (0.0538)	
training:	Epoch: [26][18/204]	Loss 0.0152 (0.0517)	
training:	Epoch: [26][19/204]	Loss 0.0145 (0.0497)	
training:	Epoch: [26][20/204]	Loss 0.0167 (0.0481)	
training:	Epoch: [26][21/204]	Loss 0.0143 (0.0464)	
training:	Epoch: [26][22/204]	Loss 0.1471 (0.0510)	
training:	Epoch: [26][23/204]	Loss 0.1063 (0.0534)	
training:	Epoch: [26][24/204]	Loss 0.1399 (0.0570)	
training:	Epoch: [26][25/204]	Loss 0.0132 (0.0553)	
training:	Epoch: [26][26/204]	Loss 0.0153 (0.0537)	
training:	Epoch: [26][27/204]	Loss 0.1502 (0.0573)	
training:	Epoch: [26][28/204]	Loss 0.0148 (0.0558)	
training:	Epoch: [26][29/204]	Loss 0.0146 (0.0544)	
training:	Epoch: [26][30/204]	Loss 0.0155 (0.0531)	
training:	Epoch: [26][31/204]	Loss 0.0134 (0.0518)	
training:	Epoch: [26][32/204]	Loss 0.1484 (0.0548)	
training:	Epoch: [26][33/204]	Loss 0.0138 (0.0536)	
training:	Epoch: [26][34/204]	Loss 0.0266 (0.0528)	
training:	Epoch: [26][35/204]	Loss 0.0168 (0.0518)	
training:	Epoch: [26][36/204]	Loss 0.0243 (0.0510)	
training:	Epoch: [26][37/204]	Loss 0.1535 (0.0538)	
training:	Epoch: [26][38/204]	Loss 0.1433 (0.0561)	
training:	Epoch: [26][39/204]	Loss 0.1395 (0.0583)	
training:	Epoch: [26][40/204]	Loss 0.0151 (0.0572)	
training:	Epoch: [26][41/204]	Loss 0.0549 (0.0571)	
training:	Epoch: [26][42/204]	Loss 0.0132 (0.0561)	
training:	Epoch: [26][43/204]	Loss 0.2998 (0.0617)	
training:	Epoch: [26][44/204]	Loss 0.1342 (0.0634)	
training:	Epoch: [26][45/204]	Loss 0.0139 (0.0623)	
training:	Epoch: [26][46/204]	Loss 0.1892 (0.0650)	
training:	Epoch: [26][47/204]	Loss 0.1471 (0.0668)	
training:	Epoch: [26][48/204]	Loss 0.0141 (0.0657)	
training:	Epoch: [26][49/204]	Loss 0.1521 (0.0675)	
training:	Epoch: [26][50/204]	Loss 0.0132 (0.0664)	
training:	Epoch: [26][51/204]	Loss 0.1548 (0.0681)	
training:	Epoch: [26][52/204]	Loss 0.0180 (0.0671)	
training:	Epoch: [26][53/204]	Loss 0.0329 (0.0665)	
training:	Epoch: [26][54/204]	Loss 0.0130 (0.0655)	
training:	Epoch: [26][55/204]	Loss 0.1497 (0.0670)	
training:	Epoch: [26][56/204]	Loss 0.1486 (0.0685)	
training:	Epoch: [26][57/204]	Loss 0.0154 (0.0676)	
training:	Epoch: [26][58/204]	Loss 0.0141 (0.0666)	
training:	Epoch: [26][59/204]	Loss 0.0172 (0.0658)	
training:	Epoch: [26][60/204]	Loss 0.0140 (0.0649)	
training:	Epoch: [26][61/204]	Loss 0.0134 (0.0641)	
training:	Epoch: [26][62/204]	Loss 0.1397 (0.0653)	
training:	Epoch: [26][63/204]	Loss 0.0151 (0.0645)	
training:	Epoch: [26][64/204]	Loss 0.2741 (0.0678)	
training:	Epoch: [26][65/204]	Loss 0.0148 (0.0670)	
training:	Epoch: [26][66/204]	Loss 0.0138 (0.0662)	
training:	Epoch: [26][67/204]	Loss 0.0135 (0.0654)	
training:	Epoch: [26][68/204]	Loss 0.0136 (0.0646)	
training:	Epoch: [26][69/204]	Loss 0.0150 (0.0639)	
training:	Epoch: [26][70/204]	Loss 0.0127 (0.0632)	
training:	Epoch: [26][71/204]	Loss 0.0142 (0.0625)	
training:	Epoch: [26][72/204]	Loss 0.1564 (0.0638)	
training:	Epoch: [26][73/204]	Loss 0.1491 (0.0650)	
training:	Epoch: [26][74/204]	Loss 0.1441 (0.0660)	
training:	Epoch: [26][75/204]	Loss 0.0314 (0.0656)	
training:	Epoch: [26][76/204]	Loss 0.0268 (0.0651)	
training:	Epoch: [26][77/204]	Loss 0.0174 (0.0644)	
training:	Epoch: [26][78/204]	Loss 0.0138 (0.0638)	
training:	Epoch: [26][79/204]	Loss 0.0135 (0.0631)	
training:	Epoch: [26][80/204]	Loss 0.1423 (0.0641)	
training:	Epoch: [26][81/204]	Loss 0.0144 (0.0635)	
training:	Epoch: [26][82/204]	Loss 0.0134 (0.0629)	
training:	Epoch: [26][83/204]	Loss 0.0143 (0.0623)	
training:	Epoch: [26][84/204]	Loss 0.0148 (0.0618)	
training:	Epoch: [26][85/204]	Loss 0.0135 (0.0612)	
training:	Epoch: [26][86/204]	Loss 0.0132 (0.0606)	
training:	Epoch: [26][87/204]	Loss 0.1526 (0.0617)	
training:	Epoch: [26][88/204]	Loss 0.0174 (0.0612)	
training:	Epoch: [26][89/204]	Loss 0.0144 (0.0607)	
training:	Epoch: [26][90/204]	Loss 0.0192 (0.0602)	
training:	Epoch: [26][91/204]	Loss 0.1429 (0.0611)	
training:	Epoch: [26][92/204]	Loss 0.0213 (0.0607)	
training:	Epoch: [26][93/204]	Loss 0.0179 (0.0602)	
training:	Epoch: [26][94/204]	Loss 0.0235 (0.0598)	
training:	Epoch: [26][95/204]	Loss 0.0155 (0.0594)	
training:	Epoch: [26][96/204]	Loss 0.0136 (0.0589)	
training:	Epoch: [26][97/204]	Loss 0.0129 (0.0584)	
training:	Epoch: [26][98/204]	Loss 0.1397 (0.0592)	
training:	Epoch: [26][99/204]	Loss 0.0138 (0.0588)	
training:	Epoch: [26][100/204]	Loss 0.0183 (0.0584)	
training:	Epoch: [26][101/204]	Loss 0.0130 (0.0579)	
training:	Epoch: [26][102/204]	Loss 0.1409 (0.0587)	
training:	Epoch: [26][103/204]	Loss 0.2665 (0.0608)	
training:	Epoch: [26][104/204]	Loss 0.1365 (0.0615)	
training:	Epoch: [26][105/204]	Loss 0.1551 (0.0624)	
training:	Epoch: [26][106/204]	Loss 0.0130 (0.0619)	
training:	Epoch: [26][107/204]	Loss 0.0127 (0.0614)	
training:	Epoch: [26][108/204]	Loss 0.2850 (0.0635)	
training:	Epoch: [26][109/204]	Loss 0.0141 (0.0631)	
training:	Epoch: [26][110/204]	Loss 0.0138 (0.0626)	
training:	Epoch: [26][111/204]	Loss 0.0126 (0.0622)	
training:	Epoch: [26][112/204]	Loss 0.1433 (0.0629)	
training:	Epoch: [26][113/204]	Loss 0.2731 (0.0648)	
training:	Epoch: [26][114/204]	Loss 0.0135 (0.0643)	
training:	Epoch: [26][115/204]	Loss 0.0144 (0.0639)	
training:	Epoch: [26][116/204]	Loss 0.0141 (0.0634)	
training:	Epoch: [26][117/204]	Loss 0.0140 (0.0630)	
training:	Epoch: [26][118/204]	Loss 0.0142 (0.0626)	
training:	Epoch: [26][119/204]	Loss 0.0130 (0.0622)	
training:	Epoch: [26][120/204]	Loss 0.0165 (0.0618)	
training:	Epoch: [26][121/204]	Loss 0.0179 (0.0614)	
training:	Epoch: [26][122/204]	Loss 0.0154 (0.0611)	
training:	Epoch: [26][123/204]	Loss 0.0137 (0.0607)	
training:	Epoch: [26][124/204]	Loss 0.0159 (0.0603)	
training:	Epoch: [26][125/204]	Loss 0.0168 (0.0600)	
training:	Epoch: [26][126/204]	Loss 0.1397 (0.0606)	
training:	Epoch: [26][127/204]	Loss 0.0161 (0.0603)	
training:	Epoch: [26][128/204]	Loss 0.1320 (0.0608)	
training:	Epoch: [26][129/204]	Loss 0.0143 (0.0605)	
training:	Epoch: [26][130/204]	Loss 0.1413 (0.0611)	
training:	Epoch: [26][131/204]	Loss 0.0141 (0.0607)	
training:	Epoch: [26][132/204]	Loss 0.0141 (0.0604)	
training:	Epoch: [26][133/204]	Loss 0.1521 (0.0611)	
training:	Epoch: [26][134/204]	Loss 0.0157 (0.0607)	
training:	Epoch: [26][135/204]	Loss 0.0227 (0.0604)	
training:	Epoch: [26][136/204]	Loss 0.2571 (0.0619)	
training:	Epoch: [26][137/204]	Loss 0.1549 (0.0626)	
training:	Epoch: [26][138/204]	Loss 0.0155 (0.0622)	
training:	Epoch: [26][139/204]	Loss 0.0143 (0.0619)	
training:	Epoch: [26][140/204]	Loss 0.1448 (0.0625)	
training:	Epoch: [26][141/204]	Loss 0.0143 (0.0621)	
training:	Epoch: [26][142/204]	Loss 0.1553 (0.0628)	
training:	Epoch: [26][143/204]	Loss 0.0156 (0.0625)	
training:	Epoch: [26][144/204]	Loss 0.0132 (0.0621)	
training:	Epoch: [26][145/204]	Loss 0.0139 (0.0618)	
training:	Epoch: [26][146/204]	Loss 0.0150 (0.0615)	
training:	Epoch: [26][147/204]	Loss 0.0138 (0.0611)	
training:	Epoch: [26][148/204]	Loss 0.0162 (0.0608)	
training:	Epoch: [26][149/204]	Loss 0.0140 (0.0605)	
training:	Epoch: [26][150/204]	Loss 0.0176 (0.0602)	
training:	Epoch: [26][151/204]	Loss 0.0206 (0.0600)	
training:	Epoch: [26][152/204]	Loss 0.0158 (0.0597)	
training:	Epoch: [26][153/204]	Loss 0.1564 (0.0603)	
training:	Epoch: [26][154/204]	Loss 0.0135 (0.0600)	
training:	Epoch: [26][155/204]	Loss 0.3101 (0.0616)	
training:	Epoch: [26][156/204]	Loss 0.1706 (0.0623)	
training:	Epoch: [26][157/204]	Loss 0.0149 (0.0620)	
training:	Epoch: [26][158/204]	Loss 0.0175 (0.0617)	
training:	Epoch: [26][159/204]	Loss 0.0144 (0.0614)	
training:	Epoch: [26][160/204]	Loss 0.0160 (0.0611)	
training:	Epoch: [26][161/204]	Loss 0.0151 (0.0609)	
training:	Epoch: [26][162/204]	Loss 0.0182 (0.0606)	
training:	Epoch: [26][163/204]	Loss 0.0152 (0.0603)	
training:	Epoch: [26][164/204]	Loss 0.1701 (0.0610)	
training:	Epoch: [26][165/204]	Loss 0.1648 (0.0616)	
training:	Epoch: [26][166/204]	Loss 0.0129 (0.0613)	
training:	Epoch: [26][167/204]	Loss 0.0156 (0.0611)	
training:	Epoch: [26][168/204]	Loss 0.1530 (0.0616)	
training:	Epoch: [26][169/204]	Loss 0.1472 (0.0621)	
training:	Epoch: [26][170/204]	Loss 0.0141 (0.0618)	
training:	Epoch: [26][171/204]	Loss 0.1274 (0.0622)	
training:	Epoch: [26][172/204]	Loss 0.0132 (0.0619)	
training:	Epoch: [26][173/204]	Loss 0.1510 (0.0624)	
training:	Epoch: [26][174/204]	Loss 0.0131 (0.0622)	
training:	Epoch: [26][175/204]	Loss 0.0148 (0.0619)	
training:	Epoch: [26][176/204]	Loss 0.1452 (0.0624)	
training:	Epoch: [26][177/204]	Loss 0.0131 (0.0621)	
training:	Epoch: [26][178/204]	Loss 0.0147 (0.0618)	
training:	Epoch: [26][179/204]	Loss 0.1728 (0.0624)	
training:	Epoch: [26][180/204]	Loss 0.0568 (0.0624)	
training:	Epoch: [26][181/204]	Loss 0.1593 (0.0629)	
training:	Epoch: [26][182/204]	Loss 0.0139 (0.0627)	
training:	Epoch: [26][183/204]	Loss 0.1579 (0.0632)	
training:	Epoch: [26][184/204]	Loss 0.0147 (0.0629)	
training:	Epoch: [26][185/204]	Loss 0.0133 (0.0627)	
training:	Epoch: [26][186/204]	Loss 0.0169 (0.0624)	
training:	Epoch: [26][187/204]	Loss 0.1550 (0.0629)	
training:	Epoch: [26][188/204]	Loss 0.0179 (0.0627)	
training:	Epoch: [26][189/204]	Loss 0.0654 (0.0627)	
training:	Epoch: [26][190/204]	Loss 0.0155 (0.0624)	
training:	Epoch: [26][191/204]	Loss 0.1550 (0.0629)	
training:	Epoch: [26][192/204]	Loss 0.1537 (0.0634)	
training:	Epoch: [26][193/204]	Loss 0.0132 (0.0631)	
training:	Epoch: [26][194/204]	Loss 0.0157 (0.0629)	
training:	Epoch: [26][195/204]	Loss 0.0145 (0.0626)	
training:	Epoch: [26][196/204]	Loss 0.0153 (0.0624)	
training:	Epoch: [26][197/204]	Loss 0.1523 (0.0629)	
training:	Epoch: [26][198/204]	Loss 0.1434 (0.0633)	
training:	Epoch: [26][199/204]	Loss 0.0147 (0.0630)	
training:	Epoch: [26][200/204]	Loss 0.0193 (0.0628)	
training:	Epoch: [26][201/204]	Loss 0.0153 (0.0626)	
training:	Epoch: [26][202/204]	Loss 0.1555 (0.0630)	
training:	Epoch: [26][203/204]	Loss 0.0141 (0.0628)	
training:	Epoch: [26][204/204]	Loss 0.0149 (0.0625)	
Training:	 Loss: 0.0624

Training:	 ACC: 0.9893 0.9893 0.9885 0.9901
Validation:	 ACC: 0.7907 0.7919 0.8158 0.7657
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8098
Pretraining:	Epoch 27/500
----------
training:	Epoch: [27][1/204]	Loss 0.2863 (0.2863)	
training:	Epoch: [27][2/204]	Loss 0.1549 (0.2206)	
training:	Epoch: [27][3/204]	Loss 0.0715 (0.1709)	
training:	Epoch: [27][4/204]	Loss 0.0137 (0.1316)	
training:	Epoch: [27][5/204]	Loss 0.0138 (0.1080)	
training:	Epoch: [27][6/204]	Loss 0.0128 (0.0922)	
training:	Epoch: [27][7/204]	Loss 0.0134 (0.0809)	
training:	Epoch: [27][8/204]	Loss 0.2726 (0.1049)	
training:	Epoch: [27][9/204]	Loss 0.1554 (0.1105)	
training:	Epoch: [27][10/204]	Loss 0.0134 (0.1008)	
training:	Epoch: [27][11/204]	Loss 0.0139 (0.0929)	
training:	Epoch: [27][12/204]	Loss 0.0151 (0.0864)	
training:	Epoch: [27][13/204]	Loss 0.0142 (0.0809)	
training:	Epoch: [27][14/204]	Loss 0.0133 (0.0760)	
training:	Epoch: [27][15/204]	Loss 0.0860 (0.0767)	
training:	Epoch: [27][16/204]	Loss 0.0133 (0.0727)	
training:	Epoch: [27][17/204]	Loss 0.0141 (0.0693)	
training:	Epoch: [27][18/204]	Loss 0.1460 (0.0735)	
training:	Epoch: [27][19/204]	Loss 0.1474 (0.0774)	
training:	Epoch: [27][20/204]	Loss 0.0155 (0.0743)	
training:	Epoch: [27][21/204]	Loss 0.0147 (0.0715)	
training:	Epoch: [27][22/204]	Loss 0.0201 (0.0692)	
training:	Epoch: [27][23/204]	Loss 0.0134 (0.0667)	
training:	Epoch: [27][24/204]	Loss 0.0126 (0.0645)	
training:	Epoch: [27][25/204]	Loss 0.2791 (0.0731)	
training:	Epoch: [27][26/204]	Loss 0.0151 (0.0708)	
training:	Epoch: [27][27/204]	Loss 0.0136 (0.0687)	
training:	Epoch: [27][28/204]	Loss 0.0389 (0.0676)	
training:	Epoch: [27][29/204]	Loss 0.0129 (0.0658)	
training:	Epoch: [27][30/204]	Loss 0.1405 (0.0682)	
training:	Epoch: [27][31/204]	Loss 0.0133 (0.0665)	
training:	Epoch: [27][32/204]	Loss 0.0211 (0.0651)	
training:	Epoch: [27][33/204]	Loss 0.0526 (0.0647)	
training:	Epoch: [27][34/204]	Loss 0.0138 (0.0632)	
training:	Epoch: [27][35/204]	Loss 0.0125 (0.0617)	
training:	Epoch: [27][36/204]	Loss 0.1492 (0.0642)	
training:	Epoch: [27][37/204]	Loss 0.0157 (0.0629)	
training:	Epoch: [27][38/204]	Loss 0.0140 (0.0616)	
training:	Epoch: [27][39/204]	Loss 0.1348 (0.0634)	
training:	Epoch: [27][40/204]	Loss 0.0133 (0.0622)	
training:	Epoch: [27][41/204]	Loss 0.0156 (0.0611)	
training:	Epoch: [27][42/204]	Loss 0.0146 (0.0599)	
training:	Epoch: [27][43/204]	Loss 0.0181 (0.0590)	
training:	Epoch: [27][44/204]	Loss 0.0336 (0.0584)	
training:	Epoch: [27][45/204]	Loss 0.0153 (0.0574)	
training:	Epoch: [27][46/204]	Loss 0.0131 (0.0565)	
training:	Epoch: [27][47/204]	Loss 0.0127 (0.0555)	
training:	Epoch: [27][48/204]	Loss 0.4248 (0.0632)	
training:	Epoch: [27][49/204]	Loss 0.0139 (0.0622)	
training:	Epoch: [27][50/204]	Loss 0.1598 (0.0642)	
training:	Epoch: [27][51/204]	Loss 0.1354 (0.0656)	
training:	Epoch: [27][52/204]	Loss 0.0131 (0.0646)	
training:	Epoch: [27][53/204]	Loss 0.0143 (0.0636)	
training:	Epoch: [27][54/204]	Loss 0.0143 (0.0627)	
training:	Epoch: [27][55/204]	Loss 0.1453 (0.0642)	
training:	Epoch: [27][56/204]	Loss 0.0143 (0.0633)	
training:	Epoch: [27][57/204]	Loss 0.0152 (0.0625)	
training:	Epoch: [27][58/204]	Loss 0.0130 (0.0616)	
training:	Epoch: [27][59/204]	Loss 0.0134 (0.0608)	
training:	Epoch: [27][60/204]	Loss 0.0211 (0.0601)	
training:	Epoch: [27][61/204]	Loss 0.1464 (0.0616)	
training:	Epoch: [27][62/204]	Loss 0.0139 (0.0608)	
training:	Epoch: [27][63/204]	Loss 0.0196 (0.0601)	
training:	Epoch: [27][64/204]	Loss 0.1530 (0.0616)	
training:	Epoch: [27][65/204]	Loss 0.0155 (0.0609)	
training:	Epoch: [27][66/204]	Loss 0.0153 (0.0602)	
training:	Epoch: [27][67/204]	Loss 0.0342 (0.0598)	
training:	Epoch: [27][68/204]	Loss 0.1532 (0.0612)	
training:	Epoch: [27][69/204]	Loss 0.0131 (0.0605)	
training:	Epoch: [27][70/204]	Loss 0.0132 (0.0598)	
training:	Epoch: [27][71/204]	Loss 0.0133 (0.0591)	
training:	Epoch: [27][72/204]	Loss 0.1526 (0.0604)	
training:	Epoch: [27][73/204]	Loss 0.1403 (0.0615)	
training:	Epoch: [27][74/204]	Loss 0.0139 (0.0609)	
training:	Epoch: [27][75/204]	Loss 0.0159 (0.0603)	
training:	Epoch: [27][76/204]	Loss 0.0132 (0.0597)	
training:	Epoch: [27][77/204]	Loss 0.0149 (0.0591)	
training:	Epoch: [27][78/204]	Loss 0.0138 (0.0585)	
training:	Epoch: [27][79/204]	Loss 0.1497 (0.0597)	
training:	Epoch: [27][80/204]	Loss 0.0142 (0.0591)	
training:	Epoch: [27][81/204]	Loss 0.1391 (0.0601)	
training:	Epoch: [27][82/204]	Loss 0.2725 (0.0627)	
training:	Epoch: [27][83/204]	Loss 0.0133 (0.0621)	
training:	Epoch: [27][84/204]	Loss 0.0160 (0.0615)	
training:	Epoch: [27][85/204]	Loss 0.0160 (0.0610)	
training:	Epoch: [27][86/204]	Loss 0.0161 (0.0605)	
training:	Epoch: [27][87/204]	Loss 0.0251 (0.0601)	
training:	Epoch: [27][88/204]	Loss 0.0136 (0.0595)	
training:	Epoch: [27][89/204]	Loss 0.0206 (0.0591)	
training:	Epoch: [27][90/204]	Loss 0.0192 (0.0587)	
training:	Epoch: [27][91/204]	Loss 0.0645 (0.0587)	
training:	Epoch: [27][92/204]	Loss 0.0135 (0.0582)	
training:	Epoch: [27][93/204]	Loss 0.1563 (0.0593)	
training:	Epoch: [27][94/204]	Loss 0.0136 (0.0588)	
training:	Epoch: [27][95/204]	Loss 0.0452 (0.0587)	
training:	Epoch: [27][96/204]	Loss 0.0133 (0.0582)	
training:	Epoch: [27][97/204]	Loss 0.0137 (0.0577)	
training:	Epoch: [27][98/204]	Loss 0.1408 (0.0586)	
training:	Epoch: [27][99/204]	Loss 0.0139 (0.0581)	
training:	Epoch: [27][100/204]	Loss 0.0138 (0.0577)	
training:	Epoch: [27][101/204]	Loss 0.1321 (0.0584)	
training:	Epoch: [27][102/204]	Loss 0.0132 (0.0580)	
training:	Epoch: [27][103/204]	Loss 0.0158 (0.0576)	
training:	Epoch: [27][104/204]	Loss 0.0146 (0.0571)	
training:	Epoch: [27][105/204]	Loss 0.0130 (0.0567)	
training:	Epoch: [27][106/204]	Loss 0.1465 (0.0576)	
training:	Epoch: [27][107/204]	Loss 0.1465 (0.0584)	
training:	Epoch: [27][108/204]	Loss 0.0241 (0.0581)	
training:	Epoch: [27][109/204]	Loss 0.0136 (0.0577)	
training:	Epoch: [27][110/204]	Loss 0.0149 (0.0573)	
training:	Epoch: [27][111/204]	Loss 0.2814 (0.0593)	
training:	Epoch: [27][112/204]	Loss 0.0141 (0.0589)	
training:	Epoch: [27][113/204]	Loss 0.1398 (0.0596)	
training:	Epoch: [27][114/204]	Loss 0.0126 (0.0592)	
training:	Epoch: [27][115/204]	Loss 0.0123 (0.0588)	
training:	Epoch: [27][116/204]	Loss 0.2856 (0.0608)	
training:	Epoch: [27][117/204]	Loss 0.0132 (0.0603)	
training:	Epoch: [27][118/204]	Loss 0.0126 (0.0599)	
training:	Epoch: [27][119/204]	Loss 0.0132 (0.0596)	
training:	Epoch: [27][120/204]	Loss 0.0138 (0.0592)	
training:	Epoch: [27][121/204]	Loss 0.0132 (0.0588)	
training:	Epoch: [27][122/204]	Loss 0.0132 (0.0584)	
training:	Epoch: [27][123/204]	Loss 0.0134 (0.0581)	
training:	Epoch: [27][124/204]	Loss 0.1564 (0.0588)	
training:	Epoch: [27][125/204]	Loss 0.0186 (0.0585)	
training:	Epoch: [27][126/204]	Loss 0.0145 (0.0582)	
training:	Epoch: [27][127/204]	Loss 0.1430 (0.0588)	
training:	Epoch: [27][128/204]	Loss 0.1323 (0.0594)	
training:	Epoch: [27][129/204]	Loss 0.0157 (0.0591)	
training:	Epoch: [27][130/204]	Loss 0.0129 (0.0587)	
training:	Epoch: [27][131/204]	Loss 0.0138 (0.0584)	
training:	Epoch: [27][132/204]	Loss 0.1755 (0.0593)	
training:	Epoch: [27][133/204]	Loss 0.2912 (0.0610)	
training:	Epoch: [27][134/204]	Loss 0.0131 (0.0607)	
training:	Epoch: [27][135/204]	Loss 0.0128 (0.0603)	
training:	Epoch: [27][136/204]	Loss 0.0161 (0.0600)	
training:	Epoch: [27][137/204]	Loss 0.0135 (0.0596)	
training:	Epoch: [27][138/204]	Loss 0.1403 (0.0602)	
training:	Epoch: [27][139/204]	Loss 0.1404 (0.0608)	
training:	Epoch: [27][140/204]	Loss 0.0145 (0.0605)	
training:	Epoch: [27][141/204]	Loss 0.1424 (0.0610)	
training:	Epoch: [27][142/204]	Loss 0.0149 (0.0607)	
training:	Epoch: [27][143/204]	Loss 0.0158 (0.0604)	
training:	Epoch: [27][144/204]	Loss 0.0186 (0.0601)	
training:	Epoch: [27][145/204]	Loss 0.0144 (0.0598)	
training:	Epoch: [27][146/204]	Loss 0.0205 (0.0595)	
training:	Epoch: [27][147/204]	Loss 0.1292 (0.0600)	
training:	Epoch: [27][148/204]	Loss 0.0160 (0.0597)	
training:	Epoch: [27][149/204]	Loss 0.1529 (0.0603)	
training:	Epoch: [27][150/204]	Loss 0.0140 (0.0600)	
training:	Epoch: [27][151/204]	Loss 0.0135 (0.0597)	
training:	Epoch: [27][152/204]	Loss 0.0163 (0.0594)	
training:	Epoch: [27][153/204]	Loss 0.0159 (0.0591)	
training:	Epoch: [27][154/204]	Loss 0.0177 (0.0589)	
training:	Epoch: [27][155/204]	Loss 0.1366 (0.0594)	
training:	Epoch: [27][156/204]	Loss 0.0240 (0.0592)	
training:	Epoch: [27][157/204]	Loss 0.1476 (0.0597)	
training:	Epoch: [27][158/204]	Loss 0.0129 (0.0594)	
training:	Epoch: [27][159/204]	Loss 0.1229 (0.0598)	
training:	Epoch: [27][160/204]	Loss 0.0132 (0.0595)	
training:	Epoch: [27][161/204]	Loss 0.0186 (0.0593)	
training:	Epoch: [27][162/204]	Loss 0.0137 (0.0590)	
training:	Epoch: [27][163/204]	Loss 0.0137 (0.0587)	
training:	Epoch: [27][164/204]	Loss 0.0134 (0.0584)	
training:	Epoch: [27][165/204]	Loss 0.0153 (0.0582)	
training:	Epoch: [27][166/204]	Loss 0.0154 (0.0579)	
training:	Epoch: [27][167/204]	Loss 0.0204 (0.0577)	
training:	Epoch: [27][168/204]	Loss 0.1547 (0.0583)	
training:	Epoch: [27][169/204]	Loss 0.0125 (0.0580)	
training:	Epoch: [27][170/204]	Loss 0.0156 (0.0577)	
training:	Epoch: [27][171/204]	Loss 0.1569 (0.0583)	
training:	Epoch: [27][172/204]	Loss 0.1468 (0.0588)	
training:	Epoch: [27][173/204]	Loss 0.0198 (0.0586)	
training:	Epoch: [27][174/204]	Loss 0.0145 (0.0584)	
training:	Epoch: [27][175/204]	Loss 0.1428 (0.0588)	
training:	Epoch: [27][176/204]	Loss 0.0140 (0.0586)	
training:	Epoch: [27][177/204]	Loss 0.0153 (0.0583)	
training:	Epoch: [27][178/204]	Loss 0.0159 (0.0581)	
training:	Epoch: [27][179/204]	Loss 0.0126 (0.0579)	
training:	Epoch: [27][180/204]	Loss 0.0127 (0.0576)	
training:	Epoch: [27][181/204]	Loss 0.1579 (0.0582)	
training:	Epoch: [27][182/204]	Loss 0.0136 (0.0579)	
training:	Epoch: [27][183/204]	Loss 0.0137 (0.0577)	
training:	Epoch: [27][184/204]	Loss 0.2823 (0.0589)	
training:	Epoch: [27][185/204]	Loss 0.0145 (0.0587)	
training:	Epoch: [27][186/204]	Loss 0.1463 (0.0591)	
training:	Epoch: [27][187/204]	Loss 0.0913 (0.0593)	
training:	Epoch: [27][188/204]	Loss 0.0136 (0.0591)	
training:	Epoch: [27][189/204]	Loss 0.0125 (0.0588)	
training:	Epoch: [27][190/204]	Loss 0.1451 (0.0593)	
training:	Epoch: [27][191/204]	Loss 0.0140 (0.0590)	
training:	Epoch: [27][192/204]	Loss 0.2741 (0.0601)	
training:	Epoch: [27][193/204]	Loss 0.0147 (0.0599)	
training:	Epoch: [27][194/204]	Loss 0.1577 (0.0604)	
training:	Epoch: [27][195/204]	Loss 0.1608 (0.0609)	
training:	Epoch: [27][196/204]	Loss 0.1395 (0.0613)	
training:	Epoch: [27][197/204]	Loss 0.0143 (0.0611)	
training:	Epoch: [27][198/204]	Loss 0.0142 (0.0609)	
training:	Epoch: [27][199/204]	Loss 0.0145 (0.0606)	
training:	Epoch: [27][200/204]	Loss 0.0132 (0.0604)	
training:	Epoch: [27][201/204]	Loss 0.0173 (0.0602)	
training:	Epoch: [27][202/204]	Loss 0.2995 (0.0614)	
training:	Epoch: [27][203/204]	Loss 0.0128 (0.0611)	
training:	Epoch: [27][204/204]	Loss 0.0133 (0.0609)	
Training:	 Loss: 0.0608

Training:	 ACC: 0.9893 0.9893 0.9885 0.9901
Validation:	 ACC: 0.7878 0.7887 0.8066 0.7691
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8171
Pretraining:	Epoch 28/500
----------
training:	Epoch: [28][1/204]	Loss 0.2957 (0.2957)	
training:	Epoch: [28][2/204]	Loss 0.0162 (0.1559)	
training:	Epoch: [28][3/204]	Loss 0.0133 (0.1084)	
training:	Epoch: [28][4/204]	Loss 0.0128 (0.0845)	
training:	Epoch: [28][5/204]	Loss 0.0134 (0.0703)	
training:	Epoch: [28][6/204]	Loss 0.0162 (0.0613)	
training:	Epoch: [28][7/204]	Loss 0.1338 (0.0716)	
training:	Epoch: [28][8/204]	Loss 0.0129 (0.0643)	
training:	Epoch: [28][9/204]	Loss 0.0149 (0.0588)	
training:	Epoch: [28][10/204]	Loss 0.0499 (0.0579)	
training:	Epoch: [28][11/204]	Loss 0.1585 (0.0671)	
training:	Epoch: [28][12/204]	Loss 0.1461 (0.0736)	
training:	Epoch: [28][13/204]	Loss 0.0136 (0.0690)	
training:	Epoch: [28][14/204]	Loss 0.0136 (0.0651)	
training:	Epoch: [28][15/204]	Loss 0.0142 (0.0617)	
training:	Epoch: [28][16/204]	Loss 0.0128 (0.0586)	
training:	Epoch: [28][17/204]	Loss 0.0149 (0.0560)	
training:	Epoch: [28][18/204]	Loss 0.2701 (0.0679)	
training:	Epoch: [28][19/204]	Loss 0.0134 (0.0651)	
training:	Epoch: [28][20/204]	Loss 0.0148 (0.0626)	
training:	Epoch: [28][21/204]	Loss 0.0181 (0.0604)	
training:	Epoch: [28][22/204]	Loss 0.1406 (0.0641)	
training:	Epoch: [28][23/204]	Loss 0.0152 (0.0620)	
training:	Epoch: [28][24/204]	Loss 0.0132 (0.0599)	
training:	Epoch: [28][25/204]	Loss 0.0181 (0.0583)	
training:	Epoch: [28][26/204]	Loss 0.0138 (0.0565)	
training:	Epoch: [28][27/204]	Loss 0.1496 (0.0600)	
training:	Epoch: [28][28/204]	Loss 0.0158 (0.0584)	
training:	Epoch: [28][29/204]	Loss 0.0133 (0.0569)	
training:	Epoch: [28][30/204]	Loss 0.1527 (0.0600)	
training:	Epoch: [28][31/204]	Loss 0.0133 (0.0585)	
training:	Epoch: [28][32/204]	Loss 0.0136 (0.0571)	
training:	Epoch: [28][33/204]	Loss 0.0177 (0.0559)	
training:	Epoch: [28][34/204]	Loss 0.0134 (0.0547)	
training:	Epoch: [28][35/204]	Loss 0.1391 (0.0571)	
training:	Epoch: [28][36/204]	Loss 0.0155 (0.0559)	
training:	Epoch: [28][37/204]	Loss 0.1486 (0.0584)	
training:	Epoch: [28][38/204]	Loss 0.0129 (0.0572)	
training:	Epoch: [28][39/204]	Loss 0.0137 (0.0561)	
training:	Epoch: [28][40/204]	Loss 0.0132 (0.0551)	
training:	Epoch: [28][41/204]	Loss 0.0157 (0.0541)	
training:	Epoch: [28][42/204]	Loss 0.0188 (0.0533)	
training:	Epoch: [28][43/204]	Loss 0.0129 (0.0523)	
training:	Epoch: [28][44/204]	Loss 0.0147 (0.0515)	
training:	Epoch: [28][45/204]	Loss 0.0132 (0.0506)	
training:	Epoch: [28][46/204]	Loss 0.0132 (0.0498)	
training:	Epoch: [28][47/204]	Loss 0.0137 (0.0490)	
training:	Epoch: [28][48/204]	Loss 0.1946 (0.0521)	
training:	Epoch: [28][49/204]	Loss 0.1571 (0.0542)	
training:	Epoch: [28][50/204]	Loss 0.1428 (0.0560)	
training:	Epoch: [28][51/204]	Loss 0.2547 (0.0599)	
training:	Epoch: [28][52/204]	Loss 0.0146 (0.0590)	
training:	Epoch: [28][53/204]	Loss 0.1352 (0.0604)	
training:	Epoch: [28][54/204]	Loss 0.0130 (0.0596)	
training:	Epoch: [28][55/204]	Loss 0.0132 (0.0587)	
training:	Epoch: [28][56/204]	Loss 0.0151 (0.0579)	
training:	Epoch: [28][57/204]	Loss 0.0143 (0.0572)	
training:	Epoch: [28][58/204]	Loss 0.0148 (0.0564)	
training:	Epoch: [28][59/204]	Loss 0.0179 (0.0558)	
training:	Epoch: [28][60/204]	Loss 0.1530 (0.0574)	
training:	Epoch: [28][61/204]	Loss 0.0138 (0.0567)	
training:	Epoch: [28][62/204]	Loss 0.0175 (0.0561)	
training:	Epoch: [28][63/204]	Loss 0.0153 (0.0554)	
training:	Epoch: [28][64/204]	Loss 0.0149 (0.0548)	
training:	Epoch: [28][65/204]	Loss 0.1569 (0.0563)	
training:	Epoch: [28][66/204]	Loss 0.2807 (0.0597)	
training:	Epoch: [28][67/204]	Loss 0.0142 (0.0591)	
training:	Epoch: [28][68/204]	Loss 0.0133 (0.0584)	
training:	Epoch: [28][69/204]	Loss 0.0136 (0.0577)	
training:	Epoch: [28][70/204]	Loss 0.0132 (0.0571)	
training:	Epoch: [28][71/204]	Loss 0.0129 (0.0565)	
training:	Epoch: [28][72/204]	Loss 0.4171 (0.0615)	
training:	Epoch: [28][73/204]	Loss 0.0147 (0.0609)	
training:	Epoch: [28][74/204]	Loss 0.0122 (0.0602)	
training:	Epoch: [28][75/204]	Loss 0.0516 (0.0601)	
training:	Epoch: [28][76/204]	Loss 0.0277 (0.0597)	
training:	Epoch: [28][77/204]	Loss 0.0165 (0.0591)	
training:	Epoch: [28][78/204]	Loss 0.0151 (0.0585)	
training:	Epoch: [28][79/204]	Loss 0.0140 (0.0580)	
training:	Epoch: [28][80/204]	Loss 0.0133 (0.0574)	
training:	Epoch: [28][81/204]	Loss 0.0133 (0.0569)	
training:	Epoch: [28][82/204]	Loss 0.0143 (0.0563)	
training:	Epoch: [28][83/204]	Loss 0.0127 (0.0558)	
training:	Epoch: [28][84/204]	Loss 0.0129 (0.0553)	
training:	Epoch: [28][85/204]	Loss 0.1446 (0.0564)	
training:	Epoch: [28][86/204]	Loss 0.0132 (0.0559)	
training:	Epoch: [28][87/204]	Loss 0.1370 (0.0568)	
training:	Epoch: [28][88/204]	Loss 0.1254 (0.0576)	
training:	Epoch: [28][89/204]	Loss 0.2947 (0.0602)	
training:	Epoch: [28][90/204]	Loss 0.0133 (0.0597)	
training:	Epoch: [28][91/204]	Loss 0.0155 (0.0592)	
training:	Epoch: [28][92/204]	Loss 0.0128 (0.0587)	
training:	Epoch: [28][93/204]	Loss 0.0210 (0.0583)	
training:	Epoch: [28][94/204]	Loss 0.0123 (0.0578)	
training:	Epoch: [28][95/204]	Loss 0.1580 (0.0589)	
training:	Epoch: [28][96/204]	Loss 0.0380 (0.0587)	
training:	Epoch: [28][97/204]	Loss 0.1577 (0.0597)	
training:	Epoch: [28][98/204]	Loss 0.0133 (0.0592)	
training:	Epoch: [28][99/204]	Loss 0.0128 (0.0587)	
training:	Epoch: [28][100/204]	Loss 0.1524 (0.0597)	
training:	Epoch: [28][101/204]	Loss 0.0134 (0.0592)	
training:	Epoch: [28][102/204]	Loss 0.0153 (0.0588)	
training:	Epoch: [28][103/204]	Loss 0.0139 (0.0584)	
training:	Epoch: [28][104/204]	Loss 0.0144 (0.0579)	
training:	Epoch: [28][105/204]	Loss 0.0148 (0.0575)	
training:	Epoch: [28][106/204]	Loss 0.0126 (0.0571)	
training:	Epoch: [28][107/204]	Loss 0.1451 (0.0579)	
training:	Epoch: [28][108/204]	Loss 0.0165 (0.0575)	
training:	Epoch: [28][109/204]	Loss 0.0322 (0.0573)	
training:	Epoch: [28][110/204]	Loss 0.0121 (0.0569)	
training:	Epoch: [28][111/204]	Loss 0.0156 (0.0565)	
training:	Epoch: [28][112/204]	Loss 0.0136 (0.0561)	
training:	Epoch: [28][113/204]	Loss 0.1346 (0.0568)	
training:	Epoch: [28][114/204]	Loss 0.1407 (0.0576)	
training:	Epoch: [28][115/204]	Loss 0.0131 (0.0572)	
training:	Epoch: [28][116/204]	Loss 0.1462 (0.0579)	
training:	Epoch: [28][117/204]	Loss 0.0177 (0.0576)	
training:	Epoch: [28][118/204]	Loss 0.0279 (0.0574)	
training:	Epoch: [28][119/204]	Loss 0.0124 (0.0570)	
training:	Epoch: [28][120/204]	Loss 0.0150 (0.0566)	
training:	Epoch: [28][121/204]	Loss 0.0154 (0.0563)	
training:	Epoch: [28][122/204]	Loss 0.0142 (0.0559)	
training:	Epoch: [28][123/204]	Loss 0.0139 (0.0556)	
training:	Epoch: [28][124/204]	Loss 0.1429 (0.0563)	
training:	Epoch: [28][125/204]	Loss 0.0138 (0.0560)	
training:	Epoch: [28][126/204]	Loss 0.0129 (0.0556)	
training:	Epoch: [28][127/204]	Loss 0.0143 (0.0553)	
training:	Epoch: [28][128/204]	Loss 0.0133 (0.0550)	
training:	Epoch: [28][129/204]	Loss 0.0139 (0.0546)	
training:	Epoch: [28][130/204]	Loss 0.0129 (0.0543)	
training:	Epoch: [28][131/204]	Loss 0.1549 (0.0551)	
training:	Epoch: [28][132/204]	Loss 0.0173 (0.0548)	
training:	Epoch: [28][133/204]	Loss 0.0154 (0.0545)	
training:	Epoch: [28][134/204]	Loss 0.0140 (0.0542)	
training:	Epoch: [28][135/204]	Loss 0.0144 (0.0539)	
training:	Epoch: [28][136/204]	Loss 0.1251 (0.0544)	
training:	Epoch: [28][137/204]	Loss 0.1568 (0.0552)	
training:	Epoch: [28][138/204]	Loss 0.1505 (0.0559)	
training:	Epoch: [28][139/204]	Loss 0.0126 (0.0556)	
training:	Epoch: [28][140/204]	Loss 0.0133 (0.0553)	
training:	Epoch: [28][141/204]	Loss 0.0143 (0.0550)	
training:	Epoch: [28][142/204]	Loss 0.1735 (0.0558)	
training:	Epoch: [28][143/204]	Loss 0.1470 (0.0564)	
training:	Epoch: [28][144/204]	Loss 0.0135 (0.0561)	
training:	Epoch: [28][145/204]	Loss 0.2901 (0.0578)	
training:	Epoch: [28][146/204]	Loss 0.1492 (0.0584)	
training:	Epoch: [28][147/204]	Loss 0.1711 (0.0592)	
training:	Epoch: [28][148/204]	Loss 0.0149 (0.0589)	
training:	Epoch: [28][149/204]	Loss 0.1802 (0.0597)	
training:	Epoch: [28][150/204]	Loss 0.0121 (0.0594)	
training:	Epoch: [28][151/204]	Loss 0.0131 (0.0590)	
training:	Epoch: [28][152/204]	Loss 0.0133 (0.0587)	
training:	Epoch: [28][153/204]	Loss 0.2921 (0.0603)	
training:	Epoch: [28][154/204]	Loss 0.0180 (0.0600)	
training:	Epoch: [28][155/204]	Loss 0.0148 (0.0597)	
training:	Epoch: [28][156/204]	Loss 0.0660 (0.0597)	
training:	Epoch: [28][157/204]	Loss 0.0124 (0.0594)	
training:	Epoch: [28][158/204]	Loss 0.0146 (0.0592)	
training:	Epoch: [28][159/204]	Loss 0.0189 (0.0589)	
training:	Epoch: [28][160/204]	Loss 0.0127 (0.0586)	
training:	Epoch: [28][161/204]	Loss 0.0133 (0.0583)	
training:	Epoch: [28][162/204]	Loss 0.0147 (0.0581)	
training:	Epoch: [28][163/204]	Loss 0.1376 (0.0586)	
training:	Epoch: [28][164/204]	Loss 0.2274 (0.0596)	
training:	Epoch: [28][165/204]	Loss 0.0162 (0.0593)	
training:	Epoch: [28][166/204]	Loss 0.0125 (0.0590)	
training:	Epoch: [28][167/204]	Loss 0.0131 (0.0588)	
training:	Epoch: [28][168/204]	Loss 0.0125 (0.0585)	
training:	Epoch: [28][169/204]	Loss 0.0159 (0.0582)	
training:	Epoch: [28][170/204]	Loss 0.1579 (0.0588)	
training:	Epoch: [28][171/204]	Loss 0.0131 (0.0586)	
training:	Epoch: [28][172/204]	Loss 0.0123 (0.0583)	
training:	Epoch: [28][173/204]	Loss 0.1481 (0.0588)	
training:	Epoch: [28][174/204]	Loss 0.0197 (0.0586)	
training:	Epoch: [28][175/204]	Loss 0.0213 (0.0584)	
training:	Epoch: [28][176/204]	Loss 0.0138 (0.0581)	
training:	Epoch: [28][177/204]	Loss 0.0137 (0.0579)	
training:	Epoch: [28][178/204]	Loss 0.0127 (0.0576)	
training:	Epoch: [28][179/204]	Loss 0.0128 (0.0574)	
training:	Epoch: [28][180/204]	Loss 0.0132 (0.0571)	
training:	Epoch: [28][181/204]	Loss 0.0406 (0.0570)	
training:	Epoch: [28][182/204]	Loss 0.0140 (0.0568)	
training:	Epoch: [28][183/204]	Loss 0.0123 (0.0565)	
training:	Epoch: [28][184/204]	Loss 0.0140 (0.0563)	
training:	Epoch: [28][185/204]	Loss 0.1524 (0.0568)	
training:	Epoch: [28][186/204]	Loss 0.0144 (0.0566)	
training:	Epoch: [28][187/204]	Loss 0.0124 (0.0564)	
training:	Epoch: [28][188/204]	Loss 0.1235 (0.0567)	
training:	Epoch: [28][189/204]	Loss 0.1495 (0.0572)	
training:	Epoch: [28][190/204]	Loss 0.0126 (0.0570)	
training:	Epoch: [28][191/204]	Loss 0.0123 (0.0567)	
training:	Epoch: [28][192/204]	Loss 0.1625 (0.0573)	
training:	Epoch: [28][193/204]	Loss 0.0126 (0.0571)	
training:	Epoch: [28][194/204]	Loss 0.0124 (0.0568)	
training:	Epoch: [28][195/204]	Loss 0.0126 (0.0566)	
training:	Epoch: [28][196/204]	Loss 0.1458 (0.0571)	
training:	Epoch: [28][197/204]	Loss 0.0120 (0.0568)	
training:	Epoch: [28][198/204]	Loss 0.0137 (0.0566)	
training:	Epoch: [28][199/204]	Loss 0.1463 (0.0571)	
training:	Epoch: [28][200/204]	Loss 0.0132 (0.0568)	
training:	Epoch: [28][201/204]	Loss 0.1321 (0.0572)	
training:	Epoch: [28][202/204]	Loss 0.0121 (0.0570)	
training:	Epoch: [28][203/204]	Loss 0.1473 (0.0574)	
training:	Epoch: [28][204/204]	Loss 0.2772 (0.0585)	
Training:	 Loss: 0.0584

Training:	 ACC: 0.9901 0.9901 0.9894 0.9908
Validation:	 ACC: 0.7838 0.7844 0.7963 0.7713
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8410
Pretraining:	Epoch 29/500
----------
training:	Epoch: [29][1/204]	Loss 0.0124 (0.0124)	
training:	Epoch: [29][2/204]	Loss 0.0130 (0.0127)	
training:	Epoch: [29][3/204]	Loss 0.0146 (0.0133)	
training:	Epoch: [29][4/204]	Loss 0.0131 (0.0133)	
training:	Epoch: [29][5/204]	Loss 0.0133 (0.0133)	
training:	Epoch: [29][6/204]	Loss 0.0138 (0.0134)	
training:	Epoch: [29][7/204]	Loss 0.0125 (0.0132)	
training:	Epoch: [29][8/204]	Loss 0.1532 (0.0307)	
training:	Epoch: [29][9/204]	Loss 0.0134 (0.0288)	
training:	Epoch: [29][10/204]	Loss 0.0129 (0.0272)	
training:	Epoch: [29][11/204]	Loss 0.1501 (0.0384)	
training:	Epoch: [29][12/204]	Loss 0.0145 (0.0364)	
training:	Epoch: [29][13/204]	Loss 0.2677 (0.0542)	
training:	Epoch: [29][14/204]	Loss 0.0130 (0.0513)	
training:	Epoch: [29][15/204]	Loss 0.0140 (0.0488)	
training:	Epoch: [29][16/204]	Loss 0.1355 (0.0542)	
training:	Epoch: [29][17/204]	Loss 0.1373 (0.0591)	
training:	Epoch: [29][18/204]	Loss 0.0134 (0.0565)	
training:	Epoch: [29][19/204]	Loss 0.1358 (0.0607)	
training:	Epoch: [29][20/204]	Loss 0.0133 (0.0583)	
training:	Epoch: [29][21/204]	Loss 0.1461 (0.0625)	
training:	Epoch: [29][22/204]	Loss 0.0138 (0.0603)	
training:	Epoch: [29][23/204]	Loss 0.2682 (0.0693)	
training:	Epoch: [29][24/204]	Loss 0.0160 (0.0671)	
training:	Epoch: [29][25/204]	Loss 0.0247 (0.0654)	
training:	Epoch: [29][26/204]	Loss 0.0142 (0.0635)	
training:	Epoch: [29][27/204]	Loss 0.0137 (0.0616)	
training:	Epoch: [29][28/204]	Loss 0.0301 (0.0605)	
training:	Epoch: [29][29/204]	Loss 0.2531 (0.0671)	
training:	Epoch: [29][30/204]	Loss 0.0131 (0.0653)	
training:	Epoch: [29][31/204]	Loss 0.0143 (0.0637)	
training:	Epoch: [29][32/204]	Loss 0.0856 (0.0644)	
training:	Epoch: [29][33/204]	Loss 0.1471 (0.0669)	
training:	Epoch: [29][34/204]	Loss 0.0152 (0.0654)	
training:	Epoch: [29][35/204]	Loss 0.0171 (0.0640)	
training:	Epoch: [29][36/204]	Loss 0.0611 (0.0639)	
training:	Epoch: [29][37/204]	Loss 0.1848 (0.0672)	
training:	Epoch: [29][38/204]	Loss 0.0134 (0.0657)	
training:	Epoch: [29][39/204]	Loss 0.1613 (0.0682)	
training:	Epoch: [29][40/204]	Loss 0.0137 (0.0668)	
training:	Epoch: [29][41/204]	Loss 0.0144 (0.0656)	
training:	Epoch: [29][42/204]	Loss 0.1555 (0.0677)	
training:	Epoch: [29][43/204]	Loss 0.0152 (0.0665)	
training:	Epoch: [29][44/204]	Loss 0.0877 (0.0670)	
training:	Epoch: [29][45/204]	Loss 0.0330 (0.0662)	
training:	Epoch: [29][46/204]	Loss 0.0194 (0.0652)	
training:	Epoch: [29][47/204]	Loss 0.1475 (0.0669)	
training:	Epoch: [29][48/204]	Loss 0.3014 (0.0718)	
training:	Epoch: [29][49/204]	Loss 0.0125 (0.0706)	
training:	Epoch: [29][50/204]	Loss 0.1582 (0.0724)	
training:	Epoch: [29][51/204]	Loss 0.0159 (0.0713)	
training:	Epoch: [29][52/204]	Loss 0.0136 (0.0701)	
training:	Epoch: [29][53/204]	Loss 0.0147 (0.0691)	
training:	Epoch: [29][54/204]	Loss 0.0133 (0.0681)	
training:	Epoch: [29][55/204]	Loss 0.2908 (0.0721)	
training:	Epoch: [29][56/204]	Loss 0.1479 (0.0735)	
training:	Epoch: [29][57/204]	Loss 0.1446 (0.0747)	
training:	Epoch: [29][58/204]	Loss 0.0145 (0.0737)	
training:	Epoch: [29][59/204]	Loss 0.0265 (0.0729)	
training:	Epoch: [29][60/204]	Loss 0.0563 (0.0726)	
training:	Epoch: [29][61/204]	Loss 0.0288 (0.0719)	
training:	Epoch: [29][62/204]	Loss 0.0157 (0.0710)	
training:	Epoch: [29][63/204]	Loss 0.1492 (0.0722)	
training:	Epoch: [29][64/204]	Loss 0.0159 (0.0713)	
training:	Epoch: [29][65/204]	Loss 0.1510 (0.0726)	
training:	Epoch: [29][66/204]	Loss 0.0134 (0.0717)	
training:	Epoch: [29][67/204]	Loss 0.1357 (0.0726)	
training:	Epoch: [29][68/204]	Loss 0.0127 (0.0717)	
training:	Epoch: [29][69/204]	Loss 0.0169 (0.0709)	
training:	Epoch: [29][70/204]	Loss 0.0144 (0.0701)	
training:	Epoch: [29][71/204]	Loss 0.1770 (0.0716)	
training:	Epoch: [29][72/204]	Loss 0.0198 (0.0709)	
training:	Epoch: [29][73/204]	Loss 0.1461 (0.0720)	
training:	Epoch: [29][74/204]	Loss 0.1497 (0.0730)	
training:	Epoch: [29][75/204]	Loss 0.0134 (0.0722)	
training:	Epoch: [29][76/204]	Loss 0.1531 (0.0733)	
training:	Epoch: [29][77/204]	Loss 0.0274 (0.0727)	
training:	Epoch: [29][78/204]	Loss 0.0125 (0.0719)	
training:	Epoch: [29][79/204]	Loss 0.0140 (0.0712)	
training:	Epoch: [29][80/204]	Loss 0.0137 (0.0705)	
training:	Epoch: [29][81/204]	Loss 0.0143 (0.0698)	
training:	Epoch: [29][82/204]	Loss 0.0125 (0.0691)	
training:	Epoch: [29][83/204]	Loss 0.0223 (0.0685)	
training:	Epoch: [29][84/204]	Loss 0.1562 (0.0695)	
training:	Epoch: [29][85/204]	Loss 0.0119 (0.0689)	
training:	Epoch: [29][86/204]	Loss 0.0166 (0.0683)	
training:	Epoch: [29][87/204]	Loss 0.1523 (0.0692)	
training:	Epoch: [29][88/204]	Loss 0.0210 (0.0687)	
training:	Epoch: [29][89/204]	Loss 0.0161 (0.0681)	
training:	Epoch: [29][90/204]	Loss 0.0133 (0.0675)	
training:	Epoch: [29][91/204]	Loss 0.0161 (0.0669)	
training:	Epoch: [29][92/204]	Loss 0.0169 (0.0664)	
training:	Epoch: [29][93/204]	Loss 0.0139 (0.0658)	
training:	Epoch: [29][94/204]	Loss 0.0128 (0.0652)	
training:	Epoch: [29][95/204]	Loss 0.0129 (0.0647)	
training:	Epoch: [29][96/204]	Loss 0.2937 (0.0671)	
training:	Epoch: [29][97/204]	Loss 0.2688 (0.0692)	
training:	Epoch: [29][98/204]	Loss 0.1413 (0.0699)	
training:	Epoch: [29][99/204]	Loss 0.0158 (0.0693)	
training:	Epoch: [29][100/204]	Loss 0.0128 (0.0688)	
training:	Epoch: [29][101/204]	Loss 0.0827 (0.0689)	
training:	Epoch: [29][102/204]	Loss 0.0128 (0.0684)	
training:	Epoch: [29][103/204]	Loss 0.0128 (0.0678)	
training:	Epoch: [29][104/204]	Loss 0.0179 (0.0673)	
training:	Epoch: [29][105/204]	Loss 0.0140 (0.0668)	
training:	Epoch: [29][106/204]	Loss 0.1519 (0.0676)	
training:	Epoch: [29][107/204]	Loss 0.0135 (0.0671)	
training:	Epoch: [29][108/204]	Loss 0.1454 (0.0679)	
training:	Epoch: [29][109/204]	Loss 0.0125 (0.0674)	
training:	Epoch: [29][110/204]	Loss 0.0826 (0.0675)	
training:	Epoch: [29][111/204]	Loss 0.0678 (0.0675)	
training:	Epoch: [29][112/204]	Loss 0.0245 (0.0671)	
training:	Epoch: [29][113/204]	Loss 0.0136 (0.0666)	
training:	Epoch: [29][114/204]	Loss 0.0138 (0.0662)	
training:	Epoch: [29][115/204]	Loss 0.2965 (0.0682)	
training:	Epoch: [29][116/204]	Loss 0.1501 (0.0689)	
training:	Epoch: [29][117/204]	Loss 0.0127 (0.0684)	
training:	Epoch: [29][118/204]	Loss 0.0156 (0.0680)	
training:	Epoch: [29][119/204]	Loss 0.0811 (0.0681)	
training:	Epoch: [29][120/204]	Loss 0.0150 (0.0676)	
training:	Epoch: [29][121/204]	Loss 0.1372 (0.0682)	
training:	Epoch: [29][122/204]	Loss 0.4063 (0.0710)	
training:	Epoch: [29][123/204]	Loss 0.0128 (0.0705)	
training:	Epoch: [29][124/204]	Loss 0.0137 (0.0700)	
training:	Epoch: [29][125/204]	Loss 0.0124 (0.0696)	
training:	Epoch: [29][126/204]	Loss 0.0133 (0.0691)	
training:	Epoch: [29][127/204]	Loss 0.0128 (0.0687)	
training:	Epoch: [29][128/204]	Loss 0.0141 (0.0683)	
training:	Epoch: [29][129/204]	Loss 0.0144 (0.0678)	
training:	Epoch: [29][130/204]	Loss 0.0152 (0.0674)	
training:	Epoch: [29][131/204]	Loss 0.0141 (0.0670)	
training:	Epoch: [29][132/204]	Loss 0.1381 (0.0676)	
training:	Epoch: [29][133/204]	Loss 0.0160 (0.0672)	
training:	Epoch: [29][134/204]	Loss 0.0127 (0.0668)	
training:	Epoch: [29][135/204]	Loss 0.0126 (0.0664)	
training:	Epoch: [29][136/204]	Loss 0.0308 (0.0661)	
training:	Epoch: [29][137/204]	Loss 0.0135 (0.0657)	
training:	Epoch: [29][138/204]	Loss 0.0128 (0.0653)	
training:	Epoch: [29][139/204]	Loss 0.0123 (0.0650)	
training:	Epoch: [29][140/204]	Loss 0.0132 (0.0646)	
training:	Epoch: [29][141/204]	Loss 0.0132 (0.0642)	
training:	Epoch: [29][142/204]	Loss 0.1483 (0.0648)	
training:	Epoch: [29][143/204]	Loss 0.2778 (0.0663)	
training:	Epoch: [29][144/204]	Loss 0.0380 (0.0661)	
training:	Epoch: [29][145/204]	Loss 0.0141 (0.0658)	
training:	Epoch: [29][146/204]	Loss 0.0134 (0.0654)	
training:	Epoch: [29][147/204]	Loss 0.0152 (0.0651)	
training:	Epoch: [29][148/204]	Loss 0.0160 (0.0647)	
training:	Epoch: [29][149/204]	Loss 0.0371 (0.0645)	
training:	Epoch: [29][150/204]	Loss 0.0134 (0.0642)	
training:	Epoch: [29][151/204]	Loss 0.2513 (0.0654)	
training:	Epoch: [29][152/204]	Loss 0.0131 (0.0651)	
training:	Epoch: [29][153/204]	Loss 0.0305 (0.0649)	
training:	Epoch: [29][154/204]	Loss 0.2981 (0.0664)	
training:	Epoch: [29][155/204]	Loss 0.0118 (0.0660)	
training:	Epoch: [29][156/204]	Loss 0.0129 (0.0657)	
training:	Epoch: [29][157/204]	Loss 0.1482 (0.0662)	
training:	Epoch: [29][158/204]	Loss 0.0132 (0.0659)	
training:	Epoch: [29][159/204]	Loss 0.0139 (0.0655)	
training:	Epoch: [29][160/204]	Loss 0.0129 (0.0652)	
training:	Epoch: [29][161/204]	Loss 0.0158 (0.0649)	
training:	Epoch: [29][162/204]	Loss 0.0136 (0.0646)	
training:	Epoch: [29][163/204]	Loss 0.0121 (0.0643)	
training:	Epoch: [29][164/204]	Loss 0.0151 (0.0640)	
training:	Epoch: [29][165/204]	Loss 0.0130 (0.0637)	
training:	Epoch: [29][166/204]	Loss 0.0169 (0.0634)	
training:	Epoch: [29][167/204]	Loss 0.0140 (0.0631)	
training:	Epoch: [29][168/204]	Loss 0.0130 (0.0628)	
training:	Epoch: [29][169/204]	Loss 0.0134 (0.0625)	
training:	Epoch: [29][170/204]	Loss 0.1530 (0.0630)	
training:	Epoch: [29][171/204]	Loss 0.0149 (0.0627)	
training:	Epoch: [29][172/204]	Loss 0.0153 (0.0625)	
training:	Epoch: [29][173/204]	Loss 0.0126 (0.0622)	
training:	Epoch: [29][174/204]	Loss 0.0127 (0.0619)	
training:	Epoch: [29][175/204]	Loss 0.1372 (0.0623)	
training:	Epoch: [29][176/204]	Loss 0.0134 (0.0621)	
training:	Epoch: [29][177/204]	Loss 0.0171 (0.0618)	
training:	Epoch: [29][178/204]	Loss 0.0136 (0.0615)	
training:	Epoch: [29][179/204]	Loss 0.1395 (0.0620)	
training:	Epoch: [29][180/204]	Loss 0.0137 (0.0617)	
training:	Epoch: [29][181/204]	Loss 0.0134 (0.0614)	
training:	Epoch: [29][182/204]	Loss 0.0294 (0.0613)	
training:	Epoch: [29][183/204]	Loss 0.0179 (0.0610)	
training:	Epoch: [29][184/204]	Loss 0.1512 (0.0615)	
training:	Epoch: [29][185/204]	Loss 0.0117 (0.0612)	
training:	Epoch: [29][186/204]	Loss 0.0135 (0.0610)	
training:	Epoch: [29][187/204]	Loss 0.0137 (0.0607)	
training:	Epoch: [29][188/204]	Loss 0.1374 (0.0611)	
training:	Epoch: [29][189/204]	Loss 0.0129 (0.0609)	
training:	Epoch: [29][190/204]	Loss 0.0143 (0.0606)	
training:	Epoch: [29][191/204]	Loss 0.0247 (0.0604)	
training:	Epoch: [29][192/204]	Loss 0.0172 (0.0602)	
training:	Epoch: [29][193/204]	Loss 0.1481 (0.0607)	
training:	Epoch: [29][194/204]	Loss 0.0180 (0.0605)	
training:	Epoch: [29][195/204]	Loss 0.0136 (0.0602)	
training:	Epoch: [29][196/204]	Loss 0.0125 (0.0600)	
training:	Epoch: [29][197/204]	Loss 0.0145 (0.0597)	
training:	Epoch: [29][198/204]	Loss 0.0116 (0.0595)	
training:	Epoch: [29][199/204]	Loss 0.0133 (0.0593)	
training:	Epoch: [29][200/204]	Loss 0.0133 (0.0590)	
training:	Epoch: [29][201/204]	Loss 0.0127 (0.0588)	
training:	Epoch: [29][202/204]	Loss 0.2901 (0.0600)	
training:	Epoch: [29][203/204]	Loss 0.1498 (0.0604)	
training:	Epoch: [29][204/204]	Loss 0.0128 (0.0602)	
Training:	 Loss: 0.0601

Training:	 ACC: 0.9899 0.9899 0.9897 0.9901
Validation:	 ACC: 0.7865 0.7892 0.8454 0.7276
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8497
Pretraining:	Epoch 30/500
----------
training:	Epoch: [30][1/204]	Loss 0.1208 (0.1208)	
training:	Epoch: [30][2/204]	Loss 0.1564 (0.1386)	
training:	Epoch: [30][3/204]	Loss 0.1395 (0.1389)	
training:	Epoch: [30][4/204]	Loss 0.0188 (0.1089)	
training:	Epoch: [30][5/204]	Loss 0.0136 (0.0898)	
training:	Epoch: [30][6/204]	Loss 0.0172 (0.0777)	
training:	Epoch: [30][7/204]	Loss 0.0204 (0.0695)	
training:	Epoch: [30][8/204]	Loss 0.0151 (0.0627)	
training:	Epoch: [30][9/204]	Loss 0.0159 (0.0575)	
training:	Epoch: [30][10/204]	Loss 0.1445 (0.0662)	
training:	Epoch: [30][11/204]	Loss 0.0130 (0.0614)	
training:	Epoch: [30][12/204]	Loss 0.1495 (0.0687)	
training:	Epoch: [30][13/204]	Loss 0.0118 (0.0644)	
training:	Epoch: [30][14/204]	Loss 0.0134 (0.0607)	
training:	Epoch: [30][15/204]	Loss 0.0124 (0.0575)	
training:	Epoch: [30][16/204]	Loss 0.1518 (0.0634)	
training:	Epoch: [30][17/204]	Loss 0.0145 (0.0605)	
training:	Epoch: [30][18/204]	Loss 0.1542 (0.0657)	
training:	Epoch: [30][19/204]	Loss 0.1498 (0.0701)	
training:	Epoch: [30][20/204]	Loss 0.0126 (0.0673)	
training:	Epoch: [30][21/204]	Loss 0.0123 (0.0646)	
training:	Epoch: [30][22/204]	Loss 0.0131 (0.0623)	
training:	Epoch: [30][23/204]	Loss 0.1519 (0.0662)	
training:	Epoch: [30][24/204]	Loss 0.0178 (0.0642)	
training:	Epoch: [30][25/204]	Loss 0.1614 (0.0681)	
training:	Epoch: [30][26/204]	Loss 0.0129 (0.0660)	
training:	Epoch: [30][27/204]	Loss 0.1565 (0.0693)	
training:	Epoch: [30][28/204]	Loss 0.0149 (0.0674)	
training:	Epoch: [30][29/204]	Loss 0.0141 (0.0655)	
training:	Epoch: [30][30/204]	Loss 0.0239 (0.0641)	
training:	Epoch: [30][31/204]	Loss 0.0129 (0.0625)	
training:	Epoch: [30][32/204]	Loss 0.0118 (0.0609)	
training:	Epoch: [30][33/204]	Loss 0.0121 (0.0594)	
training:	Epoch: [30][34/204]	Loss 0.1438 (0.0619)	
training:	Epoch: [30][35/204]	Loss 0.0116 (0.0605)	
training:	Epoch: [30][36/204]	Loss 0.1531 (0.0630)	
training:	Epoch: [30][37/204]	Loss 0.0141 (0.0617)	
training:	Epoch: [30][38/204]	Loss 0.0114 (0.0604)	
training:	Epoch: [30][39/204]	Loss 0.0122 (0.0592)	
training:	Epoch: [30][40/204]	Loss 0.1440 (0.0613)	
training:	Epoch: [30][41/204]	Loss 0.1554 (0.0636)	
training:	Epoch: [30][42/204]	Loss 0.0141 (0.0624)	
training:	Epoch: [30][43/204]	Loss 0.0134 (0.0613)	
training:	Epoch: [30][44/204]	Loss 0.0118 (0.0601)	
training:	Epoch: [30][45/204]	Loss 0.1591 (0.0623)	
training:	Epoch: [30][46/204]	Loss 0.0126 (0.0613)	
training:	Epoch: [30][47/204]	Loss 0.1477 (0.0631)	
training:	Epoch: [30][48/204]	Loss 0.0115 (0.0620)	
training:	Epoch: [30][49/204]	Loss 0.1483 (0.0638)	
training:	Epoch: [30][50/204]	Loss 0.0129 (0.0628)	
training:	Epoch: [30][51/204]	Loss 0.0121 (0.0618)	
training:	Epoch: [30][52/204]	Loss 0.0128 (0.0608)	
training:	Epoch: [30][53/204]	Loss 0.1427 (0.0624)	
training:	Epoch: [30][54/204]	Loss 0.2767 (0.0663)	
training:	Epoch: [30][55/204]	Loss 0.2910 (0.0704)	
training:	Epoch: [30][56/204]	Loss 0.0120 (0.0694)	
training:	Epoch: [30][57/204]	Loss 0.0119 (0.0684)	
training:	Epoch: [30][58/204]	Loss 0.0126 (0.0674)	
training:	Epoch: [30][59/204]	Loss 0.0133 (0.0665)	
training:	Epoch: [30][60/204]	Loss 0.0139 (0.0656)	
training:	Epoch: [30][61/204]	Loss 0.0123 (0.0647)	
training:	Epoch: [30][62/204]	Loss 0.0126 (0.0639)	
training:	Epoch: [30][63/204]	Loss 0.1548 (0.0653)	
training:	Epoch: [30][64/204]	Loss 0.1460 (0.0666)	
training:	Epoch: [30][65/204]	Loss 0.1495 (0.0679)	
training:	Epoch: [30][66/204]	Loss 0.2910 (0.0713)	
training:	Epoch: [30][67/204]	Loss 0.0124 (0.0704)	
training:	Epoch: [30][68/204]	Loss 0.0122 (0.0695)	
training:	Epoch: [30][69/204]	Loss 0.0139 (0.0687)	
training:	Epoch: [30][70/204]	Loss 0.0207 (0.0680)	
training:	Epoch: [30][71/204]	Loss 0.0128 (0.0673)	
training:	Epoch: [30][72/204]	Loss 0.0120 (0.0665)	
training:	Epoch: [30][73/204]	Loss 0.0127 (0.0658)	
training:	Epoch: [30][74/204]	Loss 0.0142 (0.0651)	
training:	Epoch: [30][75/204]	Loss 0.0121 (0.0644)	
training:	Epoch: [30][76/204]	Loss 0.0129 (0.0637)	
training:	Epoch: [30][77/204]	Loss 0.0164 (0.0631)	
training:	Epoch: [30][78/204]	Loss 0.0127 (0.0624)	
training:	Epoch: [30][79/204]	Loss 0.0129 (0.0618)	
training:	Epoch: [30][80/204]	Loss 0.0126 (0.0612)	
training:	Epoch: [30][81/204]	Loss 0.1516 (0.0623)	
training:	Epoch: [30][82/204]	Loss 0.0121 (0.0617)	
training:	Epoch: [30][83/204]	Loss 0.0684 (0.0618)	
training:	Epoch: [30][84/204]	Loss 0.0209 (0.0613)	
training:	Epoch: [30][85/204]	Loss 0.0132 (0.0607)	
training:	Epoch: [30][86/204]	Loss 0.1486 (0.0617)	
training:	Epoch: [30][87/204]	Loss 0.0147 (0.0612)	
training:	Epoch: [30][88/204]	Loss 0.0125 (0.0606)	
training:	Epoch: [30][89/204]	Loss 0.0121 (0.0601)	
training:	Epoch: [30][90/204]	Loss 0.0136 (0.0596)	
training:	Epoch: [30][91/204]	Loss 0.0121 (0.0591)	
training:	Epoch: [30][92/204]	Loss 0.1006 (0.0595)	
training:	Epoch: [30][93/204]	Loss 0.0175 (0.0591)	
training:	Epoch: [30][94/204]	Loss 0.0130 (0.0586)	
training:	Epoch: [30][95/204]	Loss 0.0141 (0.0581)	
training:	Epoch: [30][96/204]	Loss 0.2382 (0.0600)	
training:	Epoch: [30][97/204]	Loss 0.1561 (0.0610)	
training:	Epoch: [30][98/204]	Loss 0.0145 (0.0605)	
training:	Epoch: [30][99/204]	Loss 0.0180 (0.0601)	
training:	Epoch: [30][100/204]	Loss 0.0121 (0.0596)	
training:	Epoch: [30][101/204]	Loss 0.0130 (0.0591)	
training:	Epoch: [30][102/204]	Loss 0.1471 (0.0600)	
training:	Epoch: [30][103/204]	Loss 0.0124 (0.0595)	
training:	Epoch: [30][104/204]	Loss 0.0119 (0.0591)	
training:	Epoch: [30][105/204]	Loss 0.0131 (0.0586)	
training:	Epoch: [30][106/204]	Loss 0.0140 (0.0582)	
training:	Epoch: [30][107/204]	Loss 0.0173 (0.0578)	
training:	Epoch: [30][108/204]	Loss 0.0156 (0.0574)	
training:	Epoch: [30][109/204]	Loss 0.0145 (0.0570)	
training:	Epoch: [30][110/204]	Loss 0.0191 (0.0567)	
training:	Epoch: [30][111/204]	Loss 0.0129 (0.0563)	
training:	Epoch: [30][112/204]	Loss 0.0133 (0.0559)	
training:	Epoch: [30][113/204]	Loss 0.1801 (0.0570)	
training:	Epoch: [30][114/204]	Loss 0.0130 (0.0566)	
training:	Epoch: [30][115/204]	Loss 0.0123 (0.0562)	
training:	Epoch: [30][116/204]	Loss 0.1411 (0.0570)	
training:	Epoch: [30][117/204]	Loss 0.1404 (0.0577)	
training:	Epoch: [30][118/204]	Loss 0.0125 (0.0573)	
training:	Epoch: [30][119/204]	Loss 0.1491 (0.0581)	
training:	Epoch: [30][120/204]	Loss 0.0120 (0.0577)	
training:	Epoch: [30][121/204]	Loss 0.0127 (0.0573)	
training:	Epoch: [30][122/204]	Loss 0.0121 (0.0569)	
training:	Epoch: [30][123/204]	Loss 0.0128 (0.0566)	
training:	Epoch: [30][124/204]	Loss 0.0118 (0.0562)	
training:	Epoch: [30][125/204]	Loss 0.0146 (0.0559)	
training:	Epoch: [30][126/204]	Loss 0.0140 (0.0556)	
training:	Epoch: [30][127/204]	Loss 0.0147 (0.0552)	
training:	Epoch: [30][128/204]	Loss 0.0153 (0.0549)	
training:	Epoch: [30][129/204]	Loss 0.0118 (0.0546)	
training:	Epoch: [30][130/204]	Loss 0.0133 (0.0543)	
training:	Epoch: [30][131/204]	Loss 0.0119 (0.0540)	
training:	Epoch: [30][132/204]	Loss 0.0128 (0.0536)	
training:	Epoch: [30][133/204]	Loss 0.0130 (0.0533)	
training:	Epoch: [30][134/204]	Loss 0.0118 (0.0530)	
training:	Epoch: [30][135/204]	Loss 0.0112 (0.0527)	
training:	Epoch: [30][136/204]	Loss 0.0117 (0.0524)	
training:	Epoch: [30][137/204]	Loss 0.0131 (0.0521)	
training:	Epoch: [30][138/204]	Loss 0.0117 (0.0518)	
training:	Epoch: [30][139/204]	Loss 0.0126 (0.0515)	
training:	Epoch: [30][140/204]	Loss 0.1536 (0.0523)	
training:	Epoch: [30][141/204]	Loss 0.0119 (0.0520)	
training:	Epoch: [30][142/204]	Loss 0.0115 (0.0517)	
training:	Epoch: [30][143/204]	Loss 0.0121 (0.0514)	
training:	Epoch: [30][144/204]	Loss 0.2774 (0.0530)	
training:	Epoch: [30][145/204]	Loss 0.0113 (0.0527)	
training:	Epoch: [30][146/204]	Loss 0.0119 (0.0524)	
training:	Epoch: [30][147/204]	Loss 0.1510 (0.0531)	
training:	Epoch: [30][148/204]	Loss 0.1336 (0.0536)	
training:	Epoch: [30][149/204]	Loss 0.0171 (0.0534)	
training:	Epoch: [30][150/204]	Loss 0.0135 (0.0531)	
training:	Epoch: [30][151/204]	Loss 0.0127 (0.0529)	
training:	Epoch: [30][152/204]	Loss 0.0174 (0.0526)	
training:	Epoch: [30][153/204]	Loss 0.0131 (0.0524)	
training:	Epoch: [30][154/204]	Loss 0.0119 (0.0521)	
training:	Epoch: [30][155/204]	Loss 0.0142 (0.0519)	
training:	Epoch: [30][156/204]	Loss 0.2795 (0.0533)	
training:	Epoch: [30][157/204]	Loss 0.0118 (0.0531)	
training:	Epoch: [30][158/204]	Loss 0.0123 (0.0528)	
training:	Epoch: [30][159/204]	Loss 0.0112 (0.0525)	
training:	Epoch: [30][160/204]	Loss 0.1582 (0.0532)	
training:	Epoch: [30][161/204]	Loss 0.1539 (0.0538)	
training:	Epoch: [30][162/204]	Loss 0.1512 (0.0544)	
training:	Epoch: [30][163/204]	Loss 0.1492 (0.0550)	
training:	Epoch: [30][164/204]	Loss 0.0114 (0.0547)	
training:	Epoch: [30][165/204]	Loss 0.0110 (0.0545)	
training:	Epoch: [30][166/204]	Loss 0.0124 (0.0542)	
training:	Epoch: [30][167/204]	Loss 0.1497 (0.0548)	
training:	Epoch: [30][168/204]	Loss 0.1588 (0.0554)	
training:	Epoch: [30][169/204]	Loss 0.2680 (0.0567)	
training:	Epoch: [30][170/204]	Loss 0.0165 (0.0564)	
training:	Epoch: [30][171/204]	Loss 0.0113 (0.0562)	
training:	Epoch: [30][172/204]	Loss 0.0118 (0.0559)	
training:	Epoch: [30][173/204]	Loss 0.0117 (0.0557)	
training:	Epoch: [30][174/204]	Loss 0.0124 (0.0554)	
training:	Epoch: [30][175/204]	Loss 0.0124 (0.0552)	
training:	Epoch: [30][176/204]	Loss 0.1485 (0.0557)	
training:	Epoch: [30][177/204]	Loss 0.0118 (0.0555)	
training:	Epoch: [30][178/204]	Loss 0.0137 (0.0552)	
training:	Epoch: [30][179/204]	Loss 0.0129 (0.0550)	
training:	Epoch: [30][180/204]	Loss 0.0184 (0.0548)	
training:	Epoch: [30][181/204]	Loss 0.0116 (0.0545)	
training:	Epoch: [30][182/204]	Loss 0.0109 (0.0543)	
training:	Epoch: [30][183/204]	Loss 0.1536 (0.0548)	
training:	Epoch: [30][184/204]	Loss 0.1418 (0.0553)	
training:	Epoch: [30][185/204]	Loss 0.1518 (0.0558)	
training:	Epoch: [30][186/204]	Loss 0.0127 (0.0556)	
training:	Epoch: [30][187/204]	Loss 0.0119 (0.0554)	
training:	Epoch: [30][188/204]	Loss 0.0121 (0.0551)	
training:	Epoch: [30][189/204]	Loss 0.0126 (0.0549)	
training:	Epoch: [30][190/204]	Loss 0.2658 (0.0560)	
training:	Epoch: [30][191/204]	Loss 0.0121 (0.0558)	
training:	Epoch: [30][192/204]	Loss 0.0125 (0.0556)	
training:	Epoch: [30][193/204]	Loss 0.0131 (0.0553)	
training:	Epoch: [30][194/204]	Loss 0.0195 (0.0552)	
training:	Epoch: [30][195/204]	Loss 0.1248 (0.0555)	
training:	Epoch: [30][196/204]	Loss 0.0116 (0.0553)	
training:	Epoch: [30][197/204]	Loss 0.1446 (0.0557)	
training:	Epoch: [30][198/204]	Loss 0.0110 (0.0555)	
training:	Epoch: [30][199/204]	Loss 0.1335 (0.0559)	
training:	Epoch: [30][200/204]	Loss 0.0133 (0.0557)	
training:	Epoch: [30][201/204]	Loss 0.0172 (0.0555)	
training:	Epoch: [30][202/204]	Loss 0.1502 (0.0560)	
training:	Epoch: [30][203/204]	Loss 0.0124 (0.0558)	
training:	Epoch: [30][204/204]	Loss 0.0127 (0.0556)	
Training:	 Loss: 0.0555

Training:	 ACC: 0.9904 0.9904 0.9900 0.9908
Validation:	 ACC: 0.7856 0.7854 0.7820 0.7892
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8565
Pretraining:	Epoch 31/500
----------
training:	Epoch: [31][1/204]	Loss 0.0286 (0.0286)	
training:	Epoch: [31][2/204]	Loss 0.0127 (0.0207)	
training:	Epoch: [31][3/204]	Loss 0.0120 (0.0178)	
training:	Epoch: [31][4/204]	Loss 0.0402 (0.0234)	
training:	Epoch: [31][5/204]	Loss 0.0116 (0.0210)	
training:	Epoch: [31][6/204]	Loss 0.0127 (0.0196)	
training:	Epoch: [31][7/204]	Loss 0.1556 (0.0391)	
training:	Epoch: [31][8/204]	Loss 0.0145 (0.0360)	
training:	Epoch: [31][9/204]	Loss 0.0713 (0.0399)	
training:	Epoch: [31][10/204]	Loss 0.0174 (0.0377)	
training:	Epoch: [31][11/204]	Loss 0.0120 (0.0353)	
training:	Epoch: [31][12/204]	Loss 0.0126 (0.0334)	
training:	Epoch: [31][13/204]	Loss 0.0113 (0.0317)	
training:	Epoch: [31][14/204]	Loss 0.0140 (0.0305)	
training:	Epoch: [31][15/204]	Loss 0.1522 (0.0386)	
training:	Epoch: [31][16/204]	Loss 0.0118 (0.0369)	
training:	Epoch: [31][17/204]	Loss 0.0123 (0.0355)	
training:	Epoch: [31][18/204]	Loss 0.1553 (0.0421)	
training:	Epoch: [31][19/204]	Loss 0.2687 (0.0540)	
training:	Epoch: [31][20/204]	Loss 0.0129 (0.0520)	
training:	Epoch: [31][21/204]	Loss 0.0118 (0.0501)	
training:	Epoch: [31][22/204]	Loss 0.1363 (0.0540)	
training:	Epoch: [31][23/204]	Loss 0.0117 (0.0522)	
training:	Epoch: [31][24/204]	Loss 0.0121 (0.0505)	
training:	Epoch: [31][25/204]	Loss 0.1542 (0.0546)	
training:	Epoch: [31][26/204]	Loss 0.0117 (0.0530)	
training:	Epoch: [31][27/204]	Loss 0.0123 (0.0515)	
training:	Epoch: [31][28/204]	Loss 0.3053 (0.0605)	
training:	Epoch: [31][29/204]	Loss 0.0154 (0.0590)	
training:	Epoch: [31][30/204]	Loss 0.0217 (0.0577)	
training:	Epoch: [31][31/204]	Loss 0.0125 (0.0563)	
training:	Epoch: [31][32/204]	Loss 0.0120 (0.0549)	
training:	Epoch: [31][33/204]	Loss 0.1480 (0.0577)	
training:	Epoch: [31][34/204]	Loss 0.0393 (0.0572)	
training:	Epoch: [31][35/204]	Loss 0.0124 (0.0559)	
training:	Epoch: [31][36/204]	Loss 0.2616 (0.0616)	
training:	Epoch: [31][37/204]	Loss 0.1547 (0.0641)	
training:	Epoch: [31][38/204]	Loss 0.0125 (0.0628)	
training:	Epoch: [31][39/204]	Loss 0.1537 (0.0651)	
training:	Epoch: [31][40/204]	Loss 0.0179 (0.0639)	
training:	Epoch: [31][41/204]	Loss 0.0123 (0.0627)	
training:	Epoch: [31][42/204]	Loss 0.0155 (0.0615)	
training:	Epoch: [31][43/204]	Loss 0.0137 (0.0604)	
training:	Epoch: [31][44/204]	Loss 0.1492 (0.0624)	
training:	Epoch: [31][45/204]	Loss 0.1468 (0.0643)	
training:	Epoch: [31][46/204]	Loss 0.1527 (0.0662)	
training:	Epoch: [31][47/204]	Loss 0.0129 (0.0651)	
training:	Epoch: [31][48/204]	Loss 0.0116 (0.0640)	
training:	Epoch: [31][49/204]	Loss 0.0127 (0.0629)	
training:	Epoch: [31][50/204]	Loss 0.0138 (0.0620)	
training:	Epoch: [31][51/204]	Loss 0.0128 (0.0610)	
training:	Epoch: [31][52/204]	Loss 0.1558 (0.0628)	
training:	Epoch: [31][53/204]	Loss 0.0124 (0.0619)	
training:	Epoch: [31][54/204]	Loss 0.0141 (0.0610)	
training:	Epoch: [31][55/204]	Loss 0.0125 (0.0601)	
training:	Epoch: [31][56/204]	Loss 0.0119 (0.0592)	
training:	Epoch: [31][57/204]	Loss 0.0129 (0.0584)	
training:	Epoch: [31][58/204]	Loss 0.0138 (0.0577)	
training:	Epoch: [31][59/204]	Loss 0.1527 (0.0593)	
training:	Epoch: [31][60/204]	Loss 0.0116 (0.0585)	
training:	Epoch: [31][61/204]	Loss 0.0113 (0.0577)	
training:	Epoch: [31][62/204]	Loss 0.0171 (0.0570)	
training:	Epoch: [31][63/204]	Loss 0.1343 (0.0583)	
training:	Epoch: [31][64/204]	Loss 0.0127 (0.0576)	
training:	Epoch: [31][65/204]	Loss 0.0133 (0.0569)	
training:	Epoch: [31][66/204]	Loss 0.0113 (0.0562)	
training:	Epoch: [31][67/204]	Loss 0.0137 (0.0556)	
training:	Epoch: [31][68/204]	Loss 0.0127 (0.0549)	
training:	Epoch: [31][69/204]	Loss 0.0206 (0.0544)	
training:	Epoch: [31][70/204]	Loss 0.1531 (0.0558)	
training:	Epoch: [31][71/204]	Loss 0.1410 (0.0570)	
training:	Epoch: [31][72/204]	Loss 0.0369 (0.0568)	
training:	Epoch: [31][73/204]	Loss 0.0123 (0.0561)	
training:	Epoch: [31][74/204]	Loss 0.0116 (0.0555)	
training:	Epoch: [31][75/204]	Loss 0.0122 (0.0550)	
training:	Epoch: [31][76/204]	Loss 0.0123 (0.0544)	
training:	Epoch: [31][77/204]	Loss 0.0125 (0.0539)	
training:	Epoch: [31][78/204]	Loss 0.0119 (0.0533)	
training:	Epoch: [31][79/204]	Loss 0.0172 (0.0529)	
training:	Epoch: [31][80/204]	Loss 0.0119 (0.0524)	
training:	Epoch: [31][81/204]	Loss 0.1531 (0.0536)	
training:	Epoch: [31][82/204]	Loss 0.0142 (0.0531)	
training:	Epoch: [31][83/204]	Loss 0.0118 (0.0526)	
training:	Epoch: [31][84/204]	Loss 0.1610 (0.0539)	
training:	Epoch: [31][85/204]	Loss 0.0188 (0.0535)	
training:	Epoch: [31][86/204]	Loss 0.1394 (0.0545)	
training:	Epoch: [31][87/204]	Loss 0.0130 (0.0540)	
training:	Epoch: [31][88/204]	Loss 0.0652 (0.0541)	
training:	Epoch: [31][89/204]	Loss 0.0127 (0.0537)	
training:	Epoch: [31][90/204]	Loss 0.0127 (0.0532)	
training:	Epoch: [31][91/204]	Loss 0.0123 (0.0528)	
training:	Epoch: [31][92/204]	Loss 0.0127 (0.0523)	
training:	Epoch: [31][93/204]	Loss 0.0189 (0.0520)	
training:	Epoch: [31][94/204]	Loss 0.0115 (0.0515)	
training:	Epoch: [31][95/204]	Loss 0.0134 (0.0511)	
training:	Epoch: [31][96/204]	Loss 0.0150 (0.0508)	
training:	Epoch: [31][97/204]	Loss 0.0119 (0.0504)	
training:	Epoch: [31][98/204]	Loss 0.0133 (0.0500)	
training:	Epoch: [31][99/204]	Loss 0.0153 (0.0496)	
training:	Epoch: [31][100/204]	Loss 0.0190 (0.0493)	
training:	Epoch: [31][101/204]	Loss 0.0124 (0.0490)	
training:	Epoch: [31][102/204]	Loss 0.1465 (0.0499)	
training:	Epoch: [31][103/204]	Loss 0.0110 (0.0495)	
training:	Epoch: [31][104/204]	Loss 0.0115 (0.0492)	
training:	Epoch: [31][105/204]	Loss 0.0122 (0.0488)	
training:	Epoch: [31][106/204]	Loss 0.1575 (0.0499)	
training:	Epoch: [31][107/204]	Loss 0.0300 (0.0497)	
training:	Epoch: [31][108/204]	Loss 0.1488 (0.0506)	
training:	Epoch: [31][109/204]	Loss 0.0110 (0.0502)	
training:	Epoch: [31][110/204]	Loss 0.1283 (0.0509)	
training:	Epoch: [31][111/204]	Loss 0.0120 (0.0506)	
training:	Epoch: [31][112/204]	Loss 0.0118 (0.0502)	
training:	Epoch: [31][113/204]	Loss 0.0123 (0.0499)	
training:	Epoch: [31][114/204]	Loss 0.0130 (0.0496)	
training:	Epoch: [31][115/204]	Loss 0.1400 (0.0504)	
training:	Epoch: [31][116/204]	Loss 0.0199 (0.0501)	
training:	Epoch: [31][117/204]	Loss 0.0110 (0.0498)	
training:	Epoch: [31][118/204]	Loss 0.0110 (0.0494)	
training:	Epoch: [31][119/204]	Loss 0.0111 (0.0491)	
training:	Epoch: [31][120/204]	Loss 0.0143 (0.0488)	
training:	Epoch: [31][121/204]	Loss 0.0122 (0.0485)	
training:	Epoch: [31][122/204]	Loss 0.1378 (0.0493)	
training:	Epoch: [31][123/204]	Loss 0.2974 (0.0513)	
training:	Epoch: [31][124/204]	Loss 0.0111 (0.0509)	
training:	Epoch: [31][125/204]	Loss 0.0123 (0.0506)	
training:	Epoch: [31][126/204]	Loss 0.0140 (0.0503)	
training:	Epoch: [31][127/204]	Loss 0.1425 (0.0511)	
training:	Epoch: [31][128/204]	Loss 0.0156 (0.0508)	
training:	Epoch: [31][129/204]	Loss 0.0416 (0.0507)	
training:	Epoch: [31][130/204]	Loss 0.0116 (0.0504)	
training:	Epoch: [31][131/204]	Loss 0.1481 (0.0512)	
training:	Epoch: [31][132/204]	Loss 0.1397 (0.0518)	
training:	Epoch: [31][133/204]	Loss 0.1407 (0.0525)	
training:	Epoch: [31][134/204]	Loss 0.0125 (0.0522)	
training:	Epoch: [31][135/204]	Loss 0.2877 (0.0540)	
training:	Epoch: [31][136/204]	Loss 0.0115 (0.0536)	
training:	Epoch: [31][137/204]	Loss 0.1499 (0.0543)	
training:	Epoch: [31][138/204]	Loss 0.1547 (0.0551)	
training:	Epoch: [31][139/204]	Loss 0.0123 (0.0548)	
training:	Epoch: [31][140/204]	Loss 0.0141 (0.0545)	
training:	Epoch: [31][141/204]	Loss 0.0214 (0.0542)	
training:	Epoch: [31][142/204]	Loss 0.0125 (0.0539)	
training:	Epoch: [31][143/204]	Loss 0.0135 (0.0537)	
training:	Epoch: [31][144/204]	Loss 0.1382 (0.0542)	
training:	Epoch: [31][145/204]	Loss 0.1585 (0.0550)	
training:	Epoch: [31][146/204]	Loss 0.0131 (0.0547)	
training:	Epoch: [31][147/204]	Loss 0.0118 (0.0544)	
training:	Epoch: [31][148/204]	Loss 0.1512 (0.0550)	
training:	Epoch: [31][149/204]	Loss 0.1272 (0.0555)	
training:	Epoch: [31][150/204]	Loss 0.0177 (0.0553)	
training:	Epoch: [31][151/204]	Loss 0.0122 (0.0550)	
training:	Epoch: [31][152/204]	Loss 0.0114 (0.0547)	
training:	Epoch: [31][153/204]	Loss 0.0171 (0.0545)	
training:	Epoch: [31][154/204]	Loss 0.0134 (0.0542)	
training:	Epoch: [31][155/204]	Loss 0.1569 (0.0549)	
training:	Epoch: [31][156/204]	Loss 0.0159 (0.0546)	
training:	Epoch: [31][157/204]	Loss 0.0123 (0.0543)	
training:	Epoch: [31][158/204]	Loss 0.0134 (0.0541)	
training:	Epoch: [31][159/204]	Loss 0.0112 (0.0538)	
training:	Epoch: [31][160/204]	Loss 0.0122 (0.0535)	
training:	Epoch: [31][161/204]	Loss 0.0118 (0.0533)	
training:	Epoch: [31][162/204]	Loss 0.0122 (0.0530)	
training:	Epoch: [31][163/204]	Loss 0.0127 (0.0528)	
training:	Epoch: [31][164/204]	Loss 0.1368 (0.0533)	
training:	Epoch: [31][165/204]	Loss 0.0120 (0.0530)	
training:	Epoch: [31][166/204]	Loss 0.1269 (0.0535)	
training:	Epoch: [31][167/204]	Loss 0.0110 (0.0532)	
training:	Epoch: [31][168/204]	Loss 0.0127 (0.0530)	
training:	Epoch: [31][169/204]	Loss 0.0128 (0.0528)	
training:	Epoch: [31][170/204]	Loss 0.1481 (0.0533)	
training:	Epoch: [31][171/204]	Loss 0.0162 (0.0531)	
training:	Epoch: [31][172/204]	Loss 0.0118 (0.0529)	
training:	Epoch: [31][173/204]	Loss 0.0127 (0.0526)	
training:	Epoch: [31][174/204]	Loss 0.2927 (0.0540)	
training:	Epoch: [31][175/204]	Loss 0.1559 (0.0546)	
training:	Epoch: [31][176/204]	Loss 0.0143 (0.0544)	
training:	Epoch: [31][177/204]	Loss 0.1415 (0.0549)	
training:	Epoch: [31][178/204]	Loss 0.0142 (0.0546)	
training:	Epoch: [31][179/204]	Loss 0.0120 (0.0544)	
training:	Epoch: [31][180/204]	Loss 0.0118 (0.0542)	
training:	Epoch: [31][181/204]	Loss 0.0125 (0.0539)	
training:	Epoch: [31][182/204]	Loss 0.0124 (0.0537)	
training:	Epoch: [31][183/204]	Loss 0.0110 (0.0535)	
training:	Epoch: [31][184/204]	Loss 0.0119 (0.0532)	
training:	Epoch: [31][185/204]	Loss 0.1547 (0.0538)	
training:	Epoch: [31][186/204]	Loss 0.1423 (0.0543)	
training:	Epoch: [31][187/204]	Loss 0.0111 (0.0540)	
training:	Epoch: [31][188/204]	Loss 0.0109 (0.0538)	
training:	Epoch: [31][189/204]	Loss 0.1329 (0.0542)	
training:	Epoch: [31][190/204]	Loss 0.0131 (0.0540)	
training:	Epoch: [31][191/204]	Loss 0.1489 (0.0545)	
training:	Epoch: [31][192/204]	Loss 0.1580 (0.0550)	
training:	Epoch: [31][193/204]	Loss 0.0114 (0.0548)	
training:	Epoch: [31][194/204]	Loss 0.0235 (0.0546)	
training:	Epoch: [31][195/204]	Loss 0.1434 (0.0551)	
training:	Epoch: [31][196/204]	Loss 0.0119 (0.0549)	
training:	Epoch: [31][197/204]	Loss 0.1297 (0.0553)	
training:	Epoch: [31][198/204]	Loss 0.1357 (0.0557)	
training:	Epoch: [31][199/204]	Loss 0.0117 (0.0554)	
training:	Epoch: [31][200/204]	Loss 0.0345 (0.0553)	
training:	Epoch: [31][201/204]	Loss 0.1489 (0.0558)	
training:	Epoch: [31][202/204]	Loss 0.0115 (0.0556)	
training:	Epoch: [31][203/204]	Loss 0.1560 (0.0561)	
training:	Epoch: [31][204/204]	Loss 0.0200 (0.0559)	
Training:	 Loss: 0.0558

Training:	 ACC: 0.9905 0.9905 0.9900 0.9911
Validation:	 ACC: 0.7836 0.7849 0.8127 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8642
Pretraining:	Epoch 32/500
----------
training:	Epoch: [32][1/204]	Loss 0.1516 (0.1516)	
training:	Epoch: [32][2/204]	Loss 0.1481 (0.1498)	
training:	Epoch: [32][3/204]	Loss 0.0125 (0.1041)	
training:	Epoch: [32][4/204]	Loss 0.0124 (0.0812)	
training:	Epoch: [32][5/204]	Loss 0.0115 (0.0672)	
training:	Epoch: [32][6/204]	Loss 0.0125 (0.0581)	
training:	Epoch: [32][7/204]	Loss 0.0117 (0.0515)	
training:	Epoch: [32][8/204]	Loss 0.1586 (0.0649)	
training:	Epoch: [32][9/204]	Loss 0.0118 (0.0590)	
training:	Epoch: [32][10/204]	Loss 0.0119 (0.0543)	
training:	Epoch: [32][11/204]	Loss 0.0149 (0.0507)	
training:	Epoch: [32][12/204]	Loss 0.0123 (0.0475)	
training:	Epoch: [32][13/204]	Loss 0.0122 (0.0448)	
training:	Epoch: [32][14/204]	Loss 0.0137 (0.0426)	
training:	Epoch: [32][15/204]	Loss 0.0128 (0.0406)	
training:	Epoch: [32][16/204]	Loss 0.0116 (0.0388)	
training:	Epoch: [32][17/204]	Loss 0.0115 (0.0372)	
training:	Epoch: [32][18/204]	Loss 0.0114 (0.0357)	
training:	Epoch: [32][19/204]	Loss 0.1521 (0.0418)	
training:	Epoch: [32][20/204]	Loss 0.1380 (0.0467)	
training:	Epoch: [32][21/204]	Loss 0.0151 (0.0451)	
training:	Epoch: [32][22/204]	Loss 0.1483 (0.0498)	
training:	Epoch: [32][23/204]	Loss 0.0121 (0.0482)	
training:	Epoch: [32][24/204]	Loss 0.0113 (0.0467)	
training:	Epoch: [32][25/204]	Loss 0.0121 (0.0453)	
training:	Epoch: [32][26/204]	Loss 0.0364 (0.0449)	
training:	Epoch: [32][27/204]	Loss 0.0128 (0.0437)	
training:	Epoch: [32][28/204]	Loss 0.0130 (0.0426)	
training:	Epoch: [32][29/204]	Loss 0.0119 (0.0416)	
training:	Epoch: [32][30/204]	Loss 0.1531 (0.0453)	
training:	Epoch: [32][31/204]	Loss 0.0121 (0.0442)	
training:	Epoch: [32][32/204]	Loss 0.0115 (0.0432)	
training:	Epoch: [32][33/204]	Loss 0.0124 (0.0423)	
training:	Epoch: [32][34/204]	Loss 0.1508 (0.0455)	
training:	Epoch: [32][35/204]	Loss 0.0120 (0.0445)	
training:	Epoch: [32][36/204]	Loss 0.0123 (0.0436)	
training:	Epoch: [32][37/204]	Loss 0.1587 (0.0467)	
training:	Epoch: [32][38/204]	Loss 0.0117 (0.0458)	
training:	Epoch: [32][39/204]	Loss 0.0118 (0.0449)	
training:	Epoch: [32][40/204]	Loss 0.0117 (0.0441)	
training:	Epoch: [32][41/204]	Loss 0.0116 (0.0433)	
training:	Epoch: [32][42/204]	Loss 0.0117 (0.0426)	
training:	Epoch: [32][43/204]	Loss 0.1354 (0.0447)	
training:	Epoch: [32][44/204]	Loss 0.1342 (0.0468)	
training:	Epoch: [32][45/204]	Loss 0.1411 (0.0488)	
training:	Epoch: [32][46/204]	Loss 0.0118 (0.0480)	
training:	Epoch: [32][47/204]	Loss 0.0116 (0.0473)	
training:	Epoch: [32][48/204]	Loss 0.0112 (0.0465)	
training:	Epoch: [32][49/204]	Loss 0.0127 (0.0458)	
training:	Epoch: [32][50/204]	Loss 0.2053 (0.0490)	
training:	Epoch: [32][51/204]	Loss 0.0199 (0.0484)	
training:	Epoch: [32][52/204]	Loss 0.0115 (0.0477)	
training:	Epoch: [32][53/204]	Loss 0.0114 (0.0470)	
training:	Epoch: [32][54/204]	Loss 0.0122 (0.0464)	
training:	Epoch: [32][55/204]	Loss 0.1506 (0.0483)	
training:	Epoch: [32][56/204]	Loss 0.0115 (0.0476)	
training:	Epoch: [32][57/204]	Loss 0.2982 (0.0520)	
training:	Epoch: [32][58/204]	Loss 0.0117 (0.0513)	
training:	Epoch: [32][59/204]	Loss 0.0123 (0.0507)	
training:	Epoch: [32][60/204]	Loss 0.0137 (0.0501)	
training:	Epoch: [32][61/204]	Loss 0.2963 (0.0541)	
training:	Epoch: [32][62/204]	Loss 0.0145 (0.0535)	
training:	Epoch: [32][63/204]	Loss 0.1339 (0.0547)	
training:	Epoch: [32][64/204]	Loss 0.0122 (0.0541)	
training:	Epoch: [32][65/204]	Loss 0.0196 (0.0535)	
training:	Epoch: [32][66/204]	Loss 0.0112 (0.0529)	
training:	Epoch: [32][67/204]	Loss 0.2670 (0.0561)	
training:	Epoch: [32][68/204]	Loss 0.0116 (0.0554)	
training:	Epoch: [32][69/204]	Loss 0.1348 (0.0566)	
training:	Epoch: [32][70/204]	Loss 0.1543 (0.0580)	
training:	Epoch: [32][71/204]	Loss 0.0116 (0.0573)	
training:	Epoch: [32][72/204]	Loss 0.0124 (0.0567)	
training:	Epoch: [32][73/204]	Loss 0.0120 (0.0561)	
training:	Epoch: [32][74/204]	Loss 0.0136 (0.0555)	
training:	Epoch: [32][75/204]	Loss 0.0109 (0.0549)	
training:	Epoch: [32][76/204]	Loss 0.1503 (0.0562)	
training:	Epoch: [32][77/204]	Loss 0.0113 (0.0556)	
training:	Epoch: [32][78/204]	Loss 0.0141 (0.0551)	
training:	Epoch: [32][79/204]	Loss 0.0121 (0.0545)	
training:	Epoch: [32][80/204]	Loss 0.1540 (0.0558)	
training:	Epoch: [32][81/204]	Loss 0.0136 (0.0552)	
training:	Epoch: [32][82/204]	Loss 0.0115 (0.0547)	
training:	Epoch: [32][83/204]	Loss 0.0123 (0.0542)	
training:	Epoch: [32][84/204]	Loss 0.0112 (0.0537)	
training:	Epoch: [32][85/204]	Loss 0.0116 (0.0532)	
training:	Epoch: [32][86/204]	Loss 0.0114 (0.0527)	
training:	Epoch: [32][87/204]	Loss 0.0116 (0.0522)	
training:	Epoch: [32][88/204]	Loss 0.1415 (0.0532)	
training:	Epoch: [32][89/204]	Loss 0.0118 (0.0528)	
training:	Epoch: [32][90/204]	Loss 0.0107 (0.0523)	
training:	Epoch: [32][91/204]	Loss 0.1450 (0.0533)	
training:	Epoch: [32][92/204]	Loss 0.0153 (0.0529)	
training:	Epoch: [32][93/204]	Loss 0.0120 (0.0525)	
training:	Epoch: [32][94/204]	Loss 0.0119 (0.0520)	
training:	Epoch: [32][95/204]	Loss 0.0122 (0.0516)	
training:	Epoch: [32][96/204]	Loss 0.0920 (0.0520)	
training:	Epoch: [32][97/204]	Loss 0.0119 (0.0516)	
training:	Epoch: [32][98/204]	Loss 0.1525 (0.0527)	
training:	Epoch: [32][99/204]	Loss 0.0122 (0.0523)	
training:	Epoch: [32][100/204]	Loss 0.0118 (0.0519)	
training:	Epoch: [32][101/204]	Loss 0.0117 (0.0515)	
training:	Epoch: [32][102/204]	Loss 0.0125 (0.0511)	
training:	Epoch: [32][103/204]	Loss 0.0154 (0.0507)	
training:	Epoch: [32][104/204]	Loss 0.0205 (0.0504)	
training:	Epoch: [32][105/204]	Loss 0.0119 (0.0501)	
training:	Epoch: [32][106/204]	Loss 0.0110 (0.0497)	
training:	Epoch: [32][107/204]	Loss 0.1542 (0.0507)	
training:	Epoch: [32][108/204]	Loss 0.1522 (0.0516)	
training:	Epoch: [32][109/204]	Loss 0.0140 (0.0513)	
training:	Epoch: [32][110/204]	Loss 0.0130 (0.0509)	
training:	Epoch: [32][111/204]	Loss 0.0125 (0.0506)	
training:	Epoch: [32][112/204]	Loss 0.1508 (0.0515)	
training:	Epoch: [32][113/204]	Loss 0.0128 (0.0511)	
training:	Epoch: [32][114/204]	Loss 0.0116 (0.0508)	
training:	Epoch: [32][115/204]	Loss 0.2695 (0.0527)	
training:	Epoch: [32][116/204]	Loss 0.1425 (0.0535)	
training:	Epoch: [32][117/204]	Loss 0.0126 (0.0531)	
training:	Epoch: [32][118/204]	Loss 0.1379 (0.0538)	
training:	Epoch: [32][119/204]	Loss 0.0118 (0.0535)	
training:	Epoch: [32][120/204]	Loss 0.0117 (0.0531)	
training:	Epoch: [32][121/204]	Loss 0.0138 (0.0528)	
training:	Epoch: [32][122/204]	Loss 0.0114 (0.0525)	
training:	Epoch: [32][123/204]	Loss 0.0129 (0.0521)	
training:	Epoch: [32][124/204]	Loss 0.0121 (0.0518)	
training:	Epoch: [32][125/204]	Loss 0.0166 (0.0515)	
training:	Epoch: [32][126/204]	Loss 0.1378 (0.0522)	
training:	Epoch: [32][127/204]	Loss 0.0125 (0.0519)	
training:	Epoch: [32][128/204]	Loss 0.2565 (0.0535)	
training:	Epoch: [32][129/204]	Loss 0.1447 (0.0542)	
training:	Epoch: [32][130/204]	Loss 0.0117 (0.0539)	
training:	Epoch: [32][131/204]	Loss 0.0117 (0.0536)	
training:	Epoch: [32][132/204]	Loss 0.0128 (0.0533)	
training:	Epoch: [32][133/204]	Loss 0.0116 (0.0529)	
training:	Epoch: [32][134/204]	Loss 0.0119 (0.0526)	
training:	Epoch: [32][135/204]	Loss 0.1555 (0.0534)	
training:	Epoch: [32][136/204]	Loss 0.0124 (0.0531)	
training:	Epoch: [32][137/204]	Loss 0.0157 (0.0528)	
training:	Epoch: [32][138/204]	Loss 0.0123 (0.0525)	
training:	Epoch: [32][139/204]	Loss 0.0318 (0.0524)	
training:	Epoch: [32][140/204]	Loss 0.0121 (0.0521)	
training:	Epoch: [32][141/204]	Loss 0.1520 (0.0528)	
training:	Epoch: [32][142/204]	Loss 0.0127 (0.0525)	
training:	Epoch: [32][143/204]	Loss 0.0120 (0.0522)	
training:	Epoch: [32][144/204]	Loss 0.1530 (0.0529)	
training:	Epoch: [32][145/204]	Loss 0.0132 (0.0527)	
training:	Epoch: [32][146/204]	Loss 0.0113 (0.0524)	
training:	Epoch: [32][147/204]	Loss 0.3481 (0.0544)	
training:	Epoch: [32][148/204]	Loss 0.0118 (0.0541)	
training:	Epoch: [32][149/204]	Loss 0.2937 (0.0557)	
training:	Epoch: [32][150/204]	Loss 0.0197 (0.0555)	
training:	Epoch: [32][151/204]	Loss 0.0110 (0.0552)	
training:	Epoch: [32][152/204]	Loss 0.0120 (0.0549)	
training:	Epoch: [32][153/204]	Loss 0.2744 (0.0563)	
training:	Epoch: [32][154/204]	Loss 0.1370 (0.0568)	
training:	Epoch: [32][155/204]	Loss 0.0113 (0.0566)	
training:	Epoch: [32][156/204]	Loss 0.0170 (0.0563)	
training:	Epoch: [32][157/204]	Loss 0.2081 (0.0573)	
training:	Epoch: [32][158/204]	Loss 0.0130 (0.0570)	
training:	Epoch: [32][159/204]	Loss 0.0121 (0.0567)	
training:	Epoch: [32][160/204]	Loss 0.0128 (0.0564)	
training:	Epoch: [32][161/204]	Loss 0.0110 (0.0561)	
training:	Epoch: [32][162/204]	Loss 0.1527 (0.0567)	
training:	Epoch: [32][163/204]	Loss 0.0119 (0.0565)	
training:	Epoch: [32][164/204]	Loss 0.0122 (0.0562)	
training:	Epoch: [32][165/204]	Loss 0.0127 (0.0559)	
training:	Epoch: [32][166/204]	Loss 0.0131 (0.0557)	
training:	Epoch: [32][167/204]	Loss 0.0169 (0.0554)	
training:	Epoch: [32][168/204]	Loss 0.0111 (0.0552)	
training:	Epoch: [32][169/204]	Loss 0.1537 (0.0558)	
training:	Epoch: [32][170/204]	Loss 0.0117 (0.0555)	
training:	Epoch: [32][171/204]	Loss 0.0129 (0.0553)	
training:	Epoch: [32][172/204]	Loss 0.0115 (0.0550)	
training:	Epoch: [32][173/204]	Loss 0.0136 (0.0548)	
training:	Epoch: [32][174/204]	Loss 0.0801 (0.0549)	
training:	Epoch: [32][175/204]	Loss 0.1536 (0.0555)	
training:	Epoch: [32][176/204]	Loss 0.1148 (0.0558)	
training:	Epoch: [32][177/204]	Loss 0.0115 (0.0556)	
training:	Epoch: [32][178/204]	Loss 0.0144 (0.0553)	
training:	Epoch: [32][179/204]	Loss 0.0124 (0.0551)	
training:	Epoch: [32][180/204]	Loss 0.0114 (0.0548)	
training:	Epoch: [32][181/204]	Loss 0.0117 (0.0546)	
training:	Epoch: [32][182/204]	Loss 0.0124 (0.0544)	
training:	Epoch: [32][183/204]	Loss 0.0114 (0.0541)	
training:	Epoch: [32][184/204]	Loss 0.0129 (0.0539)	
training:	Epoch: [32][185/204]	Loss 0.0127 (0.0537)	
training:	Epoch: [32][186/204]	Loss 0.0579 (0.0537)	
training:	Epoch: [32][187/204]	Loss 0.3888 (0.0555)	
training:	Epoch: [32][188/204]	Loss 0.0109 (0.0553)	
training:	Epoch: [32][189/204]	Loss 0.1572 (0.0558)	
training:	Epoch: [32][190/204]	Loss 0.0161 (0.0556)	
training:	Epoch: [32][191/204]	Loss 0.1683 (0.0562)	
training:	Epoch: [32][192/204]	Loss 0.1625 (0.0567)	
training:	Epoch: [32][193/204]	Loss 0.0423 (0.0567)	
training:	Epoch: [32][194/204]	Loss 0.0116 (0.0564)	
training:	Epoch: [32][195/204]	Loss 0.0140 (0.0562)	
training:	Epoch: [32][196/204]	Loss 0.1431 (0.0567)	
training:	Epoch: [32][197/204]	Loss 0.0166 (0.0565)	
training:	Epoch: [32][198/204]	Loss 0.0124 (0.0562)	
training:	Epoch: [32][199/204]	Loss 0.0136 (0.0560)	
training:	Epoch: [32][200/204]	Loss 0.0136 (0.0558)	
training:	Epoch: [32][201/204]	Loss 0.0587 (0.0558)	
training:	Epoch: [32][202/204]	Loss 0.0113 (0.0556)	
training:	Epoch: [32][203/204]	Loss 0.0117 (0.0554)	
training:	Epoch: [32][204/204]	Loss 0.0126 (0.0552)	
Training:	 Loss: 0.0551

Training:	 ACC: 0.9904 0.9904 0.9900 0.9908
Validation:	 ACC: 0.7874 0.7887 0.8147 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8517
Pretraining:	Epoch 33/500
----------
training:	Epoch: [33][1/204]	Loss 0.0129 (0.0129)	
training:	Epoch: [33][2/204]	Loss 0.1540 (0.0834)	
training:	Epoch: [33][3/204]	Loss 0.0122 (0.0597)	
training:	Epoch: [33][4/204]	Loss 0.1285 (0.0769)	
training:	Epoch: [33][5/204]	Loss 0.0117 (0.0639)	
training:	Epoch: [33][6/204]	Loss 0.0116 (0.0551)	
training:	Epoch: [33][7/204]	Loss 0.0139 (0.0493)	
training:	Epoch: [33][8/204]	Loss 0.0130 (0.0447)	
training:	Epoch: [33][9/204]	Loss 0.0124 (0.0411)	
training:	Epoch: [33][10/204]	Loss 0.0114 (0.0382)	
training:	Epoch: [33][11/204]	Loss 0.2808 (0.0602)	
training:	Epoch: [33][12/204]	Loss 0.0130 (0.0563)	
training:	Epoch: [33][13/204]	Loss 0.1485 (0.0634)	
training:	Epoch: [33][14/204]	Loss 0.0143 (0.0599)	
training:	Epoch: [33][15/204]	Loss 0.0132 (0.0568)	
training:	Epoch: [33][16/204]	Loss 0.1550 (0.0629)	
training:	Epoch: [33][17/204]	Loss 0.1354 (0.0672)	
training:	Epoch: [33][18/204]	Loss 0.0120 (0.0641)	
training:	Epoch: [33][19/204]	Loss 0.0133 (0.0614)	
training:	Epoch: [33][20/204]	Loss 0.0118 (0.0589)	
training:	Epoch: [33][21/204]	Loss 0.0133 (0.0568)	
training:	Epoch: [33][22/204]	Loss 0.1117 (0.0593)	
training:	Epoch: [33][23/204]	Loss 0.0112 (0.0572)	
training:	Epoch: [33][24/204]	Loss 0.1344 (0.0604)	
training:	Epoch: [33][25/204]	Loss 0.0116 (0.0584)	
training:	Epoch: [33][26/204]	Loss 0.1556 (0.0622)	
training:	Epoch: [33][27/204]	Loss 0.0129 (0.0604)	
training:	Epoch: [33][28/204]	Loss 0.1493 (0.0635)	
training:	Epoch: [33][29/204]	Loss 0.0143 (0.0618)	
training:	Epoch: [33][30/204]	Loss 0.2238 (0.0672)	
training:	Epoch: [33][31/204]	Loss 0.0132 (0.0655)	
training:	Epoch: [33][32/204]	Loss 0.1514 (0.0682)	
training:	Epoch: [33][33/204]	Loss 0.0127 (0.0665)	
training:	Epoch: [33][34/204]	Loss 0.0133 (0.0649)	
training:	Epoch: [33][35/204]	Loss 0.0148 (0.0635)	
training:	Epoch: [33][36/204]	Loss 0.0149 (0.0622)	
training:	Epoch: [33][37/204]	Loss 0.1076 (0.0634)	
training:	Epoch: [33][38/204]	Loss 0.0417 (0.0628)	
training:	Epoch: [33][39/204]	Loss 0.0143 (0.0616)	
training:	Epoch: [33][40/204]	Loss 0.1511 (0.0638)	
training:	Epoch: [33][41/204]	Loss 0.0120 (0.0625)	
training:	Epoch: [33][42/204]	Loss 0.0144 (0.0614)	
training:	Epoch: [33][43/204]	Loss 0.0116 (0.0602)	
training:	Epoch: [33][44/204]	Loss 0.2536 (0.0646)	
training:	Epoch: [33][45/204]	Loss 0.0217 (0.0637)	
training:	Epoch: [33][46/204]	Loss 0.0220 (0.0628)	
training:	Epoch: [33][47/204]	Loss 0.2103 (0.0659)	
training:	Epoch: [33][48/204]	Loss 0.0122 (0.0648)	
training:	Epoch: [33][49/204]	Loss 0.0129 (0.0637)	
training:	Epoch: [33][50/204]	Loss 0.0113 (0.0627)	
training:	Epoch: [33][51/204]	Loss 0.0236 (0.0619)	
training:	Epoch: [33][52/204]	Loss 0.1534 (0.0637)	
training:	Epoch: [33][53/204]	Loss 0.0128 (0.0627)	
training:	Epoch: [33][54/204]	Loss 0.1524 (0.0644)	
training:	Epoch: [33][55/204]	Loss 0.0126 (0.0634)	
training:	Epoch: [33][56/204]	Loss 0.1420 (0.0648)	
training:	Epoch: [33][57/204]	Loss 0.0119 (0.0639)	
training:	Epoch: [33][58/204]	Loss 0.1987 (0.0662)	
training:	Epoch: [33][59/204]	Loss 0.0157 (0.0654)	
training:	Epoch: [33][60/204]	Loss 0.0135 (0.0645)	
training:	Epoch: [33][61/204]	Loss 0.1493 (0.0659)	
training:	Epoch: [33][62/204]	Loss 0.0140 (0.0651)	
training:	Epoch: [33][63/204]	Loss 0.2155 (0.0675)	
training:	Epoch: [33][64/204]	Loss 0.0130 (0.0666)	
training:	Epoch: [33][65/204]	Loss 0.0132 (0.0658)	
training:	Epoch: [33][66/204]	Loss 0.0133 (0.0650)	
training:	Epoch: [33][67/204]	Loss 0.0126 (0.0642)	
training:	Epoch: [33][68/204]	Loss 0.0129 (0.0634)	
training:	Epoch: [33][69/204]	Loss 0.0125 (0.0627)	
training:	Epoch: [33][70/204]	Loss 0.0192 (0.0621)	
training:	Epoch: [33][71/204]	Loss 0.0131 (0.0614)	
training:	Epoch: [33][72/204]	Loss 0.0122 (0.0607)	
training:	Epoch: [33][73/204]	Loss 0.0116 (0.0600)	
training:	Epoch: [33][74/204]	Loss 0.0209 (0.0595)	
training:	Epoch: [33][75/204]	Loss 0.1159 (0.0603)	
training:	Epoch: [33][76/204]	Loss 0.0132 (0.0596)	
training:	Epoch: [33][77/204]	Loss 0.1546 (0.0609)	
training:	Epoch: [33][78/204]	Loss 0.0134 (0.0603)	
training:	Epoch: [33][79/204]	Loss 0.1648 (0.0616)	
training:	Epoch: [33][80/204]	Loss 0.0129 (0.0610)	
training:	Epoch: [33][81/204]	Loss 0.0132 (0.0604)	
training:	Epoch: [33][82/204]	Loss 0.0129 (0.0598)	
training:	Epoch: [33][83/204]	Loss 0.0270 (0.0594)	
training:	Epoch: [33][84/204]	Loss 0.0113 (0.0589)	
training:	Epoch: [33][85/204]	Loss 0.1186 (0.0596)	
training:	Epoch: [33][86/204]	Loss 0.1270 (0.0603)	
training:	Epoch: [33][87/204]	Loss 0.1517 (0.0614)	
training:	Epoch: [33][88/204]	Loss 0.0996 (0.0618)	
training:	Epoch: [33][89/204]	Loss 0.0137 (0.0613)	
training:	Epoch: [33][90/204]	Loss 0.0121 (0.0607)	
training:	Epoch: [33][91/204]	Loss 0.0123 (0.0602)	
training:	Epoch: [33][92/204]	Loss 0.0169 (0.0597)	
training:	Epoch: [33][93/204]	Loss 0.0126 (0.0592)	
training:	Epoch: [33][94/204]	Loss 0.0123 (0.0587)	
training:	Epoch: [33][95/204]	Loss 0.0145 (0.0583)	
training:	Epoch: [33][96/204]	Loss 0.0129 (0.0578)	
training:	Epoch: [33][97/204]	Loss 0.0124 (0.0573)	
training:	Epoch: [33][98/204]	Loss 0.1637 (0.0584)	
training:	Epoch: [33][99/204]	Loss 0.0131 (0.0579)	
training:	Epoch: [33][100/204]	Loss 0.0106 (0.0575)	
training:	Epoch: [33][101/204]	Loss 0.0125 (0.0570)	
training:	Epoch: [33][102/204]	Loss 0.0129 (0.0566)	
training:	Epoch: [33][103/204]	Loss 0.0156 (0.0562)	
training:	Epoch: [33][104/204]	Loss 0.1612 (0.0572)	
training:	Epoch: [33][105/204]	Loss 0.0114 (0.0568)	
training:	Epoch: [33][106/204]	Loss 0.1569 (0.0577)	
training:	Epoch: [33][107/204]	Loss 0.0120 (0.0573)	
training:	Epoch: [33][108/204]	Loss 0.0111 (0.0569)	
training:	Epoch: [33][109/204]	Loss 0.0135 (0.0565)	
training:	Epoch: [33][110/204]	Loss 0.0116 (0.0561)	
training:	Epoch: [33][111/204]	Loss 0.0151 (0.0557)	
training:	Epoch: [33][112/204]	Loss 0.0121 (0.0553)	
training:	Epoch: [33][113/204]	Loss 0.1300 (0.0560)	
training:	Epoch: [33][114/204]	Loss 0.0121 (0.0556)	
training:	Epoch: [33][115/204]	Loss 0.0104 (0.0552)	
training:	Epoch: [33][116/204]	Loss 0.0117 (0.0548)	
training:	Epoch: [33][117/204]	Loss 0.0120 (0.0544)	
training:	Epoch: [33][118/204]	Loss 0.0111 (0.0541)	
training:	Epoch: [33][119/204]	Loss 0.0112 (0.0537)	
training:	Epoch: [33][120/204]	Loss 0.0411 (0.0536)	
training:	Epoch: [33][121/204]	Loss 0.1425 (0.0543)	
training:	Epoch: [33][122/204]	Loss 0.2982 (0.0563)	
training:	Epoch: [33][123/204]	Loss 0.1541 (0.0571)	
training:	Epoch: [33][124/204]	Loss 0.0204 (0.0568)	
training:	Epoch: [33][125/204]	Loss 0.0152 (0.0565)	
training:	Epoch: [33][126/204]	Loss 0.1631 (0.0574)	
training:	Epoch: [33][127/204]	Loss 0.0121 (0.0570)	
training:	Epoch: [33][128/204]	Loss 0.1428 (0.0577)	
training:	Epoch: [33][129/204]	Loss 0.0896 (0.0579)	
training:	Epoch: [33][130/204]	Loss 0.0106 (0.0575)	
training:	Epoch: [33][131/204]	Loss 0.0111 (0.0572)	
training:	Epoch: [33][132/204]	Loss 0.0117 (0.0568)	
training:	Epoch: [33][133/204]	Loss 0.0116 (0.0565)	
training:	Epoch: [33][134/204]	Loss 0.0107 (0.0562)	
training:	Epoch: [33][135/204]	Loss 0.0114 (0.0558)	
training:	Epoch: [33][136/204]	Loss 0.2084 (0.0570)	
training:	Epoch: [33][137/204]	Loss 0.2472 (0.0583)	
training:	Epoch: [33][138/204]	Loss 0.0126 (0.0580)	
training:	Epoch: [33][139/204]	Loss 0.0121 (0.0577)	
training:	Epoch: [33][140/204]	Loss 0.0118 (0.0574)	
training:	Epoch: [33][141/204]	Loss 0.1517 (0.0580)	
training:	Epoch: [33][142/204]	Loss 0.0138 (0.0577)	
training:	Epoch: [33][143/204]	Loss 0.0113 (0.0574)	
training:	Epoch: [33][144/204]	Loss 0.0099 (0.0571)	
training:	Epoch: [33][145/204]	Loss 0.0110 (0.0567)	
training:	Epoch: [33][146/204]	Loss 0.0117 (0.0564)	
training:	Epoch: [33][147/204]	Loss 0.0122 (0.0561)	
training:	Epoch: [33][148/204]	Loss 0.0275 (0.0559)	
training:	Epoch: [33][149/204]	Loss 0.0116 (0.0556)	
training:	Epoch: [33][150/204]	Loss 0.1480 (0.0563)	
training:	Epoch: [33][151/204]	Loss 0.1414 (0.0568)	
training:	Epoch: [33][152/204]	Loss 0.0105 (0.0565)	
training:	Epoch: [33][153/204]	Loss 0.0277 (0.0563)	
training:	Epoch: [33][154/204]	Loss 0.0111 (0.0560)	
training:	Epoch: [33][155/204]	Loss 0.1884 (0.0569)	
training:	Epoch: [33][156/204]	Loss 0.0098 (0.0566)	
training:	Epoch: [33][157/204]	Loss 0.1504 (0.0572)	
training:	Epoch: [33][158/204]	Loss 0.0124 (0.0569)	
training:	Epoch: [33][159/204]	Loss 0.0117 (0.0566)	
training:	Epoch: [33][160/204]	Loss 0.0111 (0.0563)	
training:	Epoch: [33][161/204]	Loss 0.1604 (0.0570)	
training:	Epoch: [33][162/204]	Loss 0.1480 (0.0575)	
training:	Epoch: [33][163/204]	Loss 0.1576 (0.0582)	
training:	Epoch: [33][164/204]	Loss 0.0119 (0.0579)	
training:	Epoch: [33][165/204]	Loss 0.0121 (0.0576)	
training:	Epoch: [33][166/204]	Loss 0.0123 (0.0573)	
training:	Epoch: [33][167/204]	Loss 0.0119 (0.0570)	
training:	Epoch: [33][168/204]	Loss 0.0130 (0.0568)	
training:	Epoch: [33][169/204]	Loss 0.0158 (0.0565)	
training:	Epoch: [33][170/204]	Loss 0.1758 (0.0572)	
training:	Epoch: [33][171/204]	Loss 0.0124 (0.0570)	
training:	Epoch: [33][172/204]	Loss 0.0120 (0.0567)	
training:	Epoch: [33][173/204]	Loss 0.0124 (0.0565)	
training:	Epoch: [33][174/204]	Loss 0.1247 (0.0569)	
training:	Epoch: [33][175/204]	Loss 0.1492 (0.0574)	
training:	Epoch: [33][176/204]	Loss 0.0100 (0.0571)	
training:	Epoch: [33][177/204]	Loss 0.1494 (0.0576)	
training:	Epoch: [33][178/204]	Loss 0.1528 (0.0582)	
training:	Epoch: [33][179/204]	Loss 0.0132 (0.0579)	
training:	Epoch: [33][180/204]	Loss 0.0112 (0.0577)	
training:	Epoch: [33][181/204]	Loss 0.1461 (0.0582)	
training:	Epoch: [33][182/204]	Loss 0.0144 (0.0579)	
training:	Epoch: [33][183/204]	Loss 0.0112 (0.0577)	
training:	Epoch: [33][184/204]	Loss 0.1511 (0.0582)	
training:	Epoch: [33][185/204]	Loss 0.1510 (0.0587)	
training:	Epoch: [33][186/204]	Loss 0.0113 (0.0584)	
training:	Epoch: [33][187/204]	Loss 0.1448 (0.0589)	
training:	Epoch: [33][188/204]	Loss 0.0112 (0.0586)	
training:	Epoch: [33][189/204]	Loss 0.0180 (0.0584)	
training:	Epoch: [33][190/204]	Loss 0.2230 (0.0593)	
training:	Epoch: [33][191/204]	Loss 0.0288 (0.0591)	
training:	Epoch: [33][192/204]	Loss 0.0107 (0.0589)	
training:	Epoch: [33][193/204]	Loss 0.0118 (0.0586)	
training:	Epoch: [33][194/204]	Loss 0.0991 (0.0588)	
training:	Epoch: [33][195/204]	Loss 0.0115 (0.0586)	
training:	Epoch: [33][196/204]	Loss 0.0944 (0.0588)	
training:	Epoch: [33][197/204]	Loss 0.0686 (0.0588)	
training:	Epoch: [33][198/204]	Loss 0.2882 (0.0600)	
training:	Epoch: [33][199/204]	Loss 0.0206 (0.0598)	
training:	Epoch: [33][200/204]	Loss 0.0124 (0.0595)	
training:	Epoch: [33][201/204]	Loss 0.0124 (0.0593)	
training:	Epoch: [33][202/204]	Loss 0.0124 (0.0591)	
training:	Epoch: [33][203/204]	Loss 0.0124 (0.0588)	
training:	Epoch: [33][204/204]	Loss 0.0130 (0.0586)	
Training:	 Loss: 0.0585

Training:	 ACC: 0.9906 0.9905 0.9891 0.9920
Validation:	 ACC: 0.7926 0.7924 0.7881 0.7971
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8309
Pretraining:	Epoch 34/500
----------
training:	Epoch: [34][1/204]	Loss 0.0132 (0.0132)	
training:	Epoch: [34][2/204]	Loss 0.0111 (0.0121)	
training:	Epoch: [34][3/204]	Loss 0.0108 (0.0117)	
training:	Epoch: [34][4/204]	Loss 0.0226 (0.0144)	
training:	Epoch: [34][5/204]	Loss 0.0122 (0.0140)	
training:	Epoch: [34][6/204]	Loss 0.2192 (0.0482)	
training:	Epoch: [34][7/204]	Loss 0.0122 (0.0430)	
training:	Epoch: [34][8/204]	Loss 0.0395 (0.0426)	
training:	Epoch: [34][9/204]	Loss 0.0125 (0.0393)	
training:	Epoch: [34][10/204]	Loss 0.0153 (0.0369)	
training:	Epoch: [34][11/204]	Loss 0.0169 (0.0350)	
training:	Epoch: [34][12/204]	Loss 0.0117 (0.0331)	
training:	Epoch: [34][13/204]	Loss 0.0128 (0.0315)	
training:	Epoch: [34][14/204]	Loss 0.0110 (0.0301)	
training:	Epoch: [34][15/204]	Loss 0.1388 (0.0373)	
training:	Epoch: [34][16/204]	Loss 0.0480 (0.0380)	
training:	Epoch: [34][17/204]	Loss 0.0130 (0.0365)	
training:	Epoch: [34][18/204]	Loss 0.0107 (0.0351)	
training:	Epoch: [34][19/204]	Loss 0.0127 (0.0339)	
training:	Epoch: [34][20/204]	Loss 0.0114 (0.0328)	
training:	Epoch: [34][21/204]	Loss 0.1563 (0.0387)	
training:	Epoch: [34][22/204]	Loss 0.0115 (0.0374)	
training:	Epoch: [34][23/204]	Loss 0.0123 (0.0363)	
training:	Epoch: [34][24/204]	Loss 0.0879 (0.0385)	
training:	Epoch: [34][25/204]	Loss 0.0111 (0.0374)	
training:	Epoch: [34][26/204]	Loss 0.1536 (0.0419)	
training:	Epoch: [34][27/204]	Loss 0.0102 (0.0407)	
training:	Epoch: [34][28/204]	Loss 0.0110 (0.0396)	
training:	Epoch: [34][29/204]	Loss 0.0155 (0.0388)	
training:	Epoch: [34][30/204]	Loss 0.1227 (0.0416)	
training:	Epoch: [34][31/204]	Loss 0.0283 (0.0412)	
training:	Epoch: [34][32/204]	Loss 0.0141 (0.0403)	
training:	Epoch: [34][33/204]	Loss 0.1351 (0.0432)	
training:	Epoch: [34][34/204]	Loss 0.0106 (0.0422)	
training:	Epoch: [34][35/204]	Loss 0.0117 (0.0414)	
training:	Epoch: [34][36/204]	Loss 0.0359 (0.0412)	
training:	Epoch: [34][37/204]	Loss 0.1126 (0.0431)	
training:	Epoch: [34][38/204]	Loss 0.0104 (0.0423)	
training:	Epoch: [34][39/204]	Loss 0.1540 (0.0451)	
training:	Epoch: [34][40/204]	Loss 0.0109 (0.0443)	
training:	Epoch: [34][41/204]	Loss 0.0136 (0.0435)	
training:	Epoch: [34][42/204]	Loss 0.0113 (0.0428)	
training:	Epoch: [34][43/204]	Loss 0.0131 (0.0421)	
training:	Epoch: [34][44/204]	Loss 0.0114 (0.0414)	
training:	Epoch: [34][45/204]	Loss 0.0124 (0.0407)	
training:	Epoch: [34][46/204]	Loss 0.0113 (0.0401)	
training:	Epoch: [34][47/204]	Loss 0.1274 (0.0419)	
training:	Epoch: [34][48/204]	Loss 0.0105 (0.0413)	
training:	Epoch: [34][49/204]	Loss 0.0127 (0.0407)	
training:	Epoch: [34][50/204]	Loss 0.1570 (0.0430)	
training:	Epoch: [34][51/204]	Loss 0.0167 (0.0425)	
training:	Epoch: [34][52/204]	Loss 0.0132 (0.0420)	
training:	Epoch: [34][53/204]	Loss 0.0118 (0.0414)	
training:	Epoch: [34][54/204]	Loss 0.0127 (0.0409)	
training:	Epoch: [34][55/204]	Loss 0.0115 (0.0403)	
training:	Epoch: [34][56/204]	Loss 0.0188 (0.0399)	
training:	Epoch: [34][57/204]	Loss 0.1540 (0.0419)	
training:	Epoch: [34][58/204]	Loss 0.1531 (0.0439)	
training:	Epoch: [34][59/204]	Loss 0.1619 (0.0459)	
training:	Epoch: [34][60/204]	Loss 0.0114 (0.0453)	
training:	Epoch: [34][61/204]	Loss 0.1027 (0.0462)	
training:	Epoch: [34][62/204]	Loss 0.0152 (0.0457)	
training:	Epoch: [34][63/204]	Loss 0.1529 (0.0474)	
training:	Epoch: [34][64/204]	Loss 0.1390 (0.0489)	
training:	Epoch: [34][65/204]	Loss 0.0114 (0.0483)	
training:	Epoch: [34][66/204]	Loss 0.1632 (0.0500)	
training:	Epoch: [34][67/204]	Loss 0.1247 (0.0511)	
training:	Epoch: [34][68/204]	Loss 0.0301 (0.0508)	
training:	Epoch: [34][69/204]	Loss 0.1500 (0.0523)	
training:	Epoch: [34][70/204]	Loss 0.0159 (0.0517)	
training:	Epoch: [34][71/204]	Loss 0.0143 (0.0512)	
training:	Epoch: [34][72/204]	Loss 0.0224 (0.0508)	
training:	Epoch: [34][73/204]	Loss 0.0122 (0.0503)	
training:	Epoch: [34][74/204]	Loss 0.1503 (0.0516)	
training:	Epoch: [34][75/204]	Loss 0.0110 (0.0511)	
training:	Epoch: [34][76/204]	Loss 0.0135 (0.0506)	
training:	Epoch: [34][77/204]	Loss 0.0119 (0.0501)	
training:	Epoch: [34][78/204]	Loss 0.2639 (0.0528)	
training:	Epoch: [34][79/204]	Loss 0.2581 (0.0554)	
training:	Epoch: [34][80/204]	Loss 0.0123 (0.0549)	
training:	Epoch: [34][81/204]	Loss 0.0121 (0.0544)	
training:	Epoch: [34][82/204]	Loss 0.0134 (0.0539)	
training:	Epoch: [34][83/204]	Loss 0.0123 (0.0534)	
training:	Epoch: [34][84/204]	Loss 0.0125 (0.0529)	
training:	Epoch: [34][85/204]	Loss 0.0126 (0.0524)	
training:	Epoch: [34][86/204]	Loss 0.0113 (0.0519)	
training:	Epoch: [34][87/204]	Loss 0.2969 (0.0547)	
training:	Epoch: [34][88/204]	Loss 0.0106 (0.0542)	
training:	Epoch: [34][89/204]	Loss 0.0144 (0.0538)	
training:	Epoch: [34][90/204]	Loss 0.1363 (0.0547)	
training:	Epoch: [34][91/204]	Loss 0.0131 (0.0543)	
training:	Epoch: [34][92/204]	Loss 0.0164 (0.0538)	
training:	Epoch: [34][93/204]	Loss 0.0116 (0.0534)	
training:	Epoch: [34][94/204]	Loss 0.0126 (0.0530)	
training:	Epoch: [34][95/204]	Loss 0.1531 (0.0540)	
training:	Epoch: [34][96/204]	Loss 0.0121 (0.0536)	
training:	Epoch: [34][97/204]	Loss 0.0582 (0.0536)	
training:	Epoch: [34][98/204]	Loss 0.0243 (0.0533)	
training:	Epoch: [34][99/204]	Loss 0.0106 (0.0529)	
training:	Epoch: [34][100/204]	Loss 0.0118 (0.0525)	
training:	Epoch: [34][101/204]	Loss 0.1382 (0.0533)	
training:	Epoch: [34][102/204]	Loss 0.1590 (0.0544)	
training:	Epoch: [34][103/204]	Loss 0.0131 (0.0540)	
training:	Epoch: [34][104/204]	Loss 0.0123 (0.0536)	
training:	Epoch: [34][105/204]	Loss 0.0108 (0.0532)	
training:	Epoch: [34][106/204]	Loss 0.1365 (0.0539)	
training:	Epoch: [34][107/204]	Loss 0.0124 (0.0536)	
training:	Epoch: [34][108/204]	Loss 0.1626 (0.0546)	
training:	Epoch: [34][109/204]	Loss 0.0119 (0.0542)	
training:	Epoch: [34][110/204]	Loss 0.0107 (0.0538)	
training:	Epoch: [34][111/204]	Loss 0.0146 (0.0534)	
training:	Epoch: [34][112/204]	Loss 0.0123 (0.0531)	
training:	Epoch: [34][113/204]	Loss 0.0108 (0.0527)	
training:	Epoch: [34][114/204]	Loss 0.0133 (0.0523)	
training:	Epoch: [34][115/204]	Loss 0.0120 (0.0520)	
training:	Epoch: [34][116/204]	Loss 0.0124 (0.0516)	
training:	Epoch: [34][117/204]	Loss 0.0114 (0.0513)	
training:	Epoch: [34][118/204]	Loss 0.1532 (0.0522)	
training:	Epoch: [34][119/204]	Loss 0.0110 (0.0518)	
training:	Epoch: [34][120/204]	Loss 0.0119 (0.0515)	
training:	Epoch: [34][121/204]	Loss 0.0117 (0.0512)	
training:	Epoch: [34][122/204]	Loss 0.0124 (0.0508)	
training:	Epoch: [34][123/204]	Loss 0.0119 (0.0505)	
training:	Epoch: [34][124/204]	Loss 0.0112 (0.0502)	
training:	Epoch: [34][125/204]	Loss 0.0121 (0.0499)	
training:	Epoch: [34][126/204]	Loss 0.0103 (0.0496)	
training:	Epoch: [34][127/204]	Loss 0.1367 (0.0503)	
training:	Epoch: [34][128/204]	Loss 0.0118 (0.0500)	
training:	Epoch: [34][129/204]	Loss 0.0105 (0.0497)	
training:	Epoch: [34][130/204]	Loss 0.1530 (0.0505)	
training:	Epoch: [34][131/204]	Loss 0.0114 (0.0502)	
training:	Epoch: [34][132/204]	Loss 0.1535 (0.0509)	
training:	Epoch: [34][133/204]	Loss 0.0113 (0.0507)	
training:	Epoch: [34][134/204]	Loss 0.1471 (0.0514)	
training:	Epoch: [34][135/204]	Loss 0.0124 (0.0511)	
training:	Epoch: [34][136/204]	Loss 0.1519 (0.0518)	
training:	Epoch: [34][137/204]	Loss 0.0118 (0.0515)	
training:	Epoch: [34][138/204]	Loss 0.0114 (0.0512)	
training:	Epoch: [34][139/204]	Loss 0.0114 (0.0510)	
training:	Epoch: [34][140/204]	Loss 0.0103 (0.0507)	
training:	Epoch: [34][141/204]	Loss 0.0101 (0.0504)	
training:	Epoch: [34][142/204]	Loss 0.0104 (0.0501)	
training:	Epoch: [34][143/204]	Loss 0.0164 (0.0499)	
training:	Epoch: [34][144/204]	Loss 0.1483 (0.0505)	
training:	Epoch: [34][145/204]	Loss 0.0122 (0.0503)	
training:	Epoch: [34][146/204]	Loss 0.1490 (0.0510)	
training:	Epoch: [34][147/204]	Loss 0.1529 (0.0516)	
training:	Epoch: [34][148/204]	Loss 0.0127 (0.0514)	
training:	Epoch: [34][149/204]	Loss 0.0104 (0.0511)	
training:	Epoch: [34][150/204]	Loss 0.4400 (0.0537)	
training:	Epoch: [34][151/204]	Loss 0.1598 (0.0544)	
training:	Epoch: [34][152/204]	Loss 0.0140 (0.0541)	
training:	Epoch: [34][153/204]	Loss 0.0101 (0.0539)	
training:	Epoch: [34][154/204]	Loss 0.0102 (0.0536)	
training:	Epoch: [34][155/204]	Loss 0.0107 (0.0533)	
training:	Epoch: [34][156/204]	Loss 0.0107 (0.0530)	
training:	Epoch: [34][157/204]	Loss 0.0138 (0.0528)	
training:	Epoch: [34][158/204]	Loss 0.1597 (0.0534)	
training:	Epoch: [34][159/204]	Loss 0.0111 (0.0532)	
training:	Epoch: [34][160/204]	Loss 0.1536 (0.0538)	
training:	Epoch: [34][161/204]	Loss 0.0103 (0.0535)	
training:	Epoch: [34][162/204]	Loss 0.0112 (0.0533)	
training:	Epoch: [34][163/204]	Loss 0.0106 (0.0530)	
training:	Epoch: [34][164/204]	Loss 0.0109 (0.0528)	
training:	Epoch: [34][165/204]	Loss 0.1527 (0.0534)	
training:	Epoch: [34][166/204]	Loss 0.1532 (0.0540)	
training:	Epoch: [34][167/204]	Loss 0.1507 (0.0545)	
training:	Epoch: [34][168/204]	Loss 0.0119 (0.0543)	
training:	Epoch: [34][169/204]	Loss 0.0100 (0.0540)	
training:	Epoch: [34][170/204]	Loss 0.1462 (0.0546)	
training:	Epoch: [34][171/204]	Loss 0.0108 (0.0543)	
training:	Epoch: [34][172/204]	Loss 0.0105 (0.0541)	
training:	Epoch: [34][173/204]	Loss 0.0106 (0.0538)	
training:	Epoch: [34][174/204]	Loss 0.0388 (0.0537)	
training:	Epoch: [34][175/204]	Loss 0.0124 (0.0535)	
training:	Epoch: [34][176/204]	Loss 0.0333 (0.0534)	
training:	Epoch: [34][177/204]	Loss 0.0117 (0.0531)	
training:	Epoch: [34][178/204]	Loss 0.0116 (0.0529)	
training:	Epoch: [34][179/204]	Loss 0.0105 (0.0527)	
training:	Epoch: [34][180/204]	Loss 0.0107 (0.0524)	
training:	Epoch: [34][181/204]	Loss 0.0132 (0.0522)	
training:	Epoch: [34][182/204]	Loss 0.0127 (0.0520)	
training:	Epoch: [34][183/204]	Loss 0.0109 (0.0518)	
training:	Epoch: [34][184/204]	Loss 0.2819 (0.0530)	
training:	Epoch: [34][185/204]	Loss 0.0105 (0.0528)	
training:	Epoch: [34][186/204]	Loss 0.2737 (0.0540)	
training:	Epoch: [34][187/204]	Loss 0.0107 (0.0537)	
training:	Epoch: [34][188/204]	Loss 0.0107 (0.0535)	
training:	Epoch: [34][189/204]	Loss 0.0105 (0.0533)	
training:	Epoch: [34][190/204]	Loss 0.1515 (0.0538)	
training:	Epoch: [34][191/204]	Loss 0.0109 (0.0536)	
training:	Epoch: [34][192/204]	Loss 0.0120 (0.0534)	
training:	Epoch: [34][193/204]	Loss 0.0104 (0.0531)	
training:	Epoch: [34][194/204]	Loss 0.0165 (0.0530)	
training:	Epoch: [34][195/204]	Loss 0.0106 (0.0527)	
training:	Epoch: [34][196/204]	Loss 0.0114 (0.0525)	
training:	Epoch: [34][197/204]	Loss 0.0112 (0.0523)	
training:	Epoch: [34][198/204]	Loss 0.0409 (0.0523)	
training:	Epoch: [34][199/204]	Loss 0.0112 (0.0521)	
training:	Epoch: [34][200/204]	Loss 0.1564 (0.0526)	
training:	Epoch: [34][201/204]	Loss 0.0112 (0.0524)	
training:	Epoch: [34][202/204]	Loss 0.2899 (0.0535)	
training:	Epoch: [34][203/204]	Loss 0.0120 (0.0533)	
training:	Epoch: [34][204/204]	Loss 0.0107 (0.0531)	
Training:	 Loss: 0.0531

Training:	 ACC: 0.9909 0.9908 0.9900 0.9917
Validation:	 ACC: 0.7808 0.7828 0.8240 0.7377
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8987
Pretraining:	Epoch 35/500
----------
training:	Epoch: [35][1/204]	Loss 0.0117 (0.0117)	
training:	Epoch: [35][2/204]	Loss 0.0107 (0.0112)	
training:	Epoch: [35][3/204]	Loss 0.1542 (0.0589)	
training:	Epoch: [35][4/204]	Loss 0.0125 (0.0473)	
training:	Epoch: [35][5/204]	Loss 0.1520 (0.0682)	
training:	Epoch: [35][6/204]	Loss 0.0103 (0.0586)	
training:	Epoch: [35][7/204]	Loss 0.0115 (0.0519)	
training:	Epoch: [35][8/204]	Loss 0.1589 (0.0652)	
training:	Epoch: [35][9/204]	Loss 0.1411 (0.0737)	
training:	Epoch: [35][10/204]	Loss 0.0173 (0.0680)	
training:	Epoch: [35][11/204]	Loss 0.0107 (0.0628)	
training:	Epoch: [35][12/204]	Loss 0.0137 (0.0587)	
training:	Epoch: [35][13/204]	Loss 0.0966 (0.0616)	
training:	Epoch: [35][14/204]	Loss 0.1603 (0.0687)	
training:	Epoch: [35][15/204]	Loss 0.0111 (0.0648)	
training:	Epoch: [35][16/204]	Loss 0.0138 (0.0617)	
training:	Epoch: [35][17/204]	Loss 0.0105 (0.0586)	
training:	Epoch: [35][18/204]	Loss 0.0112 (0.0560)	
training:	Epoch: [35][19/204]	Loss 0.0125 (0.0537)	
training:	Epoch: [35][20/204]	Loss 0.1599 (0.0590)	
training:	Epoch: [35][21/204]	Loss 0.0115 (0.0568)	
training:	Epoch: [35][22/204]	Loss 0.1371 (0.0604)	
training:	Epoch: [35][23/204]	Loss 0.0130 (0.0584)	
training:	Epoch: [35][24/204]	Loss 0.0129 (0.0565)	
training:	Epoch: [35][25/204]	Loss 0.0092 (0.0546)	
training:	Epoch: [35][26/204]	Loss 0.0110 (0.0529)	
training:	Epoch: [35][27/204]	Loss 0.0116 (0.0514)	
training:	Epoch: [35][28/204]	Loss 0.0115 (0.0499)	
training:	Epoch: [35][29/204]	Loss 0.0105 (0.0486)	
training:	Epoch: [35][30/204]	Loss 0.0118 (0.0474)	
training:	Epoch: [35][31/204]	Loss 0.0116 (0.0462)	
training:	Epoch: [35][32/204]	Loss 0.1592 (0.0497)	
training:	Epoch: [35][33/204]	Loss 0.0116 (0.0486)	
training:	Epoch: [35][34/204]	Loss 0.0870 (0.0497)	
training:	Epoch: [35][35/204]	Loss 0.2789 (0.0563)	
training:	Epoch: [35][36/204]	Loss 0.2930 (0.0628)	
training:	Epoch: [35][37/204]	Loss 0.0107 (0.0614)	
training:	Epoch: [35][38/204]	Loss 0.1437 (0.0636)	
training:	Epoch: [35][39/204]	Loss 0.0134 (0.0623)	
training:	Epoch: [35][40/204]	Loss 0.0127 (0.0611)	
training:	Epoch: [35][41/204]	Loss 0.1516 (0.0633)	
training:	Epoch: [35][42/204]	Loss 0.0117 (0.0620)	
training:	Epoch: [35][43/204]	Loss 0.0121 (0.0609)	
training:	Epoch: [35][44/204]	Loss 0.0117 (0.0598)	
training:	Epoch: [35][45/204]	Loss 0.0120 (0.0587)	
training:	Epoch: [35][46/204]	Loss 0.0116 (0.0577)	
training:	Epoch: [35][47/204]	Loss 0.0108 (0.0567)	
training:	Epoch: [35][48/204]	Loss 0.0147 (0.0558)	
training:	Epoch: [35][49/204]	Loss 0.0122 (0.0549)	
training:	Epoch: [35][50/204]	Loss 0.0108 (0.0540)	
training:	Epoch: [35][51/204]	Loss 0.0124 (0.0532)	
training:	Epoch: [35][52/204]	Loss 0.1555 (0.0552)	
training:	Epoch: [35][53/204]	Loss 0.1508 (0.0570)	
training:	Epoch: [35][54/204]	Loss 0.0114 (0.0561)	
training:	Epoch: [35][55/204]	Loss 0.0161 (0.0554)	
training:	Epoch: [35][56/204]	Loss 0.0111 (0.0546)	
training:	Epoch: [35][57/204]	Loss 0.1482 (0.0563)	
training:	Epoch: [35][58/204]	Loss 0.0109 (0.0555)	
training:	Epoch: [35][59/204]	Loss 0.0110 (0.0547)	
training:	Epoch: [35][60/204]	Loss 0.0113 (0.0540)	
training:	Epoch: [35][61/204]	Loss 0.2662 (0.0575)	
training:	Epoch: [35][62/204]	Loss 0.0113 (0.0567)	
training:	Epoch: [35][63/204]	Loss 0.0106 (0.0560)	
training:	Epoch: [35][64/204]	Loss 0.0127 (0.0553)	
training:	Epoch: [35][65/204]	Loss 0.0117 (0.0547)	
training:	Epoch: [35][66/204]	Loss 0.0110 (0.0540)	
training:	Epoch: [35][67/204]	Loss 0.0130 (0.0534)	
training:	Epoch: [35][68/204]	Loss 0.1516 (0.0548)	
training:	Epoch: [35][69/204]	Loss 0.0110 (0.0542)	
training:	Epoch: [35][70/204]	Loss 0.0107 (0.0536)	
training:	Epoch: [35][71/204]	Loss 0.0125 (0.0530)	
training:	Epoch: [35][72/204]	Loss 0.0100 (0.0524)	
training:	Epoch: [35][73/204]	Loss 0.0113 (0.0518)	
training:	Epoch: [35][74/204]	Loss 0.0115 (0.0513)	
training:	Epoch: [35][75/204]	Loss 0.1600 (0.0527)	
training:	Epoch: [35][76/204]	Loss 0.0108 (0.0522)	
training:	Epoch: [35][77/204]	Loss 0.1492 (0.0534)	
training:	Epoch: [35][78/204]	Loss 0.0105 (0.0529)	
training:	Epoch: [35][79/204]	Loss 0.0116 (0.0524)	
training:	Epoch: [35][80/204]	Loss 0.0118 (0.0519)	
training:	Epoch: [35][81/204]	Loss 0.0113 (0.0514)	
training:	Epoch: [35][82/204]	Loss 0.0120 (0.0509)	
training:	Epoch: [35][83/204]	Loss 0.0108 (0.0504)	
training:	Epoch: [35][84/204]	Loss 0.1513 (0.0516)	
training:	Epoch: [35][85/204]	Loss 0.1468 (0.0527)	
training:	Epoch: [35][86/204]	Loss 0.1506 (0.0539)	
training:	Epoch: [35][87/204]	Loss 0.0126 (0.0534)	
training:	Epoch: [35][88/204]	Loss 0.0101 (0.0529)	
training:	Epoch: [35][89/204]	Loss 0.0109 (0.0524)	
training:	Epoch: [35][90/204]	Loss 0.0110 (0.0520)	
training:	Epoch: [35][91/204]	Loss 0.0100 (0.0515)	
training:	Epoch: [35][92/204]	Loss 0.0109 (0.0511)	
training:	Epoch: [35][93/204]	Loss 0.0108 (0.0506)	
training:	Epoch: [35][94/204]	Loss 0.0114 (0.0502)	
training:	Epoch: [35][95/204]	Loss 0.0121 (0.0498)	
training:	Epoch: [35][96/204]	Loss 0.0103 (0.0494)	
training:	Epoch: [35][97/204]	Loss 0.1813 (0.0508)	
training:	Epoch: [35][98/204]	Loss 0.0110 (0.0504)	
training:	Epoch: [35][99/204]	Loss 0.0138 (0.0500)	
training:	Epoch: [35][100/204]	Loss 0.1512 (0.0510)	
training:	Epoch: [35][101/204]	Loss 0.1472 (0.0520)	
training:	Epoch: [35][102/204]	Loss 0.0104 (0.0515)	
training:	Epoch: [35][103/204]	Loss 0.0119 (0.0512)	
training:	Epoch: [35][104/204]	Loss 0.0106 (0.0508)	
training:	Epoch: [35][105/204]	Loss 0.1591 (0.0518)	
training:	Epoch: [35][106/204]	Loss 0.0101 (0.0514)	
training:	Epoch: [35][107/204]	Loss 0.1615 (0.0524)	
training:	Epoch: [35][108/204]	Loss 0.0107 (0.0520)	
training:	Epoch: [35][109/204]	Loss 0.0108 (0.0517)	
training:	Epoch: [35][110/204]	Loss 0.0103 (0.0513)	
training:	Epoch: [35][111/204]	Loss 0.0106 (0.0509)	
training:	Epoch: [35][112/204]	Loss 0.0099 (0.0506)	
training:	Epoch: [35][113/204]	Loss 0.0102 (0.0502)	
training:	Epoch: [35][114/204]	Loss 0.1176 (0.0508)	
training:	Epoch: [35][115/204]	Loss 0.0103 (0.0504)	
training:	Epoch: [35][116/204]	Loss 0.0115 (0.0501)	
training:	Epoch: [35][117/204]	Loss 0.0103 (0.0498)	
training:	Epoch: [35][118/204]	Loss 0.0103 (0.0494)	
training:	Epoch: [35][119/204]	Loss 0.0111 (0.0491)	
training:	Epoch: [35][120/204]	Loss 0.1502 (0.0500)	
training:	Epoch: [35][121/204]	Loss 0.0115 (0.0496)	
training:	Epoch: [35][122/204]	Loss 0.2878 (0.0516)	
training:	Epoch: [35][123/204]	Loss 0.0107 (0.0513)	
training:	Epoch: [35][124/204]	Loss 0.0110 (0.0509)	
training:	Epoch: [35][125/204]	Loss 0.0096 (0.0506)	
training:	Epoch: [35][126/204]	Loss 0.1445 (0.0513)	
training:	Epoch: [35][127/204]	Loss 0.0115 (0.0510)	
training:	Epoch: [35][128/204]	Loss 0.1390 (0.0517)	
training:	Epoch: [35][129/204]	Loss 0.1537 (0.0525)	
training:	Epoch: [35][130/204]	Loss 0.0129 (0.0522)	
training:	Epoch: [35][131/204]	Loss 0.0120 (0.0519)	
training:	Epoch: [35][132/204]	Loss 0.0139 (0.0516)	
training:	Epoch: [35][133/204]	Loss 0.0114 (0.0513)	
training:	Epoch: [35][134/204]	Loss 0.0105 (0.0510)	
training:	Epoch: [35][135/204]	Loss 0.0142 (0.0507)	
training:	Epoch: [35][136/204]	Loss 0.0106 (0.0504)	
training:	Epoch: [35][137/204]	Loss 0.0109 (0.0501)	
training:	Epoch: [35][138/204]	Loss 0.0108 (0.0499)	
training:	Epoch: [35][139/204]	Loss 0.0108 (0.0496)	
training:	Epoch: [35][140/204]	Loss 0.0113 (0.0493)	
training:	Epoch: [35][141/204]	Loss 0.0114 (0.0490)	
training:	Epoch: [35][142/204]	Loss 0.0104 (0.0488)	
training:	Epoch: [35][143/204]	Loss 0.0118 (0.0485)	
training:	Epoch: [35][144/204]	Loss 0.0111 (0.0482)	
training:	Epoch: [35][145/204]	Loss 0.0114 (0.0480)	
training:	Epoch: [35][146/204]	Loss 0.0109 (0.0477)	
training:	Epoch: [35][147/204]	Loss 0.0101 (0.0475)	
training:	Epoch: [35][148/204]	Loss 0.0120 (0.0472)	
training:	Epoch: [35][149/204]	Loss 0.0110 (0.0470)	
training:	Epoch: [35][150/204]	Loss 0.0108 (0.0468)	
training:	Epoch: [35][151/204]	Loss 0.0107 (0.0465)	
training:	Epoch: [35][152/204]	Loss 0.0116 (0.0463)	
training:	Epoch: [35][153/204]	Loss 0.0114 (0.0461)	
training:	Epoch: [35][154/204]	Loss 0.0105 (0.0458)	
training:	Epoch: [35][155/204]	Loss 0.0100 (0.0456)	
training:	Epoch: [35][156/204]	Loss 0.0105 (0.0454)	
training:	Epoch: [35][157/204]	Loss 0.0104 (0.0452)	
training:	Epoch: [35][158/204]	Loss 0.0101 (0.0449)	
training:	Epoch: [35][159/204]	Loss 0.0098 (0.0447)	
training:	Epoch: [35][160/204]	Loss 0.0101 (0.0445)	
training:	Epoch: [35][161/204]	Loss 0.1448 (0.0451)	
training:	Epoch: [35][162/204]	Loss 0.0101 (0.0449)	
training:	Epoch: [35][163/204]	Loss 0.0094 (0.0447)	
training:	Epoch: [35][164/204]	Loss 0.0105 (0.0445)	
training:	Epoch: [35][165/204]	Loss 0.0125 (0.0443)	
training:	Epoch: [35][166/204]	Loss 0.0256 (0.0442)	
training:	Epoch: [35][167/204]	Loss 0.0094 (0.0440)	
training:	Epoch: [35][168/204]	Loss 0.0106 (0.0438)	
training:	Epoch: [35][169/204]	Loss 0.0106 (0.0436)	
training:	Epoch: [35][170/204]	Loss 0.0102 (0.0434)	
training:	Epoch: [35][171/204]	Loss 0.0097 (0.0432)	
training:	Epoch: [35][172/204]	Loss 0.1534 (0.0438)	
training:	Epoch: [35][173/204]	Loss 0.0103 (0.0436)	
training:	Epoch: [35][174/204]	Loss 0.0088 (0.0434)	
training:	Epoch: [35][175/204]	Loss 0.1630 (0.0441)	
training:	Epoch: [35][176/204]	Loss 0.3064 (0.0456)	
training:	Epoch: [35][177/204]	Loss 0.0100 (0.0454)	
training:	Epoch: [35][178/204]	Loss 0.1316 (0.0459)	
training:	Epoch: [35][179/204]	Loss 0.0098 (0.0457)	
training:	Epoch: [35][180/204]	Loss 0.0099 (0.0455)	
training:	Epoch: [35][181/204]	Loss 0.1525 (0.0461)	
training:	Epoch: [35][182/204]	Loss 0.0098 (0.0459)	
training:	Epoch: [35][183/204]	Loss 0.0098 (0.0457)	
training:	Epoch: [35][184/204]	Loss 0.0117 (0.0455)	
training:	Epoch: [35][185/204]	Loss 0.1524 (0.0461)	
training:	Epoch: [35][186/204]	Loss 0.0096 (0.0459)	
training:	Epoch: [35][187/204]	Loss 0.0100 (0.0457)	
training:	Epoch: [35][188/204]	Loss 0.0094 (0.0455)	
training:	Epoch: [35][189/204]	Loss 0.1384 (0.0460)	
training:	Epoch: [35][190/204]	Loss 0.0096 (0.0458)	
training:	Epoch: [35][191/204]	Loss 0.1535 (0.0463)	
training:	Epoch: [35][192/204]	Loss 0.2932 (0.0476)	
training:	Epoch: [35][193/204]	Loss 0.0093 (0.0474)	
training:	Epoch: [35][194/204]	Loss 0.2891 (0.0487)	
training:	Epoch: [35][195/204]	Loss 0.2680 (0.0498)	
training:	Epoch: [35][196/204]	Loss 0.1011 (0.0501)	
training:	Epoch: [35][197/204]	Loss 0.0133 (0.0499)	
training:	Epoch: [35][198/204]	Loss 0.0116 (0.0497)	
training:	Epoch: [35][199/204]	Loss 0.0112 (0.0495)	
training:	Epoch: [35][200/204]	Loss 0.0102 (0.0493)	
training:	Epoch: [35][201/204]	Loss 0.0100 (0.0491)	
training:	Epoch: [35][202/204]	Loss 0.0096 (0.0489)	
training:	Epoch: [35][203/204]	Loss 0.2678 (0.0500)	
training:	Epoch: [35][204/204]	Loss 0.1261 (0.0504)	
Training:	 Loss: 0.0503

Training:	 ACC: 0.9912 0.9911 0.9903 0.9920
Validation:	 ACC: 0.7797 0.7817 0.8240 0.7354
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8966
Pretraining:	Epoch 36/500
----------
training:	Epoch: [36][1/204]	Loss 0.0114 (0.0114)	
training:	Epoch: [36][2/204]	Loss 0.0101 (0.0108)	
training:	Epoch: [36][3/204]	Loss 0.1523 (0.0580)	
training:	Epoch: [36][4/204]	Loss 0.0179 (0.0479)	
training:	Epoch: [36][5/204]	Loss 0.0131 (0.0410)	
training:	Epoch: [36][6/204]	Loss 0.0111 (0.0360)	
training:	Epoch: [36][7/204]	Loss 0.0255 (0.0345)	
training:	Epoch: [36][8/204]	Loss 0.0126 (0.0318)	
training:	Epoch: [36][9/204]	Loss 0.1569 (0.0457)	
training:	Epoch: [36][10/204]	Loss 0.1520 (0.0563)	
training:	Epoch: [36][11/204]	Loss 0.1487 (0.0647)	
training:	Epoch: [36][12/204]	Loss 0.1638 (0.0730)	
training:	Epoch: [36][13/204]	Loss 0.0106 (0.0682)	
training:	Epoch: [36][14/204]	Loss 0.1530 (0.0742)	
training:	Epoch: [36][15/204]	Loss 0.0124 (0.0701)	
training:	Epoch: [36][16/204]	Loss 0.0106 (0.0664)	
training:	Epoch: [36][17/204]	Loss 0.0107 (0.0631)	
training:	Epoch: [36][18/204]	Loss 0.0191 (0.0607)	
training:	Epoch: [36][19/204]	Loss 0.0105 (0.0580)	
training:	Epoch: [36][20/204]	Loss 0.3308 (0.0717)	
training:	Epoch: [36][21/204]	Loss 0.0107 (0.0687)	
training:	Epoch: [36][22/204]	Loss 0.0109 (0.0661)	
training:	Epoch: [36][23/204]	Loss 0.0147 (0.0639)	
training:	Epoch: [36][24/204]	Loss 0.0110 (0.0617)	
training:	Epoch: [36][25/204]	Loss 0.1358 (0.0646)	
training:	Epoch: [36][26/204]	Loss 0.0128 (0.0627)	
training:	Epoch: [36][27/204]	Loss 0.0096 (0.0607)	
training:	Epoch: [36][28/204]	Loss 0.0134 (0.0590)	
training:	Epoch: [36][29/204]	Loss 0.0109 (0.0573)	
training:	Epoch: [36][30/204]	Loss 0.0106 (0.0558)	
training:	Epoch: [36][31/204]	Loss 0.0145 (0.0545)	
training:	Epoch: [36][32/204]	Loss 0.0106 (0.0531)	
training:	Epoch: [36][33/204]	Loss 0.0117 (0.0518)	
training:	Epoch: [36][34/204]	Loss 0.0110 (0.0506)	
training:	Epoch: [36][35/204]	Loss 0.0191 (0.0497)	
training:	Epoch: [36][36/204]	Loss 0.0118 (0.0487)	
training:	Epoch: [36][37/204]	Loss 0.0150 (0.0478)	
training:	Epoch: [36][38/204]	Loss 0.2871 (0.0541)	
training:	Epoch: [36][39/204]	Loss 0.0101 (0.0529)	
training:	Epoch: [36][40/204]	Loss 0.0122 (0.0519)	
training:	Epoch: [36][41/204]	Loss 0.0118 (0.0509)	
training:	Epoch: [36][42/204]	Loss 0.0130 (0.0500)	
training:	Epoch: [36][43/204]	Loss 0.1563 (0.0525)	
training:	Epoch: [36][44/204]	Loss 0.0103 (0.0515)	
training:	Epoch: [36][45/204]	Loss 0.0112 (0.0507)	
training:	Epoch: [36][46/204]	Loss 0.0201 (0.0500)	
training:	Epoch: [36][47/204]	Loss 0.0108 (0.0492)	
training:	Epoch: [36][48/204]	Loss 0.0112 (0.0484)	
training:	Epoch: [36][49/204]	Loss 0.0107 (0.0476)	
training:	Epoch: [36][50/204]	Loss 0.1173 (0.0490)	
training:	Epoch: [36][51/204]	Loss 0.0097 (0.0482)	
training:	Epoch: [36][52/204]	Loss 0.0117 (0.0475)	
training:	Epoch: [36][53/204]	Loss 0.0115 (0.0468)	
training:	Epoch: [36][54/204]	Loss 0.0210 (0.0464)	
training:	Epoch: [36][55/204]	Loss 0.0106 (0.0457)	
training:	Epoch: [36][56/204]	Loss 0.0099 (0.0451)	
training:	Epoch: [36][57/204]	Loss 0.0124 (0.0445)	
training:	Epoch: [36][58/204]	Loss 0.1242 (0.0459)	
training:	Epoch: [36][59/204]	Loss 0.0106 (0.0453)	
training:	Epoch: [36][60/204]	Loss 0.0111 (0.0447)	
training:	Epoch: [36][61/204]	Loss 0.0106 (0.0441)	
training:	Epoch: [36][62/204]	Loss 0.0098 (0.0436)	
training:	Epoch: [36][63/204]	Loss 0.1490 (0.0453)	
training:	Epoch: [36][64/204]	Loss 0.1448 (0.0468)	
training:	Epoch: [36][65/204]	Loss 0.0126 (0.0463)	
training:	Epoch: [36][66/204]	Loss 0.0118 (0.0458)	
training:	Epoch: [36][67/204]	Loss 0.0110 (0.0453)	
training:	Epoch: [36][68/204]	Loss 0.0118 (0.0448)	
training:	Epoch: [36][69/204]	Loss 0.0095 (0.0442)	
training:	Epoch: [36][70/204]	Loss 0.0112 (0.0438)	
training:	Epoch: [36][71/204]	Loss 0.0781 (0.0443)	
training:	Epoch: [36][72/204]	Loss 0.0101 (0.0438)	
training:	Epoch: [36][73/204]	Loss 0.1601 (0.0454)	
training:	Epoch: [36][74/204]	Loss 0.1691 (0.0470)	
training:	Epoch: [36][75/204]	Loss 0.0108 (0.0466)	
training:	Epoch: [36][76/204]	Loss 0.1534 (0.0480)	
training:	Epoch: [36][77/204]	Loss 0.1538 (0.0493)	
training:	Epoch: [36][78/204]	Loss 0.0122 (0.0489)	
training:	Epoch: [36][79/204]	Loss 0.0179 (0.0485)	
training:	Epoch: [36][80/204]	Loss 0.0094 (0.0480)	
training:	Epoch: [36][81/204]	Loss 0.0205 (0.0476)	
training:	Epoch: [36][82/204]	Loss 0.1264 (0.0486)	
training:	Epoch: [36][83/204]	Loss 0.0145 (0.0482)	
training:	Epoch: [36][84/204]	Loss 0.0112 (0.0478)	
training:	Epoch: [36][85/204]	Loss 0.0131 (0.0474)	
training:	Epoch: [36][86/204]	Loss 0.0110 (0.0469)	
training:	Epoch: [36][87/204]	Loss 0.0112 (0.0465)	
training:	Epoch: [36][88/204]	Loss 0.0130 (0.0461)	
training:	Epoch: [36][89/204]	Loss 0.0125 (0.0458)	
training:	Epoch: [36][90/204]	Loss 0.0106 (0.0454)	
training:	Epoch: [36][91/204]	Loss 0.1495 (0.0465)	
training:	Epoch: [36][92/204]	Loss 0.0097 (0.0461)	
training:	Epoch: [36][93/204]	Loss 0.0112 (0.0457)	
training:	Epoch: [36][94/204]	Loss 0.0100 (0.0454)	
training:	Epoch: [36][95/204]	Loss 0.0124 (0.0450)	
training:	Epoch: [36][96/204]	Loss 0.0128 (0.0447)	
training:	Epoch: [36][97/204]	Loss 0.1519 (0.0458)	
training:	Epoch: [36][98/204]	Loss 0.0105 (0.0454)	
training:	Epoch: [36][99/204]	Loss 0.1544 (0.0465)	
training:	Epoch: [36][100/204]	Loss 0.1510 (0.0476)	
training:	Epoch: [36][101/204]	Loss 0.0118 (0.0472)	
training:	Epoch: [36][102/204]	Loss 0.0114 (0.0469)	
training:	Epoch: [36][103/204]	Loss 0.1548 (0.0479)	
training:	Epoch: [36][104/204]	Loss 0.0093 (0.0475)	
training:	Epoch: [36][105/204]	Loss 0.1318 (0.0483)	
training:	Epoch: [36][106/204]	Loss 0.1335 (0.0491)	
training:	Epoch: [36][107/204]	Loss 0.0114 (0.0488)	
training:	Epoch: [36][108/204]	Loss 0.0113 (0.0484)	
training:	Epoch: [36][109/204]	Loss 0.0099 (0.0481)	
training:	Epoch: [36][110/204]	Loss 0.0102 (0.0477)	
training:	Epoch: [36][111/204]	Loss 0.0098 (0.0474)	
training:	Epoch: [36][112/204]	Loss 0.1625 (0.0484)	
training:	Epoch: [36][113/204]	Loss 0.0113 (0.0481)	
training:	Epoch: [36][114/204]	Loss 0.0112 (0.0478)	
training:	Epoch: [36][115/204]	Loss 0.0100 (0.0475)	
training:	Epoch: [36][116/204]	Loss 0.0107 (0.0471)	
training:	Epoch: [36][117/204]	Loss 0.0109 (0.0468)	
training:	Epoch: [36][118/204]	Loss 0.0101 (0.0465)	
training:	Epoch: [36][119/204]	Loss 0.1340 (0.0472)	
training:	Epoch: [36][120/204]	Loss 0.1440 (0.0481)	
training:	Epoch: [36][121/204]	Loss 0.0099 (0.0477)	
training:	Epoch: [36][122/204]	Loss 0.0117 (0.0474)	
training:	Epoch: [36][123/204]	Loss 0.0114 (0.0472)	
training:	Epoch: [36][124/204]	Loss 0.0116 (0.0469)	
training:	Epoch: [36][125/204]	Loss 0.1118 (0.0474)	
training:	Epoch: [36][126/204]	Loss 0.0115 (0.0471)	
training:	Epoch: [36][127/204]	Loss 0.1570 (0.0480)	
training:	Epoch: [36][128/204]	Loss 0.1074 (0.0484)	
training:	Epoch: [36][129/204]	Loss 0.0111 (0.0481)	
training:	Epoch: [36][130/204]	Loss 0.0107 (0.0479)	
training:	Epoch: [36][131/204]	Loss 0.0122 (0.0476)	
training:	Epoch: [36][132/204]	Loss 0.2357 (0.0490)	
training:	Epoch: [36][133/204]	Loss 0.0107 (0.0487)	
training:	Epoch: [36][134/204]	Loss 0.0115 (0.0484)	
training:	Epoch: [36][135/204]	Loss 0.0143 (0.0482)	
training:	Epoch: [36][136/204]	Loss 0.1568 (0.0490)	
training:	Epoch: [36][137/204]	Loss 0.4393 (0.0518)	
training:	Epoch: [36][138/204]	Loss 0.0176 (0.0516)	
training:	Epoch: [36][139/204]	Loss 0.0641 (0.0517)	
training:	Epoch: [36][140/204]	Loss 0.0117 (0.0514)	
training:	Epoch: [36][141/204]	Loss 0.0133 (0.0511)	
training:	Epoch: [36][142/204]	Loss 0.0122 (0.0508)	
training:	Epoch: [36][143/204]	Loss 0.1562 (0.0516)	
training:	Epoch: [36][144/204]	Loss 0.0106 (0.0513)	
training:	Epoch: [36][145/204]	Loss 0.0353 (0.0512)	
training:	Epoch: [36][146/204]	Loss 0.0199 (0.0510)	
training:	Epoch: [36][147/204]	Loss 0.0285 (0.0508)	
training:	Epoch: [36][148/204]	Loss 0.0129 (0.0506)	
training:	Epoch: [36][149/204]	Loss 0.1308 (0.0511)	
training:	Epoch: [36][150/204]	Loss 0.1222 (0.0516)	
training:	Epoch: [36][151/204]	Loss 0.0143 (0.0513)	
training:	Epoch: [36][152/204]	Loss 0.0166 (0.0511)	
training:	Epoch: [36][153/204]	Loss 0.2262 (0.0522)	
training:	Epoch: [36][154/204]	Loss 0.0144 (0.0520)	
training:	Epoch: [36][155/204]	Loss 0.0456 (0.0520)	
training:	Epoch: [36][156/204]	Loss 0.0105 (0.0517)	
training:	Epoch: [36][157/204]	Loss 0.0130 (0.0514)	
training:	Epoch: [36][158/204]	Loss 0.1205 (0.0519)	
training:	Epoch: [36][159/204]	Loss 0.0128 (0.0516)	
training:	Epoch: [36][160/204]	Loss 0.0110 (0.0514)	
training:	Epoch: [36][161/204]	Loss 0.1525 (0.0520)	
training:	Epoch: [36][162/204]	Loss 0.0101 (0.0518)	
training:	Epoch: [36][163/204]	Loss 0.0119 (0.0515)	
training:	Epoch: [36][164/204]	Loss 0.0226 (0.0513)	
training:	Epoch: [36][165/204]	Loss 0.0232 (0.0512)	
training:	Epoch: [36][166/204]	Loss 0.0105 (0.0509)	
training:	Epoch: [36][167/204]	Loss 0.0116 (0.0507)	
training:	Epoch: [36][168/204]	Loss 0.0180 (0.0505)	
training:	Epoch: [36][169/204]	Loss 0.0598 (0.0505)	
training:	Epoch: [36][170/204]	Loss 0.1521 (0.0511)	
training:	Epoch: [36][171/204]	Loss 0.1615 (0.0518)	
training:	Epoch: [36][172/204]	Loss 0.0102 (0.0515)	
training:	Epoch: [36][173/204]	Loss 0.0150 (0.0513)	
training:	Epoch: [36][174/204]	Loss 0.0164 (0.0511)	
training:	Epoch: [36][175/204]	Loss 0.0686 (0.0512)	
training:	Epoch: [36][176/204]	Loss 0.0128 (0.0510)	
training:	Epoch: [36][177/204]	Loss 0.1331 (0.0515)	
training:	Epoch: [36][178/204]	Loss 0.0243 (0.0513)	
training:	Epoch: [36][179/204]	Loss 0.0204 (0.0512)	
training:	Epoch: [36][180/204]	Loss 0.1652 (0.0518)	
training:	Epoch: [36][181/204]	Loss 0.0114 (0.0516)	
training:	Epoch: [36][182/204]	Loss 0.1441 (0.0521)	
training:	Epoch: [36][183/204]	Loss 0.2855 (0.0533)	
training:	Epoch: [36][184/204]	Loss 0.0120 (0.0531)	
training:	Epoch: [36][185/204]	Loss 0.0134 (0.0529)	
training:	Epoch: [36][186/204]	Loss 0.0118 (0.0527)	
training:	Epoch: [36][187/204]	Loss 0.1637 (0.0533)	
training:	Epoch: [36][188/204]	Loss 0.0422 (0.0532)	
training:	Epoch: [36][189/204]	Loss 0.0116 (0.0530)	
training:	Epoch: [36][190/204]	Loss 0.1512 (0.0535)	
training:	Epoch: [36][191/204]	Loss 0.1024 (0.0538)	
training:	Epoch: [36][192/204]	Loss 0.0140 (0.0536)	
training:	Epoch: [36][193/204]	Loss 0.0118 (0.0533)	
training:	Epoch: [36][194/204]	Loss 0.0108 (0.0531)	
training:	Epoch: [36][195/204]	Loss 0.0155 (0.0529)	
training:	Epoch: [36][196/204]	Loss 0.1486 (0.0534)	
training:	Epoch: [36][197/204]	Loss 0.0124 (0.0532)	
training:	Epoch: [36][198/204]	Loss 0.0134 (0.0530)	
training:	Epoch: [36][199/204]	Loss 0.1343 (0.0534)	
training:	Epoch: [36][200/204]	Loss 0.0113 (0.0532)	
training:	Epoch: [36][201/204]	Loss 0.0113 (0.0530)	
training:	Epoch: [36][202/204]	Loss 0.0100 (0.0528)	
training:	Epoch: [36][203/204]	Loss 0.0100 (0.0526)	
training:	Epoch: [36][204/204]	Loss 0.0116 (0.0524)	
Training:	 Loss: 0.0523

Training:	 ACC: 0.9862 0.9864 0.9906 0.9818
Validation:	 ACC: 0.7825 0.7854 0.8465 0.7186
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8983
Pretraining:	Epoch 37/500
----------
training:	Epoch: [37][1/204]	Loss 0.0101 (0.0101)	
training:	Epoch: [37][2/204]	Loss 0.0573 (0.0337)	
training:	Epoch: [37][3/204]	Loss 0.0148 (0.0274)	
training:	Epoch: [37][4/204]	Loss 0.0121 (0.0236)	
training:	Epoch: [37][5/204]	Loss 0.0111 (0.0211)	
training:	Epoch: [37][6/204]	Loss 0.0128 (0.0197)	
training:	Epoch: [37][7/204]	Loss 0.0117 (0.0186)	
training:	Epoch: [37][8/204]	Loss 0.0108 (0.0176)	
training:	Epoch: [37][9/204]	Loss 0.0107 (0.0168)	
training:	Epoch: [37][10/204]	Loss 0.0107 (0.0162)	
training:	Epoch: [37][11/204]	Loss 0.1580 (0.0291)	
training:	Epoch: [37][12/204]	Loss 0.0106 (0.0276)	
training:	Epoch: [37][13/204]	Loss 0.0105 (0.0263)	
training:	Epoch: [37][14/204]	Loss 0.0148 (0.0254)	
training:	Epoch: [37][15/204]	Loss 0.0426 (0.0266)	
training:	Epoch: [37][16/204]	Loss 0.0187 (0.0261)	
training:	Epoch: [37][17/204]	Loss 0.1519 (0.0335)	
training:	Epoch: [37][18/204]	Loss 0.0172 (0.0326)	
training:	Epoch: [37][19/204]	Loss 0.0110 (0.0314)	
training:	Epoch: [37][20/204]	Loss 0.0413 (0.0319)	
training:	Epoch: [37][21/204]	Loss 0.3224 (0.0458)	
training:	Epoch: [37][22/204]	Loss 0.0111 (0.0442)	
training:	Epoch: [37][23/204]	Loss 0.0771 (0.0456)	
training:	Epoch: [37][24/204]	Loss 0.0127 (0.0443)	
training:	Epoch: [37][25/204]	Loss 0.0099 (0.0429)	
training:	Epoch: [37][26/204]	Loss 0.0350 (0.0426)	
training:	Epoch: [37][27/204]	Loss 0.2152 (0.0490)	
training:	Epoch: [37][28/204]	Loss 0.0176 (0.0478)	
training:	Epoch: [37][29/204]	Loss 0.1490 (0.0513)	
training:	Epoch: [37][30/204]	Loss 0.1661 (0.0552)	
training:	Epoch: [37][31/204]	Loss 0.0097 (0.0537)	
training:	Epoch: [37][32/204]	Loss 0.0108 (0.0524)	
training:	Epoch: [37][33/204]	Loss 0.0100 (0.0511)	
training:	Epoch: [37][34/204]	Loss 0.1334 (0.0535)	
training:	Epoch: [37][35/204]	Loss 0.0104 (0.0523)	
training:	Epoch: [37][36/204]	Loss 0.1618 (0.0553)	
training:	Epoch: [37][37/204]	Loss 0.1532 (0.0580)	
training:	Epoch: [37][38/204]	Loss 0.2820 (0.0638)	
training:	Epoch: [37][39/204]	Loss 0.0103 (0.0625)	
training:	Epoch: [37][40/204]	Loss 0.0225 (0.0615)	
training:	Epoch: [37][41/204]	Loss 0.2102 (0.0651)	
training:	Epoch: [37][42/204]	Loss 0.0112 (0.0638)	
training:	Epoch: [37][43/204]	Loss 0.0124 (0.0626)	
training:	Epoch: [37][44/204]	Loss 0.0110 (0.0615)	
training:	Epoch: [37][45/204]	Loss 0.0096 (0.0603)	
training:	Epoch: [37][46/204]	Loss 0.0113 (0.0592)	
training:	Epoch: [37][47/204]	Loss 0.0096 (0.0582)	
training:	Epoch: [37][48/204]	Loss 0.1489 (0.0601)	
training:	Epoch: [37][49/204]	Loss 0.0136 (0.0591)	
training:	Epoch: [37][50/204]	Loss 0.0100 (0.0581)	
training:	Epoch: [37][51/204]	Loss 0.1472 (0.0599)	
training:	Epoch: [37][52/204]	Loss 0.1121 (0.0609)	
training:	Epoch: [37][53/204]	Loss 0.0132 (0.0600)	
training:	Epoch: [37][54/204]	Loss 0.2423 (0.0634)	
training:	Epoch: [37][55/204]	Loss 0.0098 (0.0624)	
training:	Epoch: [37][56/204]	Loss 0.1477 (0.0639)	
training:	Epoch: [37][57/204]	Loss 0.0123 (0.0630)	
training:	Epoch: [37][58/204]	Loss 0.1677 (0.0648)	
training:	Epoch: [37][59/204]	Loss 0.0118 (0.0639)	
training:	Epoch: [37][60/204]	Loss 0.0134 (0.0631)	
training:	Epoch: [37][61/204]	Loss 0.0101 (0.0622)	
training:	Epoch: [37][62/204]	Loss 0.2689 (0.0655)	
training:	Epoch: [37][63/204]	Loss 0.0190 (0.0648)	
training:	Epoch: [37][64/204]	Loss 0.0117 (0.0640)	
training:	Epoch: [37][65/204]	Loss 0.1443 (0.0652)	
training:	Epoch: [37][66/204]	Loss 0.1524 (0.0665)	
training:	Epoch: [37][67/204]	Loss 0.1615 (0.0679)	
training:	Epoch: [37][68/204]	Loss 0.0142 (0.0672)	
training:	Epoch: [37][69/204]	Loss 0.1575 (0.0685)	
training:	Epoch: [37][70/204]	Loss 0.0127 (0.0677)	
training:	Epoch: [37][71/204]	Loss 0.1550 (0.0689)	
training:	Epoch: [37][72/204]	Loss 0.0160 (0.0682)	
training:	Epoch: [37][73/204]	Loss 0.0110 (0.0674)	
training:	Epoch: [37][74/204]	Loss 0.1252 (0.0682)	
training:	Epoch: [37][75/204]	Loss 0.0149 (0.0675)	
training:	Epoch: [37][76/204]	Loss 0.0126 (0.0667)	
training:	Epoch: [37][77/204]	Loss 0.0142 (0.0660)	
training:	Epoch: [37][78/204]	Loss 0.0121 (0.0654)	
training:	Epoch: [37][79/204]	Loss 0.0138 (0.0647)	
training:	Epoch: [37][80/204]	Loss 0.1495 (0.0658)	
training:	Epoch: [37][81/204]	Loss 0.0120 (0.0651)	
training:	Epoch: [37][82/204]	Loss 0.0154 (0.0645)	
training:	Epoch: [37][83/204]	Loss 0.0151 (0.0639)	
training:	Epoch: [37][84/204]	Loss 0.0145 (0.0633)	
training:	Epoch: [37][85/204]	Loss 0.0137 (0.0627)	
training:	Epoch: [37][86/204]	Loss 0.0119 (0.0621)	
training:	Epoch: [37][87/204]	Loss 0.0125 (0.0616)	
training:	Epoch: [37][88/204]	Loss 0.0465 (0.0614)	
training:	Epoch: [37][89/204]	Loss 0.0171 (0.0609)	
training:	Epoch: [37][90/204]	Loss 0.0106 (0.0603)	
training:	Epoch: [37][91/204]	Loss 0.0110 (0.0598)	
training:	Epoch: [37][92/204]	Loss 0.0131 (0.0593)	
training:	Epoch: [37][93/204]	Loss 0.0851 (0.0596)	
training:	Epoch: [37][94/204]	Loss 0.0117 (0.0591)	
training:	Epoch: [37][95/204]	Loss 0.0102 (0.0585)	
training:	Epoch: [37][96/204]	Loss 0.0124 (0.0581)	
training:	Epoch: [37][97/204]	Loss 0.0118 (0.0576)	
training:	Epoch: [37][98/204]	Loss 0.0311 (0.0573)	
training:	Epoch: [37][99/204]	Loss 0.0141 (0.0569)	
training:	Epoch: [37][100/204]	Loss 0.0108 (0.0564)	
training:	Epoch: [37][101/204]	Loss 0.0115 (0.0560)	
training:	Epoch: [37][102/204]	Loss 0.0125 (0.0555)	
training:	Epoch: [37][103/204]	Loss 0.0115 (0.0551)	
training:	Epoch: [37][104/204]	Loss 0.0109 (0.0547)	
training:	Epoch: [37][105/204]	Loss 0.1389 (0.0555)	
training:	Epoch: [37][106/204]	Loss 0.0126 (0.0551)	
training:	Epoch: [37][107/204]	Loss 0.0128 (0.0547)	
training:	Epoch: [37][108/204]	Loss 0.0203 (0.0544)	
training:	Epoch: [37][109/204]	Loss 0.0184 (0.0540)	
training:	Epoch: [37][110/204]	Loss 0.0106 (0.0536)	
training:	Epoch: [37][111/204]	Loss 0.0993 (0.0541)	
training:	Epoch: [37][112/204]	Loss 0.0124 (0.0537)	
training:	Epoch: [37][113/204]	Loss 0.0109 (0.0533)	
training:	Epoch: [37][114/204]	Loss 0.0127 (0.0530)	
training:	Epoch: [37][115/204]	Loss 0.0103 (0.0526)	
training:	Epoch: [37][116/204]	Loss 0.0970 (0.0530)	
training:	Epoch: [37][117/204]	Loss 0.1515 (0.0538)	
training:	Epoch: [37][118/204]	Loss 0.0093 (0.0534)	
training:	Epoch: [37][119/204]	Loss 0.0105 (0.0531)	
training:	Epoch: [37][120/204]	Loss 0.0106 (0.0527)	
training:	Epoch: [37][121/204]	Loss 0.1516 (0.0535)	
training:	Epoch: [37][122/204]	Loss 0.0706 (0.0537)	
training:	Epoch: [37][123/204]	Loss 0.0096 (0.0533)	
training:	Epoch: [37][124/204]	Loss 0.0118 (0.0530)	
training:	Epoch: [37][125/204]	Loss 0.0096 (0.0526)	
training:	Epoch: [37][126/204]	Loss 0.0109 (0.0523)	
training:	Epoch: [37][127/204]	Loss 0.0101 (0.0520)	
training:	Epoch: [37][128/204]	Loss 0.0160 (0.0517)	
training:	Epoch: [37][129/204]	Loss 0.1316 (0.0523)	
training:	Epoch: [37][130/204]	Loss 0.1127 (0.0528)	
training:	Epoch: [37][131/204]	Loss 0.0445 (0.0527)	
training:	Epoch: [37][132/204]	Loss 0.0110 (0.0524)	
training:	Epoch: [37][133/204]	Loss 0.0284 (0.0522)	
training:	Epoch: [37][134/204]	Loss 0.0101 (0.0519)	
training:	Epoch: [37][135/204]	Loss 0.0524 (0.0519)	
training:	Epoch: [37][136/204]	Loss 0.0108 (0.0516)	
training:	Epoch: [37][137/204]	Loss 0.0674 (0.0517)	
training:	Epoch: [37][138/204]	Loss 0.0176 (0.0515)	
training:	Epoch: [37][139/204]	Loss 0.0113 (0.0512)	
training:	Epoch: [37][140/204]	Loss 0.0103 (0.0509)	
training:	Epoch: [37][141/204]	Loss 0.0101 (0.0506)	
training:	Epoch: [37][142/204]	Loss 0.0097 (0.0503)	
training:	Epoch: [37][143/204]	Loss 0.0093 (0.0500)	
training:	Epoch: [37][144/204]	Loss 0.1559 (0.0508)	
training:	Epoch: [37][145/204]	Loss 0.0109 (0.0505)	
training:	Epoch: [37][146/204]	Loss 0.1546 (0.0512)	
training:	Epoch: [37][147/204]	Loss 0.2508 (0.0526)	
training:	Epoch: [37][148/204]	Loss 0.1536 (0.0532)	
training:	Epoch: [37][149/204]	Loss 0.0105 (0.0530)	
training:	Epoch: [37][150/204]	Loss 0.0099 (0.0527)	
training:	Epoch: [37][151/204]	Loss 0.0104 (0.0524)	
training:	Epoch: [37][152/204]	Loss 0.0187 (0.0522)	
training:	Epoch: [37][153/204]	Loss 0.0103 (0.0519)	
training:	Epoch: [37][154/204]	Loss 0.0102 (0.0516)	
training:	Epoch: [37][155/204]	Loss 0.0144 (0.0514)	
training:	Epoch: [37][156/204]	Loss 0.0127 (0.0511)	
training:	Epoch: [37][157/204]	Loss 0.2877 (0.0526)	
training:	Epoch: [37][158/204]	Loss 0.0122 (0.0524)	
training:	Epoch: [37][159/204]	Loss 0.1503 (0.0530)	
training:	Epoch: [37][160/204]	Loss 0.0131 (0.0527)	
training:	Epoch: [37][161/204]	Loss 0.0113 (0.0525)	
training:	Epoch: [37][162/204]	Loss 0.0149 (0.0523)	
training:	Epoch: [37][163/204]	Loss 0.1560 (0.0529)	
training:	Epoch: [37][164/204]	Loss 0.1467 (0.0535)	
training:	Epoch: [37][165/204]	Loss 0.0116 (0.0532)	
training:	Epoch: [37][166/204]	Loss 0.0144 (0.0530)	
training:	Epoch: [37][167/204]	Loss 0.1546 (0.0536)	
training:	Epoch: [37][168/204]	Loss 0.0098 (0.0533)	
training:	Epoch: [37][169/204]	Loss 0.0102 (0.0531)	
training:	Epoch: [37][170/204]	Loss 0.0124 (0.0528)	
training:	Epoch: [37][171/204]	Loss 0.0514 (0.0528)	
training:	Epoch: [37][172/204]	Loss 0.0101 (0.0526)	
training:	Epoch: [37][173/204]	Loss 0.1382 (0.0531)	
training:	Epoch: [37][174/204]	Loss 0.0092 (0.0528)	
training:	Epoch: [37][175/204]	Loss 0.0150 (0.0526)	
training:	Epoch: [37][176/204]	Loss 0.0107 (0.0524)	
training:	Epoch: [37][177/204]	Loss 0.0123 (0.0521)	
training:	Epoch: [37][178/204]	Loss 0.0123 (0.0519)	
training:	Epoch: [37][179/204]	Loss 0.0101 (0.0517)	
training:	Epoch: [37][180/204]	Loss 0.0970 (0.0519)	
training:	Epoch: [37][181/204]	Loss 0.0092 (0.0517)	
training:	Epoch: [37][182/204]	Loss 0.0119 (0.0515)	
training:	Epoch: [37][183/204]	Loss 0.0099 (0.0512)	
training:	Epoch: [37][184/204]	Loss 0.0104 (0.0510)	
training:	Epoch: [37][185/204]	Loss 0.1534 (0.0516)	
training:	Epoch: [37][186/204]	Loss 0.0096 (0.0514)	
training:	Epoch: [37][187/204]	Loss 0.0116 (0.0511)	
training:	Epoch: [37][188/204]	Loss 0.2711 (0.0523)	
training:	Epoch: [37][189/204]	Loss 0.0396 (0.0522)	
training:	Epoch: [37][190/204]	Loss 0.1460 (0.0527)	
training:	Epoch: [37][191/204]	Loss 0.0675 (0.0528)	
training:	Epoch: [37][192/204]	Loss 0.1289 (0.0532)	
training:	Epoch: [37][193/204]	Loss 0.3105 (0.0545)	
training:	Epoch: [37][194/204]	Loss 0.0108 (0.0543)	
training:	Epoch: [37][195/204]	Loss 0.1550 (0.0548)	
training:	Epoch: [37][196/204]	Loss 0.1498 (0.0553)	
training:	Epoch: [37][197/204]	Loss 0.0093 (0.0551)	
training:	Epoch: [37][198/204]	Loss 0.1057 (0.0553)	
training:	Epoch: [37][199/204]	Loss 0.0099 (0.0551)	
training:	Epoch: [37][200/204]	Loss 0.0092 (0.0549)	
training:	Epoch: [37][201/204]	Loss 0.0132 (0.0547)	
training:	Epoch: [37][202/204]	Loss 0.0096 (0.0545)	
training:	Epoch: [37][203/204]	Loss 0.1258 (0.0548)	
training:	Epoch: [37][204/204]	Loss 0.1556 (0.0553)	
Training:	 Loss: 0.0552

Training:	 ACC: 0.9916 0.9916 0.9909 0.9923
Validation:	 ACC: 0.7912 0.7929 0.8291 0.7534
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8557
Pretraining:	Epoch 38/500
----------
training:	Epoch: [38][1/204]	Loss 0.0117 (0.0117)	
training:	Epoch: [38][2/204]	Loss 0.0127 (0.0122)	
training:	Epoch: [38][3/204]	Loss 0.0314 (0.0186)	
training:	Epoch: [38][4/204]	Loss 0.1580 (0.0534)	
training:	Epoch: [38][5/204]	Loss 0.0101 (0.0448)	
training:	Epoch: [38][6/204]	Loss 0.1425 (0.0611)	
training:	Epoch: [38][7/204]	Loss 0.1650 (0.0759)	
training:	Epoch: [38][8/204]	Loss 0.0114 (0.0678)	
training:	Epoch: [38][9/204]	Loss 0.0178 (0.0623)	
training:	Epoch: [38][10/204]	Loss 0.0151 (0.0576)	
training:	Epoch: [38][11/204]	Loss 0.0919 (0.0607)	
training:	Epoch: [38][12/204]	Loss 0.0128 (0.0567)	
training:	Epoch: [38][13/204]	Loss 0.0147 (0.0535)	
training:	Epoch: [38][14/204]	Loss 0.0135 (0.0506)	
training:	Epoch: [38][15/204]	Loss 0.0133 (0.0481)	
training:	Epoch: [38][16/204]	Loss 0.0178 (0.0462)	
training:	Epoch: [38][17/204]	Loss 0.0191 (0.0446)	
training:	Epoch: [38][18/204]	Loss 0.1089 (0.0482)	
training:	Epoch: [38][19/204]	Loss 0.0796 (0.0499)	
training:	Epoch: [38][20/204]	Loss 0.0193 (0.0483)	
training:	Epoch: [38][21/204]	Loss 0.0110 (0.0466)	
training:	Epoch: [38][22/204]	Loss 0.0110 (0.0449)	
training:	Epoch: [38][23/204]	Loss 0.0117 (0.0435)	
training:	Epoch: [38][24/204]	Loss 0.0915 (0.0455)	
training:	Epoch: [38][25/204]	Loss 0.0161 (0.0443)	
training:	Epoch: [38][26/204]	Loss 0.0103 (0.0430)	
training:	Epoch: [38][27/204]	Loss 0.0117 (0.0418)	
training:	Epoch: [38][28/204]	Loss 0.1528 (0.0458)	
training:	Epoch: [38][29/204]	Loss 0.0421 (0.0457)	
training:	Epoch: [38][30/204]	Loss 0.3014 (0.0542)	
training:	Epoch: [38][31/204]	Loss 0.0146 (0.0529)	
training:	Epoch: [38][32/204]	Loss 0.0124 (0.0517)	
training:	Epoch: [38][33/204]	Loss 0.0119 (0.0505)	
training:	Epoch: [38][34/204]	Loss 0.1585 (0.0536)	
training:	Epoch: [38][35/204]	Loss 0.0127 (0.0525)	
training:	Epoch: [38][36/204]	Loss 0.0133 (0.0514)	
training:	Epoch: [38][37/204]	Loss 0.0132 (0.0503)	
training:	Epoch: [38][38/204]	Loss 0.0125 (0.0493)	
training:	Epoch: [38][39/204]	Loss 0.1181 (0.0511)	
training:	Epoch: [38][40/204]	Loss 0.0099 (0.0501)	
training:	Epoch: [38][41/204]	Loss 0.0110 (0.0491)	
training:	Epoch: [38][42/204]	Loss 0.1586 (0.0517)	
training:	Epoch: [38][43/204]	Loss 0.0093 (0.0507)	
training:	Epoch: [38][44/204]	Loss 0.0105 (0.0498)	
training:	Epoch: [38][45/204]	Loss 0.0127 (0.0490)	
training:	Epoch: [38][46/204]	Loss 0.0121 (0.0482)	
training:	Epoch: [38][47/204]	Loss 0.0094 (0.0474)	
training:	Epoch: [38][48/204]	Loss 0.0094 (0.0466)	
training:	Epoch: [38][49/204]	Loss 0.1535 (0.0488)	
training:	Epoch: [38][50/204]	Loss 0.0106 (0.0480)	
training:	Epoch: [38][51/204]	Loss 0.0115 (0.0473)	
training:	Epoch: [38][52/204]	Loss 0.0112 (0.0466)	
training:	Epoch: [38][53/204]	Loss 0.1316 (0.0482)	
training:	Epoch: [38][54/204]	Loss 0.1522 (0.0501)	
training:	Epoch: [38][55/204]	Loss 0.0097 (0.0494)	
training:	Epoch: [38][56/204]	Loss 0.0106 (0.0487)	
training:	Epoch: [38][57/204]	Loss 0.1581 (0.0506)	
training:	Epoch: [38][58/204]	Loss 0.3050 (0.0550)	
training:	Epoch: [38][59/204]	Loss 0.0114 (0.0543)	
training:	Epoch: [38][60/204]	Loss 0.0124 (0.0536)	
training:	Epoch: [38][61/204]	Loss 0.0103 (0.0529)	
training:	Epoch: [38][62/204]	Loss 0.0211 (0.0523)	
training:	Epoch: [38][63/204]	Loss 0.1442 (0.0538)	
training:	Epoch: [38][64/204]	Loss 0.0105 (0.0531)	
training:	Epoch: [38][65/204]	Loss 0.0113 (0.0525)	
training:	Epoch: [38][66/204]	Loss 0.1535 (0.0540)	
training:	Epoch: [38][67/204]	Loss 0.0147 (0.0534)	
training:	Epoch: [38][68/204]	Loss 0.0104 (0.0528)	
training:	Epoch: [38][69/204]	Loss 0.0102 (0.0522)	
training:	Epoch: [38][70/204]	Loss 0.0100 (0.0516)	
training:	Epoch: [38][71/204]	Loss 0.0100 (0.0510)	
training:	Epoch: [38][72/204]	Loss 0.0125 (0.0505)	
training:	Epoch: [38][73/204]	Loss 0.0096 (0.0499)	
training:	Epoch: [38][74/204]	Loss 0.0105 (0.0494)	
training:	Epoch: [38][75/204]	Loss 0.0115 (0.0489)	
training:	Epoch: [38][76/204]	Loss 0.0096 (0.0483)	
training:	Epoch: [38][77/204]	Loss 0.0094 (0.0478)	
training:	Epoch: [38][78/204]	Loss 0.0098 (0.0473)	
training:	Epoch: [38][79/204]	Loss 0.0099 (0.0469)	
training:	Epoch: [38][80/204]	Loss 0.0110 (0.0464)	
training:	Epoch: [38][81/204]	Loss 0.0094 (0.0460)	
training:	Epoch: [38][82/204]	Loss 0.0109 (0.0455)	
training:	Epoch: [38][83/204]	Loss 0.0099 (0.0451)	
training:	Epoch: [38][84/204]	Loss 0.0105 (0.0447)	
training:	Epoch: [38][85/204]	Loss 0.0095 (0.0443)	
training:	Epoch: [38][86/204]	Loss 0.0101 (0.0439)	
training:	Epoch: [38][87/204]	Loss 0.0104 (0.0435)	
training:	Epoch: [38][88/204]	Loss 0.1472 (0.0447)	
training:	Epoch: [38][89/204]	Loss 0.0100 (0.0443)	
training:	Epoch: [38][90/204]	Loss 0.1537 (0.0455)	
training:	Epoch: [38][91/204]	Loss 0.1417 (0.0466)	
training:	Epoch: [38][92/204]	Loss 0.0093 (0.0462)	
training:	Epoch: [38][93/204]	Loss 0.0092 (0.0458)	
training:	Epoch: [38][94/204]	Loss 0.1186 (0.0465)	
training:	Epoch: [38][95/204]	Loss 0.0111 (0.0462)	
training:	Epoch: [38][96/204]	Loss 0.0095 (0.0458)	
training:	Epoch: [38][97/204]	Loss 0.1547 (0.0469)	
training:	Epoch: [38][98/204]	Loss 0.0091 (0.0465)	
training:	Epoch: [38][99/204]	Loss 0.0105 (0.0462)	
training:	Epoch: [38][100/204]	Loss 0.1024 (0.0467)	
training:	Epoch: [38][101/204]	Loss 0.0095 (0.0463)	
training:	Epoch: [38][102/204]	Loss 0.1570 (0.0474)	
training:	Epoch: [38][103/204]	Loss 0.1553 (0.0485)	
training:	Epoch: [38][104/204]	Loss 0.1540 (0.0495)	
training:	Epoch: [38][105/204]	Loss 0.0099 (0.0491)	
training:	Epoch: [38][106/204]	Loss 0.0100 (0.0487)	
training:	Epoch: [38][107/204]	Loss 0.1529 (0.0497)	
training:	Epoch: [38][108/204]	Loss 0.0106 (0.0494)	
training:	Epoch: [38][109/204]	Loss 0.0101 (0.0490)	
training:	Epoch: [38][110/204]	Loss 0.0090 (0.0486)	
training:	Epoch: [38][111/204]	Loss 0.1536 (0.0496)	
training:	Epoch: [38][112/204]	Loss 0.1078 (0.0501)	
training:	Epoch: [38][113/204]	Loss 0.0149 (0.0498)	
training:	Epoch: [38][114/204]	Loss 0.0091 (0.0494)	
training:	Epoch: [38][115/204]	Loss 0.0107 (0.0491)	
training:	Epoch: [38][116/204]	Loss 0.0096 (0.0488)	
training:	Epoch: [38][117/204]	Loss 0.0146 (0.0485)	
training:	Epoch: [38][118/204]	Loss 0.0092 (0.0481)	
training:	Epoch: [38][119/204]	Loss 0.1552 (0.0490)	
training:	Epoch: [38][120/204]	Loss 0.0115 (0.0487)	
training:	Epoch: [38][121/204]	Loss 0.0131 (0.0484)	
training:	Epoch: [38][122/204]	Loss 0.0105 (0.0481)	
training:	Epoch: [38][123/204]	Loss 0.1539 (0.0490)	
training:	Epoch: [38][124/204]	Loss 0.0137 (0.0487)	
training:	Epoch: [38][125/204]	Loss 0.1488 (0.0495)	
training:	Epoch: [38][126/204]	Loss 0.0117 (0.0492)	
training:	Epoch: [38][127/204]	Loss 0.0108 (0.0489)	
training:	Epoch: [38][128/204]	Loss 0.0116 (0.0486)	
training:	Epoch: [38][129/204]	Loss 0.0456 (0.0486)	
training:	Epoch: [38][130/204]	Loss 0.0095 (0.0483)	
training:	Epoch: [38][131/204]	Loss 0.4261 (0.0512)	
training:	Epoch: [38][132/204]	Loss 0.0102 (0.0508)	
training:	Epoch: [38][133/204]	Loss 0.0154 (0.0506)	
training:	Epoch: [38][134/204]	Loss 0.0092 (0.0503)	
training:	Epoch: [38][135/204]	Loss 0.0110 (0.0500)	
training:	Epoch: [38][136/204]	Loss 0.0100 (0.0497)	
training:	Epoch: [38][137/204]	Loss 0.1598 (0.0505)	
training:	Epoch: [38][138/204]	Loss 0.0101 (0.0502)	
training:	Epoch: [38][139/204]	Loss 0.1475 (0.0509)	
training:	Epoch: [38][140/204]	Loss 0.1504 (0.0516)	
training:	Epoch: [38][141/204]	Loss 0.0118 (0.0513)	
training:	Epoch: [38][142/204]	Loss 0.0099 (0.0510)	
training:	Epoch: [38][143/204]	Loss 0.0504 (0.0510)	
training:	Epoch: [38][144/204]	Loss 0.0101 (0.0507)	
training:	Epoch: [38][145/204]	Loss 0.1361 (0.0513)	
training:	Epoch: [38][146/204]	Loss 0.0135 (0.0511)	
training:	Epoch: [38][147/204]	Loss 0.0096 (0.0508)	
training:	Epoch: [38][148/204]	Loss 0.0101 (0.0505)	
training:	Epoch: [38][149/204]	Loss 0.1590 (0.0512)	
training:	Epoch: [38][150/204]	Loss 0.1616 (0.0520)	
training:	Epoch: [38][151/204]	Loss 0.0142 (0.0517)	
training:	Epoch: [38][152/204]	Loss 0.0102 (0.0515)	
training:	Epoch: [38][153/204]	Loss 0.0109 (0.0512)	
training:	Epoch: [38][154/204]	Loss 0.0121 (0.0509)	
training:	Epoch: [38][155/204]	Loss 0.1525 (0.0516)	
training:	Epoch: [38][156/204]	Loss 0.0390 (0.0515)	
training:	Epoch: [38][157/204]	Loss 0.0093 (0.0512)	
training:	Epoch: [38][158/204]	Loss 0.0120 (0.0510)	
training:	Epoch: [38][159/204]	Loss 0.0095 (0.0507)	
training:	Epoch: [38][160/204]	Loss 0.0103 (0.0505)	
training:	Epoch: [38][161/204]	Loss 0.0103 (0.0502)	
training:	Epoch: [38][162/204]	Loss 0.0140 (0.0500)	
training:	Epoch: [38][163/204]	Loss 0.0227 (0.0498)	
training:	Epoch: [38][164/204]	Loss 0.0092 (0.0496)	
training:	Epoch: [38][165/204]	Loss 0.1587 (0.0503)	
training:	Epoch: [38][166/204]	Loss 0.0123 (0.0500)	
training:	Epoch: [38][167/204]	Loss 0.1509 (0.0506)	
training:	Epoch: [38][168/204]	Loss 0.3455 (0.0524)	
training:	Epoch: [38][169/204]	Loss 0.0153 (0.0522)	
training:	Epoch: [38][170/204]	Loss 0.0099 (0.0519)	
training:	Epoch: [38][171/204]	Loss 0.0106 (0.0517)	
training:	Epoch: [38][172/204]	Loss 0.1541 (0.0523)	
training:	Epoch: [38][173/204]	Loss 0.1566 (0.0529)	
training:	Epoch: [38][174/204]	Loss 0.0104 (0.0526)	
training:	Epoch: [38][175/204]	Loss 0.0115 (0.0524)	
training:	Epoch: [38][176/204]	Loss 0.0103 (0.0522)	
training:	Epoch: [38][177/204]	Loss 0.0097 (0.0519)	
training:	Epoch: [38][178/204]	Loss 0.0094 (0.0517)	
training:	Epoch: [38][179/204]	Loss 0.0113 (0.0515)	
training:	Epoch: [38][180/204]	Loss 0.0107 (0.0512)	
training:	Epoch: [38][181/204]	Loss 0.0115 (0.0510)	
training:	Epoch: [38][182/204]	Loss 0.0110 (0.0508)	
training:	Epoch: [38][183/204]	Loss 0.0126 (0.0506)	
training:	Epoch: [38][184/204]	Loss 0.0106 (0.0504)	
training:	Epoch: [38][185/204]	Loss 0.1577 (0.0509)	
training:	Epoch: [38][186/204]	Loss 0.0820 (0.0511)	
training:	Epoch: [38][187/204]	Loss 0.0105 (0.0509)	
training:	Epoch: [38][188/204]	Loss 0.1296 (0.0513)	
training:	Epoch: [38][189/204]	Loss 0.0098 (0.0511)	
training:	Epoch: [38][190/204]	Loss 0.0119 (0.0509)	
training:	Epoch: [38][191/204]	Loss 0.0835 (0.0511)	
training:	Epoch: [38][192/204]	Loss 0.2633 (0.0522)	
training:	Epoch: [38][193/204]	Loss 0.0101 (0.0519)	
training:	Epoch: [38][194/204]	Loss 0.0104 (0.0517)	
training:	Epoch: [38][195/204]	Loss 0.0101 (0.0515)	
training:	Epoch: [38][196/204]	Loss 0.0200 (0.0514)	
training:	Epoch: [38][197/204]	Loss 0.0101 (0.0511)	
training:	Epoch: [38][198/204]	Loss 0.0114 (0.0509)	
training:	Epoch: [38][199/204]	Loss 0.0114 (0.0507)	
training:	Epoch: [38][200/204]	Loss 0.0129 (0.0506)	
training:	Epoch: [38][201/204]	Loss 0.0127 (0.0504)	
training:	Epoch: [38][202/204]	Loss 0.0138 (0.0502)	
training:	Epoch: [38][203/204]	Loss 0.0130 (0.0500)	
training:	Epoch: [38][204/204]	Loss 0.0152 (0.0498)	
Training:	 Loss: 0.0498

Training:	 ACC: 0.9915 0.9914 0.9906 0.9923
Validation:	 ACC: 0.7870 0.7871 0.7881 0.7859
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.8864
Pretraining:	Epoch 39/500
----------
training:	Epoch: [39][1/204]	Loss 0.0118 (0.0118)	
training:	Epoch: [39][2/204]	Loss 0.1511 (0.0814)	
training:	Epoch: [39][3/204]	Loss 0.0102 (0.0577)	
training:	Epoch: [39][4/204]	Loss 0.0121 (0.0463)	
training:	Epoch: [39][5/204]	Loss 0.0108 (0.0392)	
training:	Epoch: [39][6/204]	Loss 0.0104 (0.0344)	
training:	Epoch: [39][7/204]	Loss 0.1565 (0.0518)	
training:	Epoch: [39][8/204]	Loss 0.0123 (0.0469)	
training:	Epoch: [39][9/204]	Loss 0.1441 (0.0577)	
training:	Epoch: [39][10/204]	Loss 0.0093 (0.0529)	
training:	Epoch: [39][11/204]	Loss 0.1526 (0.0619)	
training:	Epoch: [39][12/204]	Loss 0.0118 (0.0577)	
training:	Epoch: [39][13/204]	Loss 0.0097 (0.0540)	
training:	Epoch: [39][14/204]	Loss 0.0103 (0.0509)	
training:	Epoch: [39][15/204]	Loss 0.0129 (0.0484)	
training:	Epoch: [39][16/204]	Loss 0.0098 (0.0460)	
training:	Epoch: [39][17/204]	Loss 0.0101 (0.0439)	
training:	Epoch: [39][18/204]	Loss 0.0104 (0.0420)	
training:	Epoch: [39][19/204]	Loss 0.1561 (0.0480)	
training:	Epoch: [39][20/204]	Loss 0.0101 (0.0461)	
training:	Epoch: [39][21/204]	Loss 0.0109 (0.0444)	
training:	Epoch: [39][22/204]	Loss 0.0150 (0.0431)	
training:	Epoch: [39][23/204]	Loss 0.0121 (0.0418)	
training:	Epoch: [39][24/204]	Loss 0.1531 (0.0464)	
training:	Epoch: [39][25/204]	Loss 0.0115 (0.0450)	
training:	Epoch: [39][26/204]	Loss 0.0093 (0.0436)	
training:	Epoch: [39][27/204]	Loss 0.0092 (0.0424)	
training:	Epoch: [39][28/204]	Loss 0.1521 (0.0463)	
training:	Epoch: [39][29/204]	Loss 0.0108 (0.0450)	
training:	Epoch: [39][30/204]	Loss 0.0111 (0.0439)	
training:	Epoch: [39][31/204]	Loss 0.0097 (0.0428)	
training:	Epoch: [39][32/204]	Loss 0.1554 (0.0463)	
training:	Epoch: [39][33/204]	Loss 0.0131 (0.0453)	
training:	Epoch: [39][34/204]	Loss 0.0097 (0.0443)	
training:	Epoch: [39][35/204]	Loss 0.0105 (0.0433)	
training:	Epoch: [39][36/204]	Loss 0.1521 (0.0463)	
training:	Epoch: [39][37/204]	Loss 0.0104 (0.0454)	
training:	Epoch: [39][38/204]	Loss 0.1620 (0.0484)	
training:	Epoch: [39][39/204]	Loss 0.0098 (0.0474)	
training:	Epoch: [39][40/204]	Loss 0.0090 (0.0465)	
training:	Epoch: [39][41/204]	Loss 0.0105 (0.0456)	
training:	Epoch: [39][42/204]	Loss 0.0096 (0.0447)	
training:	Epoch: [39][43/204]	Loss 0.0101 (0.0439)	
training:	Epoch: [39][44/204]	Loss 0.2256 (0.0481)	
training:	Epoch: [39][45/204]	Loss 0.0097 (0.0472)	
training:	Epoch: [39][46/204]	Loss 0.0096 (0.0464)	
training:	Epoch: [39][47/204]	Loss 0.1326 (0.0482)	
training:	Epoch: [39][48/204]	Loss 0.0117 (0.0475)	
training:	Epoch: [39][49/204]	Loss 0.0094 (0.0467)	
training:	Epoch: [39][50/204]	Loss 0.0102 (0.0460)	
training:	Epoch: [39][51/204]	Loss 0.0108 (0.0453)	
training:	Epoch: [39][52/204]	Loss 0.0093 (0.0446)	
training:	Epoch: [39][53/204]	Loss 0.0108 (0.0439)	
training:	Epoch: [39][54/204]	Loss 0.1153 (0.0453)	
training:	Epoch: [39][55/204]	Loss 0.1556 (0.0473)	
training:	Epoch: [39][56/204]	Loss 0.0101 (0.0466)	
training:	Epoch: [39][57/204]	Loss 0.0097 (0.0460)	
training:	Epoch: [39][58/204]	Loss 0.0356 (0.0458)	
training:	Epoch: [39][59/204]	Loss 0.0103 (0.0452)	
training:	Epoch: [39][60/204]	Loss 0.0091 (0.0446)	
training:	Epoch: [39][61/204]	Loss 0.0092 (0.0440)	
training:	Epoch: [39][62/204]	Loss 0.1541 (0.0458)	
training:	Epoch: [39][63/204]	Loss 0.0091 (0.0452)	
training:	Epoch: [39][64/204]	Loss 0.0099 (0.0446)	
training:	Epoch: [39][65/204]	Loss 0.1469 (0.0462)	
training:	Epoch: [39][66/204]	Loss 0.0103 (0.0457)	
training:	Epoch: [39][67/204]	Loss 0.1491 (0.0472)	
training:	Epoch: [39][68/204]	Loss 0.0094 (0.0467)	
training:	Epoch: [39][69/204]	Loss 0.0096 (0.0461)	
training:	Epoch: [39][70/204]	Loss 0.1589 (0.0477)	
training:	Epoch: [39][71/204]	Loss 0.1540 (0.0492)	
training:	Epoch: [39][72/204]	Loss 0.0091 (0.0487)	
training:	Epoch: [39][73/204]	Loss 0.0118 (0.0482)	
training:	Epoch: [39][74/204]	Loss 0.0102 (0.0477)	
training:	Epoch: [39][75/204]	Loss 0.0094 (0.0471)	
training:	Epoch: [39][76/204]	Loss 0.0097 (0.0467)	
training:	Epoch: [39][77/204]	Loss 0.0090 (0.0462)	
training:	Epoch: [39][78/204]	Loss 0.1253 (0.0472)	
training:	Epoch: [39][79/204]	Loss 0.0087 (0.0467)	
training:	Epoch: [39][80/204]	Loss 0.1580 (0.0481)	
training:	Epoch: [39][81/204]	Loss 0.1543 (0.0494)	
training:	Epoch: [39][82/204]	Loss 0.0099 (0.0489)	
training:	Epoch: [39][83/204]	Loss 0.0098 (0.0484)	
training:	Epoch: [39][84/204]	Loss 0.0117 (0.0480)	
training:	Epoch: [39][85/204]	Loss 0.0096 (0.0475)	
training:	Epoch: [39][86/204]	Loss 0.0101 (0.0471)	
training:	Epoch: [39][87/204]	Loss 0.1477 (0.0483)	
training:	Epoch: [39][88/204]	Loss 0.0181 (0.0479)	
training:	Epoch: [39][89/204]	Loss 0.0093 (0.0475)	
training:	Epoch: [39][90/204]	Loss 0.0094 (0.0471)	
training:	Epoch: [39][91/204]	Loss 0.1524 (0.0482)	
training:	Epoch: [39][92/204]	Loss 0.0091 (0.0478)	
training:	Epoch: [39][93/204]	Loss 0.0101 (0.0474)	
training:	Epoch: [39][94/204]	Loss 0.2671 (0.0497)	
training:	Epoch: [39][95/204]	Loss 0.0103 (0.0493)	
training:	Epoch: [39][96/204]	Loss 0.0115 (0.0489)	
training:	Epoch: [39][97/204]	Loss 0.0113 (0.0485)	
training:	Epoch: [39][98/204]	Loss 0.0127 (0.0482)	
training:	Epoch: [39][99/204]	Loss 0.0104 (0.0478)	
training:	Epoch: [39][100/204]	Loss 0.0094 (0.0474)	
training:	Epoch: [39][101/204]	Loss 0.1472 (0.0484)	
training:	Epoch: [39][102/204]	Loss 0.1170 (0.0491)	
training:	Epoch: [39][103/204]	Loss 0.1614 (0.0502)	
training:	Epoch: [39][104/204]	Loss 0.1461 (0.0511)	
training:	Epoch: [39][105/204]	Loss 0.0102 (0.0507)	
training:	Epoch: [39][106/204]	Loss 0.0105 (0.0503)	
training:	Epoch: [39][107/204]	Loss 0.0089 (0.0499)	
training:	Epoch: [39][108/204]	Loss 0.0131 (0.0496)	
training:	Epoch: [39][109/204]	Loss 0.0108 (0.0492)	
training:	Epoch: [39][110/204]	Loss 0.1506 (0.0501)	
training:	Epoch: [39][111/204]	Loss 0.0147 (0.0498)	
training:	Epoch: [39][112/204]	Loss 0.0105 (0.0495)	
training:	Epoch: [39][113/204]	Loss 0.0106 (0.0491)	
training:	Epoch: [39][114/204]	Loss 0.0128 (0.0488)	
training:	Epoch: [39][115/204]	Loss 0.1633 (0.0498)	
training:	Epoch: [39][116/204]	Loss 0.0131 (0.0495)	
training:	Epoch: [39][117/204]	Loss 0.0099 (0.0492)	
training:	Epoch: [39][118/204]	Loss 0.0113 (0.0488)	
training:	Epoch: [39][119/204]	Loss 0.0128 (0.0485)	
training:	Epoch: [39][120/204]	Loss 0.0095 (0.0482)	
training:	Epoch: [39][121/204]	Loss 0.0148 (0.0479)	
training:	Epoch: [39][122/204]	Loss 0.0090 (0.0476)	
training:	Epoch: [39][123/204]	Loss 0.1360 (0.0483)	
training:	Epoch: [39][124/204]	Loss 0.0115 (0.0480)	
training:	Epoch: [39][125/204]	Loss 0.0128 (0.0478)	
training:	Epoch: [39][126/204]	Loss 0.0157 (0.0475)	
training:	Epoch: [39][127/204]	Loss 0.0084 (0.0472)	
training:	Epoch: [39][128/204]	Loss 0.0096 (0.0469)	
training:	Epoch: [39][129/204]	Loss 0.0100 (0.0466)	
training:	Epoch: [39][130/204]	Loss 0.0111 (0.0463)	
training:	Epoch: [39][131/204]	Loss 0.0106 (0.0461)	
training:	Epoch: [39][132/204]	Loss 0.0092 (0.0458)	
training:	Epoch: [39][133/204]	Loss 0.0120 (0.0455)	
training:	Epoch: [39][134/204]	Loss 0.0094 (0.0453)	
training:	Epoch: [39][135/204]	Loss 0.0127 (0.0450)	
training:	Epoch: [39][136/204]	Loss 0.0629 (0.0452)	
training:	Epoch: [39][137/204]	Loss 0.0088 (0.0449)	
training:	Epoch: [39][138/204]	Loss 0.0092 (0.0446)	
training:	Epoch: [39][139/204]	Loss 0.0139 (0.0444)	
training:	Epoch: [39][140/204]	Loss 0.0097 (0.0442)	
training:	Epoch: [39][141/204]	Loss 0.0092 (0.0439)	
training:	Epoch: [39][142/204]	Loss 0.0094 (0.0437)	
training:	Epoch: [39][143/204]	Loss 0.0196 (0.0435)	
training:	Epoch: [39][144/204]	Loss 0.1336 (0.0441)	
training:	Epoch: [39][145/204]	Loss 0.0105 (0.0439)	
training:	Epoch: [39][146/204]	Loss 0.0128 (0.0437)	
training:	Epoch: [39][147/204]	Loss 0.0103 (0.0435)	
training:	Epoch: [39][148/204]	Loss 0.0123 (0.0432)	
training:	Epoch: [39][149/204]	Loss 0.0092 (0.0430)	
training:	Epoch: [39][150/204]	Loss 0.0158 (0.0428)	
training:	Epoch: [39][151/204]	Loss 0.1596 (0.0436)	
training:	Epoch: [39][152/204]	Loss 0.0093 (0.0434)	
training:	Epoch: [39][153/204]	Loss 0.0122 (0.0432)	
training:	Epoch: [39][154/204]	Loss 0.0130 (0.0430)	
training:	Epoch: [39][155/204]	Loss 0.0096 (0.0428)	
training:	Epoch: [39][156/204]	Loss 0.0465 (0.0428)	
training:	Epoch: [39][157/204]	Loss 0.0094 (0.0426)	
training:	Epoch: [39][158/204]	Loss 0.1556 (0.0433)	
training:	Epoch: [39][159/204]	Loss 0.0092 (0.0431)	
training:	Epoch: [39][160/204]	Loss 0.0095 (0.0429)	
training:	Epoch: [39][161/204]	Loss 0.1599 (0.0436)	
training:	Epoch: [39][162/204]	Loss 0.0102 (0.0434)	
training:	Epoch: [39][163/204]	Loss 0.0089 (0.0432)	
training:	Epoch: [39][164/204]	Loss 0.2989 (0.0447)	
training:	Epoch: [39][165/204]	Loss 0.0084 (0.0445)	
training:	Epoch: [39][166/204]	Loss 0.4324 (0.0469)	
training:	Epoch: [39][167/204]	Loss 0.0093 (0.0466)	
training:	Epoch: [39][168/204]	Loss 0.1365 (0.0472)	
training:	Epoch: [39][169/204]	Loss 0.0131 (0.0470)	
training:	Epoch: [39][170/204]	Loss 0.0104 (0.0467)	
training:	Epoch: [39][171/204]	Loss 0.0089 (0.0465)	
training:	Epoch: [39][172/204]	Loss 0.0105 (0.0463)	
training:	Epoch: [39][173/204]	Loss 0.1392 (0.0469)	
training:	Epoch: [39][174/204]	Loss 0.0094 (0.0466)	
training:	Epoch: [39][175/204]	Loss 0.0128 (0.0464)	
training:	Epoch: [39][176/204]	Loss 0.0104 (0.0462)	
training:	Epoch: [39][177/204]	Loss 0.0098 (0.0460)	
training:	Epoch: [39][178/204]	Loss 0.0082 (0.0458)	
training:	Epoch: [39][179/204]	Loss 0.2706 (0.0471)	
training:	Epoch: [39][180/204]	Loss 0.0893 (0.0473)	
training:	Epoch: [39][181/204]	Loss 0.1306 (0.0478)	
training:	Epoch: [39][182/204]	Loss 0.0096 (0.0476)	
training:	Epoch: [39][183/204]	Loss 0.0114 (0.0474)	
training:	Epoch: [39][184/204]	Loss 0.0143 (0.0472)	
training:	Epoch: [39][185/204]	Loss 0.0090 (0.0470)	
training:	Epoch: [39][186/204]	Loss 0.0155 (0.0468)	
training:	Epoch: [39][187/204]	Loss 0.0091 (0.0466)	
training:	Epoch: [39][188/204]	Loss 0.1650 (0.0472)	
training:	Epoch: [39][189/204]	Loss 0.0092 (0.0470)	
training:	Epoch: [39][190/204]	Loss 0.0967 (0.0473)	
training:	Epoch: [39][191/204]	Loss 0.1527 (0.0479)	
training:	Epoch: [39][192/204]	Loss 0.0098 (0.0477)	
training:	Epoch: [39][193/204]	Loss 0.0097 (0.0475)	
training:	Epoch: [39][194/204]	Loss 0.0146 (0.0473)	
training:	Epoch: [39][195/204]	Loss 0.0103 (0.0471)	
training:	Epoch: [39][196/204]	Loss 0.0093 (0.0469)	
training:	Epoch: [39][197/204]	Loss 0.0110 (0.0467)	
training:	Epoch: [39][198/204]	Loss 0.1244 (0.0471)	
training:	Epoch: [39][199/204]	Loss 0.0092 (0.0469)	
training:	Epoch: [39][200/204]	Loss 0.1576 (0.0475)	
training:	Epoch: [39][201/204]	Loss 0.1555 (0.0480)	
training:	Epoch: [39][202/204]	Loss 0.1620 (0.0486)	
training:	Epoch: [39][203/204]	Loss 0.0140 (0.0484)	
training:	Epoch: [39][204/204]	Loss 0.0106 (0.0482)	
Training:	 Loss: 0.0481

Training:	 ACC: 0.9919 0.9919 0.9915 0.9923
Validation:	 ACC: 0.7841 0.7854 0.8137 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9012
Pretraining:	Epoch 40/500
----------
training:	Epoch: [40][1/204]	Loss 0.0176 (0.0176)	
training:	Epoch: [40][2/204]	Loss 0.0099 (0.0138)	
training:	Epoch: [40][3/204]	Loss 0.0100 (0.0125)	
training:	Epoch: [40][4/204]	Loss 0.0094 (0.0117)	
training:	Epoch: [40][5/204]	Loss 0.0097 (0.0113)	
training:	Epoch: [40][6/204]	Loss 0.0099 (0.0111)	
training:	Epoch: [40][7/204]	Loss 0.0109 (0.0111)	
training:	Epoch: [40][8/204]	Loss 0.0093 (0.0108)	
training:	Epoch: [40][9/204]	Loss 0.0100 (0.0107)	
training:	Epoch: [40][10/204]	Loss 0.0102 (0.0107)	
training:	Epoch: [40][11/204]	Loss 0.0105 (0.0107)	
training:	Epoch: [40][12/204]	Loss 0.0105 (0.0107)	
training:	Epoch: [40][13/204]	Loss 0.0091 (0.0105)	
training:	Epoch: [40][14/204]	Loss 0.0090 (0.0104)	
training:	Epoch: [40][15/204]	Loss 0.0101 (0.0104)	
training:	Epoch: [40][16/204]	Loss 0.0090 (0.0103)	
training:	Epoch: [40][17/204]	Loss 0.2988 (0.0273)	
training:	Epoch: [40][18/204]	Loss 0.3097 (0.0430)	
training:	Epoch: [40][19/204]	Loss 0.0093 (0.0412)	
training:	Epoch: [40][20/204]	Loss 0.0106 (0.0397)	
training:	Epoch: [40][21/204]	Loss 0.0125 (0.0384)	
training:	Epoch: [40][22/204]	Loss 0.1567 (0.0438)	
training:	Epoch: [40][23/204]	Loss 0.0111 (0.0423)	
training:	Epoch: [40][24/204]	Loss 0.0111 (0.0410)	
training:	Epoch: [40][25/204]	Loss 0.0115 (0.0399)	
training:	Epoch: [40][26/204]	Loss 0.1524 (0.0442)	
training:	Epoch: [40][27/204]	Loss 0.0103 (0.0429)	
training:	Epoch: [40][28/204]	Loss 0.0091 (0.0417)	
training:	Epoch: [40][29/204]	Loss 0.1607 (0.0458)	
training:	Epoch: [40][30/204]	Loss 0.1469 (0.0492)	
training:	Epoch: [40][31/204]	Loss 0.0093 (0.0479)	
training:	Epoch: [40][32/204]	Loss 0.0127 (0.0468)	
training:	Epoch: [40][33/204]	Loss 0.1336 (0.0494)	
training:	Epoch: [40][34/204]	Loss 0.0109 (0.0483)	
training:	Epoch: [40][35/204]	Loss 0.1498 (0.0512)	
training:	Epoch: [40][36/204]	Loss 0.0091 (0.0500)	
training:	Epoch: [40][37/204]	Loss 0.0092 (0.0489)	
training:	Epoch: [40][38/204]	Loss 0.0111 (0.0479)	
training:	Epoch: [40][39/204]	Loss 0.1529 (0.0506)	
training:	Epoch: [40][40/204]	Loss 0.2832 (0.0564)	
training:	Epoch: [40][41/204]	Loss 0.0103 (0.0553)	
training:	Epoch: [40][42/204]	Loss 0.0089 (0.0542)	
training:	Epoch: [40][43/204]	Loss 0.0096 (0.0532)	
training:	Epoch: [40][44/204]	Loss 0.0140 (0.0523)	
training:	Epoch: [40][45/204]	Loss 0.1433 (0.0543)	
training:	Epoch: [40][46/204]	Loss 0.0111 (0.0534)	
training:	Epoch: [40][47/204]	Loss 0.0105 (0.0525)	
training:	Epoch: [40][48/204]	Loss 0.0168 (0.0517)	
training:	Epoch: [40][49/204]	Loss 0.0105 (0.0509)	
training:	Epoch: [40][50/204]	Loss 0.0103 (0.0501)	
training:	Epoch: [40][51/204]	Loss 0.0091 (0.0493)	
training:	Epoch: [40][52/204]	Loss 0.0115 (0.0485)	
training:	Epoch: [40][53/204]	Loss 0.0096 (0.0478)	
training:	Epoch: [40][54/204]	Loss 0.0095 (0.0471)	
training:	Epoch: [40][55/204]	Loss 0.1524 (0.0490)	
training:	Epoch: [40][56/204]	Loss 0.0105 (0.0483)	
training:	Epoch: [40][57/204]	Loss 0.0093 (0.0476)	
training:	Epoch: [40][58/204]	Loss 0.0100 (0.0470)	
training:	Epoch: [40][59/204]	Loss 0.0096 (0.0463)	
training:	Epoch: [40][60/204]	Loss 0.3825 (0.0520)	
training:	Epoch: [40][61/204]	Loss 0.0099 (0.0513)	
training:	Epoch: [40][62/204]	Loss 0.0097 (0.0506)	
training:	Epoch: [40][63/204]	Loss 0.0114 (0.0500)	
training:	Epoch: [40][64/204]	Loss 0.0091 (0.0493)	
training:	Epoch: [40][65/204]	Loss 0.1486 (0.0509)	
training:	Epoch: [40][66/204]	Loss 0.0126 (0.0503)	
training:	Epoch: [40][67/204]	Loss 0.0121 (0.0497)	
training:	Epoch: [40][68/204]	Loss 0.1517 (0.0512)	
training:	Epoch: [40][69/204]	Loss 0.0098 (0.0506)	
training:	Epoch: [40][70/204]	Loss 0.0103 (0.0500)	
training:	Epoch: [40][71/204]	Loss 0.0092 (0.0495)	
training:	Epoch: [40][72/204]	Loss 0.1558 (0.0509)	
training:	Epoch: [40][73/204]	Loss 0.1626 (0.0525)	
training:	Epoch: [40][74/204]	Loss 0.0111 (0.0519)	
training:	Epoch: [40][75/204]	Loss 0.0102 (0.0514)	
training:	Epoch: [40][76/204]	Loss 0.0098 (0.0508)	
training:	Epoch: [40][77/204]	Loss 0.0100 (0.0503)	
training:	Epoch: [40][78/204]	Loss 0.0114 (0.0498)	
training:	Epoch: [40][79/204]	Loss 0.0109 (0.0493)	
training:	Epoch: [40][80/204]	Loss 0.0103 (0.0488)	
training:	Epoch: [40][81/204]	Loss 0.0105 (0.0483)	
training:	Epoch: [40][82/204]	Loss 0.0099 (0.0479)	
training:	Epoch: [40][83/204]	Loss 0.0103 (0.0474)	
training:	Epoch: [40][84/204]	Loss 0.0095 (0.0470)	
training:	Epoch: [40][85/204]	Loss 0.0105 (0.0465)	
training:	Epoch: [40][86/204]	Loss 0.1274 (0.0475)	
training:	Epoch: [40][87/204]	Loss 0.0098 (0.0470)	
training:	Epoch: [40][88/204]	Loss 0.0107 (0.0466)	
training:	Epoch: [40][89/204]	Loss 0.0100 (0.0462)	
training:	Epoch: [40][90/204]	Loss 0.0094 (0.0458)	
training:	Epoch: [40][91/204]	Loss 0.0100 (0.0454)	
training:	Epoch: [40][92/204]	Loss 0.0090 (0.0450)	
training:	Epoch: [40][93/204]	Loss 0.1275 (0.0459)	
training:	Epoch: [40][94/204]	Loss 0.0102 (0.0455)	
training:	Epoch: [40][95/204]	Loss 0.0102 (0.0451)	
training:	Epoch: [40][96/204]	Loss 0.0097 (0.0448)	
training:	Epoch: [40][97/204]	Loss 0.0109 (0.0444)	
training:	Epoch: [40][98/204]	Loss 0.0111 (0.0441)	
training:	Epoch: [40][99/204]	Loss 0.0095 (0.0437)	
training:	Epoch: [40][100/204]	Loss 0.0143 (0.0434)	
training:	Epoch: [40][101/204]	Loss 0.0095 (0.0431)	
training:	Epoch: [40][102/204]	Loss 0.0104 (0.0428)	
training:	Epoch: [40][103/204]	Loss 0.1697 (0.0440)	
training:	Epoch: [40][104/204]	Loss 0.1531 (0.0451)	
training:	Epoch: [40][105/204]	Loss 0.4319 (0.0487)	
training:	Epoch: [40][106/204]	Loss 0.0113 (0.0484)	
training:	Epoch: [40][107/204]	Loss 0.0088 (0.0480)	
training:	Epoch: [40][108/204]	Loss 0.1465 (0.0489)	
training:	Epoch: [40][109/204]	Loss 0.2506 (0.0508)	
training:	Epoch: [40][110/204]	Loss 0.0086 (0.0504)	
training:	Epoch: [40][111/204]	Loss 0.0092 (0.0500)	
training:	Epoch: [40][112/204]	Loss 0.0095 (0.0497)	
training:	Epoch: [40][113/204]	Loss 0.0114 (0.0493)	
training:	Epoch: [40][114/204]	Loss 0.0099 (0.0490)	
training:	Epoch: [40][115/204]	Loss 0.0111 (0.0487)	
training:	Epoch: [40][116/204]	Loss 0.0126 (0.0483)	
training:	Epoch: [40][117/204]	Loss 0.0096 (0.0480)	
training:	Epoch: [40][118/204]	Loss 0.0162 (0.0477)	
training:	Epoch: [40][119/204]	Loss 0.0106 (0.0474)	
training:	Epoch: [40][120/204]	Loss 0.0105 (0.0471)	
training:	Epoch: [40][121/204]	Loss 0.0103 (0.0468)	
training:	Epoch: [40][122/204]	Loss 0.0114 (0.0465)	
training:	Epoch: [40][123/204]	Loss 0.1104 (0.0470)	
training:	Epoch: [40][124/204]	Loss 0.1542 (0.0479)	
training:	Epoch: [40][125/204]	Loss 0.0122 (0.0476)	
training:	Epoch: [40][126/204]	Loss 0.1218 (0.0482)	
training:	Epoch: [40][127/204]	Loss 0.0090 (0.0479)	
training:	Epoch: [40][128/204]	Loss 0.0101 (0.0476)	
training:	Epoch: [40][129/204]	Loss 0.1641 (0.0485)	
training:	Epoch: [40][130/204]	Loss 0.0762 (0.0487)	
training:	Epoch: [40][131/204]	Loss 0.0098 (0.0484)	
training:	Epoch: [40][132/204]	Loss 0.1207 (0.0490)	
training:	Epoch: [40][133/204]	Loss 0.0130 (0.0487)	
training:	Epoch: [40][134/204]	Loss 0.0114 (0.0484)	
training:	Epoch: [40][135/204]	Loss 0.1547 (0.0492)	
training:	Epoch: [40][136/204]	Loss 0.0102 (0.0489)	
training:	Epoch: [40][137/204]	Loss 0.0105 (0.0486)	
training:	Epoch: [40][138/204]	Loss 0.0115 (0.0484)	
training:	Epoch: [40][139/204]	Loss 0.1539 (0.0491)	
training:	Epoch: [40][140/204]	Loss 0.0158 (0.0489)	
training:	Epoch: [40][141/204]	Loss 0.0959 (0.0492)	
training:	Epoch: [40][142/204]	Loss 0.0142 (0.0490)	
training:	Epoch: [40][143/204]	Loss 0.0169 (0.0488)	
training:	Epoch: [40][144/204]	Loss 0.0119 (0.0485)	
training:	Epoch: [40][145/204]	Loss 0.1324 (0.0491)	
training:	Epoch: [40][146/204]	Loss 0.0139 (0.0488)	
training:	Epoch: [40][147/204]	Loss 0.0149 (0.0486)	
training:	Epoch: [40][148/204]	Loss 0.0121 (0.0484)	
training:	Epoch: [40][149/204]	Loss 0.0129 (0.0481)	
training:	Epoch: [40][150/204]	Loss 0.0088 (0.0479)	
training:	Epoch: [40][151/204]	Loss 0.0088 (0.0476)	
training:	Epoch: [40][152/204]	Loss 0.0087 (0.0474)	
training:	Epoch: [40][153/204]	Loss 0.0095 (0.0471)	
training:	Epoch: [40][154/204]	Loss 0.0106 (0.0469)	
training:	Epoch: [40][155/204]	Loss 0.0114 (0.0466)	
training:	Epoch: [40][156/204]	Loss 0.0118 (0.0464)	
training:	Epoch: [40][157/204]	Loss 0.0108 (0.0462)	
training:	Epoch: [40][158/204]	Loss 0.0237 (0.0460)	
training:	Epoch: [40][159/204]	Loss 0.0092 (0.0458)	
training:	Epoch: [40][160/204]	Loss 0.0118 (0.0456)	
training:	Epoch: [40][161/204]	Loss 0.0095 (0.0454)	
training:	Epoch: [40][162/204]	Loss 0.0095 (0.0452)	
training:	Epoch: [40][163/204]	Loss 0.0099 (0.0449)	
training:	Epoch: [40][164/204]	Loss 0.0108 (0.0447)	
training:	Epoch: [40][165/204]	Loss 0.0114 (0.0445)	
training:	Epoch: [40][166/204]	Loss 0.0628 (0.0446)	
training:	Epoch: [40][167/204]	Loss 0.3004 (0.0462)	
training:	Epoch: [40][168/204]	Loss 0.0087 (0.0459)	
training:	Epoch: [40][169/204]	Loss 0.0096 (0.0457)	
training:	Epoch: [40][170/204]	Loss 0.0098 (0.0455)	
training:	Epoch: [40][171/204]	Loss 0.0102 (0.0453)	
training:	Epoch: [40][172/204]	Loss 0.1566 (0.0460)	
training:	Epoch: [40][173/204]	Loss 0.0103 (0.0458)	
training:	Epoch: [40][174/204]	Loss 0.0092 (0.0455)	
training:	Epoch: [40][175/204]	Loss 0.0093 (0.0453)	
training:	Epoch: [40][176/204]	Loss 0.0130 (0.0452)	
training:	Epoch: [40][177/204]	Loss 0.0243 (0.0450)	
training:	Epoch: [40][178/204]	Loss 0.1677 (0.0457)	
training:	Epoch: [40][179/204]	Loss 0.0117 (0.0455)	
training:	Epoch: [40][180/204]	Loss 0.0093 (0.0453)	
training:	Epoch: [40][181/204]	Loss 0.0102 (0.0451)	
training:	Epoch: [40][182/204]	Loss 0.0102 (0.0449)	
training:	Epoch: [40][183/204]	Loss 0.0099 (0.0448)	
training:	Epoch: [40][184/204]	Loss 0.0133 (0.0446)	
training:	Epoch: [40][185/204]	Loss 0.0101 (0.0444)	
training:	Epoch: [40][186/204]	Loss 0.0099 (0.0442)	
training:	Epoch: [40][187/204]	Loss 0.1522 (0.0448)	
training:	Epoch: [40][188/204]	Loss 0.0087 (0.0446)	
training:	Epoch: [40][189/204]	Loss 0.1584 (0.0452)	
training:	Epoch: [40][190/204]	Loss 0.0080 (0.0450)	
training:	Epoch: [40][191/204]	Loss 0.1443 (0.0455)	
training:	Epoch: [40][192/204]	Loss 0.0100 (0.0453)	
training:	Epoch: [40][193/204]	Loss 0.1650 (0.0460)	
training:	Epoch: [40][194/204]	Loss 0.1638 (0.0466)	
training:	Epoch: [40][195/204]	Loss 0.0098 (0.0464)	
training:	Epoch: [40][196/204]	Loss 0.0093 (0.0462)	
training:	Epoch: [40][197/204]	Loss 0.0093 (0.0460)	
training:	Epoch: [40][198/204]	Loss 0.1375 (0.0465)	
training:	Epoch: [40][199/204]	Loss 0.0090 (0.0463)	
training:	Epoch: [40][200/204]	Loss 0.0162 (0.0461)	
training:	Epoch: [40][201/204]	Loss 0.0085 (0.0459)	
training:	Epoch: [40][202/204]	Loss 0.0091 (0.0458)	
training:	Epoch: [40][203/204]	Loss 0.0162 (0.0456)	
training:	Epoch: [40][204/204]	Loss 0.0084 (0.0454)	
Training:	 Loss: 0.0454

Training:	 ACC: 0.9921 0.9920 0.9918 0.9923
Validation:	 ACC: 0.7843 0.7854 0.8086 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9019
Pretraining:	Epoch 41/500
----------
training:	Epoch: [41][1/204]	Loss 0.0093 (0.0093)	
training:	Epoch: [41][2/204]	Loss 0.0096 (0.0094)	
training:	Epoch: [41][3/204]	Loss 0.1513 (0.0567)	
training:	Epoch: [41][4/204]	Loss 0.0096 (0.0449)	
training:	Epoch: [41][5/204]	Loss 0.0091 (0.0378)	
training:	Epoch: [41][6/204]	Loss 0.0091 (0.0330)	
training:	Epoch: [41][7/204]	Loss 0.0091 (0.0296)	
training:	Epoch: [41][8/204]	Loss 0.0096 (0.0271)	
training:	Epoch: [41][9/204]	Loss 0.0097 (0.0252)	
training:	Epoch: [41][10/204]	Loss 0.0089 (0.0235)	
training:	Epoch: [41][11/204]	Loss 0.0095 (0.0223)	
training:	Epoch: [41][12/204]	Loss 0.0098 (0.0212)	
training:	Epoch: [41][13/204]	Loss 0.0091 (0.0203)	
training:	Epoch: [41][14/204]	Loss 0.0094 (0.0195)	
training:	Epoch: [41][15/204]	Loss 0.1519 (0.0283)	
training:	Epoch: [41][16/204]	Loss 0.0097 (0.0272)	
training:	Epoch: [41][17/204]	Loss 0.1227 (0.0328)	
training:	Epoch: [41][18/204]	Loss 0.0086 (0.0314)	
training:	Epoch: [41][19/204]	Loss 0.0085 (0.0302)	
training:	Epoch: [41][20/204]	Loss 0.0114 (0.0293)	
training:	Epoch: [41][21/204]	Loss 0.1480 (0.0349)	
training:	Epoch: [41][22/204]	Loss 0.0100 (0.0338)	
training:	Epoch: [41][23/204]	Loss 0.0091 (0.0327)	
training:	Epoch: [41][24/204]	Loss 0.0101 (0.0318)	
training:	Epoch: [41][25/204]	Loss 0.0086 (0.0309)	
training:	Epoch: [41][26/204]	Loss 0.0114 (0.0301)	
training:	Epoch: [41][27/204]	Loss 0.0082 (0.0293)	
training:	Epoch: [41][28/204]	Loss 0.1346 (0.0331)	
training:	Epoch: [41][29/204]	Loss 0.0086 (0.0322)	
training:	Epoch: [41][30/204]	Loss 0.0091 (0.0315)	
training:	Epoch: [41][31/204]	Loss 0.0098 (0.0308)	
training:	Epoch: [41][32/204]	Loss 0.2960 (0.0390)	
training:	Epoch: [41][33/204]	Loss 0.0101 (0.0382)	
training:	Epoch: [41][34/204]	Loss 0.0091 (0.0373)	
training:	Epoch: [41][35/204]	Loss 0.0090 (0.0365)	
training:	Epoch: [41][36/204]	Loss 0.1373 (0.0393)	
training:	Epoch: [41][37/204]	Loss 0.0160 (0.0387)	
training:	Epoch: [41][38/204]	Loss 0.0087 (0.0379)	
training:	Epoch: [41][39/204]	Loss 0.1594 (0.0410)	
training:	Epoch: [41][40/204]	Loss 0.0091 (0.0402)	
training:	Epoch: [41][41/204]	Loss 0.0082 (0.0394)	
training:	Epoch: [41][42/204]	Loss 0.0093 (0.0387)	
training:	Epoch: [41][43/204]	Loss 0.0085 (0.0380)	
training:	Epoch: [41][44/204]	Loss 0.0088 (0.0373)	
training:	Epoch: [41][45/204]	Loss 0.0085 (0.0367)	
training:	Epoch: [41][46/204]	Loss 0.1523 (0.0392)	
training:	Epoch: [41][47/204]	Loss 0.0089 (0.0386)	
training:	Epoch: [41][48/204]	Loss 0.1569 (0.0410)	
training:	Epoch: [41][49/204]	Loss 0.1566 (0.0434)	
training:	Epoch: [41][50/204]	Loss 0.0102 (0.0427)	
training:	Epoch: [41][51/204]	Loss 0.0084 (0.0421)	
training:	Epoch: [41][52/204]	Loss 0.0092 (0.0414)	
training:	Epoch: [41][53/204]	Loss 0.0112 (0.0409)	
training:	Epoch: [41][54/204]	Loss 0.0100 (0.0403)	
training:	Epoch: [41][55/204]	Loss 0.0099 (0.0397)	
training:	Epoch: [41][56/204]	Loss 0.0097 (0.0392)	
training:	Epoch: [41][57/204]	Loss 0.1528 (0.0412)	
training:	Epoch: [41][58/204]	Loss 0.0090 (0.0406)	
training:	Epoch: [41][59/204]	Loss 0.1707 (0.0428)	
training:	Epoch: [41][60/204]	Loss 0.1147 (0.0440)	
training:	Epoch: [41][61/204]	Loss 0.1504 (0.0458)	
training:	Epoch: [41][62/204]	Loss 0.0092 (0.0452)	
training:	Epoch: [41][63/204]	Loss 0.1531 (0.0469)	
training:	Epoch: [41][64/204]	Loss 0.0096 (0.0463)	
training:	Epoch: [41][65/204]	Loss 0.0107 (0.0458)	
training:	Epoch: [41][66/204]	Loss 0.0099 (0.0452)	
training:	Epoch: [41][67/204]	Loss 0.0092 (0.0447)	
training:	Epoch: [41][68/204]	Loss 0.0086 (0.0442)	
training:	Epoch: [41][69/204]	Loss 0.1390 (0.0455)	
training:	Epoch: [41][70/204]	Loss 0.1506 (0.0470)	
training:	Epoch: [41][71/204]	Loss 0.0092 (0.0465)	
training:	Epoch: [41][72/204]	Loss 0.0092 (0.0460)	
training:	Epoch: [41][73/204]	Loss 0.0097 (0.0455)	
training:	Epoch: [41][74/204]	Loss 0.0083 (0.0450)	
training:	Epoch: [41][75/204]	Loss 0.0101 (0.0445)	
training:	Epoch: [41][76/204]	Loss 0.0094 (0.0441)	
training:	Epoch: [41][77/204]	Loss 0.1505 (0.0454)	
training:	Epoch: [41][78/204]	Loss 0.0105 (0.0450)	
training:	Epoch: [41][79/204]	Loss 0.0097 (0.0445)	
training:	Epoch: [41][80/204]	Loss 0.0091 (0.0441)	
training:	Epoch: [41][81/204]	Loss 0.0097 (0.0437)	
training:	Epoch: [41][82/204]	Loss 0.1585 (0.0451)	
training:	Epoch: [41][83/204]	Loss 0.0098 (0.0446)	
training:	Epoch: [41][84/204]	Loss 0.0112 (0.0443)	
training:	Epoch: [41][85/204]	Loss 0.0099 (0.0438)	
training:	Epoch: [41][86/204]	Loss 0.4452 (0.0485)	
training:	Epoch: [41][87/204]	Loss 0.0084 (0.0481)	
training:	Epoch: [41][88/204]	Loss 0.0085 (0.0476)	
training:	Epoch: [41][89/204]	Loss 0.0092 (0.0472)	
training:	Epoch: [41][90/204]	Loss 0.0091 (0.0467)	
training:	Epoch: [41][91/204]	Loss 0.0098 (0.0463)	
training:	Epoch: [41][92/204]	Loss 0.0190 (0.0460)	
training:	Epoch: [41][93/204]	Loss 0.0090 (0.0456)	
training:	Epoch: [41][94/204]	Loss 0.1547 (0.0468)	
training:	Epoch: [41][95/204]	Loss 0.0093 (0.0464)	
training:	Epoch: [41][96/204]	Loss 0.0110 (0.0460)	
training:	Epoch: [41][97/204]	Loss 0.0092 (0.0457)	
training:	Epoch: [41][98/204]	Loss 0.0098 (0.0453)	
training:	Epoch: [41][99/204]	Loss 0.0098 (0.0449)	
training:	Epoch: [41][100/204]	Loss 0.0110 (0.0446)	
training:	Epoch: [41][101/204]	Loss 0.0093 (0.0442)	
training:	Epoch: [41][102/204]	Loss 0.0094 (0.0439)	
training:	Epoch: [41][103/204]	Loss 0.0093 (0.0436)	
training:	Epoch: [41][104/204]	Loss 0.0098 (0.0432)	
training:	Epoch: [41][105/204]	Loss 0.0104 (0.0429)	
training:	Epoch: [41][106/204]	Loss 0.0088 (0.0426)	
training:	Epoch: [41][107/204]	Loss 0.0103 (0.0423)	
training:	Epoch: [41][108/204]	Loss 0.0093 (0.0420)	
training:	Epoch: [41][109/204]	Loss 0.0107 (0.0417)	
training:	Epoch: [41][110/204]	Loss 0.1601 (0.0428)	
training:	Epoch: [41][111/204]	Loss 0.0085 (0.0425)	
training:	Epoch: [41][112/204]	Loss 0.0091 (0.0422)	
training:	Epoch: [41][113/204]	Loss 0.1556 (0.0432)	
training:	Epoch: [41][114/204]	Loss 0.0103 (0.0429)	
training:	Epoch: [41][115/204]	Loss 0.1270 (0.0436)	
training:	Epoch: [41][116/204]	Loss 0.1411 (0.0445)	
training:	Epoch: [41][117/204]	Loss 0.0093 (0.0442)	
training:	Epoch: [41][118/204]	Loss 0.0111 (0.0439)	
training:	Epoch: [41][119/204]	Loss 0.0087 (0.0436)	
training:	Epoch: [41][120/204]	Loss 0.0084 (0.0433)	
training:	Epoch: [41][121/204]	Loss 0.1309 (0.0440)	
training:	Epoch: [41][122/204]	Loss 0.1598 (0.0450)	
training:	Epoch: [41][123/204]	Loss 0.0092 (0.0447)	
training:	Epoch: [41][124/204]	Loss 0.0092 (0.0444)	
training:	Epoch: [41][125/204]	Loss 0.0088 (0.0441)	
training:	Epoch: [41][126/204]	Loss 0.0103 (0.0438)	
training:	Epoch: [41][127/204]	Loss 0.0094 (0.0436)	
training:	Epoch: [41][128/204]	Loss 0.0115 (0.0433)	
training:	Epoch: [41][129/204]	Loss 0.1130 (0.0439)	
training:	Epoch: [41][130/204]	Loss 0.0773 (0.0441)	
training:	Epoch: [41][131/204]	Loss 0.0099 (0.0439)	
training:	Epoch: [41][132/204]	Loss 0.0426 (0.0439)	
training:	Epoch: [41][133/204]	Loss 0.0100 (0.0436)	
training:	Epoch: [41][134/204]	Loss 0.0108 (0.0434)	
training:	Epoch: [41][135/204]	Loss 0.0098 (0.0431)	
training:	Epoch: [41][136/204]	Loss 0.0092 (0.0429)	
training:	Epoch: [41][137/204]	Loss 0.0110 (0.0426)	
training:	Epoch: [41][138/204]	Loss 0.0096 (0.0424)	
training:	Epoch: [41][139/204]	Loss 0.1569 (0.0432)	
training:	Epoch: [41][140/204]	Loss 0.0090 (0.0430)	
training:	Epoch: [41][141/204]	Loss 0.1590 (0.0438)	
training:	Epoch: [41][142/204]	Loss 0.0097 (0.0435)	
training:	Epoch: [41][143/204]	Loss 0.0089 (0.0433)	
training:	Epoch: [41][144/204]	Loss 0.1600 (0.0441)	
training:	Epoch: [41][145/204]	Loss 0.0092 (0.0439)	
training:	Epoch: [41][146/204]	Loss 0.3151 (0.0457)	
training:	Epoch: [41][147/204]	Loss 0.1586 (0.0465)	
training:	Epoch: [41][148/204]	Loss 0.0093 (0.0462)	
training:	Epoch: [41][149/204]	Loss 0.0096 (0.0460)	
training:	Epoch: [41][150/204]	Loss 0.1426 (0.0466)	
training:	Epoch: [41][151/204]	Loss 0.0100 (0.0464)	
training:	Epoch: [41][152/204]	Loss 0.1444 (0.0470)	
training:	Epoch: [41][153/204]	Loss 0.0103 (0.0468)	
training:	Epoch: [41][154/204]	Loss 0.0092 (0.0466)	
training:	Epoch: [41][155/204]	Loss 0.1501 (0.0472)	
training:	Epoch: [41][156/204]	Loss 0.0101 (0.0470)	
training:	Epoch: [41][157/204]	Loss 0.0096 (0.0468)	
training:	Epoch: [41][158/204]	Loss 0.0118 (0.0465)	
training:	Epoch: [41][159/204]	Loss 0.0092 (0.0463)	
training:	Epoch: [41][160/204]	Loss 0.0675 (0.0464)	
training:	Epoch: [41][161/204]	Loss 0.0097 (0.0462)	
training:	Epoch: [41][162/204]	Loss 0.0086 (0.0460)	
training:	Epoch: [41][163/204]	Loss 0.0182 (0.0458)	
training:	Epoch: [41][164/204]	Loss 0.0097 (0.0456)	
training:	Epoch: [41][165/204]	Loss 0.0268 (0.0455)	
training:	Epoch: [41][166/204]	Loss 0.0089 (0.0452)	
training:	Epoch: [41][167/204]	Loss 0.0098 (0.0450)	
training:	Epoch: [41][168/204]	Loss 0.0085 (0.0448)	
training:	Epoch: [41][169/204]	Loss 0.0090 (0.0446)	
training:	Epoch: [41][170/204]	Loss 0.0093 (0.0444)	
training:	Epoch: [41][171/204]	Loss 0.1706 (0.0451)	
training:	Epoch: [41][172/204]	Loss 0.0085 (0.0449)	
training:	Epoch: [41][173/204]	Loss 0.0098 (0.0447)	
training:	Epoch: [41][174/204]	Loss 0.1621 (0.0454)	
training:	Epoch: [41][175/204]	Loss 0.0098 (0.0452)	
training:	Epoch: [41][176/204]	Loss 0.1084 (0.0455)	
training:	Epoch: [41][177/204]	Loss 0.0092 (0.0453)	
training:	Epoch: [41][178/204]	Loss 0.0228 (0.0452)	
training:	Epoch: [41][179/204]	Loss 0.2158 (0.0462)	
training:	Epoch: [41][180/204]	Loss 0.1606 (0.0468)	
training:	Epoch: [41][181/204]	Loss 0.1344 (0.0473)	
training:	Epoch: [41][182/204]	Loss 0.0088 (0.0471)	
training:	Epoch: [41][183/204]	Loss 0.0104 (0.0469)	
training:	Epoch: [41][184/204]	Loss 0.0094 (0.0467)	
training:	Epoch: [41][185/204]	Loss 0.0101 (0.0465)	
training:	Epoch: [41][186/204]	Loss 0.0090 (0.0463)	
training:	Epoch: [41][187/204]	Loss 0.0126 (0.0461)	
training:	Epoch: [41][188/204]	Loss 0.0095 (0.0459)	
training:	Epoch: [41][189/204]	Loss 0.0106 (0.0457)	
training:	Epoch: [41][190/204]	Loss 0.0090 (0.0455)	
training:	Epoch: [41][191/204]	Loss 0.0098 (0.0453)	
training:	Epoch: [41][192/204]	Loss 0.0122 (0.0452)	
training:	Epoch: [41][193/204]	Loss 0.1480 (0.0457)	
training:	Epoch: [41][194/204]	Loss 0.0090 (0.0455)	
training:	Epoch: [41][195/204]	Loss 0.0110 (0.0453)	
training:	Epoch: [41][196/204]	Loss 0.0090 (0.0451)	
training:	Epoch: [41][197/204]	Loss 0.0091 (0.0450)	
training:	Epoch: [41][198/204]	Loss 0.1259 (0.0454)	
training:	Epoch: [41][199/204]	Loss 0.0101 (0.0452)	
training:	Epoch: [41][200/204]	Loss 0.0969 (0.0454)	
training:	Epoch: [41][201/204]	Loss 0.0116 (0.0453)	
training:	Epoch: [41][202/204]	Loss 0.0084 (0.0451)	
training:	Epoch: [41][203/204]	Loss 0.1535 (0.0456)	
training:	Epoch: [41][204/204]	Loss 0.0094 (0.0455)	
Training:	 Loss: 0.0454

Training:	 ACC: 0.9919 0.9919 0.9924 0.9914
Validation:	 ACC: 0.7794 0.7812 0.8188 0.7399
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9386
Pretraining:	Epoch 42/500
----------
training:	Epoch: [42][1/204]	Loss 0.0134 (0.0134)	
training:	Epoch: [42][2/204]	Loss 0.1606 (0.0870)	
training:	Epoch: [42][3/204]	Loss 0.0103 (0.0614)	
training:	Epoch: [42][4/204]	Loss 0.0144 (0.0497)	
training:	Epoch: [42][5/204]	Loss 0.0109 (0.0419)	
training:	Epoch: [42][6/204]	Loss 0.0107 (0.0367)	
training:	Epoch: [42][7/204]	Loss 0.0182 (0.0341)	
training:	Epoch: [42][8/204]	Loss 0.0134 (0.0315)	
training:	Epoch: [42][9/204]	Loss 0.1591 (0.0457)	
training:	Epoch: [42][10/204]	Loss 0.0099 (0.0421)	
training:	Epoch: [42][11/204]	Loss 0.0082 (0.0390)	
training:	Epoch: [42][12/204]	Loss 0.0103 (0.0366)	
training:	Epoch: [42][13/204]	Loss 0.0106 (0.0346)	
training:	Epoch: [42][14/204]	Loss 0.0100 (0.0329)	
training:	Epoch: [42][15/204]	Loss 0.0131 (0.0315)	
training:	Epoch: [42][16/204]	Loss 0.0119 (0.0303)	
training:	Epoch: [42][17/204]	Loss 0.0102 (0.0291)	
training:	Epoch: [42][18/204]	Loss 0.1599 (0.0364)	
training:	Epoch: [42][19/204]	Loss 0.1574 (0.0428)	
training:	Epoch: [42][20/204]	Loss 0.0087 (0.0411)	
training:	Epoch: [42][21/204]	Loss 0.0085 (0.0395)	
training:	Epoch: [42][22/204]	Loss 0.0105 (0.0382)	
training:	Epoch: [42][23/204]	Loss 0.0309 (0.0379)	
training:	Epoch: [42][24/204]	Loss 0.0091 (0.0367)	
training:	Epoch: [42][25/204]	Loss 0.0173 (0.0359)	
training:	Epoch: [42][26/204]	Loss 0.0094 (0.0349)	
training:	Epoch: [42][27/204]	Loss 0.1494 (0.0391)	
training:	Epoch: [42][28/204]	Loss 0.0090 (0.0381)	
training:	Epoch: [42][29/204]	Loss 0.0094 (0.0371)	
training:	Epoch: [42][30/204]	Loss 0.0088 (0.0361)	
training:	Epoch: [42][31/204]	Loss 0.0578 (0.0368)	
training:	Epoch: [42][32/204]	Loss 0.0120 (0.0360)	
training:	Epoch: [42][33/204]	Loss 0.1397 (0.0392)	
training:	Epoch: [42][34/204]	Loss 0.0157 (0.0385)	
training:	Epoch: [42][35/204]	Loss 0.0228 (0.0380)	
training:	Epoch: [42][36/204]	Loss 0.0094 (0.0373)	
training:	Epoch: [42][37/204]	Loss 0.0092 (0.0365)	
training:	Epoch: [42][38/204]	Loss 0.0091 (0.0358)	
training:	Epoch: [42][39/204]	Loss 0.0103 (0.0351)	
training:	Epoch: [42][40/204]	Loss 0.0090 (0.0345)	
training:	Epoch: [42][41/204]	Loss 0.2923 (0.0408)	
training:	Epoch: [42][42/204]	Loss 0.0085 (0.0400)	
training:	Epoch: [42][43/204]	Loss 0.0096 (0.0393)	
training:	Epoch: [42][44/204]	Loss 0.1010 (0.0407)	
training:	Epoch: [42][45/204]	Loss 0.1637 (0.0434)	
training:	Epoch: [42][46/204]	Loss 0.0090 (0.0427)	
training:	Epoch: [42][47/204]	Loss 0.0097 (0.0420)	
training:	Epoch: [42][48/204]	Loss 0.0087 (0.0413)	
training:	Epoch: [42][49/204]	Loss 0.0094 (0.0406)	
training:	Epoch: [42][50/204]	Loss 0.0103 (0.0400)	
training:	Epoch: [42][51/204]	Loss 0.0110 (0.0394)	
training:	Epoch: [42][52/204]	Loss 0.0076 (0.0388)	
training:	Epoch: [42][53/204]	Loss 0.1102 (0.0402)	
training:	Epoch: [42][54/204]	Loss 0.0088 (0.0396)	
training:	Epoch: [42][55/204]	Loss 0.0092 (0.0391)	
training:	Epoch: [42][56/204]	Loss 0.1594 (0.0412)	
training:	Epoch: [42][57/204]	Loss 0.0086 (0.0406)	
training:	Epoch: [42][58/204]	Loss 0.0077 (0.0401)	
training:	Epoch: [42][59/204]	Loss 0.0111 (0.0396)	
training:	Epoch: [42][60/204]	Loss 0.0106 (0.0391)	
training:	Epoch: [42][61/204]	Loss 0.0093 (0.0386)	
training:	Epoch: [42][62/204]	Loss 0.0293 (0.0384)	
training:	Epoch: [42][63/204]	Loss 0.0105 (0.0380)	
training:	Epoch: [42][64/204]	Loss 0.0099 (0.0376)	
training:	Epoch: [42][65/204]	Loss 0.1590 (0.0394)	
training:	Epoch: [42][66/204]	Loss 0.0094 (0.0390)	
training:	Epoch: [42][67/204]	Loss 0.1545 (0.0407)	
training:	Epoch: [42][68/204]	Loss 0.0100 (0.0402)	
training:	Epoch: [42][69/204]	Loss 0.0098 (0.0398)	
training:	Epoch: [42][70/204]	Loss 0.0102 (0.0394)	
training:	Epoch: [42][71/204]	Loss 0.0109 (0.0390)	
training:	Epoch: [42][72/204]	Loss 0.0084 (0.0386)	
training:	Epoch: [42][73/204]	Loss 0.0082 (0.0381)	
training:	Epoch: [42][74/204]	Loss 0.0088 (0.0377)	
training:	Epoch: [42][75/204]	Loss 0.0117 (0.0374)	
training:	Epoch: [42][76/204]	Loss 0.0086 (0.0370)	
training:	Epoch: [42][77/204]	Loss 0.0090 (0.0367)	
training:	Epoch: [42][78/204]	Loss 0.1567 (0.0382)	
training:	Epoch: [42][79/204]	Loss 0.0093 (0.0378)	
training:	Epoch: [42][80/204]	Loss 0.0093 (0.0375)	
training:	Epoch: [42][81/204]	Loss 0.0086 (0.0371)	
training:	Epoch: [42][82/204]	Loss 0.0086 (0.0368)	
training:	Epoch: [42][83/204]	Loss 0.0113 (0.0365)	
training:	Epoch: [42][84/204]	Loss 0.0099 (0.0361)	
training:	Epoch: [42][85/204]	Loss 0.1583 (0.0376)	
training:	Epoch: [42][86/204]	Loss 0.0094 (0.0373)	
training:	Epoch: [42][87/204]	Loss 0.2127 (0.0393)	
training:	Epoch: [42][88/204]	Loss 0.0091 (0.0389)	
training:	Epoch: [42][89/204]	Loss 0.0088 (0.0386)	
training:	Epoch: [42][90/204]	Loss 0.1551 (0.0399)	
training:	Epoch: [42][91/204]	Loss 0.0084 (0.0395)	
training:	Epoch: [42][92/204]	Loss 0.1551 (0.0408)	
training:	Epoch: [42][93/204]	Loss 0.0089 (0.0405)	
training:	Epoch: [42][94/204]	Loss 0.0109 (0.0401)	
training:	Epoch: [42][95/204]	Loss 0.0100 (0.0398)	
training:	Epoch: [42][96/204]	Loss 0.0101 (0.0395)	
training:	Epoch: [42][97/204]	Loss 0.1552 (0.0407)	
training:	Epoch: [42][98/204]	Loss 0.3003 (0.0434)	
training:	Epoch: [42][99/204]	Loss 0.0097 (0.0430)	
training:	Epoch: [42][100/204]	Loss 0.0113 (0.0427)	
training:	Epoch: [42][101/204]	Loss 0.0087 (0.0424)	
training:	Epoch: [42][102/204]	Loss 0.1522 (0.0434)	
training:	Epoch: [42][103/204]	Loss 0.1173 (0.0442)	
training:	Epoch: [42][104/204]	Loss 0.0123 (0.0438)	
training:	Epoch: [42][105/204]	Loss 0.1369 (0.0447)	
training:	Epoch: [42][106/204]	Loss 0.0101 (0.0444)	
training:	Epoch: [42][107/204]	Loss 0.0105 (0.0441)	
training:	Epoch: [42][108/204]	Loss 0.0099 (0.0438)	
training:	Epoch: [42][109/204]	Loss 0.3066 (0.0462)	
training:	Epoch: [42][110/204]	Loss 0.0094 (0.0458)	
training:	Epoch: [42][111/204]	Loss 0.0096 (0.0455)	
training:	Epoch: [42][112/204]	Loss 0.0869 (0.0459)	
training:	Epoch: [42][113/204]	Loss 0.0097 (0.0456)	
training:	Epoch: [42][114/204]	Loss 0.0089 (0.0452)	
training:	Epoch: [42][115/204]	Loss 0.0137 (0.0450)	
training:	Epoch: [42][116/204]	Loss 0.0125 (0.0447)	
training:	Epoch: [42][117/204]	Loss 0.1565 (0.0457)	
training:	Epoch: [42][118/204]	Loss 0.0171 (0.0454)	
training:	Epoch: [42][119/204]	Loss 0.0097 (0.0451)	
training:	Epoch: [42][120/204]	Loss 0.0096 (0.0448)	
training:	Epoch: [42][121/204]	Loss 0.0099 (0.0445)	
training:	Epoch: [42][122/204]	Loss 0.0090 (0.0442)	
training:	Epoch: [42][123/204]	Loss 0.0111 (0.0440)	
training:	Epoch: [42][124/204]	Loss 0.0097 (0.0437)	
training:	Epoch: [42][125/204]	Loss 0.0091 (0.0434)	
training:	Epoch: [42][126/204]	Loss 0.0104 (0.0431)	
training:	Epoch: [42][127/204]	Loss 0.0105 (0.0429)	
training:	Epoch: [42][128/204]	Loss 0.1651 (0.0438)	
training:	Epoch: [42][129/204]	Loss 0.0115 (0.0436)	
training:	Epoch: [42][130/204]	Loss 0.0100 (0.0433)	
training:	Epoch: [42][131/204]	Loss 0.0144 (0.0431)	
training:	Epoch: [42][132/204]	Loss 0.1538 (0.0440)	
training:	Epoch: [42][133/204]	Loss 0.1547 (0.0448)	
training:	Epoch: [42][134/204]	Loss 0.0129 (0.0446)	
training:	Epoch: [42][135/204]	Loss 0.1527 (0.0454)	
training:	Epoch: [42][136/204]	Loss 0.0091 (0.0451)	
training:	Epoch: [42][137/204]	Loss 0.0127 (0.0448)	
training:	Epoch: [42][138/204]	Loss 0.0247 (0.0447)	
training:	Epoch: [42][139/204]	Loss 0.0087 (0.0444)	
training:	Epoch: [42][140/204]	Loss 0.0109 (0.0442)	
training:	Epoch: [42][141/204]	Loss 0.0089 (0.0440)	
training:	Epoch: [42][142/204]	Loss 0.0081 (0.0437)	
training:	Epoch: [42][143/204]	Loss 0.0095 (0.0435)	
training:	Epoch: [42][144/204]	Loss 0.0105 (0.0432)	
training:	Epoch: [42][145/204]	Loss 0.1407 (0.0439)	
training:	Epoch: [42][146/204]	Loss 0.0091 (0.0437)	
training:	Epoch: [42][147/204]	Loss 0.0099 (0.0434)	
training:	Epoch: [42][148/204]	Loss 0.0114 (0.0432)	
training:	Epoch: [42][149/204]	Loss 0.0140 (0.0430)	
training:	Epoch: [42][150/204]	Loss 0.0150 (0.0428)	
training:	Epoch: [42][151/204]	Loss 0.0195 (0.0427)	
training:	Epoch: [42][152/204]	Loss 0.0119 (0.0425)	
training:	Epoch: [42][153/204]	Loss 0.0087 (0.0423)	
training:	Epoch: [42][154/204]	Loss 0.0089 (0.0420)	
training:	Epoch: [42][155/204]	Loss 0.0093 (0.0418)	
training:	Epoch: [42][156/204]	Loss 0.1430 (0.0425)	
training:	Epoch: [42][157/204]	Loss 0.1569 (0.0432)	
training:	Epoch: [42][158/204]	Loss 0.1374 (0.0438)	
training:	Epoch: [42][159/204]	Loss 0.1469 (0.0445)	
training:	Epoch: [42][160/204]	Loss 0.0093 (0.0442)	
training:	Epoch: [42][161/204]	Loss 0.0107 (0.0440)	
training:	Epoch: [42][162/204]	Loss 0.1525 (0.0447)	
training:	Epoch: [42][163/204]	Loss 0.0078 (0.0445)	
training:	Epoch: [42][164/204]	Loss 0.1491 (0.0451)	
training:	Epoch: [42][165/204]	Loss 0.0101 (0.0449)	
training:	Epoch: [42][166/204]	Loss 0.3128 (0.0465)	
training:	Epoch: [42][167/204]	Loss 0.0102 (0.0463)	
training:	Epoch: [42][168/204]	Loss 0.1482 (0.0469)	
training:	Epoch: [42][169/204]	Loss 0.0098 (0.0467)	
training:	Epoch: [42][170/204]	Loss 0.1474 (0.0473)	
training:	Epoch: [42][171/204]	Loss 0.0116 (0.0471)	
training:	Epoch: [42][172/204]	Loss 0.1301 (0.0475)	
training:	Epoch: [42][173/204]	Loss 0.0097 (0.0473)	
training:	Epoch: [42][174/204]	Loss 0.1547 (0.0479)	
training:	Epoch: [42][175/204]	Loss 0.0105 (0.0477)	
training:	Epoch: [42][176/204]	Loss 0.0125 (0.0475)	
training:	Epoch: [42][177/204]	Loss 0.0086 (0.0473)	
training:	Epoch: [42][178/204]	Loss 0.0084 (0.0471)	
training:	Epoch: [42][179/204]	Loss 0.0095 (0.0469)	
training:	Epoch: [42][180/204]	Loss 0.1608 (0.0475)	
training:	Epoch: [42][181/204]	Loss 0.0102 (0.0473)	
training:	Epoch: [42][182/204]	Loss 0.0089 (0.0471)	
training:	Epoch: [42][183/204]	Loss 0.0090 (0.0469)	
training:	Epoch: [42][184/204]	Loss 0.0091 (0.0467)	
training:	Epoch: [42][185/204]	Loss 0.0109 (0.0465)	
training:	Epoch: [42][186/204]	Loss 0.0102 (0.0463)	
training:	Epoch: [42][187/204]	Loss 0.0121 (0.0461)	
training:	Epoch: [42][188/204]	Loss 0.0095 (0.0459)	
training:	Epoch: [42][189/204]	Loss 0.0108 (0.0457)	
training:	Epoch: [42][190/204]	Loss 0.0095 (0.0455)	
training:	Epoch: [42][191/204]	Loss 0.0093 (0.0454)	
training:	Epoch: [42][192/204]	Loss 0.0088 (0.0452)	
training:	Epoch: [42][193/204]	Loss 0.0105 (0.0450)	
training:	Epoch: [42][194/204]	Loss 0.0139 (0.0448)	
training:	Epoch: [42][195/204]	Loss 0.1578 (0.0454)	
training:	Epoch: [42][196/204]	Loss 0.0091 (0.0452)	
training:	Epoch: [42][197/204]	Loss 0.0089 (0.0450)	
training:	Epoch: [42][198/204]	Loss 0.0099 (0.0449)	
training:	Epoch: [42][199/204]	Loss 0.0143 (0.0447)	
training:	Epoch: [42][200/204]	Loss 0.0085 (0.0445)	
training:	Epoch: [42][201/204]	Loss 0.0120 (0.0444)	
training:	Epoch: [42][202/204]	Loss 0.0102 (0.0442)	
training:	Epoch: [42][203/204]	Loss 0.0088 (0.0440)	
training:	Epoch: [42][204/204]	Loss 0.0087 (0.0438)	
Training:	 Loss: 0.0438

Training:	 ACC: 0.9925 0.9925 0.9924 0.9927
Validation:	 ACC: 0.7803 0.7822 0.8229 0.7377
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9447
Pretraining:	Epoch 43/500
----------
training:	Epoch: [43][1/204]	Loss 0.1548 (0.1548)	
training:	Epoch: [43][2/204]	Loss 0.0093 (0.0820)	
training:	Epoch: [43][3/204]	Loss 0.0085 (0.0575)	
training:	Epoch: [43][4/204]	Loss 0.0090 (0.0454)	
training:	Epoch: [43][5/204]	Loss 0.0098 (0.0383)	
training:	Epoch: [43][6/204]	Loss 0.1671 (0.0597)	
training:	Epoch: [43][7/204]	Loss 0.0090 (0.0525)	
training:	Epoch: [43][8/204]	Loss 0.0091 (0.0471)	
training:	Epoch: [43][9/204]	Loss 0.1716 (0.0609)	
training:	Epoch: [43][10/204]	Loss 0.0082 (0.0556)	
training:	Epoch: [43][11/204]	Loss 0.0087 (0.0514)	
training:	Epoch: [43][12/204]	Loss 0.1373 (0.0585)	
training:	Epoch: [43][13/204]	Loss 0.0094 (0.0548)	
training:	Epoch: [43][14/204]	Loss 0.0080 (0.0514)	
training:	Epoch: [43][15/204]	Loss 0.0082 (0.0485)	
training:	Epoch: [43][16/204]	Loss 0.0107 (0.0462)	
training:	Epoch: [43][17/204]	Loss 0.0088 (0.0440)	
training:	Epoch: [43][18/204]	Loss 0.0093 (0.0420)	
training:	Epoch: [43][19/204]	Loss 0.0359 (0.0417)	
training:	Epoch: [43][20/204]	Loss 0.0106 (0.0402)	
training:	Epoch: [43][21/204]	Loss 0.0087 (0.0387)	
training:	Epoch: [43][22/204]	Loss 0.0085 (0.0373)	
training:	Epoch: [43][23/204]	Loss 0.0098 (0.0361)	
training:	Epoch: [43][24/204]	Loss 0.0085 (0.0350)	
training:	Epoch: [43][25/204]	Loss 0.0091 (0.0339)	
training:	Epoch: [43][26/204]	Loss 0.0087 (0.0329)	
training:	Epoch: [43][27/204]	Loss 0.0081 (0.0320)	
training:	Epoch: [43][28/204]	Loss 0.0083 (0.0312)	
training:	Epoch: [43][29/204]	Loss 0.2698 (0.0394)	
training:	Epoch: [43][30/204]	Loss 0.1409 (0.0428)	
training:	Epoch: [43][31/204]	Loss 0.1546 (0.0464)	
training:	Epoch: [43][32/204]	Loss 0.0080 (0.0452)	
training:	Epoch: [43][33/204]	Loss 0.0090 (0.0441)	
training:	Epoch: [43][34/204]	Loss 0.0088 (0.0431)	
training:	Epoch: [43][35/204]	Loss 0.0086 (0.0421)	
training:	Epoch: [43][36/204]	Loss 0.0239 (0.0416)	
training:	Epoch: [43][37/204]	Loss 0.0265 (0.0412)	
training:	Epoch: [43][38/204]	Loss 0.0309 (0.0409)	
training:	Epoch: [43][39/204]	Loss 0.0085 (0.0401)	
training:	Epoch: [43][40/204]	Loss 0.0086 (0.0393)	
training:	Epoch: [43][41/204]	Loss 0.0089 (0.0385)	
training:	Epoch: [43][42/204]	Loss 0.0087 (0.0378)	
training:	Epoch: [43][43/204]	Loss 0.1465 (0.0403)	
training:	Epoch: [43][44/204]	Loss 0.0173 (0.0398)	
training:	Epoch: [43][45/204]	Loss 0.0726 (0.0406)	
training:	Epoch: [43][46/204]	Loss 0.0101 (0.0399)	
training:	Epoch: [43][47/204]	Loss 0.0098 (0.0392)	
training:	Epoch: [43][48/204]	Loss 0.0124 (0.0387)	
training:	Epoch: [43][49/204]	Loss 0.0146 (0.0382)	
training:	Epoch: [43][50/204]	Loss 0.0198 (0.0378)	
training:	Epoch: [43][51/204]	Loss 0.0090 (0.0373)	
training:	Epoch: [43][52/204]	Loss 0.0084 (0.0367)	
training:	Epoch: [43][53/204]	Loss 0.1420 (0.0387)	
training:	Epoch: [43][54/204]	Loss 0.0093 (0.0382)	
training:	Epoch: [43][55/204]	Loss 0.0100 (0.0376)	
training:	Epoch: [43][56/204]	Loss 0.0091 (0.0371)	
training:	Epoch: [43][57/204]	Loss 0.0091 (0.0366)	
training:	Epoch: [43][58/204]	Loss 0.0118 (0.0362)	
training:	Epoch: [43][59/204]	Loss 0.0091 (0.0358)	
training:	Epoch: [43][60/204]	Loss 0.3064 (0.0403)	
training:	Epoch: [43][61/204]	Loss 0.0276 (0.0401)	
training:	Epoch: [43][62/204]	Loss 0.0105 (0.0396)	
training:	Epoch: [43][63/204]	Loss 0.0313 (0.0394)	
training:	Epoch: [43][64/204]	Loss 0.0130 (0.0390)	
training:	Epoch: [43][65/204]	Loss 0.0091 (0.0386)	
training:	Epoch: [43][66/204]	Loss 0.0086 (0.0381)	
training:	Epoch: [43][67/204]	Loss 0.1474 (0.0398)	
training:	Epoch: [43][68/204]	Loss 0.0089 (0.0393)	
training:	Epoch: [43][69/204]	Loss 0.0081 (0.0388)	
training:	Epoch: [43][70/204]	Loss 0.0091 (0.0384)	
training:	Epoch: [43][71/204]	Loss 0.0086 (0.0380)	
training:	Epoch: [43][72/204]	Loss 0.0091 (0.0376)	
training:	Epoch: [43][73/204]	Loss 0.0100 (0.0372)	
training:	Epoch: [43][74/204]	Loss 0.0082 (0.0368)	
training:	Epoch: [43][75/204]	Loss 0.0693 (0.0373)	
training:	Epoch: [43][76/204]	Loss 0.0090 (0.0369)	
training:	Epoch: [43][77/204]	Loss 0.0080 (0.0365)	
training:	Epoch: [43][78/204]	Loss 0.0087 (0.0362)	
training:	Epoch: [43][79/204]	Loss 0.1580 (0.0377)	
training:	Epoch: [43][80/204]	Loss 0.0113 (0.0374)	
training:	Epoch: [43][81/204]	Loss 0.0089 (0.0370)	
training:	Epoch: [43][82/204]	Loss 0.0090 (0.0367)	
training:	Epoch: [43][83/204]	Loss 0.1428 (0.0380)	
training:	Epoch: [43][84/204]	Loss 0.0083 (0.0376)	
training:	Epoch: [43][85/204]	Loss 0.1536 (0.0390)	
training:	Epoch: [43][86/204]	Loss 0.1566 (0.0403)	
training:	Epoch: [43][87/204]	Loss 0.0130 (0.0400)	
training:	Epoch: [43][88/204]	Loss 0.0129 (0.0397)	
training:	Epoch: [43][89/204]	Loss 0.0085 (0.0394)	
training:	Epoch: [43][90/204]	Loss 0.0085 (0.0390)	
training:	Epoch: [43][91/204]	Loss 0.0097 (0.0387)	
training:	Epoch: [43][92/204]	Loss 0.0080 (0.0384)	
training:	Epoch: [43][93/204]	Loss 0.0082 (0.0380)	
training:	Epoch: [43][94/204]	Loss 0.0095 (0.0377)	
training:	Epoch: [43][95/204]	Loss 0.0632 (0.0380)	
training:	Epoch: [43][96/204]	Loss 0.1285 (0.0389)	
training:	Epoch: [43][97/204]	Loss 0.0123 (0.0387)	
training:	Epoch: [43][98/204]	Loss 0.0506 (0.0388)	
training:	Epoch: [43][99/204]	Loss 0.1610 (0.0400)	
training:	Epoch: [43][100/204]	Loss 0.3088 (0.0427)	
training:	Epoch: [43][101/204]	Loss 0.0232 (0.0425)	
training:	Epoch: [43][102/204]	Loss 0.0106 (0.0422)	
training:	Epoch: [43][103/204]	Loss 0.0416 (0.0422)	
training:	Epoch: [43][104/204]	Loss 0.0079 (0.0419)	
training:	Epoch: [43][105/204]	Loss 0.0084 (0.0416)	
training:	Epoch: [43][106/204]	Loss 0.0099 (0.0413)	
training:	Epoch: [43][107/204]	Loss 0.0140 (0.0410)	
training:	Epoch: [43][108/204]	Loss 0.0086 (0.0407)	
training:	Epoch: [43][109/204]	Loss 0.0096 (0.0404)	
training:	Epoch: [43][110/204]	Loss 0.0090 (0.0401)	
training:	Epoch: [43][111/204]	Loss 0.1560 (0.0412)	
training:	Epoch: [43][112/204]	Loss 0.0098 (0.0409)	
training:	Epoch: [43][113/204]	Loss 0.0168 (0.0407)	
training:	Epoch: [43][114/204]	Loss 0.0098 (0.0404)	
training:	Epoch: [43][115/204]	Loss 0.0105 (0.0401)	
training:	Epoch: [43][116/204]	Loss 0.0080 (0.0399)	
training:	Epoch: [43][117/204]	Loss 0.0079 (0.0396)	
training:	Epoch: [43][118/204]	Loss 0.0090 (0.0393)	
training:	Epoch: [43][119/204]	Loss 0.1666 (0.0404)	
training:	Epoch: [43][120/204]	Loss 0.1660 (0.0415)	
training:	Epoch: [43][121/204]	Loss 0.0093 (0.0412)	
training:	Epoch: [43][122/204]	Loss 0.1602 (0.0422)	
training:	Epoch: [43][123/204]	Loss 0.0171 (0.0420)	
training:	Epoch: [43][124/204]	Loss 0.0102 (0.0417)	
training:	Epoch: [43][125/204]	Loss 0.0091 (0.0414)	
training:	Epoch: [43][126/204]	Loss 0.0087 (0.0412)	
training:	Epoch: [43][127/204]	Loss 0.0086 (0.0409)	
training:	Epoch: [43][128/204]	Loss 0.0085 (0.0407)	
training:	Epoch: [43][129/204]	Loss 0.0080 (0.0404)	
training:	Epoch: [43][130/204]	Loss 0.0084 (0.0402)	
training:	Epoch: [43][131/204]	Loss 0.0466 (0.0402)	
training:	Epoch: [43][132/204]	Loss 0.0786 (0.0405)	
training:	Epoch: [43][133/204]	Loss 0.1550 (0.0414)	
training:	Epoch: [43][134/204]	Loss 0.1551 (0.0422)	
training:	Epoch: [43][135/204]	Loss 0.1596 (0.0431)	
training:	Epoch: [43][136/204]	Loss 0.0172 (0.0429)	
training:	Epoch: [43][137/204]	Loss 0.0087 (0.0427)	
training:	Epoch: [43][138/204]	Loss 0.0085 (0.0424)	
training:	Epoch: [43][139/204]	Loss 0.0114 (0.0422)	
training:	Epoch: [43][140/204]	Loss 0.1301 (0.0428)	
training:	Epoch: [43][141/204]	Loss 0.1445 (0.0435)	
training:	Epoch: [43][142/204]	Loss 0.0097 (0.0433)	
training:	Epoch: [43][143/204]	Loss 0.0087 (0.0431)	
training:	Epoch: [43][144/204]	Loss 0.0150 (0.0429)	
training:	Epoch: [43][145/204]	Loss 0.0089 (0.0426)	
training:	Epoch: [43][146/204]	Loss 0.0083 (0.0424)	
training:	Epoch: [43][147/204]	Loss 0.0082 (0.0422)	
training:	Epoch: [43][148/204]	Loss 0.0083 (0.0419)	
training:	Epoch: [43][149/204]	Loss 0.1566 (0.0427)	
training:	Epoch: [43][150/204]	Loss 0.0084 (0.0425)	
training:	Epoch: [43][151/204]	Loss 0.1259 (0.0430)	
training:	Epoch: [43][152/204]	Loss 0.0090 (0.0428)	
training:	Epoch: [43][153/204]	Loss 0.0081 (0.0426)	
training:	Epoch: [43][154/204]	Loss 0.0099 (0.0424)	
training:	Epoch: [43][155/204]	Loss 0.0080 (0.0421)	
training:	Epoch: [43][156/204]	Loss 0.0078 (0.0419)	
training:	Epoch: [43][157/204]	Loss 0.0196 (0.0418)	
training:	Epoch: [43][158/204]	Loss 0.0098 (0.0416)	
training:	Epoch: [43][159/204]	Loss 0.0092 (0.0414)	
training:	Epoch: [43][160/204]	Loss 0.1588 (0.0421)	
training:	Epoch: [43][161/204]	Loss 0.1589 (0.0428)	
training:	Epoch: [43][162/204]	Loss 0.0182 (0.0427)	
training:	Epoch: [43][163/204]	Loss 0.0100 (0.0425)	
training:	Epoch: [43][164/204]	Loss 0.1545 (0.0432)	
training:	Epoch: [43][165/204]	Loss 0.0080 (0.0429)	
training:	Epoch: [43][166/204]	Loss 0.0085 (0.0427)	
training:	Epoch: [43][167/204]	Loss 0.1102 (0.0431)	
training:	Epoch: [43][168/204]	Loss 0.0086 (0.0429)	
training:	Epoch: [43][169/204]	Loss 0.1575 (0.0436)	
training:	Epoch: [43][170/204]	Loss 0.1348 (0.0441)	
training:	Epoch: [43][171/204]	Loss 0.0103 (0.0439)	
training:	Epoch: [43][172/204]	Loss 0.0079 (0.0437)	
training:	Epoch: [43][173/204]	Loss 0.1667 (0.0445)	
training:	Epoch: [43][174/204]	Loss 0.0079 (0.0442)	
training:	Epoch: [43][175/204]	Loss 0.0082 (0.0440)	
training:	Epoch: [43][176/204]	Loss 0.1576 (0.0447)	
training:	Epoch: [43][177/204]	Loss 0.0085 (0.0445)	
training:	Epoch: [43][178/204]	Loss 0.0121 (0.0443)	
training:	Epoch: [43][179/204]	Loss 0.0196 (0.0442)	
training:	Epoch: [43][180/204]	Loss 0.0100 (0.0440)	
training:	Epoch: [43][181/204]	Loss 0.1542 (0.0446)	
training:	Epoch: [43][182/204]	Loss 0.0500 (0.0446)	
training:	Epoch: [43][183/204]	Loss 0.0101 (0.0444)	
training:	Epoch: [43][184/204]	Loss 0.0090 (0.0442)	
training:	Epoch: [43][185/204]	Loss 0.0079 (0.0440)	
training:	Epoch: [43][186/204]	Loss 0.0110 (0.0438)	
training:	Epoch: [43][187/204]	Loss 0.1583 (0.0445)	
training:	Epoch: [43][188/204]	Loss 0.0084 (0.0443)	
training:	Epoch: [43][189/204]	Loss 0.1612 (0.0449)	
training:	Epoch: [43][190/204]	Loss 0.0107 (0.0447)	
training:	Epoch: [43][191/204]	Loss 0.1496 (0.0453)	
training:	Epoch: [43][192/204]	Loss 0.0083 (0.0451)	
training:	Epoch: [43][193/204]	Loss 0.0091 (0.0449)	
training:	Epoch: [43][194/204]	Loss 0.0079 (0.0447)	
training:	Epoch: [43][195/204]	Loss 0.0521 (0.0447)	
training:	Epoch: [43][196/204]	Loss 0.1955 (0.0455)	
training:	Epoch: [43][197/204]	Loss 0.0089 (0.0453)	
training:	Epoch: [43][198/204]	Loss 0.0091 (0.0451)	
training:	Epoch: [43][199/204]	Loss 0.0320 (0.0451)	
training:	Epoch: [43][200/204]	Loss 0.0088 (0.0449)	
training:	Epoch: [43][201/204]	Loss 0.2780 (0.0460)	
training:	Epoch: [43][202/204]	Loss 0.1376 (0.0465)	
training:	Epoch: [43][203/204]	Loss 0.0088 (0.0463)	
training:	Epoch: [43][204/204]	Loss 0.0096 (0.0461)	
Training:	 Loss: 0.0461

Training:	 ACC: 0.9927 0.9927 0.9927 0.9927
Validation:	 ACC: 0.7780 0.7790 0.8014 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9592
Pretraining:	Epoch 44/500
----------
training:	Epoch: [44][1/204]	Loss 0.1498 (0.1498)	
training:	Epoch: [44][2/204]	Loss 0.0106 (0.0802)	
training:	Epoch: [44][3/204]	Loss 0.1546 (0.1050)	
training:	Epoch: [44][4/204]	Loss 0.0095 (0.0811)	
training:	Epoch: [44][5/204]	Loss 0.0097 (0.0668)	
training:	Epoch: [44][6/204]	Loss 0.0092 (0.0572)	
training:	Epoch: [44][7/204]	Loss 0.0097 (0.0504)	
training:	Epoch: [44][8/204]	Loss 0.0105 (0.0454)	
training:	Epoch: [44][9/204]	Loss 0.0117 (0.0417)	
training:	Epoch: [44][10/204]	Loss 0.1490 (0.0524)	
training:	Epoch: [44][11/204]	Loss 0.0094 (0.0485)	
training:	Epoch: [44][12/204]	Loss 0.0099 (0.0453)	
training:	Epoch: [44][13/204]	Loss 0.1552 (0.0537)	
training:	Epoch: [44][14/204]	Loss 0.0108 (0.0507)	
training:	Epoch: [44][15/204]	Loss 0.0101 (0.0480)	
training:	Epoch: [44][16/204]	Loss 0.0088 (0.0455)	
training:	Epoch: [44][17/204]	Loss 0.1575 (0.0521)	
training:	Epoch: [44][18/204]	Loss 0.0086 (0.0497)	
training:	Epoch: [44][19/204]	Loss 0.0096 (0.0476)	
training:	Epoch: [44][20/204]	Loss 0.1434 (0.0524)	
training:	Epoch: [44][21/204]	Loss 0.1104 (0.0551)	
training:	Epoch: [44][22/204]	Loss 0.1568 (0.0598)	
training:	Epoch: [44][23/204]	Loss 0.0102 (0.0576)	
training:	Epoch: [44][24/204]	Loss 0.0102 (0.0556)	
training:	Epoch: [44][25/204]	Loss 0.0123 (0.0539)	
training:	Epoch: [44][26/204]	Loss 0.0117 (0.0523)	
training:	Epoch: [44][27/204]	Loss 0.1507 (0.0559)	
training:	Epoch: [44][28/204]	Loss 0.0092 (0.0543)	
training:	Epoch: [44][29/204]	Loss 0.0096 (0.0527)	
training:	Epoch: [44][30/204]	Loss 0.0109 (0.0513)	
training:	Epoch: [44][31/204]	Loss 0.0109 (0.0500)	
training:	Epoch: [44][32/204]	Loss 0.0107 (0.0488)	
training:	Epoch: [44][33/204]	Loss 0.0122 (0.0477)	
training:	Epoch: [44][34/204]	Loss 0.1580 (0.0509)	
training:	Epoch: [44][35/204]	Loss 0.0096 (0.0497)	
training:	Epoch: [44][36/204]	Loss 0.0136 (0.0487)	
training:	Epoch: [44][37/204]	Loss 0.0086 (0.0477)	
training:	Epoch: [44][38/204]	Loss 0.0099 (0.0467)	
training:	Epoch: [44][39/204]	Loss 0.1543 (0.0494)	
training:	Epoch: [44][40/204]	Loss 0.0091 (0.0484)	
training:	Epoch: [44][41/204]	Loss 0.0099 (0.0475)	
training:	Epoch: [44][42/204]	Loss 0.0088 (0.0466)	
training:	Epoch: [44][43/204]	Loss 0.1551 (0.0491)	
training:	Epoch: [44][44/204]	Loss 0.0084 (0.0482)	
training:	Epoch: [44][45/204]	Loss 0.0082 (0.0473)	
training:	Epoch: [44][46/204]	Loss 0.0099 (0.0465)	
training:	Epoch: [44][47/204]	Loss 0.1550 (0.0488)	
training:	Epoch: [44][48/204]	Loss 0.0982 (0.0498)	
training:	Epoch: [44][49/204]	Loss 0.0090 (0.0490)	
training:	Epoch: [44][50/204]	Loss 0.0080 (0.0481)	
training:	Epoch: [44][51/204]	Loss 0.0194 (0.0476)	
training:	Epoch: [44][52/204]	Loss 0.0085 (0.0468)	
training:	Epoch: [44][53/204]	Loss 0.0084 (0.0461)	
training:	Epoch: [44][54/204]	Loss 0.1569 (0.0482)	
training:	Epoch: [44][55/204]	Loss 0.0091 (0.0474)	
training:	Epoch: [44][56/204]	Loss 0.1578 (0.0494)	
training:	Epoch: [44][57/204]	Loss 0.2235 (0.0525)	
training:	Epoch: [44][58/204]	Loss 0.0105 (0.0517)	
training:	Epoch: [44][59/204]	Loss 0.0091 (0.0510)	
training:	Epoch: [44][60/204]	Loss 0.0132 (0.0504)	
training:	Epoch: [44][61/204]	Loss 0.0107 (0.0497)	
training:	Epoch: [44][62/204]	Loss 0.0085 (0.0491)	
training:	Epoch: [44][63/204]	Loss 0.0099 (0.0485)	
training:	Epoch: [44][64/204]	Loss 0.0094 (0.0478)	
training:	Epoch: [44][65/204]	Loss 0.0079 (0.0472)	
training:	Epoch: [44][66/204]	Loss 0.0082 (0.0466)	
training:	Epoch: [44][67/204]	Loss 0.0091 (0.0461)	
training:	Epoch: [44][68/204]	Loss 0.0135 (0.0456)	
training:	Epoch: [44][69/204]	Loss 0.0114 (0.0451)	
training:	Epoch: [44][70/204]	Loss 0.0105 (0.0446)	
training:	Epoch: [44][71/204]	Loss 0.1550 (0.0462)	
training:	Epoch: [44][72/204]	Loss 0.0095 (0.0457)	
training:	Epoch: [44][73/204]	Loss 0.0096 (0.0452)	
training:	Epoch: [44][74/204]	Loss 0.0087 (0.0447)	
training:	Epoch: [44][75/204]	Loss 0.1646 (0.0463)	
training:	Epoch: [44][76/204]	Loss 0.0085 (0.0458)	
training:	Epoch: [44][77/204]	Loss 0.1578 (0.0472)	
training:	Epoch: [44][78/204]	Loss 0.0090 (0.0467)	
training:	Epoch: [44][79/204]	Loss 0.0087 (0.0463)	
training:	Epoch: [44][80/204]	Loss 0.0093 (0.0458)	
training:	Epoch: [44][81/204]	Loss 0.0085 (0.0453)	
training:	Epoch: [44][82/204]	Loss 0.1632 (0.0468)	
training:	Epoch: [44][83/204]	Loss 0.2615 (0.0494)	
training:	Epoch: [44][84/204]	Loss 0.0096 (0.0489)	
training:	Epoch: [44][85/204]	Loss 0.0095 (0.0484)	
training:	Epoch: [44][86/204]	Loss 0.0085 (0.0480)	
training:	Epoch: [44][87/204]	Loss 0.0086 (0.0475)	
training:	Epoch: [44][88/204]	Loss 0.0099 (0.0471)	
training:	Epoch: [44][89/204]	Loss 0.1565 (0.0483)	
training:	Epoch: [44][90/204]	Loss 0.0088 (0.0479)	
training:	Epoch: [44][91/204]	Loss 0.0678 (0.0481)	
training:	Epoch: [44][92/204]	Loss 0.0094 (0.0477)	
training:	Epoch: [44][93/204]	Loss 0.0093 (0.0473)	
training:	Epoch: [44][94/204]	Loss 0.1460 (0.0483)	
training:	Epoch: [44][95/204]	Loss 0.0090 (0.0479)	
training:	Epoch: [44][96/204]	Loss 0.0089 (0.0475)	
training:	Epoch: [44][97/204]	Loss 0.0084 (0.0471)	
training:	Epoch: [44][98/204]	Loss 0.0117 (0.0467)	
training:	Epoch: [44][99/204]	Loss 0.0088 (0.0463)	
training:	Epoch: [44][100/204]	Loss 0.0087 (0.0460)	
training:	Epoch: [44][101/204]	Loss 0.0249 (0.0458)	
training:	Epoch: [44][102/204]	Loss 0.0085 (0.0454)	
training:	Epoch: [44][103/204]	Loss 0.0163 (0.0451)	
training:	Epoch: [44][104/204]	Loss 0.0104 (0.0448)	
training:	Epoch: [44][105/204]	Loss 0.0090 (0.0444)	
training:	Epoch: [44][106/204]	Loss 0.0099 (0.0441)	
training:	Epoch: [44][107/204]	Loss 0.0083 (0.0438)	
training:	Epoch: [44][108/204]	Loss 0.0092 (0.0435)	
training:	Epoch: [44][109/204]	Loss 0.0078 (0.0431)	
training:	Epoch: [44][110/204]	Loss 0.0081 (0.0428)	
training:	Epoch: [44][111/204]	Loss 0.0077 (0.0425)	
training:	Epoch: [44][112/204]	Loss 0.0118 (0.0422)	
training:	Epoch: [44][113/204]	Loss 0.0089 (0.0419)	
training:	Epoch: [44][114/204]	Loss 0.0085 (0.0416)	
training:	Epoch: [44][115/204]	Loss 0.1528 (0.0426)	
training:	Epoch: [44][116/204]	Loss 0.0089 (0.0423)	
training:	Epoch: [44][117/204]	Loss 0.0076 (0.0420)	
training:	Epoch: [44][118/204]	Loss 0.0090 (0.0417)	
training:	Epoch: [44][119/204]	Loss 0.0084 (0.0414)	
training:	Epoch: [44][120/204]	Loss 0.0080 (0.0412)	
training:	Epoch: [44][121/204]	Loss 0.0092 (0.0409)	
training:	Epoch: [44][122/204]	Loss 0.0095 (0.0406)	
training:	Epoch: [44][123/204]	Loss 0.1537 (0.0416)	
training:	Epoch: [44][124/204]	Loss 0.1575 (0.0425)	
training:	Epoch: [44][125/204]	Loss 0.0759 (0.0428)	
training:	Epoch: [44][126/204]	Loss 0.0088 (0.0425)	
training:	Epoch: [44][127/204]	Loss 0.0096 (0.0422)	
training:	Epoch: [44][128/204]	Loss 0.1554 (0.0431)	
training:	Epoch: [44][129/204]	Loss 0.0097 (0.0429)	
training:	Epoch: [44][130/204]	Loss 0.0091 (0.0426)	
training:	Epoch: [44][131/204]	Loss 0.0103 (0.0424)	
training:	Epoch: [44][132/204]	Loss 0.0085 (0.0421)	
training:	Epoch: [44][133/204]	Loss 0.0082 (0.0418)	
training:	Epoch: [44][134/204]	Loss 0.0103 (0.0416)	
training:	Epoch: [44][135/204]	Loss 0.1546 (0.0424)	
training:	Epoch: [44][136/204]	Loss 0.0084 (0.0422)	
training:	Epoch: [44][137/204]	Loss 0.0104 (0.0420)	
training:	Epoch: [44][138/204]	Loss 0.0085 (0.0417)	
training:	Epoch: [44][139/204]	Loss 0.0081 (0.0415)	
training:	Epoch: [44][140/204]	Loss 0.0091 (0.0412)	
training:	Epoch: [44][141/204]	Loss 0.0095 (0.0410)	
training:	Epoch: [44][142/204]	Loss 0.0094 (0.0408)	
training:	Epoch: [44][143/204]	Loss 0.1657 (0.0417)	
training:	Epoch: [44][144/204]	Loss 0.1374 (0.0423)	
training:	Epoch: [44][145/204]	Loss 0.0100 (0.0421)	
training:	Epoch: [44][146/204]	Loss 0.0095 (0.0419)	
training:	Epoch: [44][147/204]	Loss 0.1588 (0.0427)	
training:	Epoch: [44][148/204]	Loss 0.0095 (0.0425)	
training:	Epoch: [44][149/204]	Loss 0.1436 (0.0431)	
training:	Epoch: [44][150/204]	Loss 0.0078 (0.0429)	
training:	Epoch: [44][151/204]	Loss 0.0088 (0.0427)	
training:	Epoch: [44][152/204]	Loss 0.0114 (0.0425)	
training:	Epoch: [44][153/204]	Loss 0.0113 (0.0423)	
training:	Epoch: [44][154/204]	Loss 0.0081 (0.0420)	
training:	Epoch: [44][155/204]	Loss 0.0101 (0.0418)	
training:	Epoch: [44][156/204]	Loss 0.0086 (0.0416)	
training:	Epoch: [44][157/204]	Loss 0.0102 (0.0414)	
training:	Epoch: [44][158/204]	Loss 0.2884 (0.0430)	
training:	Epoch: [44][159/204]	Loss 0.0086 (0.0428)	
training:	Epoch: [44][160/204]	Loss 0.0080 (0.0426)	
training:	Epoch: [44][161/204]	Loss 0.0087 (0.0423)	
training:	Epoch: [44][162/204]	Loss 0.0087 (0.0421)	
training:	Epoch: [44][163/204]	Loss 0.0120 (0.0420)	
training:	Epoch: [44][164/204]	Loss 0.0089 (0.0418)	
training:	Epoch: [44][165/204]	Loss 0.0084 (0.0416)	
training:	Epoch: [44][166/204]	Loss 0.0087 (0.0414)	
training:	Epoch: [44][167/204]	Loss 0.0082 (0.0412)	
training:	Epoch: [44][168/204]	Loss 0.0199 (0.0410)	
training:	Epoch: [44][169/204]	Loss 0.0237 (0.0409)	
training:	Epoch: [44][170/204]	Loss 0.0080 (0.0407)	
training:	Epoch: [44][171/204]	Loss 0.0085 (0.0405)	
training:	Epoch: [44][172/204]	Loss 0.0086 (0.0404)	
training:	Epoch: [44][173/204]	Loss 0.0080 (0.0402)	
training:	Epoch: [44][174/204]	Loss 0.0183 (0.0400)	
training:	Epoch: [44][175/204]	Loss 0.0098 (0.0399)	
training:	Epoch: [44][176/204]	Loss 0.0088 (0.0397)	
training:	Epoch: [44][177/204]	Loss 0.0088 (0.0395)	
training:	Epoch: [44][178/204]	Loss 0.0162 (0.0394)	
training:	Epoch: [44][179/204]	Loss 0.0082 (0.0392)	
training:	Epoch: [44][180/204]	Loss 0.1342 (0.0397)	
training:	Epoch: [44][181/204]	Loss 0.0086 (0.0396)	
training:	Epoch: [44][182/204]	Loss 0.1879 (0.0404)	
training:	Epoch: [44][183/204]	Loss 0.0079 (0.0402)	
training:	Epoch: [44][184/204]	Loss 0.2890 (0.0416)	
training:	Epoch: [44][185/204]	Loss 0.0128 (0.0414)	
training:	Epoch: [44][186/204]	Loss 0.1299 (0.0419)	
training:	Epoch: [44][187/204]	Loss 0.0076 (0.0417)	
training:	Epoch: [44][188/204]	Loss 0.0088 (0.0415)	
training:	Epoch: [44][189/204]	Loss 0.0103 (0.0414)	
training:	Epoch: [44][190/204]	Loss 0.0083 (0.0412)	
training:	Epoch: [44][191/204]	Loss 0.0085 (0.0410)	
training:	Epoch: [44][192/204]	Loss 0.0099 (0.0409)	
training:	Epoch: [44][193/204]	Loss 0.1337 (0.0413)	
training:	Epoch: [44][194/204]	Loss 0.0085 (0.0412)	
training:	Epoch: [44][195/204]	Loss 0.0077 (0.0410)	
training:	Epoch: [44][196/204]	Loss 0.0090 (0.0408)	
training:	Epoch: [44][197/204]	Loss 0.3023 (0.0422)	
training:	Epoch: [44][198/204]	Loss 0.1403 (0.0427)	
training:	Epoch: [44][199/204]	Loss 0.1591 (0.0432)	
training:	Epoch: [44][200/204]	Loss 0.0077 (0.0431)	
training:	Epoch: [44][201/204]	Loss 0.0141 (0.0429)	
training:	Epoch: [44][202/204]	Loss 0.0085 (0.0427)	
training:	Epoch: [44][203/204]	Loss 0.0083 (0.0426)	
training:	Epoch: [44][204/204]	Loss 0.0093 (0.0424)	
Training:	 Loss: 0.0423

Training:	 ACC: 0.9928 0.9928 0.9929 0.9927
Validation:	 ACC: 0.7791 0.7796 0.7902 0.7679
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9686
Pretraining:	Epoch 45/500
----------
training:	Epoch: [45][1/204]	Loss 0.0081 (0.0081)	
training:	Epoch: [45][2/204]	Loss 0.0080 (0.0081)	
training:	Epoch: [45][3/204]	Loss 0.0117 (0.0093)	
training:	Epoch: [45][4/204]	Loss 0.1168 (0.0361)	
training:	Epoch: [45][5/204]	Loss 0.0098 (0.0309)	
training:	Epoch: [45][6/204]	Loss 0.0131 (0.0279)	
training:	Epoch: [45][7/204]	Loss 0.0078 (0.0250)	
training:	Epoch: [45][8/204]	Loss 0.0167 (0.0240)	
training:	Epoch: [45][9/204]	Loss 0.0080 (0.0222)	
training:	Epoch: [45][10/204]	Loss 0.0085 (0.0208)	
training:	Epoch: [45][11/204]	Loss 0.0133 (0.0202)	
training:	Epoch: [45][12/204]	Loss 0.0099 (0.0193)	
training:	Epoch: [45][13/204]	Loss 0.1576 (0.0299)	
training:	Epoch: [45][14/204]	Loss 0.0081 (0.0284)	
training:	Epoch: [45][15/204]	Loss 0.0102 (0.0272)	
training:	Epoch: [45][16/204]	Loss 0.0086 (0.0260)	
training:	Epoch: [45][17/204]	Loss 0.0088 (0.0250)	
training:	Epoch: [45][18/204]	Loss 0.0652 (0.0272)	
training:	Epoch: [45][19/204]	Loss 0.0086 (0.0263)	
training:	Epoch: [45][20/204]	Loss 0.0083 (0.0254)	
training:	Epoch: [45][21/204]	Loss 0.0080 (0.0245)	
training:	Epoch: [45][22/204]	Loss 0.0086 (0.0238)	
training:	Epoch: [45][23/204]	Loss 0.0101 (0.0232)	
training:	Epoch: [45][24/204]	Loss 0.0090 (0.0226)	
training:	Epoch: [45][25/204]	Loss 0.0082 (0.0220)	
training:	Epoch: [45][26/204]	Loss 0.0085 (0.0215)	
training:	Epoch: [45][27/204]	Loss 0.0083 (0.0210)	
training:	Epoch: [45][28/204]	Loss 0.0745 (0.0229)	
training:	Epoch: [45][29/204]	Loss 0.0076 (0.0224)	
training:	Epoch: [45][30/204]	Loss 0.0092 (0.0220)	
training:	Epoch: [45][31/204]	Loss 0.0084 (0.0215)	
training:	Epoch: [45][32/204]	Loss 0.1615 (0.0259)	
training:	Epoch: [45][33/204]	Loss 0.0078 (0.0254)	
training:	Epoch: [45][34/204]	Loss 0.0107 (0.0249)	
training:	Epoch: [45][35/204]	Loss 0.0085 (0.0245)	
training:	Epoch: [45][36/204]	Loss 0.3190 (0.0326)	
training:	Epoch: [45][37/204]	Loss 0.0089 (0.0320)	
training:	Epoch: [45][38/204]	Loss 0.0076 (0.0314)	
training:	Epoch: [45][39/204]	Loss 0.0084 (0.0308)	
training:	Epoch: [45][40/204]	Loss 0.0096 (0.0302)	
training:	Epoch: [45][41/204]	Loss 0.1513 (0.0332)	
training:	Epoch: [45][42/204]	Loss 0.1447 (0.0358)	
training:	Epoch: [45][43/204]	Loss 0.0089 (0.0352)	
training:	Epoch: [45][44/204]	Loss 0.0084 (0.0346)	
training:	Epoch: [45][45/204]	Loss 0.1592 (0.0374)	
training:	Epoch: [45][46/204]	Loss 0.0079 (0.0367)	
training:	Epoch: [45][47/204]	Loss 0.1511 (0.0392)	
training:	Epoch: [45][48/204]	Loss 0.0072 (0.0385)	
training:	Epoch: [45][49/204]	Loss 0.0087 (0.0379)	
training:	Epoch: [45][50/204]	Loss 0.0091 (0.0373)	
training:	Epoch: [45][51/204]	Loss 0.0095 (0.0368)	
training:	Epoch: [45][52/204]	Loss 0.0124 (0.0363)	
training:	Epoch: [45][53/204]	Loss 0.0084 (0.0358)	
training:	Epoch: [45][54/204]	Loss 0.0680 (0.0364)	
training:	Epoch: [45][55/204]	Loss 0.0081 (0.0359)	
training:	Epoch: [45][56/204]	Loss 0.0097 (0.0354)	
training:	Epoch: [45][57/204]	Loss 0.1726 (0.0378)	
training:	Epoch: [45][58/204]	Loss 0.0095 (0.0373)	
training:	Epoch: [45][59/204]	Loss 0.1458 (0.0392)	
training:	Epoch: [45][60/204]	Loss 0.1539 (0.0411)	
training:	Epoch: [45][61/204]	Loss 0.0241 (0.0408)	
training:	Epoch: [45][62/204]	Loss 0.1479 (0.0425)	
training:	Epoch: [45][63/204]	Loss 0.0096 (0.0420)	
training:	Epoch: [45][64/204]	Loss 0.1529 (0.0437)	
training:	Epoch: [45][65/204]	Loss 0.0086 (0.0432)	
training:	Epoch: [45][66/204]	Loss 0.0094 (0.0427)	
training:	Epoch: [45][67/204]	Loss 0.0087 (0.0422)	
training:	Epoch: [45][68/204]	Loss 0.0081 (0.0417)	
training:	Epoch: [45][69/204]	Loss 0.1608 (0.0434)	
training:	Epoch: [45][70/204]	Loss 0.0079 (0.0429)	
training:	Epoch: [45][71/204]	Loss 0.0098 (0.0424)	
training:	Epoch: [45][72/204]	Loss 0.0221 (0.0421)	
training:	Epoch: [45][73/204]	Loss 0.0090 (0.0417)	
training:	Epoch: [45][74/204]	Loss 0.0084 (0.0412)	
training:	Epoch: [45][75/204]	Loss 0.0107 (0.0408)	
training:	Epoch: [45][76/204]	Loss 0.0082 (0.0404)	
training:	Epoch: [45][77/204]	Loss 0.0077 (0.0400)	
training:	Epoch: [45][78/204]	Loss 0.1133 (0.0409)	
training:	Epoch: [45][79/204]	Loss 0.0100 (0.0405)	
training:	Epoch: [45][80/204]	Loss 0.0085 (0.0401)	
training:	Epoch: [45][81/204]	Loss 0.1629 (0.0416)	
training:	Epoch: [45][82/204]	Loss 0.1545 (0.0430)	
training:	Epoch: [45][83/204]	Loss 0.0098 (0.0426)	
training:	Epoch: [45][84/204]	Loss 0.0087 (0.0422)	
training:	Epoch: [45][85/204]	Loss 0.0080 (0.0418)	
training:	Epoch: [45][86/204]	Loss 0.1453 (0.0430)	
training:	Epoch: [45][87/204]	Loss 0.0092 (0.0426)	
training:	Epoch: [45][88/204]	Loss 0.0074 (0.0422)	
training:	Epoch: [45][89/204]	Loss 0.0100 (0.0419)	
training:	Epoch: [45][90/204]	Loss 0.0109 (0.0415)	
training:	Epoch: [45][91/204]	Loss 0.1510 (0.0427)	
training:	Epoch: [45][92/204]	Loss 0.0213 (0.0425)	
training:	Epoch: [45][93/204]	Loss 0.0103 (0.0421)	
training:	Epoch: [45][94/204]	Loss 0.1550 (0.0433)	
training:	Epoch: [45][95/204]	Loss 0.0113 (0.0430)	
training:	Epoch: [45][96/204]	Loss 0.0101 (0.0427)	
training:	Epoch: [45][97/204]	Loss 0.0115 (0.0423)	
training:	Epoch: [45][98/204]	Loss 0.0083 (0.0420)	
training:	Epoch: [45][99/204]	Loss 0.1673 (0.0433)	
training:	Epoch: [45][100/204]	Loss 0.0107 (0.0429)	
training:	Epoch: [45][101/204]	Loss 0.0087 (0.0426)	
training:	Epoch: [45][102/204]	Loss 0.0101 (0.0423)	
training:	Epoch: [45][103/204]	Loss 0.0081 (0.0419)	
training:	Epoch: [45][104/204]	Loss 0.0095 (0.0416)	
training:	Epoch: [45][105/204]	Loss 0.0099 (0.0413)	
training:	Epoch: [45][106/204]	Loss 0.0083 (0.0410)	
training:	Epoch: [45][107/204]	Loss 0.0086 (0.0407)	
training:	Epoch: [45][108/204]	Loss 0.3093 (0.0432)	
training:	Epoch: [45][109/204]	Loss 0.0779 (0.0435)	
training:	Epoch: [45][110/204]	Loss 0.0088 (0.0432)	
training:	Epoch: [45][111/204]	Loss 0.1593 (0.0442)	
training:	Epoch: [45][112/204]	Loss 0.0091 (0.0439)	
training:	Epoch: [45][113/204]	Loss 0.4956 (0.0479)	
training:	Epoch: [45][114/204]	Loss 0.0111 (0.0476)	
training:	Epoch: [45][115/204]	Loss 0.0078 (0.0473)	
training:	Epoch: [45][116/204]	Loss 0.0087 (0.0469)	
training:	Epoch: [45][117/204]	Loss 0.0087 (0.0466)	
training:	Epoch: [45][118/204]	Loss 0.0115 (0.0463)	
training:	Epoch: [45][119/204]	Loss 0.0109 (0.0460)	
training:	Epoch: [45][120/204]	Loss 0.0121 (0.0457)	
training:	Epoch: [45][121/204]	Loss 0.1426 (0.0465)	
training:	Epoch: [45][122/204]	Loss 0.0078 (0.0462)	
training:	Epoch: [45][123/204]	Loss 0.0085 (0.0459)	
training:	Epoch: [45][124/204]	Loss 0.0914 (0.0463)	
training:	Epoch: [45][125/204]	Loss 0.0097 (0.0460)	
training:	Epoch: [45][126/204]	Loss 0.0103 (0.0457)	
training:	Epoch: [45][127/204]	Loss 0.0106 (0.0454)	
training:	Epoch: [45][128/204]	Loss 0.0086 (0.0451)	
training:	Epoch: [45][129/204]	Loss 0.0086 (0.0448)	
training:	Epoch: [45][130/204]	Loss 0.0106 (0.0446)	
training:	Epoch: [45][131/204]	Loss 0.0101 (0.0443)	
training:	Epoch: [45][132/204]	Loss 0.0408 (0.0443)	
training:	Epoch: [45][133/204]	Loss 0.0115 (0.0440)	
training:	Epoch: [45][134/204]	Loss 0.1586 (0.0449)	
training:	Epoch: [45][135/204]	Loss 0.1381 (0.0456)	
training:	Epoch: [45][136/204]	Loss 0.0082 (0.0453)	
training:	Epoch: [45][137/204]	Loss 0.0100 (0.0451)	
training:	Epoch: [45][138/204]	Loss 0.1318 (0.0457)	
training:	Epoch: [45][139/204]	Loss 0.0080 (0.0454)	
training:	Epoch: [45][140/204]	Loss 0.1543 (0.0462)	
training:	Epoch: [45][141/204]	Loss 0.0091 (0.0459)	
training:	Epoch: [45][142/204]	Loss 0.0571 (0.0460)	
training:	Epoch: [45][143/204]	Loss 0.0083 (0.0457)	
training:	Epoch: [45][144/204]	Loss 0.0133 (0.0455)	
training:	Epoch: [45][145/204]	Loss 0.0073 (0.0453)	
training:	Epoch: [45][146/204]	Loss 0.0448 (0.0453)	
training:	Epoch: [45][147/204]	Loss 0.0082 (0.0450)	
training:	Epoch: [45][148/204]	Loss 0.1361 (0.0456)	
training:	Epoch: [45][149/204]	Loss 0.2650 (0.0471)	
training:	Epoch: [45][150/204]	Loss 0.0411 (0.0470)	
training:	Epoch: [45][151/204]	Loss 0.0094 (0.0468)	
training:	Epoch: [45][152/204]	Loss 0.0099 (0.0466)	
training:	Epoch: [45][153/204]	Loss 0.0084 (0.0463)	
training:	Epoch: [45][154/204]	Loss 0.0100 (0.0461)	
training:	Epoch: [45][155/204]	Loss 0.0087 (0.0458)	
training:	Epoch: [45][156/204]	Loss 0.0491 (0.0459)	
training:	Epoch: [45][157/204]	Loss 0.1575 (0.0466)	
training:	Epoch: [45][158/204]	Loss 0.0102 (0.0463)	
training:	Epoch: [45][159/204]	Loss 0.0099 (0.0461)	
training:	Epoch: [45][160/204]	Loss 0.0092 (0.0459)	
training:	Epoch: [45][161/204]	Loss 0.0099 (0.0457)	
training:	Epoch: [45][162/204]	Loss 0.0127 (0.0454)	
training:	Epoch: [45][163/204]	Loss 0.0099 (0.0452)	
training:	Epoch: [45][164/204]	Loss 0.0122 (0.0450)	
training:	Epoch: [45][165/204]	Loss 0.0090 (0.0448)	
training:	Epoch: [45][166/204]	Loss 0.0090 (0.0446)	
training:	Epoch: [45][167/204]	Loss 0.0131 (0.0444)	
training:	Epoch: [45][168/204]	Loss 0.0087 (0.0442)	
training:	Epoch: [45][169/204]	Loss 0.1653 (0.0449)	
training:	Epoch: [45][170/204]	Loss 0.0107 (0.0447)	
training:	Epoch: [45][171/204]	Loss 0.0206 (0.0446)	
training:	Epoch: [45][172/204]	Loss 0.1383 (0.0451)	
training:	Epoch: [45][173/204]	Loss 0.0852 (0.0453)	
training:	Epoch: [45][174/204]	Loss 0.0082 (0.0451)	
training:	Epoch: [45][175/204]	Loss 0.0090 (0.0449)	
training:	Epoch: [45][176/204]	Loss 0.0156 (0.0448)	
training:	Epoch: [45][177/204]	Loss 0.0100 (0.0446)	
training:	Epoch: [45][178/204]	Loss 0.0081 (0.0444)	
training:	Epoch: [45][179/204]	Loss 0.0080 (0.0442)	
training:	Epoch: [45][180/204]	Loss 0.0089 (0.0440)	
training:	Epoch: [45][181/204]	Loss 0.0154 (0.0438)	
training:	Epoch: [45][182/204]	Loss 0.0079 (0.0436)	
training:	Epoch: [45][183/204]	Loss 0.0741 (0.0438)	
training:	Epoch: [45][184/204]	Loss 0.0083 (0.0436)	
training:	Epoch: [45][185/204]	Loss 0.0091 (0.0434)	
training:	Epoch: [45][186/204]	Loss 0.0098 (0.0432)	
training:	Epoch: [45][187/204]	Loss 0.0088 (0.0430)	
training:	Epoch: [45][188/204]	Loss 0.0108 (0.0429)	
training:	Epoch: [45][189/204]	Loss 0.0097 (0.0427)	
training:	Epoch: [45][190/204]	Loss 0.0078 (0.0425)	
training:	Epoch: [45][191/204]	Loss 0.0119 (0.0423)	
training:	Epoch: [45][192/204]	Loss 0.0532 (0.0424)	
training:	Epoch: [45][193/204]	Loss 0.0104 (0.0422)	
training:	Epoch: [45][194/204]	Loss 0.1590 (0.0428)	
training:	Epoch: [45][195/204]	Loss 0.0086 (0.0427)	
training:	Epoch: [45][196/204]	Loss 0.0095 (0.0425)	
training:	Epoch: [45][197/204]	Loss 0.0087 (0.0423)	
training:	Epoch: [45][198/204]	Loss 0.1540 (0.0429)	
training:	Epoch: [45][199/204]	Loss 0.2991 (0.0442)	
training:	Epoch: [45][200/204]	Loss 0.0101 (0.0440)	
training:	Epoch: [45][201/204]	Loss 0.1589 (0.0446)	
training:	Epoch: [45][202/204]	Loss 0.0113 (0.0444)	
training:	Epoch: [45][203/204]	Loss 0.0094 (0.0442)	
training:	Epoch: [45][204/204]	Loss 0.0114 (0.0441)	
Training:	 Loss: 0.0440

Training:	 ACC: 0.9925 0.9925 0.9935 0.9914
Validation:	 ACC: 0.7797 0.7822 0.8352 0.7242
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9605
Pretraining:	Epoch 46/500
----------
training:	Epoch: [46][1/204]	Loss 0.0084 (0.0084)	
training:	Epoch: [46][2/204]	Loss 0.1478 (0.0781)	
training:	Epoch: [46][3/204]	Loss 0.0082 (0.0548)	
training:	Epoch: [46][4/204]	Loss 0.0090 (0.0434)	
training:	Epoch: [46][5/204]	Loss 0.0164 (0.0380)	
training:	Epoch: [46][6/204]	Loss 0.0072 (0.0328)	
training:	Epoch: [46][7/204]	Loss 0.0272 (0.0320)	
training:	Epoch: [46][8/204]	Loss 0.0085 (0.0291)	
training:	Epoch: [46][9/204]	Loss 0.0081 (0.0268)	
training:	Epoch: [46][10/204]	Loss 0.0102 (0.0251)	
training:	Epoch: [46][11/204]	Loss 0.0109 (0.0238)	
training:	Epoch: [46][12/204]	Loss 0.0076 (0.0225)	
training:	Epoch: [46][13/204]	Loss 0.0081 (0.0214)	
training:	Epoch: [46][14/204]	Loss 0.0088 (0.0205)	
training:	Epoch: [46][15/204]	Loss 0.0111 (0.0198)	
training:	Epoch: [46][16/204]	Loss 0.1414 (0.0274)	
training:	Epoch: [46][17/204]	Loss 0.0086 (0.0263)	
training:	Epoch: [46][18/204]	Loss 0.1063 (0.0308)	
training:	Epoch: [46][19/204]	Loss 0.0080 (0.0296)	
training:	Epoch: [46][20/204]	Loss 0.1207 (0.0341)	
training:	Epoch: [46][21/204]	Loss 0.0087 (0.0329)	
training:	Epoch: [46][22/204]	Loss 0.0088 (0.0318)	
training:	Epoch: [46][23/204]	Loss 0.0078 (0.0308)	
training:	Epoch: [46][24/204]	Loss 0.1711 (0.0366)	
training:	Epoch: [46][25/204]	Loss 0.1558 (0.0414)	
training:	Epoch: [46][26/204]	Loss 0.0359 (0.0412)	
training:	Epoch: [46][27/204]	Loss 0.0168 (0.0403)	
training:	Epoch: [46][28/204]	Loss 0.0095 (0.0392)	
training:	Epoch: [46][29/204]	Loss 0.0089 (0.0381)	
training:	Epoch: [46][30/204]	Loss 0.0085 (0.0371)	
training:	Epoch: [46][31/204]	Loss 0.0105 (0.0363)	
training:	Epoch: [46][32/204]	Loss 0.0095 (0.0354)	
training:	Epoch: [46][33/204]	Loss 0.0076 (0.0346)	
training:	Epoch: [46][34/204]	Loss 0.0109 (0.0339)	
training:	Epoch: [46][35/204]	Loss 0.0083 (0.0332)	
training:	Epoch: [46][36/204]	Loss 0.0090 (0.0325)	
training:	Epoch: [46][37/204]	Loss 0.1579 (0.0359)	
training:	Epoch: [46][38/204]	Loss 0.0475 (0.0362)	
training:	Epoch: [46][39/204]	Loss 0.0073 (0.0355)	
training:	Epoch: [46][40/204]	Loss 0.0089 (0.0348)	
training:	Epoch: [46][41/204]	Loss 0.0091 (0.0342)	
training:	Epoch: [46][42/204]	Loss 0.0093 (0.0336)	
training:	Epoch: [46][43/204]	Loss 0.0114 (0.0331)	
training:	Epoch: [46][44/204]	Loss 0.0084 (0.0325)	
training:	Epoch: [46][45/204]	Loss 0.0186 (0.0322)	
training:	Epoch: [46][46/204]	Loss 0.0081 (0.0317)	
training:	Epoch: [46][47/204]	Loss 0.0085 (0.0312)	
training:	Epoch: [46][48/204]	Loss 0.0105 (0.0307)	
training:	Epoch: [46][49/204]	Loss 0.0083 (0.0303)	
training:	Epoch: [46][50/204]	Loss 0.0777 (0.0312)	
training:	Epoch: [46][51/204]	Loss 0.0077 (0.0308)	
training:	Epoch: [46][52/204]	Loss 0.0077 (0.0303)	
training:	Epoch: [46][53/204]	Loss 0.0095 (0.0299)	
training:	Epoch: [46][54/204]	Loss 0.0105 (0.0296)	
training:	Epoch: [46][55/204]	Loss 0.0069 (0.0292)	
training:	Epoch: [46][56/204]	Loss 0.1594 (0.0315)	
training:	Epoch: [46][57/204]	Loss 0.1410 (0.0334)	
training:	Epoch: [46][58/204]	Loss 0.0092 (0.0330)	
training:	Epoch: [46][59/204]	Loss 0.0081 (0.0326)	
training:	Epoch: [46][60/204]	Loss 0.0096 (0.0322)	
training:	Epoch: [46][61/204]	Loss 0.0082 (0.0318)	
training:	Epoch: [46][62/204]	Loss 0.0097 (0.0314)	
training:	Epoch: [46][63/204]	Loss 0.0076 (0.0311)	
training:	Epoch: [46][64/204]	Loss 0.1529 (0.0330)	
training:	Epoch: [46][65/204]	Loss 0.0146 (0.0327)	
training:	Epoch: [46][66/204]	Loss 0.0125 (0.0324)	
training:	Epoch: [46][67/204]	Loss 0.1515 (0.0342)	
training:	Epoch: [46][68/204]	Loss 0.0079 (0.0338)	
training:	Epoch: [46][69/204]	Loss 0.0066 (0.0334)	
training:	Epoch: [46][70/204]	Loss 0.1577 (0.0351)	
training:	Epoch: [46][71/204]	Loss 0.0082 (0.0348)	
training:	Epoch: [46][72/204]	Loss 0.0076 (0.0344)	
training:	Epoch: [46][73/204]	Loss 0.0078 (0.0340)	
training:	Epoch: [46][74/204]	Loss 0.0083 (0.0337)	
training:	Epoch: [46][75/204]	Loss 0.0079 (0.0333)	
training:	Epoch: [46][76/204]	Loss 0.0178 (0.0331)	
training:	Epoch: [46][77/204]	Loss 0.0079 (0.0328)	
training:	Epoch: [46][78/204]	Loss 0.1520 (0.0343)	
training:	Epoch: [46][79/204]	Loss 0.1597 (0.0359)	
training:	Epoch: [46][80/204]	Loss 0.0085 (0.0356)	
training:	Epoch: [46][81/204]	Loss 0.0427 (0.0357)	
training:	Epoch: [46][82/204]	Loss 0.0103 (0.0354)	
training:	Epoch: [46][83/204]	Loss 0.0079 (0.0350)	
training:	Epoch: [46][84/204]	Loss 0.0079 (0.0347)	
training:	Epoch: [46][85/204]	Loss 0.0086 (0.0344)	
training:	Epoch: [46][86/204]	Loss 0.0073 (0.0341)	
training:	Epoch: [46][87/204]	Loss 0.0084 (0.0338)	
training:	Epoch: [46][88/204]	Loss 0.0081 (0.0335)	
training:	Epoch: [46][89/204]	Loss 0.0075 (0.0332)	
training:	Epoch: [46][90/204]	Loss 0.0090 (0.0329)	
training:	Epoch: [46][91/204]	Loss 0.0088 (0.0327)	
training:	Epoch: [46][92/204]	Loss 0.1542 (0.0340)	
training:	Epoch: [46][93/204]	Loss 0.0079 (0.0337)	
training:	Epoch: [46][94/204]	Loss 0.0081 (0.0334)	
training:	Epoch: [46][95/204]	Loss 0.0322 (0.0334)	
training:	Epoch: [46][96/204]	Loss 0.1546 (0.0347)	
training:	Epoch: [46][97/204]	Loss 0.1608 (0.0360)	
training:	Epoch: [46][98/204]	Loss 0.0074 (0.0357)	
training:	Epoch: [46][99/204]	Loss 0.1347 (0.0367)	
training:	Epoch: [46][100/204]	Loss 0.0090 (0.0364)	
training:	Epoch: [46][101/204]	Loss 0.0088 (0.0361)	
training:	Epoch: [46][102/204]	Loss 0.0138 (0.0359)	
training:	Epoch: [46][103/204]	Loss 0.0084 (0.0357)	
training:	Epoch: [46][104/204]	Loss 0.0076 (0.0354)	
training:	Epoch: [46][105/204]	Loss 0.0077 (0.0351)	
training:	Epoch: [46][106/204]	Loss 0.0075 (0.0349)	
training:	Epoch: [46][107/204]	Loss 0.0082 (0.0346)	
training:	Epoch: [46][108/204]	Loss 0.1485 (0.0357)	
training:	Epoch: [46][109/204]	Loss 0.1601 (0.0368)	
training:	Epoch: [46][110/204]	Loss 0.0167 (0.0366)	
training:	Epoch: [46][111/204]	Loss 0.0085 (0.0364)	
training:	Epoch: [46][112/204]	Loss 0.0103 (0.0361)	
training:	Epoch: [46][113/204]	Loss 0.0081 (0.0359)	
training:	Epoch: [46][114/204]	Loss 0.1581 (0.0370)	
training:	Epoch: [46][115/204]	Loss 0.0079 (0.0367)	
training:	Epoch: [46][116/204]	Loss 0.1321 (0.0375)	
training:	Epoch: [46][117/204]	Loss 0.0077 (0.0373)	
training:	Epoch: [46][118/204]	Loss 0.0074 (0.0370)	
training:	Epoch: [46][119/204]	Loss 0.0093 (0.0368)	
training:	Epoch: [46][120/204]	Loss 0.0069 (0.0365)	
training:	Epoch: [46][121/204]	Loss 0.0101 (0.0363)	
training:	Epoch: [46][122/204]	Loss 0.0211 (0.0362)	
training:	Epoch: [46][123/204]	Loss 0.0108 (0.0360)	
training:	Epoch: [46][124/204]	Loss 0.0078 (0.0358)	
training:	Epoch: [46][125/204]	Loss 0.0078 (0.0355)	
training:	Epoch: [46][126/204]	Loss 0.0084 (0.0353)	
training:	Epoch: [46][127/204]	Loss 0.0093 (0.0351)	
training:	Epoch: [46][128/204]	Loss 0.0079 (0.0349)	
training:	Epoch: [46][129/204]	Loss 0.0080 (0.0347)	
training:	Epoch: [46][130/204]	Loss 0.0902 (0.0351)	
training:	Epoch: [46][131/204]	Loss 0.0094 (0.0349)	
training:	Epoch: [46][132/204]	Loss 0.1514 (0.0358)	
training:	Epoch: [46][133/204]	Loss 0.0111 (0.0356)	
training:	Epoch: [46][134/204]	Loss 0.1525 (0.0365)	
training:	Epoch: [46][135/204]	Loss 0.1545 (0.0374)	
training:	Epoch: [46][136/204]	Loss 0.0076 (0.0372)	
training:	Epoch: [46][137/204]	Loss 0.0131 (0.0370)	
training:	Epoch: [46][138/204]	Loss 0.0089 (0.0368)	
training:	Epoch: [46][139/204]	Loss 0.0174 (0.0366)	
training:	Epoch: [46][140/204]	Loss 0.0095 (0.0364)	
training:	Epoch: [46][141/204]	Loss 0.1626 (0.0373)	
training:	Epoch: [46][142/204]	Loss 0.0127 (0.0372)	
training:	Epoch: [46][143/204]	Loss 0.1624 (0.0380)	
training:	Epoch: [46][144/204]	Loss 0.1521 (0.0388)	
training:	Epoch: [46][145/204]	Loss 0.0203 (0.0387)	
training:	Epoch: [46][146/204]	Loss 0.0143 (0.0385)	
training:	Epoch: [46][147/204]	Loss 0.0101 (0.0383)	
training:	Epoch: [46][148/204]	Loss 0.0091 (0.0381)	
training:	Epoch: [46][149/204]	Loss 0.0102 (0.0380)	
training:	Epoch: [46][150/204]	Loss 0.0090 (0.0378)	
training:	Epoch: [46][151/204]	Loss 0.0084 (0.0376)	
training:	Epoch: [46][152/204]	Loss 0.0072 (0.0374)	
training:	Epoch: [46][153/204]	Loss 0.1494 (0.0381)	
training:	Epoch: [46][154/204]	Loss 0.0093 (0.0379)	
training:	Epoch: [46][155/204]	Loss 0.0080 (0.0377)	
training:	Epoch: [46][156/204]	Loss 0.0213 (0.0376)	
training:	Epoch: [46][157/204]	Loss 0.1605 (0.0384)	
training:	Epoch: [46][158/204]	Loss 0.0081 (0.0382)	
training:	Epoch: [46][159/204]	Loss 0.3095 (0.0399)	
training:	Epoch: [46][160/204]	Loss 0.1515 (0.0406)	
training:	Epoch: [46][161/204]	Loss 0.1453 (0.0413)	
training:	Epoch: [46][162/204]	Loss 0.0073 (0.0411)	
training:	Epoch: [46][163/204]	Loss 0.0101 (0.0409)	
training:	Epoch: [46][164/204]	Loss 0.0312 (0.0408)	
training:	Epoch: [46][165/204]	Loss 0.0080 (0.0406)	
training:	Epoch: [46][166/204]	Loss 0.1595 (0.0413)	
training:	Epoch: [46][167/204]	Loss 0.1501 (0.0420)	
training:	Epoch: [46][168/204]	Loss 0.0090 (0.0418)	
training:	Epoch: [46][169/204]	Loss 0.0083 (0.0416)	
training:	Epoch: [46][170/204]	Loss 0.0092 (0.0414)	
training:	Epoch: [46][171/204]	Loss 0.0089 (0.0412)	
training:	Epoch: [46][172/204]	Loss 0.0108 (0.0410)	
training:	Epoch: [46][173/204]	Loss 0.0077 (0.0408)	
training:	Epoch: [46][174/204]	Loss 0.0100 (0.0407)	
training:	Epoch: [46][175/204]	Loss 0.0098 (0.0405)	
training:	Epoch: [46][176/204]	Loss 0.0082 (0.0403)	
training:	Epoch: [46][177/204]	Loss 0.0096 (0.0401)	
training:	Epoch: [46][178/204]	Loss 0.0082 (0.0399)	
training:	Epoch: [46][179/204]	Loss 0.1629 (0.0406)	
training:	Epoch: [46][180/204]	Loss 0.1656 (0.0413)	
training:	Epoch: [46][181/204]	Loss 0.0380 (0.0413)	
training:	Epoch: [46][182/204]	Loss 0.0131 (0.0411)	
training:	Epoch: [46][183/204]	Loss 0.0093 (0.0410)	
training:	Epoch: [46][184/204]	Loss 0.0097 (0.0408)	
training:	Epoch: [46][185/204]	Loss 0.1584 (0.0414)	
training:	Epoch: [46][186/204]	Loss 0.0077 (0.0413)	
training:	Epoch: [46][187/204]	Loss 0.0082 (0.0411)	
training:	Epoch: [46][188/204]	Loss 0.0081 (0.0409)	
training:	Epoch: [46][189/204]	Loss 0.1585 (0.0415)	
training:	Epoch: [46][190/204]	Loss 0.0089 (0.0414)	
training:	Epoch: [46][191/204]	Loss 0.0075 (0.0412)	
training:	Epoch: [46][192/204]	Loss 0.0077 (0.0410)	
training:	Epoch: [46][193/204]	Loss 0.0108 (0.0408)	
training:	Epoch: [46][194/204]	Loss 0.0854 (0.0411)	
training:	Epoch: [46][195/204]	Loss 0.0078 (0.0409)	
training:	Epoch: [46][196/204]	Loss 0.0089 (0.0407)	
training:	Epoch: [46][197/204]	Loss 0.0082 (0.0406)	
training:	Epoch: [46][198/204]	Loss 0.0103 (0.0404)	
training:	Epoch: [46][199/204]	Loss 0.1390 (0.0409)	
training:	Epoch: [46][200/204]	Loss 0.0083 (0.0408)	
training:	Epoch: [46][201/204]	Loss 0.0093 (0.0406)	
training:	Epoch: [46][202/204]	Loss 0.0088 (0.0404)	
training:	Epoch: [46][203/204]	Loss 0.1268 (0.0409)	
training:	Epoch: [46][204/204]	Loss 0.0092 (0.0407)	
Training:	 Loss: 0.0407

Training:	 ACC: 0.9931 0.9931 0.9932 0.9930
Validation:	 ACC: 0.7835 0.7833 0.7799 0.7870
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9761
Pretraining:	Epoch 47/500
----------
training:	Epoch: [47][1/204]	Loss 0.0086 (0.0086)	
training:	Epoch: [47][2/204]	Loss 0.1584 (0.0835)	
training:	Epoch: [47][3/204]	Loss 0.0086 (0.0585)	
training:	Epoch: [47][4/204]	Loss 0.0084 (0.0460)	
training:	Epoch: [47][5/204]	Loss 0.0085 (0.0385)	
training:	Epoch: [47][6/204]	Loss 0.0083 (0.0335)	
training:	Epoch: [47][7/204]	Loss 0.0088 (0.0299)	
training:	Epoch: [47][8/204]	Loss 0.1361 (0.0432)	
training:	Epoch: [47][9/204]	Loss 0.0101 (0.0395)	
training:	Epoch: [47][10/204]	Loss 0.0102 (0.0366)	
training:	Epoch: [47][11/204]	Loss 0.0085 (0.0340)	
training:	Epoch: [47][12/204]	Loss 0.0080 (0.0319)	
training:	Epoch: [47][13/204]	Loss 0.0080 (0.0300)	
training:	Epoch: [47][14/204]	Loss 0.0082 (0.0285)	
training:	Epoch: [47][15/204]	Loss 0.0086 (0.0272)	
training:	Epoch: [47][16/204]	Loss 0.0076 (0.0259)	
training:	Epoch: [47][17/204]	Loss 0.1388 (0.0326)	
training:	Epoch: [47][18/204]	Loss 0.1589 (0.0396)	
training:	Epoch: [47][19/204]	Loss 0.2429 (0.0503)	
training:	Epoch: [47][20/204]	Loss 0.0085 (0.0482)	
training:	Epoch: [47][21/204]	Loss 0.0080 (0.0463)	
training:	Epoch: [47][22/204]	Loss 0.2837 (0.0571)	
training:	Epoch: [47][23/204]	Loss 0.0078 (0.0549)	
training:	Epoch: [47][24/204]	Loss 0.0088 (0.0530)	
training:	Epoch: [47][25/204]	Loss 0.0093 (0.0513)	
training:	Epoch: [47][26/204]	Loss 0.0075 (0.0496)	
training:	Epoch: [47][27/204]	Loss 0.0102 (0.0481)	
training:	Epoch: [47][28/204]	Loss 0.1511 (0.0518)	
training:	Epoch: [47][29/204]	Loss 0.0091 (0.0503)	
training:	Epoch: [47][30/204]	Loss 0.0119 (0.0490)	
training:	Epoch: [47][31/204]	Loss 0.0079 (0.0477)	
training:	Epoch: [47][32/204]	Loss 0.0087 (0.0465)	
training:	Epoch: [47][33/204]	Loss 0.0087 (0.0454)	
training:	Epoch: [47][34/204]	Loss 0.0079 (0.0443)	
training:	Epoch: [47][35/204]	Loss 0.0097 (0.0433)	
training:	Epoch: [47][36/204]	Loss 0.0087 (0.0423)	
training:	Epoch: [47][37/204]	Loss 0.0078 (0.0414)	
training:	Epoch: [47][38/204]	Loss 0.0091 (0.0405)	
training:	Epoch: [47][39/204]	Loss 0.0077 (0.0397)	
training:	Epoch: [47][40/204]	Loss 0.1617 (0.0427)	
training:	Epoch: [47][41/204]	Loss 0.1575 (0.0455)	
training:	Epoch: [47][42/204]	Loss 0.0107 (0.0447)	
training:	Epoch: [47][43/204]	Loss 0.0086 (0.0439)	
training:	Epoch: [47][44/204]	Loss 0.0090 (0.0431)	
training:	Epoch: [47][45/204]	Loss 0.1523 (0.0455)	
training:	Epoch: [47][46/204]	Loss 0.0104 (0.0447)	
training:	Epoch: [47][47/204]	Loss 0.0094 (0.0440)	
training:	Epoch: [47][48/204]	Loss 0.0087 (0.0432)	
training:	Epoch: [47][49/204]	Loss 0.0131 (0.0426)	
training:	Epoch: [47][50/204]	Loss 0.1483 (0.0447)	
training:	Epoch: [47][51/204]	Loss 0.0079 (0.0440)	
training:	Epoch: [47][52/204]	Loss 0.0078 (0.0433)	
training:	Epoch: [47][53/204]	Loss 0.0090 (0.0427)	
training:	Epoch: [47][54/204]	Loss 0.0078 (0.0420)	
training:	Epoch: [47][55/204]	Loss 0.0081 (0.0414)	
training:	Epoch: [47][56/204]	Loss 0.1518 (0.0434)	
training:	Epoch: [47][57/204]	Loss 0.1241 (0.0448)	
training:	Epoch: [47][58/204]	Loss 0.0087 (0.0442)	
training:	Epoch: [47][59/204]	Loss 0.0099 (0.0436)	
training:	Epoch: [47][60/204]	Loss 0.0085 (0.0430)	
training:	Epoch: [47][61/204]	Loss 0.0082 (0.0424)	
training:	Epoch: [47][62/204]	Loss 0.0097 (0.0419)	
training:	Epoch: [47][63/204]	Loss 0.1388 (0.0435)	
training:	Epoch: [47][64/204]	Loss 0.0087 (0.0429)	
training:	Epoch: [47][65/204]	Loss 0.0083 (0.0424)	
training:	Epoch: [47][66/204]	Loss 0.0096 (0.0419)	
training:	Epoch: [47][67/204]	Loss 0.0084 (0.0414)	
training:	Epoch: [47][68/204]	Loss 0.0079 (0.0409)	
training:	Epoch: [47][69/204]	Loss 0.0141 (0.0405)	
training:	Epoch: [47][70/204]	Loss 0.0082 (0.0400)	
training:	Epoch: [47][71/204]	Loss 0.0096 (0.0396)	
training:	Epoch: [47][72/204]	Loss 0.0092 (0.0392)	
training:	Epoch: [47][73/204]	Loss 0.1880 (0.0412)	
training:	Epoch: [47][74/204]	Loss 0.0086 (0.0408)	
training:	Epoch: [47][75/204]	Loss 0.0121 (0.0404)	
training:	Epoch: [47][76/204]	Loss 0.1598 (0.0420)	
training:	Epoch: [47][77/204]	Loss 0.1481 (0.0434)	
training:	Epoch: [47][78/204]	Loss 0.0081 (0.0429)	
training:	Epoch: [47][79/204]	Loss 0.0096 (0.0425)	
training:	Epoch: [47][80/204]	Loss 0.0084 (0.0421)	
training:	Epoch: [47][81/204]	Loss 0.0073 (0.0416)	
training:	Epoch: [47][82/204]	Loss 0.0091 (0.0412)	
training:	Epoch: [47][83/204]	Loss 0.0093 (0.0408)	
training:	Epoch: [47][84/204]	Loss 0.0140 (0.0405)	
training:	Epoch: [47][85/204]	Loss 0.1479 (0.0418)	
training:	Epoch: [47][86/204]	Loss 0.0090 (0.0414)	
training:	Epoch: [47][87/204]	Loss 0.0083 (0.0410)	
training:	Epoch: [47][88/204]	Loss 0.0083 (0.0407)	
training:	Epoch: [47][89/204]	Loss 0.0074 (0.0403)	
training:	Epoch: [47][90/204]	Loss 0.1261 (0.0412)	
training:	Epoch: [47][91/204]	Loss 0.0090 (0.0409)	
training:	Epoch: [47][92/204]	Loss 0.0084 (0.0405)	
training:	Epoch: [47][93/204]	Loss 0.0332 (0.0404)	
training:	Epoch: [47][94/204]	Loss 0.0085 (0.0401)	
training:	Epoch: [47][95/204]	Loss 0.0079 (0.0398)	
training:	Epoch: [47][96/204]	Loss 0.0147 (0.0395)	
training:	Epoch: [47][97/204]	Loss 0.0078 (0.0392)	
training:	Epoch: [47][98/204]	Loss 0.0076 (0.0389)	
training:	Epoch: [47][99/204]	Loss 0.0081 (0.0385)	
training:	Epoch: [47][100/204]	Loss 0.0090 (0.0383)	
training:	Epoch: [47][101/204]	Loss 0.0080 (0.0380)	
training:	Epoch: [47][102/204]	Loss 0.1438 (0.0390)	
training:	Epoch: [47][103/204]	Loss 0.0088 (0.0387)	
training:	Epoch: [47][104/204]	Loss 0.0081 (0.0384)	
training:	Epoch: [47][105/204]	Loss 0.0081 (0.0381)	
training:	Epoch: [47][106/204]	Loss 0.0074 (0.0378)	
training:	Epoch: [47][107/204]	Loss 0.0133 (0.0376)	
training:	Epoch: [47][108/204]	Loss 0.0079 (0.0373)	
training:	Epoch: [47][109/204]	Loss 0.0081 (0.0371)	
training:	Epoch: [47][110/204]	Loss 0.0143 (0.0368)	
training:	Epoch: [47][111/204]	Loss 0.0075 (0.0366)	
training:	Epoch: [47][112/204]	Loss 0.0085 (0.0363)	
training:	Epoch: [47][113/204]	Loss 0.0093 (0.0361)	
training:	Epoch: [47][114/204]	Loss 0.0087 (0.0359)	
training:	Epoch: [47][115/204]	Loss 0.0078 (0.0356)	
training:	Epoch: [47][116/204]	Loss 0.0084 (0.0354)	
training:	Epoch: [47][117/204]	Loss 0.0089 (0.0351)	
training:	Epoch: [47][118/204]	Loss 0.1624 (0.0362)	
training:	Epoch: [47][119/204]	Loss 0.0089 (0.0360)	
training:	Epoch: [47][120/204]	Loss 0.0104 (0.0358)	
training:	Epoch: [47][121/204]	Loss 0.0076 (0.0355)	
training:	Epoch: [47][122/204]	Loss 0.1515 (0.0365)	
training:	Epoch: [47][123/204]	Loss 0.0081 (0.0363)	
training:	Epoch: [47][124/204]	Loss 0.0077 (0.0360)	
training:	Epoch: [47][125/204]	Loss 0.0088 (0.0358)	
training:	Epoch: [47][126/204]	Loss 0.1668 (0.0369)	
training:	Epoch: [47][127/204]	Loss 0.0084 (0.0366)	
training:	Epoch: [47][128/204]	Loss 0.0073 (0.0364)	
training:	Epoch: [47][129/204]	Loss 0.1641 (0.0374)	
training:	Epoch: [47][130/204]	Loss 0.0113 (0.0372)	
training:	Epoch: [47][131/204]	Loss 0.0080 (0.0370)	
training:	Epoch: [47][132/204]	Loss 0.1495 (0.0378)	
training:	Epoch: [47][133/204]	Loss 0.0075 (0.0376)	
training:	Epoch: [47][134/204]	Loss 0.0072 (0.0374)	
training:	Epoch: [47][135/204]	Loss 0.0075 (0.0371)	
training:	Epoch: [47][136/204]	Loss 0.0078 (0.0369)	
training:	Epoch: [47][137/204]	Loss 0.0079 (0.0367)	
training:	Epoch: [47][138/204]	Loss 0.1581 (0.0376)	
training:	Epoch: [47][139/204]	Loss 0.0079 (0.0374)	
training:	Epoch: [47][140/204]	Loss 0.0088 (0.0372)	
training:	Epoch: [47][141/204]	Loss 0.0085 (0.0370)	
training:	Epoch: [47][142/204]	Loss 0.0087 (0.0368)	
training:	Epoch: [47][143/204]	Loss 0.0080 (0.0366)	
training:	Epoch: [47][144/204]	Loss 0.0090 (0.0364)	
training:	Epoch: [47][145/204]	Loss 0.1544 (0.0372)	
training:	Epoch: [47][146/204]	Loss 0.1611 (0.0380)	
training:	Epoch: [47][147/204]	Loss 0.0074 (0.0378)	
training:	Epoch: [47][148/204]	Loss 0.0076 (0.0376)	
training:	Epoch: [47][149/204]	Loss 0.0087 (0.0374)	
training:	Epoch: [47][150/204]	Loss 0.1567 (0.0382)	
training:	Epoch: [47][151/204]	Loss 0.1079 (0.0387)	
training:	Epoch: [47][152/204]	Loss 0.0069 (0.0385)	
training:	Epoch: [47][153/204]	Loss 0.0077 (0.0383)	
training:	Epoch: [47][154/204]	Loss 0.0074 (0.0381)	
training:	Epoch: [47][155/204]	Loss 0.0096 (0.0379)	
training:	Epoch: [47][156/204]	Loss 0.0072 (0.0377)	
training:	Epoch: [47][157/204]	Loss 0.1656 (0.0385)	
training:	Epoch: [47][158/204]	Loss 0.0072 (0.0383)	
training:	Epoch: [47][159/204]	Loss 0.0080 (0.0381)	
training:	Epoch: [47][160/204]	Loss 0.0075 (0.0379)	
training:	Epoch: [47][161/204]	Loss 0.0074 (0.0378)	
training:	Epoch: [47][162/204]	Loss 0.0076 (0.0376)	
training:	Epoch: [47][163/204]	Loss 0.2961 (0.0392)	
training:	Epoch: [47][164/204]	Loss 0.0076 (0.0390)	
training:	Epoch: [47][165/204]	Loss 0.1664 (0.0397)	
training:	Epoch: [47][166/204]	Loss 0.0090 (0.0395)	
training:	Epoch: [47][167/204]	Loss 0.0083 (0.0394)	
training:	Epoch: [47][168/204]	Loss 0.0071 (0.0392)	
training:	Epoch: [47][169/204]	Loss 0.0094 (0.0390)	
training:	Epoch: [47][170/204]	Loss 0.0076 (0.0388)	
training:	Epoch: [47][171/204]	Loss 0.0087 (0.0386)	
training:	Epoch: [47][172/204]	Loss 0.0081 (0.0385)	
training:	Epoch: [47][173/204]	Loss 0.0611 (0.0386)	
training:	Epoch: [47][174/204]	Loss 0.1571 (0.0393)	
training:	Epoch: [47][175/204]	Loss 0.0082 (0.0391)	
training:	Epoch: [47][176/204]	Loss 0.1444 (0.0397)	
training:	Epoch: [47][177/204]	Loss 0.0087 (0.0395)	
training:	Epoch: [47][178/204]	Loss 0.0087 (0.0393)	
training:	Epoch: [47][179/204]	Loss 0.0088 (0.0392)	
training:	Epoch: [47][180/204]	Loss 0.0085 (0.0390)	
training:	Epoch: [47][181/204]	Loss 0.0120 (0.0388)	
training:	Epoch: [47][182/204]	Loss 0.0095 (0.0387)	
training:	Epoch: [47][183/204]	Loss 0.0081 (0.0385)	
training:	Epoch: [47][184/204]	Loss 0.0080 (0.0384)	
training:	Epoch: [47][185/204]	Loss 0.2691 (0.0396)	
training:	Epoch: [47][186/204]	Loss 0.0108 (0.0394)	
training:	Epoch: [47][187/204]	Loss 0.0074 (0.0393)	
training:	Epoch: [47][188/204]	Loss 0.0077 (0.0391)	
training:	Epoch: [47][189/204]	Loss 0.0083 (0.0389)	
training:	Epoch: [47][190/204]	Loss 0.0084 (0.0388)	
training:	Epoch: [47][191/204]	Loss 0.1457 (0.0393)	
training:	Epoch: [47][192/204]	Loss 0.0073 (0.0392)	
training:	Epoch: [47][193/204]	Loss 0.0081 (0.0390)	
training:	Epoch: [47][194/204]	Loss 0.1577 (0.0396)	
training:	Epoch: [47][195/204]	Loss 0.0078 (0.0395)	
training:	Epoch: [47][196/204]	Loss 0.0081 (0.0393)	
training:	Epoch: [47][197/204]	Loss 0.1250 (0.0397)	
training:	Epoch: [47][198/204]	Loss 0.0090 (0.0396)	
training:	Epoch: [47][199/204]	Loss 0.0083 (0.0394)	
training:	Epoch: [47][200/204]	Loss 0.0079 (0.0393)	
training:	Epoch: [47][201/204]	Loss 0.0091 (0.0391)	
training:	Epoch: [47][202/204]	Loss 0.0069 (0.0390)	
training:	Epoch: [47][203/204]	Loss 0.0105 (0.0388)	
training:	Epoch: [47][204/204]	Loss 0.0106 (0.0387)	
Training:	 Loss: 0.0386

Training:	 ACC: 0.9936 0.9936 0.9938 0.9933
Validation:	 ACC: 0.7773 0.7780 0.7912 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9900
Pretraining:	Epoch 48/500
----------
training:	Epoch: [48][1/204]	Loss 0.0089 (0.0089)	
training:	Epoch: [48][2/204]	Loss 0.0116 (0.0103)	
training:	Epoch: [48][3/204]	Loss 0.0078 (0.0094)	
training:	Epoch: [48][4/204]	Loss 0.2996 (0.0820)	
training:	Epoch: [48][5/204]	Loss 0.0078 (0.0672)	
training:	Epoch: [48][6/204]	Loss 0.1449 (0.0801)	
training:	Epoch: [48][7/204]	Loss 0.1606 (0.0916)	
training:	Epoch: [48][8/204]	Loss 0.1457 (0.0984)	
training:	Epoch: [48][9/204]	Loss 0.0095 (0.0885)	
training:	Epoch: [48][10/204]	Loss 0.0088 (0.0805)	
training:	Epoch: [48][11/204]	Loss 0.1641 (0.0881)	
training:	Epoch: [48][12/204]	Loss 0.1585 (0.0940)	
training:	Epoch: [48][13/204]	Loss 0.0075 (0.0873)	
training:	Epoch: [48][14/204]	Loss 0.0082 (0.0817)	
training:	Epoch: [48][15/204]	Loss 0.0086 (0.0768)	
training:	Epoch: [48][16/204]	Loss 0.1228 (0.0797)	
training:	Epoch: [48][17/204]	Loss 0.0088 (0.0755)	
training:	Epoch: [48][18/204]	Loss 0.0100 (0.0719)	
training:	Epoch: [48][19/204]	Loss 0.0083 (0.0685)	
training:	Epoch: [48][20/204]	Loss 0.0085 (0.0655)	
training:	Epoch: [48][21/204]	Loss 0.0073 (0.0628)	
training:	Epoch: [48][22/204]	Loss 0.0097 (0.0603)	
training:	Epoch: [48][23/204]	Loss 0.0084 (0.0581)	
training:	Epoch: [48][24/204]	Loss 0.2434 (0.0658)	
training:	Epoch: [48][25/204]	Loss 0.0102 (0.0636)	
training:	Epoch: [48][26/204]	Loss 0.0086 (0.0615)	
training:	Epoch: [48][27/204]	Loss 0.0082 (0.0595)	
training:	Epoch: [48][28/204]	Loss 0.0085 (0.0577)	
training:	Epoch: [48][29/204]	Loss 0.0080 (0.0560)	
training:	Epoch: [48][30/204]	Loss 0.0086 (0.0544)	
training:	Epoch: [48][31/204]	Loss 0.0116 (0.0530)	
training:	Epoch: [48][32/204]	Loss 0.0070 (0.0516)	
training:	Epoch: [48][33/204]	Loss 0.0084 (0.0503)	
training:	Epoch: [48][34/204]	Loss 0.0087 (0.0490)	
training:	Epoch: [48][35/204]	Loss 0.1524 (0.0520)	
training:	Epoch: [48][36/204]	Loss 0.0078 (0.0508)	
training:	Epoch: [48][37/204]	Loss 0.0081 (0.0496)	
training:	Epoch: [48][38/204]	Loss 0.0081 (0.0485)	
training:	Epoch: [48][39/204]	Loss 0.0093 (0.0475)	
training:	Epoch: [48][40/204]	Loss 0.0102 (0.0466)	
training:	Epoch: [48][41/204]	Loss 0.1478 (0.0490)	
training:	Epoch: [48][42/204]	Loss 0.0083 (0.0481)	
training:	Epoch: [48][43/204]	Loss 0.0088 (0.0472)	
training:	Epoch: [48][44/204]	Loss 0.0120 (0.0464)	
training:	Epoch: [48][45/204]	Loss 0.0092 (0.0455)	
training:	Epoch: [48][46/204]	Loss 0.0078 (0.0447)	
training:	Epoch: [48][47/204]	Loss 0.0080 (0.0439)	
training:	Epoch: [48][48/204]	Loss 0.0083 (0.0432)	
training:	Epoch: [48][49/204]	Loss 0.0088 (0.0425)	
training:	Epoch: [48][50/204]	Loss 0.0081 (0.0418)	
training:	Epoch: [48][51/204]	Loss 0.0080 (0.0411)	
training:	Epoch: [48][52/204]	Loss 0.1440 (0.0431)	
training:	Epoch: [48][53/204]	Loss 0.0069 (0.0424)	
training:	Epoch: [48][54/204]	Loss 0.1461 (0.0443)	
training:	Epoch: [48][55/204]	Loss 0.0085 (0.0437)	
training:	Epoch: [48][56/204]	Loss 0.0076 (0.0430)	
training:	Epoch: [48][57/204]	Loss 0.0080 (0.0424)	
training:	Epoch: [48][58/204]	Loss 0.0081 (0.0418)	
training:	Epoch: [48][59/204]	Loss 0.0082 (0.0413)	
training:	Epoch: [48][60/204]	Loss 0.0085 (0.0407)	
training:	Epoch: [48][61/204]	Loss 0.1493 (0.0425)	
training:	Epoch: [48][62/204]	Loss 0.0086 (0.0420)	
training:	Epoch: [48][63/204]	Loss 0.0565 (0.0422)	
training:	Epoch: [48][64/204]	Loss 0.0091 (0.0417)	
training:	Epoch: [48][65/204]	Loss 0.0075 (0.0411)	
training:	Epoch: [48][66/204]	Loss 0.0094 (0.0407)	
training:	Epoch: [48][67/204]	Loss 0.0071 (0.0402)	
training:	Epoch: [48][68/204]	Loss 0.0080 (0.0397)	
training:	Epoch: [48][69/204]	Loss 0.0078 (0.0392)	
training:	Epoch: [48][70/204]	Loss 0.0080 (0.0388)	
training:	Epoch: [48][71/204]	Loss 0.1605 (0.0405)	
training:	Epoch: [48][72/204]	Loss 0.0086 (0.0401)	
training:	Epoch: [48][73/204]	Loss 0.0081 (0.0396)	
training:	Epoch: [48][74/204]	Loss 0.0082 (0.0392)	
training:	Epoch: [48][75/204]	Loss 0.0069 (0.0388)	
training:	Epoch: [48][76/204]	Loss 0.0076 (0.0384)	
training:	Epoch: [48][77/204]	Loss 0.0079 (0.0380)	
training:	Epoch: [48][78/204]	Loss 0.0084 (0.0376)	
training:	Epoch: [48][79/204]	Loss 0.0082 (0.0372)	
training:	Epoch: [48][80/204]	Loss 0.0084 (0.0368)	
training:	Epoch: [48][81/204]	Loss 0.0083 (0.0365)	
training:	Epoch: [48][82/204]	Loss 0.0078 (0.0361)	
training:	Epoch: [48][83/204]	Loss 0.0081 (0.0358)	
training:	Epoch: [48][84/204]	Loss 0.1514 (0.0372)	
training:	Epoch: [48][85/204]	Loss 0.0075 (0.0368)	
training:	Epoch: [48][86/204]	Loss 0.0081 (0.0365)	
training:	Epoch: [48][87/204]	Loss 0.0073 (0.0362)	
training:	Epoch: [48][88/204]	Loss 0.0074 (0.0358)	
training:	Epoch: [48][89/204]	Loss 0.0081 (0.0355)	
training:	Epoch: [48][90/204]	Loss 0.0075 (0.0352)	
training:	Epoch: [48][91/204]	Loss 0.0078 (0.0349)	
training:	Epoch: [48][92/204]	Loss 0.0066 (0.0346)	
training:	Epoch: [48][93/204]	Loss 0.0071 (0.0343)	
training:	Epoch: [48][94/204]	Loss 0.0084 (0.0340)	
training:	Epoch: [48][95/204]	Loss 0.0082 (0.0338)	
training:	Epoch: [48][96/204]	Loss 0.0085 (0.0335)	
training:	Epoch: [48][97/204]	Loss 0.0088 (0.0332)	
training:	Epoch: [48][98/204]	Loss 0.0086 (0.0330)	
training:	Epoch: [48][99/204]	Loss 0.0076 (0.0327)	
training:	Epoch: [48][100/204]	Loss 0.1558 (0.0340)	
training:	Epoch: [48][101/204]	Loss 0.0079 (0.0337)	
training:	Epoch: [48][102/204]	Loss 0.0079 (0.0335)	
training:	Epoch: [48][103/204]	Loss 0.0071 (0.0332)	
training:	Epoch: [48][104/204]	Loss 0.1437 (0.0343)	
training:	Epoch: [48][105/204]	Loss 0.0069 (0.0340)	
training:	Epoch: [48][106/204]	Loss 0.0080 (0.0338)	
training:	Epoch: [48][107/204]	Loss 0.0066 (0.0335)	
training:	Epoch: [48][108/204]	Loss 0.1345 (0.0344)	
training:	Epoch: [48][109/204]	Loss 0.0071 (0.0342)	
training:	Epoch: [48][110/204]	Loss 0.0067 (0.0339)	
training:	Epoch: [48][111/204]	Loss 0.0075 (0.0337)	
training:	Epoch: [48][112/204]	Loss 0.0066 (0.0335)	
training:	Epoch: [48][113/204]	Loss 0.0066 (0.0332)	
training:	Epoch: [48][114/204]	Loss 0.0773 (0.0336)	
training:	Epoch: [48][115/204]	Loss 0.0076 (0.0334)	
training:	Epoch: [48][116/204]	Loss 0.0082 (0.0332)	
training:	Epoch: [48][117/204]	Loss 0.0099 (0.0330)	
training:	Epoch: [48][118/204]	Loss 0.0086 (0.0328)	
training:	Epoch: [48][119/204]	Loss 0.0091 (0.0326)	
training:	Epoch: [48][120/204]	Loss 0.0072 (0.0323)	
training:	Epoch: [48][121/204]	Loss 0.1582 (0.0334)	
training:	Epoch: [48][122/204]	Loss 0.0080 (0.0332)	
training:	Epoch: [48][123/204]	Loss 0.0087 (0.0330)	
training:	Epoch: [48][124/204]	Loss 0.0085 (0.0328)	
training:	Epoch: [48][125/204]	Loss 0.1674 (0.0339)	
training:	Epoch: [48][126/204]	Loss 0.1667 (0.0349)	
training:	Epoch: [48][127/204]	Loss 0.1607 (0.0359)	
training:	Epoch: [48][128/204]	Loss 0.0084 (0.0357)	
training:	Epoch: [48][129/204]	Loss 0.0116 (0.0355)	
training:	Epoch: [48][130/204]	Loss 0.0081 (0.0353)	
training:	Epoch: [48][131/204]	Loss 0.0087 (0.0351)	
training:	Epoch: [48][132/204]	Loss 0.0077 (0.0349)	
training:	Epoch: [48][133/204]	Loss 0.0080 (0.0347)	
training:	Epoch: [48][134/204]	Loss 0.0088 (0.0345)	
training:	Epoch: [48][135/204]	Loss 0.1419 (0.0353)	
training:	Epoch: [48][136/204]	Loss 0.0079 (0.0351)	
training:	Epoch: [48][137/204]	Loss 0.0079 (0.0349)	
training:	Epoch: [48][138/204]	Loss 0.0102 (0.0347)	
training:	Epoch: [48][139/204]	Loss 0.1507 (0.0355)	
training:	Epoch: [48][140/204]	Loss 0.0078 (0.0353)	
training:	Epoch: [48][141/204]	Loss 0.0069 (0.0351)	
training:	Epoch: [48][142/204]	Loss 0.0076 (0.0349)	
training:	Epoch: [48][143/204]	Loss 0.0075 (0.0348)	
training:	Epoch: [48][144/204]	Loss 0.1185 (0.0353)	
training:	Epoch: [48][145/204]	Loss 0.0118 (0.0352)	
training:	Epoch: [48][146/204]	Loss 0.0074 (0.0350)	
training:	Epoch: [48][147/204]	Loss 0.0393 (0.0350)	
training:	Epoch: [48][148/204]	Loss 0.0096 (0.0348)	
training:	Epoch: [48][149/204]	Loss 0.0094 (0.0347)	
training:	Epoch: [48][150/204]	Loss 0.0075 (0.0345)	
training:	Epoch: [48][151/204]	Loss 0.0071 (0.0343)	
training:	Epoch: [48][152/204]	Loss 0.1544 (0.0351)	
training:	Epoch: [48][153/204]	Loss 0.0097 (0.0349)	
training:	Epoch: [48][154/204]	Loss 0.0087 (0.0348)	
training:	Epoch: [48][155/204]	Loss 0.0073 (0.0346)	
training:	Epoch: [48][156/204]	Loss 0.1208 (0.0351)	
training:	Epoch: [48][157/204]	Loss 0.0081 (0.0350)	
training:	Epoch: [48][158/204]	Loss 0.0114 (0.0348)	
training:	Epoch: [48][159/204]	Loss 0.3163 (0.0366)	
training:	Epoch: [48][160/204]	Loss 0.1757 (0.0375)	
training:	Epoch: [48][161/204]	Loss 0.0457 (0.0375)	
training:	Epoch: [48][162/204]	Loss 0.0082 (0.0373)	
training:	Epoch: [48][163/204]	Loss 0.1438 (0.0380)	
training:	Epoch: [48][164/204]	Loss 0.0083 (0.0378)	
training:	Epoch: [48][165/204]	Loss 0.0071 (0.0376)	
training:	Epoch: [48][166/204]	Loss 0.0084 (0.0374)	
training:	Epoch: [48][167/204]	Loss 0.0081 (0.0373)	
training:	Epoch: [48][168/204]	Loss 0.0079 (0.0371)	
training:	Epoch: [48][169/204]	Loss 0.0078 (0.0369)	
training:	Epoch: [48][170/204]	Loss 0.0107 (0.0368)	
training:	Epoch: [48][171/204]	Loss 0.0099 (0.0366)	
training:	Epoch: [48][172/204]	Loss 0.0112 (0.0365)	
training:	Epoch: [48][173/204]	Loss 0.0082 (0.0363)	
training:	Epoch: [48][174/204]	Loss 0.0122 (0.0362)	
training:	Epoch: [48][175/204]	Loss 0.0076 (0.0360)	
training:	Epoch: [48][176/204]	Loss 0.0100 (0.0358)	
training:	Epoch: [48][177/204]	Loss 0.0105 (0.0357)	
training:	Epoch: [48][178/204]	Loss 0.0130 (0.0356)	
training:	Epoch: [48][179/204]	Loss 0.1521 (0.0362)	
training:	Epoch: [48][180/204]	Loss 0.0116 (0.0361)	
training:	Epoch: [48][181/204]	Loss 0.1561 (0.0367)	
training:	Epoch: [48][182/204]	Loss 0.0083 (0.0366)	
training:	Epoch: [48][183/204]	Loss 0.1611 (0.0373)	
training:	Epoch: [48][184/204]	Loss 0.0089 (0.0371)	
training:	Epoch: [48][185/204]	Loss 0.1461 (0.0377)	
training:	Epoch: [48][186/204]	Loss 0.1809 (0.0385)	
training:	Epoch: [48][187/204]	Loss 0.0071 (0.0383)	
training:	Epoch: [48][188/204]	Loss 0.0112 (0.0382)	
training:	Epoch: [48][189/204]	Loss 0.0072 (0.0380)	
training:	Epoch: [48][190/204]	Loss 0.0102 (0.0379)	
training:	Epoch: [48][191/204]	Loss 0.0068 (0.0377)	
training:	Epoch: [48][192/204]	Loss 0.0223 (0.0376)	
training:	Epoch: [48][193/204]	Loss 0.0083 (0.0375)	
training:	Epoch: [48][194/204]	Loss 0.1680 (0.0381)	
training:	Epoch: [48][195/204]	Loss 0.0137 (0.0380)	
training:	Epoch: [48][196/204]	Loss 0.0148 (0.0379)	
training:	Epoch: [48][197/204]	Loss 0.1619 (0.0385)	
training:	Epoch: [48][198/204]	Loss 0.0070 (0.0384)	
training:	Epoch: [48][199/204]	Loss 0.0082 (0.0382)	
training:	Epoch: [48][200/204]	Loss 0.0088 (0.0381)	
training:	Epoch: [48][201/204]	Loss 0.0098 (0.0379)	
training:	Epoch: [48][202/204]	Loss 0.0135 (0.0378)	
training:	Epoch: [48][203/204]	Loss 0.0119 (0.0377)	
training:	Epoch: [48][204/204]	Loss 0.0124 (0.0375)	
Training:	 Loss: 0.0375

Training:	 ACC: 0.9932 0.9933 0.9944 0.9920
Validation:	 ACC: 0.7681 0.7705 0.8209 0.7152
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0250
Pretraining:	Epoch 49/500
----------
training:	Epoch: [49][1/204]	Loss 0.0067 (0.0067)	
training:	Epoch: [49][2/204]	Loss 0.0102 (0.0084)	
training:	Epoch: [49][3/204]	Loss 0.0134 (0.0101)	
training:	Epoch: [49][4/204]	Loss 0.0113 (0.0104)	
training:	Epoch: [49][5/204]	Loss 0.1637 (0.0411)	
training:	Epoch: [49][6/204]	Loss 0.0074 (0.0355)	
training:	Epoch: [49][7/204]	Loss 0.0069 (0.0314)	
training:	Epoch: [49][8/204]	Loss 0.0075 (0.0284)	
training:	Epoch: [49][9/204]	Loss 0.0072 (0.0260)	
training:	Epoch: [49][10/204]	Loss 0.0064 (0.0241)	
training:	Epoch: [49][11/204]	Loss 0.1362 (0.0343)	
training:	Epoch: [49][12/204]	Loss 0.0070 (0.0320)	
training:	Epoch: [49][13/204]	Loss 0.1571 (0.0416)	
training:	Epoch: [49][14/204]	Loss 0.0096 (0.0393)	
training:	Epoch: [49][15/204]	Loss 0.0079 (0.0372)	
training:	Epoch: [49][16/204]	Loss 0.0074 (0.0354)	
training:	Epoch: [49][17/204]	Loss 0.0079 (0.0338)	
training:	Epoch: [49][18/204]	Loss 0.0073 (0.0323)	
training:	Epoch: [49][19/204]	Loss 0.0134 (0.0313)	
training:	Epoch: [49][20/204]	Loss 0.0081 (0.0301)	
training:	Epoch: [49][21/204]	Loss 0.0096 (0.0292)	
training:	Epoch: [49][22/204]	Loss 0.1586 (0.0350)	
training:	Epoch: [49][23/204]	Loss 0.0074 (0.0338)	
training:	Epoch: [49][24/204]	Loss 0.0076 (0.0327)	
training:	Epoch: [49][25/204]	Loss 0.0076 (0.0317)	
training:	Epoch: [49][26/204]	Loss 0.0071 (0.0308)	
training:	Epoch: [49][27/204]	Loss 0.2188 (0.0378)	
training:	Epoch: [49][28/204]	Loss 0.0068 (0.0367)	
training:	Epoch: [49][29/204]	Loss 0.0072 (0.0356)	
training:	Epoch: [49][30/204]	Loss 0.0079 (0.0347)	
training:	Epoch: [49][31/204]	Loss 0.2933 (0.0430)	
training:	Epoch: [49][32/204]	Loss 0.0080 (0.0420)	
training:	Epoch: [49][33/204]	Loss 0.0103 (0.0410)	
training:	Epoch: [49][34/204]	Loss 0.1214 (0.0434)	
training:	Epoch: [49][35/204]	Loss 0.0068 (0.0423)	
training:	Epoch: [49][36/204]	Loss 0.0398 (0.0422)	
training:	Epoch: [49][37/204]	Loss 0.0077 (0.0413)	
training:	Epoch: [49][38/204]	Loss 0.0255 (0.0409)	
training:	Epoch: [49][39/204]	Loss 0.0073 (0.0400)	
training:	Epoch: [49][40/204]	Loss 0.1516 (0.0428)	
training:	Epoch: [49][41/204]	Loss 0.0082 (0.0420)	
training:	Epoch: [49][42/204]	Loss 0.0082 (0.0412)	
training:	Epoch: [49][43/204]	Loss 0.0072 (0.0404)	
training:	Epoch: [49][44/204]	Loss 0.0067 (0.0396)	
training:	Epoch: [49][45/204]	Loss 0.0074 (0.0389)	
training:	Epoch: [49][46/204]	Loss 0.0072 (0.0382)	
training:	Epoch: [49][47/204]	Loss 0.0072 (0.0376)	
training:	Epoch: [49][48/204]	Loss 0.1011 (0.0389)	
training:	Epoch: [49][49/204]	Loss 0.0073 (0.0382)	
training:	Epoch: [49][50/204]	Loss 0.0074 (0.0376)	
training:	Epoch: [49][51/204]	Loss 0.0088 (0.0371)	
training:	Epoch: [49][52/204]	Loss 0.0068 (0.0365)	
training:	Epoch: [49][53/204]	Loss 0.1154 (0.0380)	
training:	Epoch: [49][54/204]	Loss 0.0073 (0.0374)	
training:	Epoch: [49][55/204]	Loss 0.0087 (0.0369)	
training:	Epoch: [49][56/204]	Loss 0.0062 (0.0363)	
training:	Epoch: [49][57/204]	Loss 0.1621 (0.0385)	
training:	Epoch: [49][58/204]	Loss 0.1291 (0.0401)	
training:	Epoch: [49][59/204]	Loss 0.0115 (0.0396)	
training:	Epoch: [49][60/204]	Loss 0.0365 (0.0396)	
training:	Epoch: [49][61/204]	Loss 0.0137 (0.0391)	
training:	Epoch: [49][62/204]	Loss 0.0079 (0.0386)	
training:	Epoch: [49][63/204]	Loss 0.0071 (0.0381)	
training:	Epoch: [49][64/204]	Loss 0.0092 (0.0377)	
training:	Epoch: [49][65/204]	Loss 0.0124 (0.0373)	
training:	Epoch: [49][66/204]	Loss 0.0095 (0.0369)	
training:	Epoch: [49][67/204]	Loss 0.0077 (0.0364)	
training:	Epoch: [49][68/204]	Loss 0.1377 (0.0379)	
training:	Epoch: [49][69/204]	Loss 0.0070 (0.0375)	
training:	Epoch: [49][70/204]	Loss 0.0077 (0.0370)	
training:	Epoch: [49][71/204]	Loss 0.0085 (0.0366)	
training:	Epoch: [49][72/204]	Loss 0.1509 (0.0382)	
training:	Epoch: [49][73/204]	Loss 0.1802 (0.0402)	
training:	Epoch: [49][74/204]	Loss 0.0082 (0.0397)	
training:	Epoch: [49][75/204]	Loss 0.0158 (0.0394)	
training:	Epoch: [49][76/204]	Loss 0.0096 (0.0390)	
training:	Epoch: [49][77/204]	Loss 0.0282 (0.0389)	
training:	Epoch: [49][78/204]	Loss 0.0069 (0.0385)	
training:	Epoch: [49][79/204]	Loss 0.0086 (0.0381)	
training:	Epoch: [49][80/204]	Loss 0.0064 (0.0377)	
training:	Epoch: [49][81/204]	Loss 0.0090 (0.0374)	
training:	Epoch: [49][82/204]	Loss 0.0093 (0.0370)	
training:	Epoch: [49][83/204]	Loss 0.0094 (0.0367)	
training:	Epoch: [49][84/204]	Loss 0.0090 (0.0363)	
training:	Epoch: [49][85/204]	Loss 0.0068 (0.0360)	
training:	Epoch: [49][86/204]	Loss 0.0194 (0.0358)	
training:	Epoch: [49][87/204]	Loss 0.0074 (0.0355)	
training:	Epoch: [49][88/204]	Loss 0.1372 (0.0366)	
training:	Epoch: [49][89/204]	Loss 0.0070 (0.0363)	
training:	Epoch: [49][90/204]	Loss 0.0077 (0.0360)	
training:	Epoch: [49][91/204]	Loss 0.0084 (0.0357)	
training:	Epoch: [49][92/204]	Loss 0.0060 (0.0354)	
training:	Epoch: [49][93/204]	Loss 0.1606 (0.0367)	
training:	Epoch: [49][94/204]	Loss 0.0073 (0.0364)	
training:	Epoch: [49][95/204]	Loss 0.0073 (0.0361)	
training:	Epoch: [49][96/204]	Loss 0.0076 (0.0358)	
training:	Epoch: [49][97/204]	Loss 0.0078 (0.0355)	
training:	Epoch: [49][98/204]	Loss 0.1626 (0.0368)	
training:	Epoch: [49][99/204]	Loss 0.1689 (0.0381)	
training:	Epoch: [49][100/204]	Loss 0.0081 (0.0378)	
training:	Epoch: [49][101/204]	Loss 0.0077 (0.0375)	
training:	Epoch: [49][102/204]	Loss 0.1517 (0.0387)	
training:	Epoch: [49][103/204]	Loss 0.0201 (0.0385)	
training:	Epoch: [49][104/204]	Loss 0.0276 (0.0384)	
training:	Epoch: [49][105/204]	Loss 0.1535 (0.0395)	
training:	Epoch: [49][106/204]	Loss 0.0076 (0.0392)	
training:	Epoch: [49][107/204]	Loss 0.0076 (0.0389)	
training:	Epoch: [49][108/204]	Loss 0.0070 (0.0386)	
training:	Epoch: [49][109/204]	Loss 0.0082 (0.0383)	
training:	Epoch: [49][110/204]	Loss 0.0111 (0.0380)	
training:	Epoch: [49][111/204]	Loss 0.0076 (0.0378)	
training:	Epoch: [49][112/204]	Loss 0.0079 (0.0375)	
training:	Epoch: [49][113/204]	Loss 0.0284 (0.0374)	
training:	Epoch: [49][114/204]	Loss 0.0073 (0.0372)	
training:	Epoch: [49][115/204]	Loss 0.0101 (0.0369)	
training:	Epoch: [49][116/204]	Loss 0.0084 (0.0367)	
training:	Epoch: [49][117/204]	Loss 0.0112 (0.0365)	
training:	Epoch: [49][118/204]	Loss 0.0268 (0.0364)	
training:	Epoch: [49][119/204]	Loss 0.0305 (0.0363)	
training:	Epoch: [49][120/204]	Loss 0.1444 (0.0372)	
training:	Epoch: [49][121/204]	Loss 0.0205 (0.0371)	
training:	Epoch: [49][122/204]	Loss 0.0114 (0.0369)	
training:	Epoch: [49][123/204]	Loss 0.1652 (0.0379)	
training:	Epoch: [49][124/204]	Loss 0.0064 (0.0377)	
training:	Epoch: [49][125/204]	Loss 0.1652 (0.0387)	
training:	Epoch: [49][126/204]	Loss 0.2235 (0.0402)	
training:	Epoch: [49][127/204]	Loss 0.0076 (0.0399)	
training:	Epoch: [49][128/204]	Loss 0.1664 (0.0409)	
training:	Epoch: [49][129/204]	Loss 0.1881 (0.0420)	
training:	Epoch: [49][130/204]	Loss 0.0070 (0.0418)	
training:	Epoch: [49][131/204]	Loss 0.0071 (0.0415)	
training:	Epoch: [49][132/204]	Loss 0.0087 (0.0413)	
training:	Epoch: [49][133/204]	Loss 0.1448 (0.0420)	
training:	Epoch: [49][134/204]	Loss 0.0072 (0.0418)	
training:	Epoch: [49][135/204]	Loss 0.1474 (0.0426)	
training:	Epoch: [49][136/204]	Loss 0.0073 (0.0423)	
training:	Epoch: [49][137/204]	Loss 0.0071 (0.0420)	
training:	Epoch: [49][138/204]	Loss 0.0072 (0.0418)	
training:	Epoch: [49][139/204]	Loss 0.0078 (0.0415)	
training:	Epoch: [49][140/204]	Loss 0.0081 (0.0413)	
training:	Epoch: [49][141/204]	Loss 0.0077 (0.0411)	
training:	Epoch: [49][142/204]	Loss 0.0082 (0.0408)	
training:	Epoch: [49][143/204]	Loss 0.0080 (0.0406)	
training:	Epoch: [49][144/204]	Loss 0.0087 (0.0404)	
training:	Epoch: [49][145/204]	Loss 0.1615 (0.0412)	
training:	Epoch: [49][146/204]	Loss 0.0073 (0.0410)	
training:	Epoch: [49][147/204]	Loss 0.1314 (0.0416)	
training:	Epoch: [49][148/204]	Loss 0.0070 (0.0414)	
training:	Epoch: [49][149/204]	Loss 0.1542 (0.0421)	
training:	Epoch: [49][150/204]	Loss 0.0175 (0.0420)	
training:	Epoch: [49][151/204]	Loss 0.0075 (0.0417)	
training:	Epoch: [49][152/204]	Loss 0.0073 (0.0415)	
training:	Epoch: [49][153/204]	Loss 0.0104 (0.0413)	
training:	Epoch: [49][154/204]	Loss 0.0077 (0.0411)	
training:	Epoch: [49][155/204]	Loss 0.0076 (0.0409)	
training:	Epoch: [49][156/204]	Loss 0.0075 (0.0407)	
training:	Epoch: [49][157/204]	Loss 0.0076 (0.0404)	
training:	Epoch: [49][158/204]	Loss 0.0076 (0.0402)	
training:	Epoch: [49][159/204]	Loss 0.0074 (0.0400)	
training:	Epoch: [49][160/204]	Loss 0.0091 (0.0398)	
training:	Epoch: [49][161/204]	Loss 0.0087 (0.0396)	
training:	Epoch: [49][162/204]	Loss 0.0167 (0.0395)	
training:	Epoch: [49][163/204]	Loss 0.0080 (0.0393)	
training:	Epoch: [49][164/204]	Loss 0.0980 (0.0397)	
training:	Epoch: [49][165/204]	Loss 0.1494 (0.0403)	
training:	Epoch: [49][166/204]	Loss 0.0139 (0.0402)	
training:	Epoch: [49][167/204]	Loss 0.0076 (0.0400)	
training:	Epoch: [49][168/204]	Loss 0.0071 (0.0398)	
training:	Epoch: [49][169/204]	Loss 0.0529 (0.0399)	
training:	Epoch: [49][170/204]	Loss 0.0073 (0.0397)	
training:	Epoch: [49][171/204]	Loss 0.0087 (0.0395)	
training:	Epoch: [49][172/204]	Loss 0.0079 (0.0393)	
training:	Epoch: [49][173/204]	Loss 0.0079 (0.0391)	
training:	Epoch: [49][174/204]	Loss 0.1512 (0.0398)	
training:	Epoch: [49][175/204]	Loss 0.0086 (0.0396)	
training:	Epoch: [49][176/204]	Loss 0.0072 (0.0394)	
training:	Epoch: [49][177/204]	Loss 0.0070 (0.0392)	
training:	Epoch: [49][178/204]	Loss 0.0071 (0.0390)	
training:	Epoch: [49][179/204]	Loss 0.0063 (0.0389)	
training:	Epoch: [49][180/204]	Loss 0.0125 (0.0387)	
training:	Epoch: [49][181/204]	Loss 0.0072 (0.0385)	
training:	Epoch: [49][182/204]	Loss 0.0070 (0.0384)	
training:	Epoch: [49][183/204]	Loss 0.0064 (0.0382)	
training:	Epoch: [49][184/204]	Loss 0.1608 (0.0389)	
training:	Epoch: [49][185/204]	Loss 0.0075 (0.0387)	
training:	Epoch: [49][186/204]	Loss 0.0075 (0.0385)	
training:	Epoch: [49][187/204]	Loss 0.1512 (0.0391)	
training:	Epoch: [49][188/204]	Loss 0.0076 (0.0389)	
training:	Epoch: [49][189/204]	Loss 0.0081 (0.0388)	
training:	Epoch: [49][190/204]	Loss 0.0074 (0.0386)	
training:	Epoch: [49][191/204]	Loss 0.0066 (0.0385)	
training:	Epoch: [49][192/204]	Loss 0.0073 (0.0383)	
training:	Epoch: [49][193/204]	Loss 0.0095 (0.0381)	
training:	Epoch: [49][194/204]	Loss 0.0073 (0.0380)	
training:	Epoch: [49][195/204]	Loss 0.1498 (0.0386)	
training:	Epoch: [49][196/204]	Loss 0.0071 (0.0384)	
training:	Epoch: [49][197/204]	Loss 0.1620 (0.0390)	
training:	Epoch: [49][198/204]	Loss 0.0060 (0.0389)	
training:	Epoch: [49][199/204]	Loss 0.1262 (0.0393)	
training:	Epoch: [49][200/204]	Loss 0.1614 (0.0399)	
training:	Epoch: [49][201/204]	Loss 0.0074 (0.0397)	
training:	Epoch: [49][202/204]	Loss 0.0098 (0.0396)	
training:	Epoch: [49][203/204]	Loss 0.0078 (0.0394)	
training:	Epoch: [49][204/204]	Loss 0.0100 (0.0393)	
Training:	 Loss: 0.0392

Training:	 ACC: 0.9905 0.9904 0.9871 0.9939
Validation:	 ACC: 0.7845 0.7828 0.7472 0.8217
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9654
Pretraining:	Epoch 50/500
----------
training:	Epoch: [50][1/204]	Loss 0.0084 (0.0084)	
training:	Epoch: [50][2/204]	Loss 0.0098 (0.0091)	
training:	Epoch: [50][3/204]	Loss 0.0294 (0.0159)	
training:	Epoch: [50][4/204]	Loss 0.0137 (0.0153)	
training:	Epoch: [50][5/204]	Loss 0.0105 (0.0144)	
training:	Epoch: [50][6/204]	Loss 0.0073 (0.0132)	
training:	Epoch: [50][7/204]	Loss 0.0077 (0.0124)	
training:	Epoch: [50][8/204]	Loss 0.0089 (0.0120)	
training:	Epoch: [50][9/204]	Loss 0.0084 (0.0116)	
training:	Epoch: [50][10/204]	Loss 0.0231 (0.0127)	
training:	Epoch: [50][11/204]	Loss 0.0069 (0.0122)	
training:	Epoch: [50][12/204]	Loss 0.1596 (0.0245)	
training:	Epoch: [50][13/204]	Loss 0.0080 (0.0232)	
training:	Epoch: [50][14/204]	Loss 0.1158 (0.0298)	
training:	Epoch: [50][15/204]	Loss 0.0079 (0.0284)	
training:	Epoch: [50][16/204]	Loss 0.0077 (0.0271)	
training:	Epoch: [50][17/204]	Loss 0.0389 (0.0278)	
training:	Epoch: [50][18/204]	Loss 0.0079 (0.0267)	
training:	Epoch: [50][19/204]	Loss 0.0070 (0.0256)	
training:	Epoch: [50][20/204]	Loss 0.0081 (0.0247)	
training:	Epoch: [50][21/204]	Loss 0.0065 (0.0239)	
training:	Epoch: [50][22/204]	Loss 0.0088 (0.0232)	
training:	Epoch: [50][23/204]	Loss 0.1608 (0.0292)	
training:	Epoch: [50][24/204]	Loss 0.1610 (0.0347)	
training:	Epoch: [50][25/204]	Loss 0.0079 (0.0336)	
training:	Epoch: [50][26/204]	Loss 0.0074 (0.0326)	
training:	Epoch: [50][27/204]	Loss 0.1520 (0.0370)	
training:	Epoch: [50][28/204]	Loss 0.0082 (0.0360)	
training:	Epoch: [50][29/204]	Loss 0.0566 (0.0367)	
training:	Epoch: [50][30/204]	Loss 0.0064 (0.0357)	
training:	Epoch: [50][31/204]	Loss 0.0068 (0.0348)	
training:	Epoch: [50][32/204]	Loss 0.0082 (0.0339)	
training:	Epoch: [50][33/204]	Loss 0.0084 (0.0331)	
training:	Epoch: [50][34/204]	Loss 0.1309 (0.0360)	
training:	Epoch: [50][35/204]	Loss 0.0068 (0.0352)	
training:	Epoch: [50][36/204]	Loss 0.0130 (0.0346)	
training:	Epoch: [50][37/204]	Loss 0.2979 (0.0417)	
training:	Epoch: [50][38/204]	Loss 0.1492 (0.0445)	
training:	Epoch: [50][39/204]	Loss 0.1595 (0.0475)	
training:	Epoch: [50][40/204]	Loss 0.1298 (0.0495)	
training:	Epoch: [50][41/204]	Loss 0.0079 (0.0485)	
training:	Epoch: [50][42/204]	Loss 0.0082 (0.0476)	
training:	Epoch: [50][43/204]	Loss 0.0074 (0.0466)	
training:	Epoch: [50][44/204]	Loss 0.1304 (0.0485)	
training:	Epoch: [50][45/204]	Loss 0.0070 (0.0476)	
training:	Epoch: [50][46/204]	Loss 0.0069 (0.0467)	
training:	Epoch: [50][47/204]	Loss 0.0074 (0.0459)	
training:	Epoch: [50][48/204]	Loss 0.1205 (0.0474)	
training:	Epoch: [50][49/204]	Loss 0.0076 (0.0466)	
training:	Epoch: [50][50/204]	Loss 0.1609 (0.0489)	
training:	Epoch: [50][51/204]	Loss 0.0075 (0.0481)	
training:	Epoch: [50][52/204]	Loss 0.0065 (0.0473)	
training:	Epoch: [50][53/204]	Loss 0.0081 (0.0466)	
training:	Epoch: [50][54/204]	Loss 0.0074 (0.0458)	
training:	Epoch: [50][55/204]	Loss 0.0078 (0.0451)	
training:	Epoch: [50][56/204]	Loss 0.1636 (0.0473)	
training:	Epoch: [50][57/204]	Loss 0.0084 (0.0466)	
training:	Epoch: [50][58/204]	Loss 0.0125 (0.0460)	
training:	Epoch: [50][59/204]	Loss 0.0068 (0.0453)	
training:	Epoch: [50][60/204]	Loss 0.0084 (0.0447)	
training:	Epoch: [50][61/204]	Loss 0.0072 (0.0441)	
training:	Epoch: [50][62/204]	Loss 0.0379 (0.0440)	
training:	Epoch: [50][63/204]	Loss 0.0077 (0.0434)	
training:	Epoch: [50][64/204]	Loss 0.0100 (0.0429)	
training:	Epoch: [50][65/204]	Loss 0.1541 (0.0446)	
training:	Epoch: [50][66/204]	Loss 0.0067 (0.0440)	
training:	Epoch: [50][67/204]	Loss 0.0059 (0.0435)	
training:	Epoch: [50][68/204]	Loss 0.0067 (0.0429)	
training:	Epoch: [50][69/204]	Loss 0.0071 (0.0424)	
training:	Epoch: [50][70/204]	Loss 0.0081 (0.0419)	
training:	Epoch: [50][71/204]	Loss 0.0086 (0.0414)	
training:	Epoch: [50][72/204]	Loss 0.0063 (0.0410)	
training:	Epoch: [50][73/204]	Loss 0.0075 (0.0405)	
training:	Epoch: [50][74/204]	Loss 0.0069 (0.0400)	
training:	Epoch: [50][75/204]	Loss 0.0098 (0.0396)	
training:	Epoch: [50][76/204]	Loss 0.0076 (0.0392)	
training:	Epoch: [50][77/204]	Loss 0.0134 (0.0389)	
training:	Epoch: [50][78/204]	Loss 0.0073 (0.0385)	
training:	Epoch: [50][79/204]	Loss 0.0076 (0.0381)	
training:	Epoch: [50][80/204]	Loss 0.0168 (0.0378)	
training:	Epoch: [50][81/204]	Loss 0.0144 (0.0375)	
training:	Epoch: [50][82/204]	Loss 0.0080 (0.0372)	
training:	Epoch: [50][83/204]	Loss 0.0073 (0.0368)	
training:	Epoch: [50][84/204]	Loss 0.0087 (0.0365)	
training:	Epoch: [50][85/204]	Loss 0.0071 (0.0361)	
training:	Epoch: [50][86/204]	Loss 0.0166 (0.0359)	
training:	Epoch: [50][87/204]	Loss 0.1500 (0.0372)	
training:	Epoch: [50][88/204]	Loss 0.0088 (0.0369)	
training:	Epoch: [50][89/204]	Loss 0.2418 (0.0392)	
training:	Epoch: [50][90/204]	Loss 0.0113 (0.0389)	
training:	Epoch: [50][91/204]	Loss 0.0072 (0.0385)	
training:	Epoch: [50][92/204]	Loss 0.0111 (0.0382)	
training:	Epoch: [50][93/204]	Loss 0.0108 (0.0379)	
training:	Epoch: [50][94/204]	Loss 0.1488 (0.0391)	
training:	Epoch: [50][95/204]	Loss 0.0066 (0.0388)	
training:	Epoch: [50][96/204]	Loss 0.0103 (0.0385)	
training:	Epoch: [50][97/204]	Loss 0.0073 (0.0382)	
training:	Epoch: [50][98/204]	Loss 0.1647 (0.0395)	
training:	Epoch: [50][99/204]	Loss 0.0076 (0.0391)	
training:	Epoch: [50][100/204]	Loss 0.1213 (0.0400)	
training:	Epoch: [50][101/204]	Loss 0.0068 (0.0396)	
training:	Epoch: [50][102/204]	Loss 0.0066 (0.0393)	
training:	Epoch: [50][103/204]	Loss 0.0064 (0.0390)	
training:	Epoch: [50][104/204]	Loss 0.0075 (0.0387)	
training:	Epoch: [50][105/204]	Loss 0.0077 (0.0384)	
training:	Epoch: [50][106/204]	Loss 0.0070 (0.0381)	
training:	Epoch: [50][107/204]	Loss 0.0067 (0.0378)	
training:	Epoch: [50][108/204]	Loss 0.0070 (0.0375)	
training:	Epoch: [50][109/204]	Loss 0.0078 (0.0372)	
training:	Epoch: [50][110/204]	Loss 0.0124 (0.0370)	
training:	Epoch: [50][111/204]	Loss 0.0227 (0.0369)	
training:	Epoch: [50][112/204]	Loss 0.0089 (0.0366)	
training:	Epoch: [50][113/204]	Loss 0.0236 (0.0365)	
training:	Epoch: [50][114/204]	Loss 0.0192 (0.0364)	
training:	Epoch: [50][115/204]	Loss 0.0082 (0.0361)	
training:	Epoch: [50][116/204]	Loss 0.1559 (0.0372)	
training:	Epoch: [50][117/204]	Loss 0.0067 (0.0369)	
training:	Epoch: [50][118/204]	Loss 0.0068 (0.0366)	
training:	Epoch: [50][119/204]	Loss 0.0152 (0.0365)	
training:	Epoch: [50][120/204]	Loss 0.0068 (0.0362)	
training:	Epoch: [50][121/204]	Loss 0.1660 (0.0373)	
training:	Epoch: [50][122/204]	Loss 0.0067 (0.0370)	
training:	Epoch: [50][123/204]	Loss 0.0403 (0.0371)	
training:	Epoch: [50][124/204]	Loss 0.0062 (0.0368)	
training:	Epoch: [50][125/204]	Loss 0.0313 (0.0368)	
training:	Epoch: [50][126/204]	Loss 0.0074 (0.0365)	
training:	Epoch: [50][127/204]	Loss 0.1649 (0.0375)	
training:	Epoch: [50][128/204]	Loss 0.0066 (0.0373)	
training:	Epoch: [50][129/204]	Loss 0.0079 (0.0371)	
training:	Epoch: [50][130/204]	Loss 0.0068 (0.0368)	
training:	Epoch: [50][131/204]	Loss 0.1315 (0.0376)	
training:	Epoch: [50][132/204]	Loss 0.0070 (0.0373)	
training:	Epoch: [50][133/204]	Loss 0.0066 (0.0371)	
training:	Epoch: [50][134/204]	Loss 0.0071 (0.0369)	
training:	Epoch: [50][135/204]	Loss 0.0068 (0.0367)	
training:	Epoch: [50][136/204]	Loss 0.0071 (0.0364)	
training:	Epoch: [50][137/204]	Loss 0.0070 (0.0362)	
training:	Epoch: [50][138/204]	Loss 0.0076 (0.0360)	
training:	Epoch: [50][139/204]	Loss 0.1573 (0.0369)	
training:	Epoch: [50][140/204]	Loss 0.0775 (0.0372)	
training:	Epoch: [50][141/204]	Loss 0.0078 (0.0370)	
training:	Epoch: [50][142/204]	Loss 0.1240 (0.0376)	
training:	Epoch: [50][143/204]	Loss 0.2239 (0.0389)	
training:	Epoch: [50][144/204]	Loss 0.0063 (0.0387)	
training:	Epoch: [50][145/204]	Loss 0.0068 (0.0384)	
training:	Epoch: [50][146/204]	Loss 0.1571 (0.0393)	
training:	Epoch: [50][147/204]	Loss 0.0072 (0.0390)	
training:	Epoch: [50][148/204]	Loss 0.0072 (0.0388)	
training:	Epoch: [50][149/204]	Loss 0.0091 (0.0386)	
training:	Epoch: [50][150/204]	Loss 0.0108 (0.0384)	
training:	Epoch: [50][151/204]	Loss 0.0071 (0.0382)	
training:	Epoch: [50][152/204]	Loss 0.0065 (0.0380)	
training:	Epoch: [50][153/204]	Loss 0.0073 (0.0378)	
training:	Epoch: [50][154/204]	Loss 0.0194 (0.0377)	
training:	Epoch: [50][155/204]	Loss 0.2404 (0.0390)	
training:	Epoch: [50][156/204]	Loss 0.0083 (0.0388)	
training:	Epoch: [50][157/204]	Loss 0.0142 (0.0387)	
training:	Epoch: [50][158/204]	Loss 0.0072 (0.0385)	
training:	Epoch: [50][159/204]	Loss 0.0246 (0.0384)	
training:	Epoch: [50][160/204]	Loss 0.0078 (0.0382)	
training:	Epoch: [50][161/204]	Loss 0.0065 (0.0380)	
training:	Epoch: [50][162/204]	Loss 0.0068 (0.0378)	
training:	Epoch: [50][163/204]	Loss 0.0063 (0.0376)	
training:	Epoch: [50][164/204]	Loss 0.0223 (0.0375)	
training:	Epoch: [50][165/204]	Loss 0.0124 (0.0373)	
training:	Epoch: [50][166/204]	Loss 0.1687 (0.0381)	
training:	Epoch: [50][167/204]	Loss 0.0061 (0.0379)	
training:	Epoch: [50][168/204]	Loss 0.1660 (0.0387)	
training:	Epoch: [50][169/204]	Loss 0.1461 (0.0393)	
training:	Epoch: [50][170/204]	Loss 0.0066 (0.0392)	
training:	Epoch: [50][171/204]	Loss 0.0074 (0.0390)	
training:	Epoch: [50][172/204]	Loss 0.1492 (0.0396)	
training:	Epoch: [50][173/204]	Loss 0.0070 (0.0394)	
training:	Epoch: [50][174/204]	Loss 0.0169 (0.0393)	
training:	Epoch: [50][175/204]	Loss 0.0907 (0.0396)	
training:	Epoch: [50][176/204]	Loss 0.0064 (0.0394)	
training:	Epoch: [50][177/204]	Loss 0.1024 (0.0397)	
training:	Epoch: [50][178/204]	Loss 0.0070 (0.0396)	
training:	Epoch: [50][179/204]	Loss 0.0064 (0.0394)	
training:	Epoch: [50][180/204]	Loss 0.0071 (0.0392)	
training:	Epoch: [50][181/204]	Loss 0.1779 (0.0400)	
training:	Epoch: [50][182/204]	Loss 0.0074 (0.0398)	
training:	Epoch: [50][183/204]	Loss 0.0062 (0.0396)	
training:	Epoch: [50][184/204]	Loss 0.0588 (0.0397)	
training:	Epoch: [50][185/204]	Loss 0.0082 (0.0395)	
training:	Epoch: [50][186/204]	Loss 0.0397 (0.0395)	
training:	Epoch: [50][187/204]	Loss 0.0081 (0.0394)	
training:	Epoch: [50][188/204]	Loss 0.0073 (0.0392)	
training:	Epoch: [50][189/204]	Loss 0.1535 (0.0398)	
training:	Epoch: [50][190/204]	Loss 0.0364 (0.0398)	
training:	Epoch: [50][191/204]	Loss 0.1513 (0.0404)	
training:	Epoch: [50][192/204]	Loss 0.1626 (0.0410)	
training:	Epoch: [50][193/204]	Loss 0.0097 (0.0408)	
training:	Epoch: [50][194/204]	Loss 0.0065 (0.0407)	
training:	Epoch: [50][195/204]	Loss 0.0095 (0.0405)	
training:	Epoch: [50][196/204]	Loss 0.0073 (0.0403)	
training:	Epoch: [50][197/204]	Loss 0.0074 (0.0402)	
training:	Epoch: [50][198/204]	Loss 0.0159 (0.0400)	
training:	Epoch: [50][199/204]	Loss 0.0073 (0.0399)	
training:	Epoch: [50][200/204]	Loss 0.0073 (0.0397)	
training:	Epoch: [50][201/204]	Loss 0.1855 (0.0404)	
training:	Epoch: [50][202/204]	Loss 0.0063 (0.0403)	
training:	Epoch: [50][203/204]	Loss 0.1581 (0.0409)	
training:	Epoch: [50][204/204]	Loss 0.0907 (0.0411)	
Training:	 Loss: 0.0410

Training:	 ACC: 0.9945 0.9945 0.9947 0.9943
Validation:	 ACC: 0.7828 0.7838 0.8055 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9392
Pretraining:	Epoch 51/500
----------
training:	Epoch: [51][1/204]	Loss 0.0092 (0.0092)	
training:	Epoch: [51][2/204]	Loss 0.0071 (0.0082)	
training:	Epoch: [51][3/204]	Loss 0.0077 (0.0080)	
training:	Epoch: [51][4/204]	Loss 0.0247 (0.0122)	
training:	Epoch: [51][5/204]	Loss 0.0226 (0.0143)	
training:	Epoch: [51][6/204]	Loss 0.2006 (0.0453)	
training:	Epoch: [51][7/204]	Loss 0.3352 (0.0867)	
training:	Epoch: [51][8/204]	Loss 0.0175 (0.0781)	
training:	Epoch: [51][9/204]	Loss 0.0111 (0.0706)	
training:	Epoch: [51][10/204]	Loss 0.0136 (0.0649)	
training:	Epoch: [51][11/204]	Loss 0.0074 (0.0597)	
training:	Epoch: [51][12/204]	Loss 0.0098 (0.0555)	
training:	Epoch: [51][13/204]	Loss 0.0072 (0.0518)	
training:	Epoch: [51][14/204]	Loss 0.0070 (0.0486)	
training:	Epoch: [51][15/204]	Loss 0.0094 (0.0460)	
training:	Epoch: [51][16/204]	Loss 0.0067 (0.0436)	
training:	Epoch: [51][17/204]	Loss 0.0116 (0.0417)	
training:	Epoch: [51][18/204]	Loss 0.0075 (0.0398)	
training:	Epoch: [51][19/204]	Loss 0.0085 (0.0381)	
training:	Epoch: [51][20/204]	Loss 0.0083 (0.0366)	
training:	Epoch: [51][21/204]	Loss 0.0470 (0.0371)	
training:	Epoch: [51][22/204]	Loss 0.0080 (0.0358)	
training:	Epoch: [51][23/204]	Loss 0.0077 (0.0346)	
training:	Epoch: [51][24/204]	Loss 0.0066 (0.0334)	
training:	Epoch: [51][25/204]	Loss 0.1346 (0.0375)	
training:	Epoch: [51][26/204]	Loss 0.1675 (0.0425)	
training:	Epoch: [51][27/204]	Loss 0.1203 (0.0454)	
training:	Epoch: [51][28/204]	Loss 0.1508 (0.0491)	
training:	Epoch: [51][29/204]	Loss 0.1615 (0.0530)	
training:	Epoch: [51][30/204]	Loss 0.0084 (0.0515)	
training:	Epoch: [51][31/204]	Loss 0.0065 (0.0501)	
training:	Epoch: [51][32/204]	Loss 0.0081 (0.0487)	
training:	Epoch: [51][33/204]	Loss 0.0072 (0.0475)	
training:	Epoch: [51][34/204]	Loss 0.1584 (0.0507)	
training:	Epoch: [51][35/204]	Loss 0.0072 (0.0495)	
training:	Epoch: [51][36/204]	Loss 0.1608 (0.0526)	
training:	Epoch: [51][37/204]	Loss 0.0075 (0.0514)	
training:	Epoch: [51][38/204]	Loss 0.0070 (0.0502)	
training:	Epoch: [51][39/204]	Loss 0.0067 (0.0491)	
training:	Epoch: [51][40/204]	Loss 0.1568 (0.0518)	
training:	Epoch: [51][41/204]	Loss 0.0066 (0.0507)	
training:	Epoch: [51][42/204]	Loss 0.0086 (0.0497)	
training:	Epoch: [51][43/204]	Loss 0.0084 (0.0487)	
training:	Epoch: [51][44/204]	Loss 0.0094 (0.0478)	
training:	Epoch: [51][45/204]	Loss 0.0067 (0.0469)	
training:	Epoch: [51][46/204]	Loss 0.0125 (0.0462)	
training:	Epoch: [51][47/204]	Loss 0.0074 (0.0453)	
training:	Epoch: [51][48/204]	Loss 0.0116 (0.0446)	
training:	Epoch: [51][49/204]	Loss 0.1431 (0.0467)	
training:	Epoch: [51][50/204]	Loss 0.0075 (0.0459)	
training:	Epoch: [51][51/204]	Loss 0.0079 (0.0451)	
training:	Epoch: [51][52/204]	Loss 0.1552 (0.0472)	
training:	Epoch: [51][53/204]	Loss 0.0071 (0.0465)	
training:	Epoch: [51][54/204]	Loss 0.0063 (0.0457)	
training:	Epoch: [51][55/204]	Loss 0.0097 (0.0451)	
training:	Epoch: [51][56/204]	Loss 0.1076 (0.0462)	
training:	Epoch: [51][57/204]	Loss 0.0112 (0.0456)	
training:	Epoch: [51][58/204]	Loss 0.0080 (0.0449)	
training:	Epoch: [51][59/204]	Loss 0.0082 (0.0443)	
training:	Epoch: [51][60/204]	Loss 0.0070 (0.0437)	
training:	Epoch: [51][61/204]	Loss 0.0127 (0.0432)	
training:	Epoch: [51][62/204]	Loss 0.0069 (0.0426)	
training:	Epoch: [51][63/204]	Loss 0.0086 (0.0421)	
training:	Epoch: [51][64/204]	Loss 0.0081 (0.0415)	
training:	Epoch: [51][65/204]	Loss 0.0112 (0.0411)	
training:	Epoch: [51][66/204]	Loss 0.0077 (0.0406)	
training:	Epoch: [51][67/204]	Loss 0.1599 (0.0423)	
training:	Epoch: [51][68/204]	Loss 0.0075 (0.0418)	
training:	Epoch: [51][69/204]	Loss 0.0099 (0.0414)	
training:	Epoch: [51][70/204]	Loss 0.0191 (0.0410)	
training:	Epoch: [51][71/204]	Loss 0.0072 (0.0406)	
training:	Epoch: [51][72/204]	Loss 0.0277 (0.0404)	
training:	Epoch: [51][73/204]	Loss 0.1354 (0.0417)	
training:	Epoch: [51][74/204]	Loss 0.0072 (0.0412)	
training:	Epoch: [51][75/204]	Loss 0.0082 (0.0408)	
training:	Epoch: [51][76/204]	Loss 0.1601 (0.0424)	
training:	Epoch: [51][77/204]	Loss 0.0064 (0.0419)	
training:	Epoch: [51][78/204]	Loss 0.0080 (0.0415)	
training:	Epoch: [51][79/204]	Loss 0.1026 (0.0422)	
training:	Epoch: [51][80/204]	Loss 0.0067 (0.0418)	
training:	Epoch: [51][81/204]	Loss 0.1605 (0.0432)	
training:	Epoch: [51][82/204]	Loss 0.0081 (0.0428)	
training:	Epoch: [51][83/204]	Loss 0.0080 (0.0424)	
training:	Epoch: [51][84/204]	Loss 0.0078 (0.0420)	
training:	Epoch: [51][85/204]	Loss 0.0107 (0.0416)	
training:	Epoch: [51][86/204]	Loss 0.0068 (0.0412)	
training:	Epoch: [51][87/204]	Loss 0.0067 (0.0408)	
training:	Epoch: [51][88/204]	Loss 0.0071 (0.0404)	
training:	Epoch: [51][89/204]	Loss 0.0065 (0.0401)	
training:	Epoch: [51][90/204]	Loss 0.0078 (0.0397)	
training:	Epoch: [51][91/204]	Loss 0.0073 (0.0393)	
training:	Epoch: [51][92/204]	Loss 0.0074 (0.0390)	
training:	Epoch: [51][93/204]	Loss 0.0378 (0.0390)	
training:	Epoch: [51][94/204]	Loss 0.0076 (0.0386)	
training:	Epoch: [51][95/204]	Loss 0.1518 (0.0398)	
training:	Epoch: [51][96/204]	Loss 0.1593 (0.0411)	
training:	Epoch: [51][97/204]	Loss 0.1262 (0.0420)	
training:	Epoch: [51][98/204]	Loss 0.0067 (0.0416)	
training:	Epoch: [51][99/204]	Loss 0.0082 (0.0413)	
training:	Epoch: [51][100/204]	Loss 0.0078 (0.0409)	
training:	Epoch: [51][101/204]	Loss 0.0080 (0.0406)	
training:	Epoch: [51][102/204]	Loss 0.0097 (0.0403)	
training:	Epoch: [51][103/204]	Loss 0.0086 (0.0400)	
training:	Epoch: [51][104/204]	Loss 0.0108 (0.0397)	
training:	Epoch: [51][105/204]	Loss 0.0066 (0.0394)	
training:	Epoch: [51][106/204]	Loss 0.0083 (0.0391)	
training:	Epoch: [51][107/204]	Loss 0.0092 (0.0388)	
training:	Epoch: [51][108/204]	Loss 0.1325 (0.0397)	
training:	Epoch: [51][109/204]	Loss 0.0063 (0.0394)	
training:	Epoch: [51][110/204]	Loss 0.1615 (0.0405)	
training:	Epoch: [51][111/204]	Loss 0.0078 (0.0402)	
training:	Epoch: [51][112/204]	Loss 0.0076 (0.0399)	
training:	Epoch: [51][113/204]	Loss 0.0066 (0.0396)	
training:	Epoch: [51][114/204]	Loss 0.0074 (0.0393)	
training:	Epoch: [51][115/204]	Loss 0.0092 (0.0391)	
training:	Epoch: [51][116/204]	Loss 0.0072 (0.0388)	
training:	Epoch: [51][117/204]	Loss 0.0070 (0.0385)	
training:	Epoch: [51][118/204]	Loss 0.0087 (0.0383)	
training:	Epoch: [51][119/204]	Loss 0.0081 (0.0380)	
training:	Epoch: [51][120/204]	Loss 0.0072 (0.0378)	
training:	Epoch: [51][121/204]	Loss 0.1474 (0.0387)	
training:	Epoch: [51][122/204]	Loss 0.1544 (0.0396)	
training:	Epoch: [51][123/204]	Loss 0.0079 (0.0394)	
training:	Epoch: [51][124/204]	Loss 0.0073 (0.0391)	
training:	Epoch: [51][125/204]	Loss 0.0078 (0.0388)	
training:	Epoch: [51][126/204]	Loss 0.0079 (0.0386)	
training:	Epoch: [51][127/204]	Loss 0.0069 (0.0384)	
training:	Epoch: [51][128/204]	Loss 0.0097 (0.0381)	
training:	Epoch: [51][129/204]	Loss 0.0085 (0.0379)	
training:	Epoch: [51][130/204]	Loss 0.0094 (0.0377)	
training:	Epoch: [51][131/204]	Loss 0.0098 (0.0375)	
training:	Epoch: [51][132/204]	Loss 0.0078 (0.0372)	
training:	Epoch: [51][133/204]	Loss 0.0071 (0.0370)	
training:	Epoch: [51][134/204]	Loss 0.0087 (0.0368)	
training:	Epoch: [51][135/204]	Loss 0.0089 (0.0366)	
training:	Epoch: [51][136/204]	Loss 0.0087 (0.0364)	
training:	Epoch: [51][137/204]	Loss 0.0186 (0.0363)	
training:	Epoch: [51][138/204]	Loss 0.2368 (0.0377)	
training:	Epoch: [51][139/204]	Loss 0.0094 (0.0375)	
training:	Epoch: [51][140/204]	Loss 0.1308 (0.0382)	
training:	Epoch: [51][141/204]	Loss 0.0198 (0.0380)	
training:	Epoch: [51][142/204]	Loss 0.0073 (0.0378)	
training:	Epoch: [51][143/204]	Loss 0.0070 (0.0376)	
training:	Epoch: [51][144/204]	Loss 0.0132 (0.0374)	
training:	Epoch: [51][145/204]	Loss 0.0073 (0.0372)	
training:	Epoch: [51][146/204]	Loss 0.0074 (0.0370)	
training:	Epoch: [51][147/204]	Loss 0.0068 (0.0368)	
training:	Epoch: [51][148/204]	Loss 0.0094 (0.0366)	
training:	Epoch: [51][149/204]	Loss 0.1483 (0.0374)	
training:	Epoch: [51][150/204]	Loss 0.0073 (0.0372)	
training:	Epoch: [51][151/204]	Loss 0.0076 (0.0370)	
training:	Epoch: [51][152/204]	Loss 0.0075 (0.0368)	
training:	Epoch: [51][153/204]	Loss 0.0072 (0.0366)	
training:	Epoch: [51][154/204]	Loss 0.0067 (0.0364)	
training:	Epoch: [51][155/204]	Loss 0.0075 (0.0362)	
training:	Epoch: [51][156/204]	Loss 0.0103 (0.0361)	
training:	Epoch: [51][157/204]	Loss 0.1623 (0.0369)	
training:	Epoch: [51][158/204]	Loss 0.0066 (0.0367)	
training:	Epoch: [51][159/204]	Loss 0.0069 (0.0365)	
training:	Epoch: [51][160/204]	Loss 0.0129 (0.0363)	
training:	Epoch: [51][161/204]	Loss 0.0081 (0.0362)	
training:	Epoch: [51][162/204]	Loss 0.0067 (0.0360)	
training:	Epoch: [51][163/204]	Loss 0.0074 (0.0358)	
training:	Epoch: [51][164/204]	Loss 0.1700 (0.0366)	
training:	Epoch: [51][165/204]	Loss 0.0080 (0.0365)	
training:	Epoch: [51][166/204]	Loss 0.0079 (0.0363)	
training:	Epoch: [51][167/204]	Loss 0.0069 (0.0361)	
training:	Epoch: [51][168/204]	Loss 0.0076 (0.0359)	
training:	Epoch: [51][169/204]	Loss 0.0068 (0.0358)	
training:	Epoch: [51][170/204]	Loss 0.1452 (0.0364)	
training:	Epoch: [51][171/204]	Loss 0.0068 (0.0362)	
training:	Epoch: [51][172/204]	Loss 0.0071 (0.0361)	
training:	Epoch: [51][173/204]	Loss 0.0061 (0.0359)	
training:	Epoch: [51][174/204]	Loss 0.0065 (0.0357)	
training:	Epoch: [51][175/204]	Loss 0.0082 (0.0356)	
training:	Epoch: [51][176/204]	Loss 0.0095 (0.0354)	
training:	Epoch: [51][177/204]	Loss 0.0068 (0.0353)	
training:	Epoch: [51][178/204]	Loss 0.0072 (0.0351)	
training:	Epoch: [51][179/204]	Loss 0.0071 (0.0349)	
training:	Epoch: [51][180/204]	Loss 0.1607 (0.0356)	
training:	Epoch: [51][181/204]	Loss 0.0100 (0.0355)	
training:	Epoch: [51][182/204]	Loss 0.0101 (0.0354)	
training:	Epoch: [51][183/204]	Loss 0.0068 (0.0352)	
training:	Epoch: [51][184/204]	Loss 0.0069 (0.0350)	
training:	Epoch: [51][185/204]	Loss 0.0067 (0.0349)	
training:	Epoch: [51][186/204]	Loss 0.0186 (0.0348)	
training:	Epoch: [51][187/204]	Loss 0.0097 (0.0347)	
training:	Epoch: [51][188/204]	Loss 0.0100 (0.0345)	
training:	Epoch: [51][189/204]	Loss 0.0078 (0.0344)	
training:	Epoch: [51][190/204]	Loss 0.0083 (0.0343)	
training:	Epoch: [51][191/204]	Loss 0.0098 (0.0341)	
training:	Epoch: [51][192/204]	Loss 0.0083 (0.0340)	
training:	Epoch: [51][193/204]	Loss 0.0065 (0.0339)	
training:	Epoch: [51][194/204]	Loss 0.0061 (0.0337)	
training:	Epoch: [51][195/204]	Loss 0.0107 (0.0336)	
training:	Epoch: [51][196/204]	Loss 0.0059 (0.0335)	
training:	Epoch: [51][197/204]	Loss 0.1530 (0.0341)	
training:	Epoch: [51][198/204]	Loss 0.0066 (0.0339)	
training:	Epoch: [51][199/204]	Loss 0.0061 (0.0338)	
training:	Epoch: [51][200/204]	Loss 0.0078 (0.0337)	
training:	Epoch: [51][201/204]	Loss 0.1607 (0.0343)	
training:	Epoch: [51][202/204]	Loss 0.0090 (0.0342)	
training:	Epoch: [51][203/204]	Loss 0.0061 (0.0340)	
training:	Epoch: [51][204/204]	Loss 0.0251 (0.0340)	
Training:	 Loss: 0.0339

Training:	 ACC: 0.9945 0.9945 0.9944 0.9946
Validation:	 ACC: 0.7739 0.7747 0.7922 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 0.9913
Pretraining:	Epoch 52/500
----------
training:	Epoch: [52][1/204]	Loss 0.1594 (0.1594)	
training:	Epoch: [52][2/204]	Loss 0.0250 (0.0922)	
training:	Epoch: [52][3/204]	Loss 0.1370 (0.1072)	
training:	Epoch: [52][4/204]	Loss 0.0074 (0.0822)	
training:	Epoch: [52][5/204]	Loss 0.1649 (0.0987)	
training:	Epoch: [52][6/204]	Loss 0.0061 (0.0833)	
training:	Epoch: [52][7/204]	Loss 0.3095 (0.1156)	
training:	Epoch: [52][8/204]	Loss 0.1967 (0.1258)	
training:	Epoch: [52][9/204]	Loss 0.0072 (0.1126)	
training:	Epoch: [52][10/204]	Loss 0.0079 (0.1021)	
training:	Epoch: [52][11/204]	Loss 0.0088 (0.0936)	
training:	Epoch: [52][12/204]	Loss 0.1681 (0.0998)	
training:	Epoch: [52][13/204]	Loss 0.0066 (0.0927)	
training:	Epoch: [52][14/204]	Loss 0.0066 (0.0865)	
training:	Epoch: [52][15/204]	Loss 0.0200 (0.0821)	
training:	Epoch: [52][16/204]	Loss 0.0067 (0.0774)	
training:	Epoch: [52][17/204]	Loss 0.0076 (0.0733)	
training:	Epoch: [52][18/204]	Loss 0.0187 (0.0702)	
training:	Epoch: [52][19/204]	Loss 0.0194 (0.0676)	
training:	Epoch: [52][20/204]	Loss 0.0064 (0.0645)	
training:	Epoch: [52][21/204]	Loss 0.1616 (0.0691)	
training:	Epoch: [52][22/204]	Loss 0.0154 (0.0667)	
training:	Epoch: [52][23/204]	Loss 0.0072 (0.0641)	
training:	Epoch: [52][24/204]	Loss 0.0262 (0.0625)	
training:	Epoch: [52][25/204]	Loss 0.0092 (0.0604)	
training:	Epoch: [52][26/204]	Loss 0.1668 (0.0645)	
training:	Epoch: [52][27/204]	Loss 0.0067 (0.0623)	
training:	Epoch: [52][28/204]	Loss 0.0071 (0.0604)	
training:	Epoch: [52][29/204]	Loss 0.0058 (0.0585)	
training:	Epoch: [52][30/204]	Loss 0.0068 (0.0568)	
training:	Epoch: [52][31/204]	Loss 0.0139 (0.0554)	
training:	Epoch: [52][32/204]	Loss 0.0071 (0.0539)	
training:	Epoch: [52][33/204]	Loss 0.0068 (0.0524)	
training:	Epoch: [52][34/204]	Loss 0.0081 (0.0511)	
training:	Epoch: [52][35/204]	Loss 0.0078 (0.0499)	
training:	Epoch: [52][36/204]	Loss 0.0309 (0.0494)	
training:	Epoch: [52][37/204]	Loss 0.0103 (0.0483)	
training:	Epoch: [52][38/204]	Loss 0.0074 (0.0472)	
training:	Epoch: [52][39/204]	Loss 0.0231 (0.0466)	
training:	Epoch: [52][40/204]	Loss 0.0058 (0.0456)	
training:	Epoch: [52][41/204]	Loss 0.0067 (0.0446)	
training:	Epoch: [52][42/204]	Loss 0.0069 (0.0437)	
training:	Epoch: [52][43/204]	Loss 0.0069 (0.0429)	
training:	Epoch: [52][44/204]	Loss 0.0059 (0.0420)	
training:	Epoch: [52][45/204]	Loss 0.0843 (0.0430)	
training:	Epoch: [52][46/204]	Loss 0.1625 (0.0456)	
training:	Epoch: [52][47/204]	Loss 0.0083 (0.0448)	
training:	Epoch: [52][48/204]	Loss 0.0611 (0.0451)	
training:	Epoch: [52][49/204]	Loss 0.0064 (0.0443)	
training:	Epoch: [52][50/204]	Loss 0.0071 (0.0436)	
training:	Epoch: [52][51/204]	Loss 0.0071 (0.0429)	
training:	Epoch: [52][52/204]	Loss 0.1609 (0.0452)	
training:	Epoch: [52][53/204]	Loss 0.0067 (0.0444)	
training:	Epoch: [52][54/204]	Loss 0.1532 (0.0464)	
training:	Epoch: [52][55/204]	Loss 0.0067 (0.0457)	
training:	Epoch: [52][56/204]	Loss 0.0077 (0.0450)	
training:	Epoch: [52][57/204]	Loss 0.1725 (0.0473)	
training:	Epoch: [52][58/204]	Loss 0.0122 (0.0467)	
training:	Epoch: [52][59/204]	Loss 0.0060 (0.0460)	
training:	Epoch: [52][60/204]	Loss 0.0074 (0.0453)	
training:	Epoch: [52][61/204]	Loss 0.0081 (0.0447)	
training:	Epoch: [52][62/204]	Loss 0.0070 (0.0441)	
training:	Epoch: [52][63/204]	Loss 0.0068 (0.0435)	
training:	Epoch: [52][64/204]	Loss 0.0064 (0.0429)	
training:	Epoch: [52][65/204]	Loss 0.0079 (0.0424)	
training:	Epoch: [52][66/204]	Loss 0.0067 (0.0419)	
training:	Epoch: [52][67/204]	Loss 0.0086 (0.0414)	
training:	Epoch: [52][68/204]	Loss 0.0076 (0.0409)	
training:	Epoch: [52][69/204]	Loss 0.0072 (0.0404)	
training:	Epoch: [52][70/204]	Loss 0.0072 (0.0399)	
training:	Epoch: [52][71/204]	Loss 0.0073 (0.0395)	
training:	Epoch: [52][72/204]	Loss 0.0077 (0.0390)	
training:	Epoch: [52][73/204]	Loss 0.0069 (0.0386)	
training:	Epoch: [52][74/204]	Loss 0.0072 (0.0381)	
training:	Epoch: [52][75/204]	Loss 0.0059 (0.0377)	
training:	Epoch: [52][76/204]	Loss 0.0068 (0.0373)	
training:	Epoch: [52][77/204]	Loss 0.0062 (0.0369)	
training:	Epoch: [52][78/204]	Loss 0.1524 (0.0384)	
training:	Epoch: [52][79/204]	Loss 0.0070 (0.0380)	
training:	Epoch: [52][80/204]	Loss 0.1615 (0.0395)	
training:	Epoch: [52][81/204]	Loss 0.0095 (0.0392)	
training:	Epoch: [52][82/204]	Loss 0.0173 (0.0389)	
training:	Epoch: [52][83/204]	Loss 0.0076 (0.0385)	
training:	Epoch: [52][84/204]	Loss 0.0078 (0.0382)	
training:	Epoch: [52][85/204]	Loss 0.0065 (0.0378)	
training:	Epoch: [52][86/204]	Loss 0.3024 (0.0409)	
training:	Epoch: [52][87/204]	Loss 0.0067 (0.0405)	
training:	Epoch: [52][88/204]	Loss 0.0072 (0.0401)	
training:	Epoch: [52][89/204]	Loss 0.0073 (0.0397)	
training:	Epoch: [52][90/204]	Loss 0.0069 (0.0394)	
training:	Epoch: [52][91/204]	Loss 0.0101 (0.0390)	
training:	Epoch: [52][92/204]	Loss 0.0082 (0.0387)	
training:	Epoch: [52][93/204]	Loss 0.0075 (0.0384)	
training:	Epoch: [52][94/204]	Loss 0.0062 (0.0380)	
training:	Epoch: [52][95/204]	Loss 0.0066 (0.0377)	
training:	Epoch: [52][96/204]	Loss 0.1479 (0.0388)	
training:	Epoch: [52][97/204]	Loss 0.1619 (0.0401)	
training:	Epoch: [52][98/204]	Loss 0.0088 (0.0398)	
training:	Epoch: [52][99/204]	Loss 0.1352 (0.0408)	
training:	Epoch: [52][100/204]	Loss 0.0067 (0.0404)	
training:	Epoch: [52][101/204]	Loss 0.0067 (0.0401)	
training:	Epoch: [52][102/204]	Loss 0.0088 (0.0398)	
training:	Epoch: [52][103/204]	Loss 0.0068 (0.0395)	
training:	Epoch: [52][104/204]	Loss 0.0065 (0.0391)	
training:	Epoch: [52][105/204]	Loss 0.0074 (0.0388)	
training:	Epoch: [52][106/204]	Loss 0.0076 (0.0385)	
training:	Epoch: [52][107/204]	Loss 0.0070 (0.0382)	
training:	Epoch: [52][108/204]	Loss 0.0067 (0.0380)	
training:	Epoch: [52][109/204]	Loss 0.0068 (0.0377)	
training:	Epoch: [52][110/204]	Loss 0.1450 (0.0386)	
training:	Epoch: [52][111/204]	Loss 0.0067 (0.0384)	
training:	Epoch: [52][112/204]	Loss 0.0073 (0.0381)	
training:	Epoch: [52][113/204]	Loss 0.0076 (0.0378)	
training:	Epoch: [52][114/204]	Loss 0.0063 (0.0375)	
training:	Epoch: [52][115/204]	Loss 0.0065 (0.0373)	
training:	Epoch: [52][116/204]	Loss 0.0065 (0.0370)	
training:	Epoch: [52][117/204]	Loss 0.0211 (0.0369)	
training:	Epoch: [52][118/204]	Loss 0.0062 (0.0366)	
training:	Epoch: [52][119/204]	Loss 0.0061 (0.0363)	
training:	Epoch: [52][120/204]	Loss 0.0070 (0.0361)	
training:	Epoch: [52][121/204]	Loss 0.1241 (0.0368)	
training:	Epoch: [52][122/204]	Loss 0.0061 (0.0366)	
training:	Epoch: [52][123/204]	Loss 0.0067 (0.0363)	
training:	Epoch: [52][124/204]	Loss 0.0065 (0.0361)	
training:	Epoch: [52][125/204]	Loss 0.0143 (0.0359)	
training:	Epoch: [52][126/204]	Loss 0.0065 (0.0357)	
training:	Epoch: [52][127/204]	Loss 0.0068 (0.0355)	
training:	Epoch: [52][128/204]	Loss 0.0059 (0.0352)	
training:	Epoch: [52][129/204]	Loss 0.0060 (0.0350)	
training:	Epoch: [52][130/204]	Loss 0.0060 (0.0348)	
training:	Epoch: [52][131/204]	Loss 0.0068 (0.0346)	
training:	Epoch: [52][132/204]	Loss 0.0087 (0.0344)	
training:	Epoch: [52][133/204]	Loss 0.0065 (0.0342)	
training:	Epoch: [52][134/204]	Loss 0.0062 (0.0339)	
training:	Epoch: [52][135/204]	Loss 0.0064 (0.0337)	
training:	Epoch: [52][136/204]	Loss 0.0067 (0.0335)	
training:	Epoch: [52][137/204]	Loss 0.0066 (0.0333)	
training:	Epoch: [52][138/204]	Loss 0.0066 (0.0332)	
training:	Epoch: [52][139/204]	Loss 0.0111 (0.0330)	
training:	Epoch: [52][140/204]	Loss 0.1529 (0.0339)	
training:	Epoch: [52][141/204]	Loss 0.0075 (0.0337)	
training:	Epoch: [52][142/204]	Loss 0.0064 (0.0335)	
training:	Epoch: [52][143/204]	Loss 0.0071 (0.0333)	
training:	Epoch: [52][144/204]	Loss 0.0064 (0.0331)	
training:	Epoch: [52][145/204]	Loss 0.0058 (0.0329)	
training:	Epoch: [52][146/204]	Loss 0.0063 (0.0327)	
training:	Epoch: [52][147/204]	Loss 0.0071 (0.0326)	
training:	Epoch: [52][148/204]	Loss 0.0073 (0.0324)	
training:	Epoch: [52][149/204]	Loss 0.0078 (0.0322)	
training:	Epoch: [52][150/204]	Loss 0.1425 (0.0330)	
training:	Epoch: [52][151/204]	Loss 0.0069 (0.0328)	
training:	Epoch: [52][152/204]	Loss 0.1680 (0.0337)	
training:	Epoch: [52][153/204]	Loss 0.0062 (0.0335)	
training:	Epoch: [52][154/204]	Loss 0.1632 (0.0343)	
training:	Epoch: [52][155/204]	Loss 0.0069 (0.0342)	
training:	Epoch: [52][156/204]	Loss 0.0067 (0.0340)	
training:	Epoch: [52][157/204]	Loss 0.0111 (0.0338)	
training:	Epoch: [52][158/204]	Loss 0.0061 (0.0337)	
training:	Epoch: [52][159/204]	Loss 0.0077 (0.0335)	
training:	Epoch: [52][160/204]	Loss 0.0057 (0.0333)	
training:	Epoch: [52][161/204]	Loss 0.1506 (0.0341)	
training:	Epoch: [52][162/204]	Loss 0.0064 (0.0339)	
training:	Epoch: [52][163/204]	Loss 0.0063 (0.0337)	
training:	Epoch: [52][164/204]	Loss 0.0069 (0.0335)	
training:	Epoch: [52][165/204]	Loss 0.0064 (0.0334)	
training:	Epoch: [52][166/204]	Loss 0.0067 (0.0332)	
training:	Epoch: [52][167/204]	Loss 0.0060 (0.0331)	
training:	Epoch: [52][168/204]	Loss 0.0060 (0.0329)	
training:	Epoch: [52][169/204]	Loss 0.0068 (0.0327)	
training:	Epoch: [52][170/204]	Loss 0.0061 (0.0326)	
training:	Epoch: [52][171/204]	Loss 0.0062 (0.0324)	
training:	Epoch: [52][172/204]	Loss 0.0073 (0.0323)	
training:	Epoch: [52][173/204]	Loss 0.0058 (0.0321)	
training:	Epoch: [52][174/204]	Loss 0.0066 (0.0320)	
training:	Epoch: [52][175/204]	Loss 0.0092 (0.0319)	
training:	Epoch: [52][176/204]	Loss 0.0073 (0.0317)	
training:	Epoch: [52][177/204]	Loss 0.0065 (0.0316)	
training:	Epoch: [52][178/204]	Loss 0.0058 (0.0314)	
training:	Epoch: [52][179/204]	Loss 0.0058 (0.0313)	
training:	Epoch: [52][180/204]	Loss 0.0064 (0.0311)	
training:	Epoch: [52][181/204]	Loss 0.1598 (0.0319)	
training:	Epoch: [52][182/204]	Loss 0.0065 (0.0317)	
training:	Epoch: [52][183/204]	Loss 0.0070 (0.0316)	
training:	Epoch: [52][184/204]	Loss 0.0066 (0.0314)	
training:	Epoch: [52][185/204]	Loss 0.1540 (0.0321)	
training:	Epoch: [52][186/204]	Loss 0.0066 (0.0320)	
training:	Epoch: [52][187/204]	Loss 0.0064 (0.0318)	
training:	Epoch: [52][188/204]	Loss 0.0065 (0.0317)	
training:	Epoch: [52][189/204]	Loss 0.0073 (0.0316)	
training:	Epoch: [52][190/204]	Loss 0.2777 (0.0329)	
training:	Epoch: [52][191/204]	Loss 0.1370 (0.0334)	
training:	Epoch: [52][192/204]	Loss 0.0179 (0.0333)	
training:	Epoch: [52][193/204]	Loss 0.0061 (0.0332)	
training:	Epoch: [52][194/204]	Loss 0.0058 (0.0330)	
training:	Epoch: [52][195/204]	Loss 0.0057 (0.0329)	
training:	Epoch: [52][196/204]	Loss 0.0057 (0.0328)	
training:	Epoch: [52][197/204]	Loss 0.0056 (0.0326)	
training:	Epoch: [52][198/204]	Loss 0.0159 (0.0325)	
training:	Epoch: [52][199/204]	Loss 0.1139 (0.0330)	
training:	Epoch: [52][200/204]	Loss 0.0059 (0.0328)	
training:	Epoch: [52][201/204]	Loss 0.0064 (0.0327)	
training:	Epoch: [52][202/204]	Loss 0.1565 (0.0333)	
training:	Epoch: [52][203/204]	Loss 0.0059 (0.0332)	
training:	Epoch: [52][204/204]	Loss 0.0062 (0.0330)	
Training:	 Loss: 0.0330

Training:	 ACC: 0.9948 0.9948 0.9950 0.9946
Validation:	 ACC: 0.7743 0.7758 0.8086 0.7399
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0171
Pretraining:	Epoch 53/500
----------
training:	Epoch: [53][1/204]	Loss 0.0060 (0.0060)	
training:	Epoch: [53][2/204]	Loss 0.1185 (0.0622)	
training:	Epoch: [53][3/204]	Loss 0.0059 (0.0435)	
training:	Epoch: [53][4/204]	Loss 0.0062 (0.0342)	
training:	Epoch: [53][5/204]	Loss 0.0060 (0.0285)	
training:	Epoch: [53][6/204]	Loss 0.0066 (0.0249)	
training:	Epoch: [53][7/204]	Loss 0.0068 (0.0223)	
training:	Epoch: [53][8/204]	Loss 0.0066 (0.0203)	
training:	Epoch: [53][9/204]	Loss 0.0084 (0.0190)	
training:	Epoch: [53][10/204]	Loss 0.0057 (0.0177)	
training:	Epoch: [53][11/204]	Loss 0.0070 (0.0167)	
training:	Epoch: [53][12/204]	Loss 0.0067 (0.0159)	
training:	Epoch: [53][13/204]	Loss 0.0079 (0.0152)	
training:	Epoch: [53][14/204]	Loss 0.0087 (0.0148)	
training:	Epoch: [53][15/204]	Loss 0.1421 (0.0233)	
training:	Epoch: [53][16/204]	Loss 0.0111 (0.0225)	
training:	Epoch: [53][17/204]	Loss 0.1367 (0.0292)	
training:	Epoch: [53][18/204]	Loss 0.0063 (0.0280)	
training:	Epoch: [53][19/204]	Loss 0.0058 (0.0268)	
training:	Epoch: [53][20/204]	Loss 0.1589 (0.0334)	
training:	Epoch: [53][21/204]	Loss 0.0064 (0.0321)	
training:	Epoch: [53][22/204]	Loss 0.0074 (0.0310)	
training:	Epoch: [53][23/204]	Loss 0.0090 (0.0300)	
training:	Epoch: [53][24/204]	Loss 0.0075 (0.0291)	
training:	Epoch: [53][25/204]	Loss 0.0079 (0.0282)	
training:	Epoch: [53][26/204]	Loss 0.0077 (0.0275)	
training:	Epoch: [53][27/204]	Loss 0.1690 (0.0327)	
training:	Epoch: [53][28/204]	Loss 0.0071 (0.0318)	
training:	Epoch: [53][29/204]	Loss 0.0164 (0.0313)	
training:	Epoch: [53][30/204]	Loss 0.0072 (0.0305)	
training:	Epoch: [53][31/204]	Loss 0.0070 (0.0297)	
training:	Epoch: [53][32/204]	Loss 0.0081 (0.0290)	
training:	Epoch: [53][33/204]	Loss 0.0082 (0.0284)	
training:	Epoch: [53][34/204]	Loss 0.0078 (0.0278)	
training:	Epoch: [53][35/204]	Loss 0.0062 (0.0272)	
training:	Epoch: [53][36/204]	Loss 0.1605 (0.0309)	
training:	Epoch: [53][37/204]	Loss 0.0064 (0.0302)	
training:	Epoch: [53][38/204]	Loss 0.0062 (0.0296)	
training:	Epoch: [53][39/204]	Loss 0.0063 (0.0290)	
training:	Epoch: [53][40/204]	Loss 0.0061 (0.0284)	
training:	Epoch: [53][41/204]	Loss 0.0094 (0.0279)	
training:	Epoch: [53][42/204]	Loss 0.1698 (0.0313)	
training:	Epoch: [53][43/204]	Loss 0.0061 (0.0307)	
training:	Epoch: [53][44/204]	Loss 0.0076 (0.0302)	
training:	Epoch: [53][45/204]	Loss 0.0089 (0.0297)	
training:	Epoch: [53][46/204]	Loss 0.0065 (0.0292)	
training:	Epoch: [53][47/204]	Loss 0.0060 (0.0287)	
training:	Epoch: [53][48/204]	Loss 0.3241 (0.0349)	
training:	Epoch: [53][49/204]	Loss 0.1514 (0.0373)	
training:	Epoch: [53][50/204]	Loss 0.0069 (0.0367)	
training:	Epoch: [53][51/204]	Loss 0.0065 (0.0361)	
training:	Epoch: [53][52/204]	Loss 0.0060 (0.0355)	
training:	Epoch: [53][53/204]	Loss 0.0067 (0.0349)	
training:	Epoch: [53][54/204]	Loss 0.0065 (0.0344)	
training:	Epoch: [53][55/204]	Loss 0.0327 (0.0344)	
training:	Epoch: [53][56/204]	Loss 0.1517 (0.0365)	
training:	Epoch: [53][57/204]	Loss 0.0058 (0.0359)	
training:	Epoch: [53][58/204]	Loss 0.1584 (0.0381)	
training:	Epoch: [53][59/204]	Loss 0.1358 (0.0397)	
training:	Epoch: [53][60/204]	Loss 0.0070 (0.0392)	
training:	Epoch: [53][61/204]	Loss 0.0056 (0.0386)	
training:	Epoch: [53][62/204]	Loss 0.1449 (0.0403)	
training:	Epoch: [53][63/204]	Loss 0.0067 (0.0398)	
training:	Epoch: [53][64/204]	Loss 0.0065 (0.0393)	
training:	Epoch: [53][65/204]	Loss 0.0070 (0.0388)	
training:	Epoch: [53][66/204]	Loss 0.1314 (0.0402)	
training:	Epoch: [53][67/204]	Loss 0.0074 (0.0397)	
training:	Epoch: [53][68/204]	Loss 0.0071 (0.0392)	
training:	Epoch: [53][69/204]	Loss 0.0073 (0.0388)	
training:	Epoch: [53][70/204]	Loss 0.0068 (0.0383)	
training:	Epoch: [53][71/204]	Loss 0.1669 (0.0401)	
training:	Epoch: [53][72/204]	Loss 0.0070 (0.0396)	
training:	Epoch: [53][73/204]	Loss 0.0061 (0.0392)	
training:	Epoch: [53][74/204]	Loss 0.0074 (0.0388)	
training:	Epoch: [53][75/204]	Loss 0.0138 (0.0384)	
training:	Epoch: [53][76/204]	Loss 0.1428 (0.0398)	
training:	Epoch: [53][77/204]	Loss 0.0084 (0.0394)	
training:	Epoch: [53][78/204]	Loss 0.0072 (0.0390)	
training:	Epoch: [53][79/204]	Loss 0.1780 (0.0407)	
training:	Epoch: [53][80/204]	Loss 0.0098 (0.0404)	
training:	Epoch: [53][81/204]	Loss 0.0079 (0.0400)	
training:	Epoch: [53][82/204]	Loss 0.1617 (0.0414)	
training:	Epoch: [53][83/204]	Loss 0.0067 (0.0410)	
training:	Epoch: [53][84/204]	Loss 0.0075 (0.0406)	
training:	Epoch: [53][85/204]	Loss 0.0063 (0.0402)	
training:	Epoch: [53][86/204]	Loss 0.0069 (0.0398)	
training:	Epoch: [53][87/204]	Loss 0.0064 (0.0394)	
training:	Epoch: [53][88/204]	Loss 0.0070 (0.0391)	
training:	Epoch: [53][89/204]	Loss 0.1449 (0.0403)	
training:	Epoch: [53][90/204]	Loss 0.1468 (0.0414)	
training:	Epoch: [53][91/204]	Loss 0.0082 (0.0411)	
training:	Epoch: [53][92/204]	Loss 0.0067 (0.0407)	
training:	Epoch: [53][93/204]	Loss 0.0067 (0.0403)	
training:	Epoch: [53][94/204]	Loss 0.0059 (0.0400)	
training:	Epoch: [53][95/204]	Loss 0.0088 (0.0396)	
training:	Epoch: [53][96/204]	Loss 0.0075 (0.0393)	
training:	Epoch: [53][97/204]	Loss 0.0074 (0.0390)	
training:	Epoch: [53][98/204]	Loss 0.0074 (0.0387)	
training:	Epoch: [53][99/204]	Loss 0.1383 (0.0397)	
training:	Epoch: [53][100/204]	Loss 0.0072 (0.0393)	
training:	Epoch: [53][101/204]	Loss 0.0072 (0.0390)	
training:	Epoch: [53][102/204]	Loss 0.1412 (0.0400)	
training:	Epoch: [53][103/204]	Loss 0.0077 (0.0397)	
training:	Epoch: [53][104/204]	Loss 0.0071 (0.0394)	
training:	Epoch: [53][105/204]	Loss 0.1490 (0.0404)	
training:	Epoch: [53][106/204]	Loss 0.0077 (0.0401)	
training:	Epoch: [53][107/204]	Loss 0.0088 (0.0398)	
training:	Epoch: [53][108/204]	Loss 0.0075 (0.0395)	
training:	Epoch: [53][109/204]	Loss 0.1400 (0.0405)	
training:	Epoch: [53][110/204]	Loss 0.0077 (0.0402)	
training:	Epoch: [53][111/204]	Loss 0.0080 (0.0399)	
training:	Epoch: [53][112/204]	Loss 0.0068 (0.0396)	
training:	Epoch: [53][113/204]	Loss 0.0109 (0.0393)	
training:	Epoch: [53][114/204]	Loss 0.0070 (0.0390)	
training:	Epoch: [53][115/204]	Loss 0.0073 (0.0388)	
training:	Epoch: [53][116/204]	Loss 0.0077 (0.0385)	
training:	Epoch: [53][117/204]	Loss 0.0073 (0.0382)	
training:	Epoch: [53][118/204]	Loss 0.0074 (0.0380)	
training:	Epoch: [53][119/204]	Loss 0.0074 (0.0377)	
training:	Epoch: [53][120/204]	Loss 0.1464 (0.0386)	
training:	Epoch: [53][121/204]	Loss 0.0069 (0.0384)	
training:	Epoch: [53][122/204]	Loss 0.0088 (0.0381)	
training:	Epoch: [53][123/204]	Loss 0.0068 (0.0379)	
training:	Epoch: [53][124/204]	Loss 0.0079 (0.0376)	
training:	Epoch: [53][125/204]	Loss 0.0189 (0.0375)	
training:	Epoch: [53][126/204]	Loss 0.0068 (0.0372)	
training:	Epoch: [53][127/204]	Loss 0.0061 (0.0370)	
training:	Epoch: [53][128/204]	Loss 0.0063 (0.0367)	
training:	Epoch: [53][129/204]	Loss 0.0069 (0.0365)	
training:	Epoch: [53][130/204]	Loss 0.0065 (0.0363)	
training:	Epoch: [53][131/204]	Loss 0.1593 (0.0372)	
training:	Epoch: [53][132/204]	Loss 0.0065 (0.0370)	
training:	Epoch: [53][133/204]	Loss 0.0069 (0.0368)	
training:	Epoch: [53][134/204]	Loss 0.0076 (0.0365)	
training:	Epoch: [53][135/204]	Loss 0.1095 (0.0371)	
training:	Epoch: [53][136/204]	Loss 0.1569 (0.0380)	
training:	Epoch: [53][137/204]	Loss 0.0074 (0.0377)	
training:	Epoch: [53][138/204]	Loss 0.0074 (0.0375)	
training:	Epoch: [53][139/204]	Loss 0.0091 (0.0373)	
training:	Epoch: [53][140/204]	Loss 0.0070 (0.0371)	
training:	Epoch: [53][141/204]	Loss 0.0082 (0.0369)	
training:	Epoch: [53][142/204]	Loss 0.0070 (0.0367)	
training:	Epoch: [53][143/204]	Loss 0.0096 (0.0365)	
training:	Epoch: [53][144/204]	Loss 0.0803 (0.0368)	
training:	Epoch: [53][145/204]	Loss 0.0073 (0.0366)	
training:	Epoch: [53][146/204]	Loss 0.0065 (0.0364)	
training:	Epoch: [53][147/204]	Loss 0.0074 (0.0362)	
training:	Epoch: [53][148/204]	Loss 0.0081 (0.0360)	
training:	Epoch: [53][149/204]	Loss 0.0068 (0.0358)	
training:	Epoch: [53][150/204]	Loss 0.0066 (0.0356)	
training:	Epoch: [53][151/204]	Loss 0.0085 (0.0354)	
training:	Epoch: [53][152/204]	Loss 0.0080 (0.0353)	
training:	Epoch: [53][153/204]	Loss 0.0078 (0.0351)	
training:	Epoch: [53][154/204]	Loss 0.0085 (0.0349)	
training:	Epoch: [53][155/204]	Loss 0.0068 (0.0347)	
training:	Epoch: [53][156/204]	Loss 0.0060 (0.0345)	
training:	Epoch: [53][157/204]	Loss 0.0064 (0.0344)	
training:	Epoch: [53][158/204]	Loss 0.1373 (0.0350)	
training:	Epoch: [53][159/204]	Loss 0.0066 (0.0348)	
training:	Epoch: [53][160/204]	Loss 0.0069 (0.0347)	
training:	Epoch: [53][161/204]	Loss 0.0090 (0.0345)	
training:	Epoch: [53][162/204]	Loss 0.0073 (0.0343)	
training:	Epoch: [53][163/204]	Loss 0.0064 (0.0342)	
training:	Epoch: [53][164/204]	Loss 0.0069 (0.0340)	
training:	Epoch: [53][165/204]	Loss 0.0068 (0.0338)	
training:	Epoch: [53][166/204]	Loss 0.0085 (0.0337)	
training:	Epoch: [53][167/204]	Loss 0.0077 (0.0335)	
training:	Epoch: [53][168/204]	Loss 0.0059 (0.0334)	
training:	Epoch: [53][169/204]	Loss 0.0071 (0.0332)	
training:	Epoch: [53][170/204]	Loss 0.0067 (0.0330)	
training:	Epoch: [53][171/204]	Loss 0.0082 (0.0329)	
training:	Epoch: [53][172/204]	Loss 0.0066 (0.0327)	
training:	Epoch: [53][173/204]	Loss 0.0087 (0.0326)	
training:	Epoch: [53][174/204]	Loss 0.0067 (0.0325)	
training:	Epoch: [53][175/204]	Loss 0.0068 (0.0323)	
training:	Epoch: [53][176/204]	Loss 0.1572 (0.0330)	
training:	Epoch: [53][177/204]	Loss 0.0072 (0.0329)	
training:	Epoch: [53][178/204]	Loss 0.0061 (0.0327)	
training:	Epoch: [53][179/204]	Loss 0.0630 (0.0329)	
training:	Epoch: [53][180/204]	Loss 0.0061 (0.0327)	
training:	Epoch: [53][181/204]	Loss 0.0068 (0.0326)	
training:	Epoch: [53][182/204]	Loss 0.0060 (0.0325)	
training:	Epoch: [53][183/204]	Loss 0.0072 (0.0323)	
training:	Epoch: [53][184/204]	Loss 0.0061 (0.0322)	
training:	Epoch: [53][185/204]	Loss 0.0062 (0.0320)	
training:	Epoch: [53][186/204]	Loss 0.0059 (0.0319)	
training:	Epoch: [53][187/204]	Loss 0.0074 (0.0318)	
training:	Epoch: [53][188/204]	Loss 0.0058 (0.0316)	
training:	Epoch: [53][189/204]	Loss 0.1588 (0.0323)	
training:	Epoch: [53][190/204]	Loss 0.0058 (0.0322)	
training:	Epoch: [53][191/204]	Loss 0.0071 (0.0320)	
training:	Epoch: [53][192/204]	Loss 0.0063 (0.0319)	
training:	Epoch: [53][193/204]	Loss 0.0084 (0.0318)	
training:	Epoch: [53][194/204]	Loss 0.0061 (0.0316)	
training:	Epoch: [53][195/204]	Loss 0.0077 (0.0315)	
training:	Epoch: [53][196/204]	Loss 0.0061 (0.0314)	
training:	Epoch: [53][197/204]	Loss 0.0060 (0.0313)	
training:	Epoch: [53][198/204]	Loss 0.0061 (0.0311)	
training:	Epoch: [53][199/204]	Loss 0.0076 (0.0310)	
training:	Epoch: [53][200/204]	Loss 0.0070 (0.0309)	
training:	Epoch: [53][201/204]	Loss 0.0063 (0.0308)	
training:	Epoch: [53][202/204]	Loss 0.0079 (0.0307)	
training:	Epoch: [53][203/204]	Loss 0.0067 (0.0305)	
training:	Epoch: [53][204/204]	Loss 0.0075 (0.0304)	
Training:	 Loss: 0.0304

Training:	 ACC: 0.9948 0.9948 0.9950 0.9946
Validation:	 ACC: 0.7701 0.7721 0.8127 0.7276
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0374
Pretraining:	Epoch 54/500
----------
training:	Epoch: [54][1/204]	Loss 0.0068 (0.0068)	
training:	Epoch: [54][2/204]	Loss 0.1373 (0.0721)	
training:	Epoch: [54][3/204]	Loss 0.0064 (0.0502)	
training:	Epoch: [54][4/204]	Loss 0.0062 (0.0392)	
training:	Epoch: [54][5/204]	Loss 0.0064 (0.0326)	
training:	Epoch: [54][6/204]	Loss 0.1609 (0.0540)	
training:	Epoch: [54][7/204]	Loss 0.0063 (0.0472)	
training:	Epoch: [54][8/204]	Loss 0.0058 (0.0420)	
training:	Epoch: [54][9/204]	Loss 0.0068 (0.0381)	
training:	Epoch: [54][10/204]	Loss 0.0053 (0.0348)	
training:	Epoch: [54][11/204]	Loss 0.0057 (0.0322)	
training:	Epoch: [54][12/204]	Loss 0.0058 (0.0300)	
training:	Epoch: [54][13/204]	Loss 0.0073 (0.0282)	
training:	Epoch: [54][14/204]	Loss 0.0056 (0.0266)	
training:	Epoch: [54][15/204]	Loss 0.0062 (0.0253)	
training:	Epoch: [54][16/204]	Loss 0.0074 (0.0241)	
training:	Epoch: [54][17/204]	Loss 0.0053 (0.0230)	
training:	Epoch: [54][18/204]	Loss 0.0056 (0.0221)	
training:	Epoch: [54][19/204]	Loss 0.1532 (0.0290)	
training:	Epoch: [54][20/204]	Loss 0.0074 (0.0279)	
training:	Epoch: [54][21/204]	Loss 0.1697 (0.0346)	
training:	Epoch: [54][22/204]	Loss 0.0067 (0.0334)	
training:	Epoch: [54][23/204]	Loss 0.0067 (0.0322)	
training:	Epoch: [54][24/204]	Loss 0.0049 (0.0311)	
training:	Epoch: [54][25/204]	Loss 0.0065 (0.0301)	
training:	Epoch: [54][26/204]	Loss 0.1049 (0.0330)	
training:	Epoch: [54][27/204]	Loss 0.1270 (0.0364)	
training:	Epoch: [54][28/204]	Loss 0.0105 (0.0355)	
training:	Epoch: [54][29/204]	Loss 0.0070 (0.0345)	
training:	Epoch: [54][30/204]	Loss 0.0062 (0.0336)	
training:	Epoch: [54][31/204]	Loss 0.0066 (0.0327)	
training:	Epoch: [54][32/204]	Loss 0.1662 (0.0369)	
training:	Epoch: [54][33/204]	Loss 0.0062 (0.0360)	
training:	Epoch: [54][34/204]	Loss 0.0076 (0.0351)	
training:	Epoch: [54][35/204]	Loss 0.0066 (0.0343)	
training:	Epoch: [54][36/204]	Loss 0.0069 (0.0336)	
training:	Epoch: [54][37/204]	Loss 0.0059 (0.0328)	
training:	Epoch: [54][38/204]	Loss 0.0067 (0.0321)	
training:	Epoch: [54][39/204]	Loss 0.0084 (0.0315)	
training:	Epoch: [54][40/204]	Loss 0.0073 (0.0309)	
training:	Epoch: [54][41/204]	Loss 0.0068 (0.0303)	
training:	Epoch: [54][42/204]	Loss 0.0082 (0.0298)	
training:	Epoch: [54][43/204]	Loss 0.0066 (0.0293)	
training:	Epoch: [54][44/204]	Loss 0.1705 (0.0325)	
training:	Epoch: [54][45/204]	Loss 0.0071 (0.0319)	
training:	Epoch: [54][46/204]	Loss 0.0068 (0.0314)	
training:	Epoch: [54][47/204]	Loss 0.1540 (0.0340)	
training:	Epoch: [54][48/204]	Loss 0.0073 (0.0334)	
training:	Epoch: [54][49/204]	Loss 0.0079 (0.0329)	
training:	Epoch: [54][50/204]	Loss 0.0068 (0.0324)	
training:	Epoch: [54][51/204]	Loss 0.0066 (0.0319)	
training:	Epoch: [54][52/204]	Loss 0.0076 (0.0314)	
training:	Epoch: [54][53/204]	Loss 0.0074 (0.0309)	
training:	Epoch: [54][54/204]	Loss 0.0081 (0.0305)	
training:	Epoch: [54][55/204]	Loss 0.0078 (0.0301)	
training:	Epoch: [54][56/204]	Loss 0.0549 (0.0305)	
training:	Epoch: [54][57/204]	Loss 0.0066 (0.0301)	
training:	Epoch: [54][58/204]	Loss 0.0078 (0.0297)	
training:	Epoch: [54][59/204]	Loss 0.0062 (0.0293)	
training:	Epoch: [54][60/204]	Loss 0.0062 (0.0290)	
training:	Epoch: [54][61/204]	Loss 0.0058 (0.0286)	
training:	Epoch: [54][62/204]	Loss 0.0067 (0.0282)	
training:	Epoch: [54][63/204]	Loss 0.0074 (0.0279)	
training:	Epoch: [54][64/204]	Loss 0.1604 (0.0300)	
training:	Epoch: [54][65/204]	Loss 0.0067 (0.0296)	
training:	Epoch: [54][66/204]	Loss 0.0057 (0.0292)	
training:	Epoch: [54][67/204]	Loss 0.0070 (0.0289)	
training:	Epoch: [54][68/204]	Loss 0.0061 (0.0286)	
training:	Epoch: [54][69/204]	Loss 0.0081 (0.0283)	
training:	Epoch: [54][70/204]	Loss 0.1347 (0.0298)	
training:	Epoch: [54][71/204]	Loss 0.0057 (0.0295)	
training:	Epoch: [54][72/204]	Loss 0.0067 (0.0291)	
training:	Epoch: [54][73/204]	Loss 0.1426 (0.0307)	
training:	Epoch: [54][74/204]	Loss 0.0060 (0.0304)	
training:	Epoch: [54][75/204]	Loss 0.0090 (0.0301)	
training:	Epoch: [54][76/204]	Loss 0.0070 (0.0298)	
training:	Epoch: [54][77/204]	Loss 0.0090 (0.0295)	
training:	Epoch: [54][78/204]	Loss 0.0072 (0.0292)	
training:	Epoch: [54][79/204]	Loss 0.0075 (0.0289)	
training:	Epoch: [54][80/204]	Loss 0.0058 (0.0287)	
training:	Epoch: [54][81/204]	Loss 0.0063 (0.0284)	
training:	Epoch: [54][82/204]	Loss 0.0066 (0.0281)	
training:	Epoch: [54][83/204]	Loss 0.1527 (0.0296)	
training:	Epoch: [54][84/204]	Loss 0.0069 (0.0293)	
training:	Epoch: [54][85/204]	Loss 0.0059 (0.0291)	
training:	Epoch: [54][86/204]	Loss 0.0085 (0.0288)	
training:	Epoch: [54][87/204]	Loss 0.0062 (0.0286)	
training:	Epoch: [54][88/204]	Loss 0.0069 (0.0283)	
training:	Epoch: [54][89/204]	Loss 0.2871 (0.0312)	
training:	Epoch: [54][90/204]	Loss 0.0066 (0.0310)	
training:	Epoch: [54][91/204]	Loss 0.0065 (0.0307)	
training:	Epoch: [54][92/204]	Loss 0.0054 (0.0304)	
training:	Epoch: [54][93/204]	Loss 0.0066 (0.0302)	
training:	Epoch: [54][94/204]	Loss 0.0083 (0.0299)	
training:	Epoch: [54][95/204]	Loss 0.0070 (0.0297)	
training:	Epoch: [54][96/204]	Loss 0.1458 (0.0309)	
training:	Epoch: [54][97/204]	Loss 0.0084 (0.0307)	
training:	Epoch: [54][98/204]	Loss 0.0053 (0.0304)	
training:	Epoch: [54][99/204]	Loss 0.1626 (0.0317)	
training:	Epoch: [54][100/204]	Loss 0.0058 (0.0315)	
training:	Epoch: [54][101/204]	Loss 0.0375 (0.0315)	
training:	Epoch: [54][102/204]	Loss 0.1536 (0.0327)	
training:	Epoch: [54][103/204]	Loss 0.1726 (0.0341)	
training:	Epoch: [54][104/204]	Loss 0.0066 (0.0338)	
training:	Epoch: [54][105/204]	Loss 0.0070 (0.0336)	
training:	Epoch: [54][106/204]	Loss 0.0126 (0.0334)	
training:	Epoch: [54][107/204]	Loss 0.0053 (0.0331)	
training:	Epoch: [54][108/204]	Loss 0.0059 (0.0329)	
training:	Epoch: [54][109/204]	Loss 0.0073 (0.0326)	
training:	Epoch: [54][110/204]	Loss 0.0064 (0.0324)	
training:	Epoch: [54][111/204]	Loss 0.0056 (0.0321)	
training:	Epoch: [54][112/204]	Loss 0.0059 (0.0319)	
training:	Epoch: [54][113/204]	Loss 0.0071 (0.0317)	
training:	Epoch: [54][114/204]	Loss 0.1627 (0.0328)	
training:	Epoch: [54][115/204]	Loss 0.0072 (0.0326)	
training:	Epoch: [54][116/204]	Loss 0.1403 (0.0335)	
training:	Epoch: [54][117/204]	Loss 0.1497 (0.0345)	
training:	Epoch: [54][118/204]	Loss 0.0080 (0.0343)	
training:	Epoch: [54][119/204]	Loss 0.0062 (0.0341)	
training:	Epoch: [54][120/204]	Loss 0.0073 (0.0339)	
training:	Epoch: [54][121/204]	Loss 0.0074 (0.0336)	
training:	Epoch: [54][122/204]	Loss 0.0066 (0.0334)	
training:	Epoch: [54][123/204]	Loss 0.0060 (0.0332)	
training:	Epoch: [54][124/204]	Loss 0.0047 (0.0330)	
training:	Epoch: [54][125/204]	Loss 0.0065 (0.0328)	
training:	Epoch: [54][126/204]	Loss 0.0066 (0.0325)	
training:	Epoch: [54][127/204]	Loss 0.0109 (0.0324)	
training:	Epoch: [54][128/204]	Loss 0.0076 (0.0322)	
training:	Epoch: [54][129/204]	Loss 0.1520 (0.0331)	
training:	Epoch: [54][130/204]	Loss 0.0060 (0.0329)	
training:	Epoch: [54][131/204]	Loss 0.0060 (0.0327)	
training:	Epoch: [54][132/204]	Loss 0.0064 (0.0325)	
training:	Epoch: [54][133/204]	Loss 0.0061 (0.0323)	
training:	Epoch: [54][134/204]	Loss 0.1434 (0.0331)	
training:	Epoch: [54][135/204]	Loss 0.1528 (0.0340)	
training:	Epoch: [54][136/204]	Loss 0.0074 (0.0338)	
training:	Epoch: [54][137/204]	Loss 0.0089 (0.0336)	
training:	Epoch: [54][138/204]	Loss 0.0071 (0.0334)	
training:	Epoch: [54][139/204]	Loss 0.0061 (0.0332)	
training:	Epoch: [54][140/204]	Loss 0.0056 (0.0331)	
training:	Epoch: [54][141/204]	Loss 0.0062 (0.0329)	
training:	Epoch: [54][142/204]	Loss 0.1234 (0.0335)	
training:	Epoch: [54][143/204]	Loss 0.0061 (0.0333)	
training:	Epoch: [54][144/204]	Loss 0.0061 (0.0331)	
training:	Epoch: [54][145/204]	Loss 0.0065 (0.0329)	
training:	Epoch: [54][146/204]	Loss 0.1650 (0.0338)	
training:	Epoch: [54][147/204]	Loss 0.0063 (0.0337)	
training:	Epoch: [54][148/204]	Loss 0.0066 (0.0335)	
training:	Epoch: [54][149/204]	Loss 0.0077 (0.0333)	
training:	Epoch: [54][150/204]	Loss 0.0067 (0.0331)	
training:	Epoch: [54][151/204]	Loss 0.0061 (0.0329)	
training:	Epoch: [54][152/204]	Loss 0.0063 (0.0328)	
training:	Epoch: [54][153/204]	Loss 0.1448 (0.0335)	
training:	Epoch: [54][154/204]	Loss 0.0062 (0.0333)	
training:	Epoch: [54][155/204]	Loss 0.0085 (0.0332)	
training:	Epoch: [54][156/204]	Loss 0.0061 (0.0330)	
training:	Epoch: [54][157/204]	Loss 0.0069 (0.0328)	
training:	Epoch: [54][158/204]	Loss 0.0060 (0.0326)	
training:	Epoch: [54][159/204]	Loss 0.0072 (0.0325)	
training:	Epoch: [54][160/204]	Loss 0.0058 (0.0323)	
training:	Epoch: [54][161/204]	Loss 0.0060 (0.0322)	
training:	Epoch: [54][162/204]	Loss 0.0065 (0.0320)	
training:	Epoch: [54][163/204]	Loss 0.0062 (0.0318)	
training:	Epoch: [54][164/204]	Loss 0.1105 (0.0323)	
training:	Epoch: [54][165/204]	Loss 0.0058 (0.0322)	
training:	Epoch: [54][166/204]	Loss 0.0064 (0.0320)	
training:	Epoch: [54][167/204]	Loss 0.0065 (0.0319)	
training:	Epoch: [54][168/204]	Loss 0.0122 (0.0317)	
training:	Epoch: [54][169/204]	Loss 0.0064 (0.0316)	
training:	Epoch: [54][170/204]	Loss 0.0063 (0.0314)	
training:	Epoch: [54][171/204]	Loss 0.0069 (0.0313)	
training:	Epoch: [54][172/204]	Loss 0.0059 (0.0311)	
training:	Epoch: [54][173/204]	Loss 0.0081 (0.0310)	
training:	Epoch: [54][174/204]	Loss 0.0052 (0.0309)	
training:	Epoch: [54][175/204]	Loss 0.0059 (0.0307)	
training:	Epoch: [54][176/204]	Loss 0.0078 (0.0306)	
training:	Epoch: [54][177/204]	Loss 0.0060 (0.0305)	
training:	Epoch: [54][178/204]	Loss 0.0057 (0.0303)	
training:	Epoch: [54][179/204]	Loss 0.0073 (0.0302)	
training:	Epoch: [54][180/204]	Loss 0.0084 (0.0301)	
training:	Epoch: [54][181/204]	Loss 0.0062 (0.0299)	
training:	Epoch: [54][182/204]	Loss 0.0079 (0.0298)	
training:	Epoch: [54][183/204]	Loss 0.0064 (0.0297)	
training:	Epoch: [54][184/204]	Loss 0.0060 (0.0296)	
training:	Epoch: [54][185/204]	Loss 0.0065 (0.0294)	
training:	Epoch: [54][186/204]	Loss 0.0064 (0.0293)	
training:	Epoch: [54][187/204]	Loss 0.0089 (0.0292)	
training:	Epoch: [54][188/204]	Loss 0.0057 (0.0291)	
training:	Epoch: [54][189/204]	Loss 0.0051 (0.0289)	
training:	Epoch: [54][190/204]	Loss 0.0067 (0.0288)	
training:	Epoch: [54][191/204]	Loss 0.0062 (0.0287)	
training:	Epoch: [54][192/204]	Loss 0.0068 (0.0286)	
training:	Epoch: [54][193/204]	Loss 0.0053 (0.0285)	
training:	Epoch: [54][194/204]	Loss 0.0053 (0.0284)	
training:	Epoch: [54][195/204]	Loss 0.0067 (0.0282)	
training:	Epoch: [54][196/204]	Loss 0.0055 (0.0281)	
training:	Epoch: [54][197/204]	Loss 0.1537 (0.0288)	
training:	Epoch: [54][198/204]	Loss 0.0060 (0.0287)	
training:	Epoch: [54][199/204]	Loss 0.0056 (0.0285)	
training:	Epoch: [54][200/204]	Loss 0.0066 (0.0284)	
training:	Epoch: [54][201/204]	Loss 0.1628 (0.0291)	
training:	Epoch: [54][202/204]	Loss 0.0061 (0.0290)	
training:	Epoch: [54][203/204]	Loss 0.0064 (0.0289)	
training:	Epoch: [54][204/204]	Loss 0.1709 (0.0296)	
Training:	 Loss: 0.0295

Training:	 ACC: 0.9951 0.9951 0.9956 0.9946
Validation:	 ACC: 0.7723 0.7742 0.8137 0.7309
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0439
Pretraining:	Epoch 55/500
----------
training:	Epoch: [55][1/204]	Loss 0.0059 (0.0059)	
training:	Epoch: [55][2/204]	Loss 0.0065 (0.0062)	
training:	Epoch: [55][3/204]	Loss 0.0061 (0.0062)	
training:	Epoch: [55][4/204]	Loss 0.0054 (0.0060)	
training:	Epoch: [55][5/204]	Loss 0.0064 (0.0061)	
training:	Epoch: [55][6/204]	Loss 0.0068 (0.0062)	
training:	Epoch: [55][7/204]	Loss 0.0048 (0.0060)	
training:	Epoch: [55][8/204]	Loss 0.0062 (0.0060)	
training:	Epoch: [55][9/204]	Loss 0.0055 (0.0060)	
training:	Epoch: [55][10/204]	Loss 0.0072 (0.0061)	
training:	Epoch: [55][11/204]	Loss 0.0057 (0.0060)	
training:	Epoch: [55][12/204]	Loss 0.0063 (0.0061)	
training:	Epoch: [55][13/204]	Loss 0.1629 (0.0181)	
training:	Epoch: [55][14/204]	Loss 0.0066 (0.0173)	
training:	Epoch: [55][15/204]	Loss 0.0052 (0.0165)	
training:	Epoch: [55][16/204]	Loss 0.0066 (0.0159)	
training:	Epoch: [55][17/204]	Loss 0.0054 (0.0153)	
training:	Epoch: [55][18/204]	Loss 0.0051 (0.0147)	
training:	Epoch: [55][19/204]	Loss 0.0070 (0.0143)	
training:	Epoch: [55][20/204]	Loss 0.0057 (0.0139)	
training:	Epoch: [55][21/204]	Loss 0.0069 (0.0135)	
training:	Epoch: [55][22/204]	Loss 0.0060 (0.0132)	
training:	Epoch: [55][23/204]	Loss 0.0057 (0.0129)	
training:	Epoch: [55][24/204]	Loss 0.0054 (0.0125)	
training:	Epoch: [55][25/204]	Loss 0.0064 (0.0123)	
training:	Epoch: [55][26/204]	Loss 0.0063 (0.0121)	
training:	Epoch: [55][27/204]	Loss 0.0063 (0.0119)	
training:	Epoch: [55][28/204]	Loss 0.1622 (0.0172)	
training:	Epoch: [55][29/204]	Loss 0.0054 (0.0168)	
training:	Epoch: [55][30/204]	Loss 0.1362 (0.0208)	
training:	Epoch: [55][31/204]	Loss 0.1527 (0.0251)	
training:	Epoch: [55][32/204]	Loss 0.0067 (0.0245)	
training:	Epoch: [55][33/204]	Loss 0.3036 (0.0329)	
training:	Epoch: [55][34/204]	Loss 0.0068 (0.0322)	
training:	Epoch: [55][35/204]	Loss 0.1627 (0.0359)	
training:	Epoch: [55][36/204]	Loss 0.0063 (0.0351)	
training:	Epoch: [55][37/204]	Loss 0.0059 (0.0343)	
training:	Epoch: [55][38/204]	Loss 0.0069 (0.0336)	
training:	Epoch: [55][39/204]	Loss 0.0269 (0.0334)	
training:	Epoch: [55][40/204]	Loss 0.0060 (0.0327)	
training:	Epoch: [55][41/204]	Loss 0.0053 (0.0320)	
training:	Epoch: [55][42/204]	Loss 0.0060 (0.0314)	
training:	Epoch: [55][43/204]	Loss 0.0062 (0.0308)	
training:	Epoch: [55][44/204]	Loss 0.0090 (0.0303)	
training:	Epoch: [55][45/204]	Loss 0.0057 (0.0298)	
training:	Epoch: [55][46/204]	Loss 0.0066 (0.0293)	
training:	Epoch: [55][47/204]	Loss 0.0063 (0.0288)	
training:	Epoch: [55][48/204]	Loss 0.0074 (0.0283)	
training:	Epoch: [55][49/204]	Loss 0.0060 (0.0279)	
training:	Epoch: [55][50/204]	Loss 0.1632 (0.0306)	
training:	Epoch: [55][51/204]	Loss 0.0055 (0.0301)	
training:	Epoch: [55][52/204]	Loss 0.0072 (0.0297)	
training:	Epoch: [55][53/204]	Loss 0.0056 (0.0292)	
training:	Epoch: [55][54/204]	Loss 0.0064 (0.0288)	
training:	Epoch: [55][55/204]	Loss 0.0059 (0.0284)	
training:	Epoch: [55][56/204]	Loss 0.0060 (0.0280)	
training:	Epoch: [55][57/204]	Loss 0.0057 (0.0276)	
training:	Epoch: [55][58/204]	Loss 0.0058 (0.0272)	
training:	Epoch: [55][59/204]	Loss 0.0070 (0.0269)	
training:	Epoch: [55][60/204]	Loss 0.0057 (0.0265)	
training:	Epoch: [55][61/204]	Loss 0.0060 (0.0262)	
training:	Epoch: [55][62/204]	Loss 0.0091 (0.0259)	
training:	Epoch: [55][63/204]	Loss 0.0062 (0.0256)	
training:	Epoch: [55][64/204]	Loss 0.0066 (0.0253)	
training:	Epoch: [55][65/204]	Loss 0.0057 (0.0250)	
training:	Epoch: [55][66/204]	Loss 0.0060 (0.0247)	
training:	Epoch: [55][67/204]	Loss 0.0053 (0.0244)	
training:	Epoch: [55][68/204]	Loss 0.0054 (0.0241)	
training:	Epoch: [55][69/204]	Loss 0.0180 (0.0240)	
training:	Epoch: [55][70/204]	Loss 0.1472 (0.0258)	
training:	Epoch: [55][71/204]	Loss 0.0061 (0.0255)	
training:	Epoch: [55][72/204]	Loss 0.0058 (0.0253)	
training:	Epoch: [55][73/204]	Loss 0.0055 (0.0250)	
training:	Epoch: [55][74/204]	Loss 0.0059 (0.0247)	
training:	Epoch: [55][75/204]	Loss 0.0047 (0.0245)	
training:	Epoch: [55][76/204]	Loss 0.0051 (0.0242)	
training:	Epoch: [55][77/204]	Loss 0.0074 (0.0240)	
training:	Epoch: [55][78/204]	Loss 0.0076 (0.0238)	
training:	Epoch: [55][79/204]	Loss 0.0064 (0.0236)	
training:	Epoch: [55][80/204]	Loss 0.0063 (0.0233)	
training:	Epoch: [55][81/204]	Loss 0.0054 (0.0231)	
training:	Epoch: [55][82/204]	Loss 0.0063 (0.0229)	
training:	Epoch: [55][83/204]	Loss 0.0064 (0.0227)	
training:	Epoch: [55][84/204]	Loss 0.0058 (0.0225)	
training:	Epoch: [55][85/204]	Loss 0.0058 (0.0223)	
training:	Epoch: [55][86/204]	Loss 0.0058 (0.0221)	
training:	Epoch: [55][87/204]	Loss 0.0054 (0.0219)	
training:	Epoch: [55][88/204]	Loss 0.0054 (0.0217)	
training:	Epoch: [55][89/204]	Loss 0.1593 (0.0233)	
training:	Epoch: [55][90/204]	Loss 0.0055 (0.0231)	
training:	Epoch: [55][91/204]	Loss 0.0057 (0.0229)	
training:	Epoch: [55][92/204]	Loss 0.0056 (0.0227)	
training:	Epoch: [55][93/204]	Loss 0.0065 (0.0225)	
training:	Epoch: [55][94/204]	Loss 0.0050 (0.0224)	
training:	Epoch: [55][95/204]	Loss 0.0058 (0.0222)	
training:	Epoch: [55][96/204]	Loss 0.0064 (0.0220)	
training:	Epoch: [55][97/204]	Loss 0.0057 (0.0218)	
training:	Epoch: [55][98/204]	Loss 0.0053 (0.0217)	
training:	Epoch: [55][99/204]	Loss 0.0054 (0.0215)	
training:	Epoch: [55][100/204]	Loss 0.0056 (0.0214)	
training:	Epoch: [55][101/204]	Loss 0.0067 (0.0212)	
training:	Epoch: [55][102/204]	Loss 0.0056 (0.0211)	
training:	Epoch: [55][103/204]	Loss 0.1747 (0.0225)	
training:	Epoch: [55][104/204]	Loss 0.0049 (0.0224)	
training:	Epoch: [55][105/204]	Loss 0.0048 (0.0222)	
training:	Epoch: [55][106/204]	Loss 0.0053 (0.0221)	
training:	Epoch: [55][107/204]	Loss 0.0079 (0.0219)	
training:	Epoch: [55][108/204]	Loss 0.2991 (0.0245)	
training:	Epoch: [55][109/204]	Loss 0.0064 (0.0243)	
training:	Epoch: [55][110/204]	Loss 0.0059 (0.0242)	
training:	Epoch: [55][111/204]	Loss 0.0055 (0.0240)	
training:	Epoch: [55][112/204]	Loss 0.0055 (0.0238)	
training:	Epoch: [55][113/204]	Loss 0.0050 (0.0237)	
training:	Epoch: [55][114/204]	Loss 0.0049 (0.0235)	
training:	Epoch: [55][115/204]	Loss 0.0049 (0.0233)	
training:	Epoch: [55][116/204]	Loss 0.0049 (0.0232)	
training:	Epoch: [55][117/204]	Loss 0.0058 (0.0230)	
training:	Epoch: [55][118/204]	Loss 0.0055 (0.0229)	
training:	Epoch: [55][119/204]	Loss 0.0062 (0.0227)	
training:	Epoch: [55][120/204]	Loss 0.0048 (0.0226)	
training:	Epoch: [55][121/204]	Loss 0.0060 (0.0224)	
training:	Epoch: [55][122/204]	Loss 0.1334 (0.0234)	
training:	Epoch: [55][123/204]	Loss 0.0053 (0.0232)	
training:	Epoch: [55][124/204]	Loss 0.0048 (0.0231)	
training:	Epoch: [55][125/204]	Loss 0.0048 (0.0229)	
training:	Epoch: [55][126/204]	Loss 0.0047 (0.0228)	
training:	Epoch: [55][127/204]	Loss 0.3107 (0.0250)	
training:	Epoch: [55][128/204]	Loss 0.0053 (0.0249)	
training:	Epoch: [55][129/204]	Loss 0.0052 (0.0247)	
training:	Epoch: [55][130/204]	Loss 0.0056 (0.0246)	
training:	Epoch: [55][131/204]	Loss 0.0070 (0.0244)	
training:	Epoch: [55][132/204]	Loss 0.0052 (0.0243)	
training:	Epoch: [55][133/204]	Loss 0.1675 (0.0254)	
training:	Epoch: [55][134/204]	Loss 0.0057 (0.0252)	
training:	Epoch: [55][135/204]	Loss 0.0048 (0.0251)	
training:	Epoch: [55][136/204]	Loss 0.0049 (0.0249)	
training:	Epoch: [55][137/204]	Loss 0.0062 (0.0248)	
training:	Epoch: [55][138/204]	Loss 0.0055 (0.0247)	
training:	Epoch: [55][139/204]	Loss 0.0056 (0.0245)	
training:	Epoch: [55][140/204]	Loss 0.0053 (0.0244)	
training:	Epoch: [55][141/204]	Loss 0.1702 (0.0254)	
training:	Epoch: [55][142/204]	Loss 0.0058 (0.0253)	
training:	Epoch: [55][143/204]	Loss 0.2888 (0.0271)	
training:	Epoch: [55][144/204]	Loss 0.0068 (0.0270)	
training:	Epoch: [55][145/204]	Loss 0.0055 (0.0268)	
training:	Epoch: [55][146/204]	Loss 0.0049 (0.0267)	
training:	Epoch: [55][147/204]	Loss 0.0047 (0.0265)	
training:	Epoch: [55][148/204]	Loss 0.0055 (0.0264)	
training:	Epoch: [55][149/204]	Loss 0.0059 (0.0262)	
training:	Epoch: [55][150/204]	Loss 0.0061 (0.0261)	
training:	Epoch: [55][151/204]	Loss 0.0085 (0.0260)	
training:	Epoch: [55][152/204]	Loss 0.0066 (0.0259)	
training:	Epoch: [55][153/204]	Loss 0.1718 (0.0268)	
training:	Epoch: [55][154/204]	Loss 0.1378 (0.0275)	
training:	Epoch: [55][155/204]	Loss 0.1498 (0.0283)	
training:	Epoch: [55][156/204]	Loss 0.0057 (0.0282)	
training:	Epoch: [55][157/204]	Loss 0.0059 (0.0280)	
training:	Epoch: [55][158/204]	Loss 0.0051 (0.0279)	
training:	Epoch: [55][159/204]	Loss 0.0073 (0.0278)	
training:	Epoch: [55][160/204]	Loss 0.1417 (0.0285)	
training:	Epoch: [55][161/204]	Loss 0.0057 (0.0283)	
training:	Epoch: [55][162/204]	Loss 0.1087 (0.0288)	
training:	Epoch: [55][163/204]	Loss 0.0066 (0.0287)	
training:	Epoch: [55][164/204]	Loss 0.1704 (0.0296)	
training:	Epoch: [55][165/204]	Loss 0.0067 (0.0294)	
training:	Epoch: [55][166/204]	Loss 0.0064 (0.0293)	
training:	Epoch: [55][167/204]	Loss 0.0066 (0.0292)	
training:	Epoch: [55][168/204]	Loss 0.0066 (0.0290)	
training:	Epoch: [55][169/204]	Loss 0.0062 (0.0289)	
training:	Epoch: [55][170/204]	Loss 0.0055 (0.0287)	
training:	Epoch: [55][171/204]	Loss 0.1439 (0.0294)	
training:	Epoch: [55][172/204]	Loss 0.0064 (0.0293)	
training:	Epoch: [55][173/204]	Loss 0.0053 (0.0291)	
training:	Epoch: [55][174/204]	Loss 0.0066 (0.0290)	
training:	Epoch: [55][175/204]	Loss 0.0060 (0.0289)	
training:	Epoch: [55][176/204]	Loss 0.0066 (0.0288)	
training:	Epoch: [55][177/204]	Loss 0.0052 (0.0286)	
training:	Epoch: [55][178/204]	Loss 0.0080 (0.0285)	
training:	Epoch: [55][179/204]	Loss 0.3048 (0.0301)	
training:	Epoch: [55][180/204]	Loss 0.0064 (0.0299)	
training:	Epoch: [55][181/204]	Loss 0.1651 (0.0307)	
training:	Epoch: [55][182/204]	Loss 0.0074 (0.0305)	
training:	Epoch: [55][183/204]	Loss 0.0063 (0.0304)	
training:	Epoch: [55][184/204]	Loss 0.0871 (0.0307)	
training:	Epoch: [55][185/204]	Loss 0.0063 (0.0306)	
training:	Epoch: [55][186/204]	Loss 0.0055 (0.0305)	
training:	Epoch: [55][187/204]	Loss 0.0052 (0.0303)	
training:	Epoch: [55][188/204]	Loss 0.0061 (0.0302)	
training:	Epoch: [55][189/204]	Loss 0.0101 (0.0301)	
training:	Epoch: [55][190/204]	Loss 0.0066 (0.0300)	
training:	Epoch: [55][191/204]	Loss 0.0061 (0.0298)	
training:	Epoch: [55][192/204]	Loss 0.0063 (0.0297)	
training:	Epoch: [55][193/204]	Loss 0.0065 (0.0296)	
training:	Epoch: [55][194/204]	Loss 0.0086 (0.0295)	
training:	Epoch: [55][195/204]	Loss 0.0070 (0.0294)	
training:	Epoch: [55][196/204]	Loss 0.0074 (0.0293)	
training:	Epoch: [55][197/204]	Loss 0.0062 (0.0291)	
training:	Epoch: [55][198/204]	Loss 0.0072 (0.0290)	
training:	Epoch: [55][199/204]	Loss 0.0068 (0.0289)	
training:	Epoch: [55][200/204]	Loss 0.0078 (0.0288)	
training:	Epoch: [55][201/204]	Loss 0.0066 (0.0287)	
training:	Epoch: [55][202/204]	Loss 0.0100 (0.0286)	
training:	Epoch: [55][203/204]	Loss 0.0055 (0.0285)	
training:	Epoch: [55][204/204]	Loss 0.0082 (0.0284)	
Training:	 Loss: 0.0283

Training:	 ACC: 0.9954 0.9954 0.9959 0.9949
Validation:	 ACC: 0.7756 0.7769 0.8045 0.7466
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0422
Pretraining:	Epoch 56/500
----------
training:	Epoch: [56][1/204]	Loss 0.0080 (0.0080)	
training:	Epoch: [56][2/204]	Loss 0.1490 (0.0785)	
training:	Epoch: [56][3/204]	Loss 0.0070 (0.0547)	
training:	Epoch: [56][4/204]	Loss 0.1448 (0.0772)	
training:	Epoch: [56][5/204]	Loss 0.0073 (0.0632)	
training:	Epoch: [56][6/204]	Loss 0.1714 (0.0813)	
training:	Epoch: [56][7/204]	Loss 0.0076 (0.0708)	
training:	Epoch: [56][8/204]	Loss 0.0063 (0.0627)	
training:	Epoch: [56][9/204]	Loss 0.0061 (0.0564)	
training:	Epoch: [56][10/204]	Loss 0.0071 (0.0515)	
training:	Epoch: [56][11/204]	Loss 0.0067 (0.0474)	
training:	Epoch: [56][12/204]	Loss 0.0065 (0.0440)	
training:	Epoch: [56][13/204]	Loss 0.0075 (0.0412)	
training:	Epoch: [56][14/204]	Loss 0.0056 (0.0386)	
training:	Epoch: [56][15/204]	Loss 0.0080 (0.0366)	
training:	Epoch: [56][16/204]	Loss 0.0074 (0.0348)	
training:	Epoch: [56][17/204]	Loss 0.0065 (0.0331)	
training:	Epoch: [56][18/204]	Loss 0.0081 (0.0317)	
training:	Epoch: [56][19/204]	Loss 0.0073 (0.0304)	
training:	Epoch: [56][20/204]	Loss 0.0067 (0.0292)	
training:	Epoch: [56][21/204]	Loss 0.1343 (0.0343)	
training:	Epoch: [56][22/204]	Loss 0.0073 (0.0330)	
training:	Epoch: [56][23/204]	Loss 0.1046 (0.0361)	
training:	Epoch: [56][24/204]	Loss 0.1622 (0.0414)	
training:	Epoch: [56][25/204]	Loss 0.0060 (0.0400)	
training:	Epoch: [56][26/204]	Loss 0.0060 (0.0387)	
training:	Epoch: [56][27/204]	Loss 0.1230 (0.0418)	
training:	Epoch: [56][28/204]	Loss 0.1645 (0.0462)	
training:	Epoch: [56][29/204]	Loss 0.0096 (0.0449)	
training:	Epoch: [56][30/204]	Loss 0.0048 (0.0436)	
training:	Epoch: [56][31/204]	Loss 0.0063 (0.0424)	
training:	Epoch: [56][32/204]	Loss 0.0060 (0.0412)	
training:	Epoch: [56][33/204]	Loss 0.1371 (0.0441)	
training:	Epoch: [56][34/204]	Loss 0.0056 (0.0430)	
training:	Epoch: [56][35/204]	Loss 0.1670 (0.0466)	
training:	Epoch: [56][36/204]	Loss 0.0061 (0.0454)	
training:	Epoch: [56][37/204]	Loss 0.1454 (0.0481)	
training:	Epoch: [56][38/204]	Loss 0.0068 (0.0470)	
training:	Epoch: [56][39/204]	Loss 0.0069 (0.0460)	
training:	Epoch: [56][40/204]	Loss 0.1383 (0.0483)	
training:	Epoch: [56][41/204]	Loss 0.0066 (0.0473)	
training:	Epoch: [56][42/204]	Loss 0.0083 (0.0464)	
training:	Epoch: [56][43/204]	Loss 0.0079 (0.0455)	
training:	Epoch: [56][44/204]	Loss 0.0073 (0.0446)	
training:	Epoch: [56][45/204]	Loss 0.0062 (0.0438)	
training:	Epoch: [56][46/204]	Loss 0.0067 (0.0430)	
training:	Epoch: [56][47/204]	Loss 0.0071 (0.0422)	
training:	Epoch: [56][48/204]	Loss 0.0071 (0.0415)	
training:	Epoch: [56][49/204]	Loss 0.0076 (0.0408)	
training:	Epoch: [56][50/204]	Loss 0.1652 (0.0433)	
training:	Epoch: [56][51/204]	Loss 0.0071 (0.0425)	
training:	Epoch: [56][52/204]	Loss 0.1584 (0.0448)	
training:	Epoch: [56][53/204]	Loss 0.0072 (0.0441)	
training:	Epoch: [56][54/204]	Loss 0.0087 (0.0434)	
training:	Epoch: [56][55/204]	Loss 0.0069 (0.0428)	
training:	Epoch: [56][56/204]	Loss 0.0112 (0.0422)	
training:	Epoch: [56][57/204]	Loss 0.1622 (0.0443)	
training:	Epoch: [56][58/204]	Loss 0.0073 (0.0437)	
training:	Epoch: [56][59/204]	Loss 0.1521 (0.0455)	
training:	Epoch: [56][60/204]	Loss 0.0066 (0.0448)	
training:	Epoch: [56][61/204]	Loss 0.0082 (0.0442)	
training:	Epoch: [56][62/204]	Loss 0.0059 (0.0436)	
training:	Epoch: [56][63/204]	Loss 0.0058 (0.0430)	
training:	Epoch: [56][64/204]	Loss 0.0080 (0.0425)	
training:	Epoch: [56][65/204]	Loss 0.0076 (0.0419)	
training:	Epoch: [56][66/204]	Loss 0.0069 (0.0414)	
training:	Epoch: [56][67/204]	Loss 0.0060 (0.0409)	
training:	Epoch: [56][68/204]	Loss 0.1630 (0.0427)	
training:	Epoch: [56][69/204]	Loss 0.0066 (0.0422)	
training:	Epoch: [56][70/204]	Loss 0.0065 (0.0416)	
training:	Epoch: [56][71/204]	Loss 0.0067 (0.0412)	
training:	Epoch: [56][72/204]	Loss 0.0062 (0.0407)	
training:	Epoch: [56][73/204]	Loss 0.0078 (0.0402)	
training:	Epoch: [56][74/204]	Loss 0.1547 (0.0418)	
training:	Epoch: [56][75/204]	Loss 0.0074 (0.0413)	
training:	Epoch: [56][76/204]	Loss 0.0064 (0.0408)	
training:	Epoch: [56][77/204]	Loss 0.0073 (0.0404)	
training:	Epoch: [56][78/204]	Loss 0.0063 (0.0400)	
training:	Epoch: [56][79/204]	Loss 0.0056 (0.0395)	
training:	Epoch: [56][80/204]	Loss 0.0062 (0.0391)	
training:	Epoch: [56][81/204]	Loss 0.0066 (0.0387)	
training:	Epoch: [56][82/204]	Loss 0.0065 (0.0383)	
training:	Epoch: [56][83/204]	Loss 0.0061 (0.0379)	
training:	Epoch: [56][84/204]	Loss 0.0079 (0.0376)	
training:	Epoch: [56][85/204]	Loss 0.0063 (0.0372)	
training:	Epoch: [56][86/204]	Loss 0.0110 (0.0369)	
training:	Epoch: [56][87/204]	Loss 0.0063 (0.0366)	
training:	Epoch: [56][88/204]	Loss 0.0079 (0.0362)	
training:	Epoch: [56][89/204]	Loss 0.0048 (0.0359)	
training:	Epoch: [56][90/204]	Loss 0.0060 (0.0355)	
training:	Epoch: [56][91/204]	Loss 0.0060 (0.0352)	
training:	Epoch: [56][92/204]	Loss 0.0096 (0.0349)	
training:	Epoch: [56][93/204]	Loss 0.0067 (0.0346)	
training:	Epoch: [56][94/204]	Loss 0.0067 (0.0343)	
training:	Epoch: [56][95/204]	Loss 0.0062 (0.0340)	
training:	Epoch: [56][96/204]	Loss 0.0065 (0.0338)	
training:	Epoch: [56][97/204]	Loss 0.0065 (0.0335)	
training:	Epoch: [56][98/204]	Loss 0.0059 (0.0332)	
training:	Epoch: [56][99/204]	Loss 0.0063 (0.0329)	
training:	Epoch: [56][100/204]	Loss 0.0055 (0.0327)	
training:	Epoch: [56][101/204]	Loss 0.0055 (0.0324)	
training:	Epoch: [56][102/204]	Loss 0.0066 (0.0321)	
training:	Epoch: [56][103/204]	Loss 0.0072 (0.0319)	
training:	Epoch: [56][104/204]	Loss 0.0069 (0.0317)	
training:	Epoch: [56][105/204]	Loss 0.0056 (0.0314)	
training:	Epoch: [56][106/204]	Loss 0.0054 (0.0312)	
training:	Epoch: [56][107/204]	Loss 0.0077 (0.0309)	
training:	Epoch: [56][108/204]	Loss 0.0078 (0.0307)	
training:	Epoch: [56][109/204]	Loss 0.0072 (0.0305)	
training:	Epoch: [56][110/204]	Loss 0.0067 (0.0303)	
training:	Epoch: [56][111/204]	Loss 0.0069 (0.0301)	
training:	Epoch: [56][112/204]	Loss 0.0058 (0.0299)	
training:	Epoch: [56][113/204]	Loss 0.0057 (0.0296)	
training:	Epoch: [56][114/204]	Loss 0.0060 (0.0294)	
training:	Epoch: [56][115/204]	Loss 0.0048 (0.0292)	
training:	Epoch: [56][116/204]	Loss 0.0072 (0.0290)	
training:	Epoch: [56][117/204]	Loss 0.0058 (0.0288)	
training:	Epoch: [56][118/204]	Loss 0.0063 (0.0286)	
training:	Epoch: [56][119/204]	Loss 0.1501 (0.0297)	
training:	Epoch: [56][120/204]	Loss 0.0058 (0.0295)	
training:	Epoch: [56][121/204]	Loss 0.1467 (0.0304)	
training:	Epoch: [56][122/204]	Loss 0.0055 (0.0302)	
training:	Epoch: [56][123/204]	Loss 0.0061 (0.0300)	
training:	Epoch: [56][124/204]	Loss 0.0063 (0.0298)	
training:	Epoch: [56][125/204]	Loss 0.1251 (0.0306)	
training:	Epoch: [56][126/204]	Loss 0.0065 (0.0304)	
training:	Epoch: [56][127/204]	Loss 0.0072 (0.0302)	
training:	Epoch: [56][128/204]	Loss 0.0076 (0.0301)	
training:	Epoch: [56][129/204]	Loss 0.1532 (0.0310)	
training:	Epoch: [56][130/204]	Loss 0.0060 (0.0308)	
training:	Epoch: [56][131/204]	Loss 0.0054 (0.0306)	
training:	Epoch: [56][132/204]	Loss 0.0052 (0.0304)	
training:	Epoch: [56][133/204]	Loss 0.0065 (0.0303)	
training:	Epoch: [56][134/204]	Loss 0.0057 (0.0301)	
training:	Epoch: [56][135/204]	Loss 0.0054 (0.0299)	
training:	Epoch: [56][136/204]	Loss 0.0068 (0.0297)	
training:	Epoch: [56][137/204]	Loss 0.0051 (0.0295)	
training:	Epoch: [56][138/204]	Loss 0.0059 (0.0294)	
training:	Epoch: [56][139/204]	Loss 0.0061 (0.0292)	
training:	Epoch: [56][140/204]	Loss 0.1634 (0.0302)	
training:	Epoch: [56][141/204]	Loss 0.0053 (0.0300)	
training:	Epoch: [56][142/204]	Loss 0.0062 (0.0298)	
training:	Epoch: [56][143/204]	Loss 0.0056 (0.0296)	
training:	Epoch: [56][144/204]	Loss 0.0052 (0.0295)	
training:	Epoch: [56][145/204]	Loss 0.0056 (0.0293)	
training:	Epoch: [56][146/204]	Loss 0.0053 (0.0291)	
training:	Epoch: [56][147/204]	Loss 0.0047 (0.0290)	
training:	Epoch: [56][148/204]	Loss 0.1712 (0.0299)	
training:	Epoch: [56][149/204]	Loss 0.1556 (0.0308)	
training:	Epoch: [56][150/204]	Loss 0.0060 (0.0306)	
training:	Epoch: [56][151/204]	Loss 0.0055 (0.0305)	
training:	Epoch: [56][152/204]	Loss 0.1650 (0.0313)	
training:	Epoch: [56][153/204]	Loss 0.0060 (0.0312)	
training:	Epoch: [56][154/204]	Loss 0.1506 (0.0319)	
training:	Epoch: [56][155/204]	Loss 0.0047 (0.0318)	
training:	Epoch: [56][156/204]	Loss 0.0057 (0.0316)	
training:	Epoch: [56][157/204]	Loss 0.0058 (0.0314)	
training:	Epoch: [56][158/204]	Loss 0.0048 (0.0313)	
training:	Epoch: [56][159/204]	Loss 0.0071 (0.0311)	
training:	Epoch: [56][160/204]	Loss 0.0054 (0.0310)	
training:	Epoch: [56][161/204]	Loss 0.0069 (0.0308)	
training:	Epoch: [56][162/204]	Loss 0.0065 (0.0307)	
training:	Epoch: [56][163/204]	Loss 0.1033 (0.0311)	
training:	Epoch: [56][164/204]	Loss 0.0054 (0.0309)	
training:	Epoch: [56][165/204]	Loss 0.0055 (0.0308)	
training:	Epoch: [56][166/204]	Loss 0.0055 (0.0306)	
training:	Epoch: [56][167/204]	Loss 0.0060 (0.0305)	
training:	Epoch: [56][168/204]	Loss 0.0065 (0.0304)	
training:	Epoch: [56][169/204]	Loss 0.0077 (0.0302)	
training:	Epoch: [56][170/204]	Loss 0.0096 (0.0301)	
training:	Epoch: [56][171/204]	Loss 0.0078 (0.0300)	
training:	Epoch: [56][172/204]	Loss 0.0152 (0.0299)	
training:	Epoch: [56][173/204]	Loss 0.0120 (0.0298)	
training:	Epoch: [56][174/204]	Loss 0.0104 (0.0297)	
training:	Epoch: [56][175/204]	Loss 0.1627 (0.0304)	
training:	Epoch: [56][176/204]	Loss 0.0071 (0.0303)	
training:	Epoch: [56][177/204]	Loss 0.0059 (0.0302)	
training:	Epoch: [56][178/204]	Loss 0.0364 (0.0302)	
training:	Epoch: [56][179/204]	Loss 0.1080 (0.0306)	
training:	Epoch: [56][180/204]	Loss 0.0064 (0.0305)	
training:	Epoch: [56][181/204]	Loss 0.0062 (0.0304)	
training:	Epoch: [56][182/204]	Loss 0.0069 (0.0302)	
training:	Epoch: [56][183/204]	Loss 0.1295 (0.0308)	
training:	Epoch: [56][184/204]	Loss 0.0055 (0.0306)	
training:	Epoch: [56][185/204]	Loss 0.0107 (0.0305)	
training:	Epoch: [56][186/204]	Loss 0.0054 (0.0304)	
training:	Epoch: [56][187/204]	Loss 0.0075 (0.0303)	
training:	Epoch: [56][188/204]	Loss 0.2464 (0.0314)	
training:	Epoch: [56][189/204]	Loss 0.0088 (0.0313)	
training:	Epoch: [56][190/204]	Loss 0.0064 (0.0312)	
training:	Epoch: [56][191/204]	Loss 0.0913 (0.0315)	
training:	Epoch: [56][192/204]	Loss 0.0076 (0.0314)	
training:	Epoch: [56][193/204]	Loss 0.0075 (0.0312)	
training:	Epoch: [56][194/204]	Loss 0.0055 (0.0311)	
training:	Epoch: [56][195/204]	Loss 0.0106 (0.0310)	
training:	Epoch: [56][196/204]	Loss 0.0079 (0.0309)	
training:	Epoch: [56][197/204]	Loss 0.0085 (0.0308)	
training:	Epoch: [56][198/204]	Loss 0.0067 (0.0306)	
training:	Epoch: [56][199/204]	Loss 0.0078 (0.0305)	
training:	Epoch: [56][200/204]	Loss 0.0191 (0.0305)	
training:	Epoch: [56][201/204]	Loss 0.0071 (0.0304)	
training:	Epoch: [56][202/204]	Loss 0.0362 (0.0304)	
training:	Epoch: [56][203/204]	Loss 0.0083 (0.0303)	
training:	Epoch: [56][204/204]	Loss 0.0064 (0.0302)	
Training:	 Loss: 0.0301

Training:	 ACC: 0.9943 0.9943 0.9959 0.9927
Validation:	 ACC: 0.7696 0.7726 0.8362 0.7029
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0668
Pretraining:	Epoch 57/500
----------
training:	Epoch: [57][1/204]	Loss 0.0093 (0.0093)	
training:	Epoch: [57][2/204]	Loss 0.0061 (0.0077)	
training:	Epoch: [57][3/204]	Loss 0.0082 (0.0079)	
training:	Epoch: [57][4/204]	Loss 0.1536 (0.0443)	
training:	Epoch: [57][5/204]	Loss 0.1710 (0.0697)	
training:	Epoch: [57][6/204]	Loss 0.0089 (0.0595)	
training:	Epoch: [57][7/204]	Loss 0.0062 (0.0519)	
training:	Epoch: [57][8/204]	Loss 0.0062 (0.0462)	
training:	Epoch: [57][9/204]	Loss 0.0238 (0.0437)	
training:	Epoch: [57][10/204]	Loss 0.0067 (0.0400)	
training:	Epoch: [57][11/204]	Loss 0.0056 (0.0369)	
training:	Epoch: [57][12/204]	Loss 0.0068 (0.0344)	
training:	Epoch: [57][13/204]	Loss 0.0057 (0.0322)	
training:	Epoch: [57][14/204]	Loss 0.0065 (0.0303)	
training:	Epoch: [57][15/204]	Loss 0.0071 (0.0288)	
training:	Epoch: [57][16/204]	Loss 0.0055 (0.0273)	
training:	Epoch: [57][17/204]	Loss 0.0061 (0.0261)	
training:	Epoch: [57][18/204]	Loss 0.0142 (0.0254)	
training:	Epoch: [57][19/204]	Loss 0.0047 (0.0243)	
training:	Epoch: [57][20/204]	Loss 0.0053 (0.0234)	
training:	Epoch: [57][21/204]	Loss 0.0098 (0.0227)	
training:	Epoch: [57][22/204]	Loss 0.0061 (0.0220)	
training:	Epoch: [57][23/204]	Loss 0.0073 (0.0213)	
training:	Epoch: [57][24/204]	Loss 0.1646 (0.0273)	
training:	Epoch: [57][25/204]	Loss 0.0054 (0.0264)	
training:	Epoch: [57][26/204]	Loss 0.0054 (0.0256)	
training:	Epoch: [57][27/204]	Loss 0.1451 (0.0300)	
training:	Epoch: [57][28/204]	Loss 0.0061 (0.0292)	
training:	Epoch: [57][29/204]	Loss 0.0062 (0.0284)	
training:	Epoch: [57][30/204]	Loss 0.0062 (0.0277)	
training:	Epoch: [57][31/204]	Loss 0.0068 (0.0270)	
training:	Epoch: [57][32/204]	Loss 0.0262 (0.0270)	
training:	Epoch: [57][33/204]	Loss 0.0070 (0.0264)	
training:	Epoch: [57][34/204]	Loss 0.0052 (0.0257)	
training:	Epoch: [57][35/204]	Loss 0.0053 (0.0251)	
training:	Epoch: [57][36/204]	Loss 0.0051 (0.0246)	
training:	Epoch: [57][37/204]	Loss 0.0060 (0.0241)	
training:	Epoch: [57][38/204]	Loss 0.0055 (0.0236)	
training:	Epoch: [57][39/204]	Loss 0.0053 (0.0231)	
training:	Epoch: [57][40/204]	Loss 0.0052 (0.0227)	
training:	Epoch: [57][41/204]	Loss 0.0079 (0.0223)	
training:	Epoch: [57][42/204]	Loss 0.0048 (0.0219)	
training:	Epoch: [57][43/204]	Loss 0.0052 (0.0215)	
training:	Epoch: [57][44/204]	Loss 0.0126 (0.0213)	
training:	Epoch: [57][45/204]	Loss 0.1698 (0.0246)	
training:	Epoch: [57][46/204]	Loss 0.0057 (0.0242)	
training:	Epoch: [57][47/204]	Loss 0.0084 (0.0239)	
training:	Epoch: [57][48/204]	Loss 0.0053 (0.0235)	
training:	Epoch: [57][49/204]	Loss 0.0060 (0.0231)	
training:	Epoch: [57][50/204]	Loss 0.0054 (0.0228)	
training:	Epoch: [57][51/204]	Loss 0.0053 (0.0224)	
training:	Epoch: [57][52/204]	Loss 0.0060 (0.0221)	
training:	Epoch: [57][53/204]	Loss 0.0055 (0.0218)	
training:	Epoch: [57][54/204]	Loss 0.0049 (0.0215)	
training:	Epoch: [57][55/204]	Loss 0.0054 (0.0212)	
training:	Epoch: [57][56/204]	Loss 0.0051 (0.0209)	
training:	Epoch: [57][57/204]	Loss 0.0054 (0.0206)	
training:	Epoch: [57][58/204]	Loss 0.0053 (0.0204)	
training:	Epoch: [57][59/204]	Loss 0.1577 (0.0227)	
training:	Epoch: [57][60/204]	Loss 0.0061 (0.0224)	
training:	Epoch: [57][61/204]	Loss 0.0068 (0.0222)	
training:	Epoch: [57][62/204]	Loss 0.0070 (0.0219)	
training:	Epoch: [57][63/204]	Loss 0.0055 (0.0217)	
training:	Epoch: [57][64/204]	Loss 0.0048 (0.0214)	
training:	Epoch: [57][65/204]	Loss 0.0052 (0.0211)	
training:	Epoch: [57][66/204]	Loss 0.1211 (0.0227)	
training:	Epoch: [57][67/204]	Loss 0.0046 (0.0224)	
training:	Epoch: [57][68/204]	Loss 0.0048 (0.0221)	
training:	Epoch: [57][69/204]	Loss 0.0063 (0.0219)	
training:	Epoch: [57][70/204]	Loss 0.0053 (0.0217)	
training:	Epoch: [57][71/204]	Loss 0.0051 (0.0214)	
training:	Epoch: [57][72/204]	Loss 0.0065 (0.0212)	
training:	Epoch: [57][73/204]	Loss 0.0056 (0.0210)	
training:	Epoch: [57][74/204]	Loss 0.0052 (0.0208)	
training:	Epoch: [57][75/204]	Loss 0.0053 (0.0206)	
training:	Epoch: [57][76/204]	Loss 0.0059 (0.0204)	
training:	Epoch: [57][77/204]	Loss 0.1519 (0.0221)	
training:	Epoch: [57][78/204]	Loss 0.0058 (0.0219)	
training:	Epoch: [57][79/204]	Loss 0.1432 (0.0234)	
training:	Epoch: [57][80/204]	Loss 0.0052 (0.0232)	
training:	Epoch: [57][81/204]	Loss 0.0051 (0.0230)	
training:	Epoch: [57][82/204]	Loss 0.0051 (0.0228)	
training:	Epoch: [57][83/204]	Loss 0.0053 (0.0225)	
training:	Epoch: [57][84/204]	Loss 0.0277 (0.0226)	
training:	Epoch: [57][85/204]	Loss 0.0044 (0.0224)	
training:	Epoch: [57][86/204]	Loss 0.1616 (0.0240)	
training:	Epoch: [57][87/204]	Loss 0.1691 (0.0257)	
training:	Epoch: [57][88/204]	Loss 0.0055 (0.0255)	
training:	Epoch: [57][89/204]	Loss 0.0050 (0.0252)	
training:	Epoch: [57][90/204]	Loss 0.0057 (0.0250)	
training:	Epoch: [57][91/204]	Loss 0.0061 (0.0248)	
training:	Epoch: [57][92/204]	Loss 0.0054 (0.0246)	
training:	Epoch: [57][93/204]	Loss 0.0052 (0.0244)	
training:	Epoch: [57][94/204]	Loss 0.0058 (0.0242)	
training:	Epoch: [57][95/204]	Loss 0.0061 (0.0240)	
training:	Epoch: [57][96/204]	Loss 0.0065 (0.0238)	
training:	Epoch: [57][97/204]	Loss 0.1215 (0.0248)	
training:	Epoch: [57][98/204]	Loss 0.1750 (0.0263)	
training:	Epoch: [57][99/204]	Loss 0.0051 (0.0261)	
training:	Epoch: [57][100/204]	Loss 0.0055 (0.0259)	
training:	Epoch: [57][101/204]	Loss 0.0053 (0.0257)	
training:	Epoch: [57][102/204]	Loss 0.0054 (0.0255)	
training:	Epoch: [57][103/204]	Loss 0.0060 (0.0253)	
training:	Epoch: [57][104/204]	Loss 0.0059 (0.0251)	
training:	Epoch: [57][105/204]	Loss 0.0091 (0.0250)	
training:	Epoch: [57][106/204]	Loss 0.0063 (0.0248)	
training:	Epoch: [57][107/204]	Loss 0.0050 (0.0246)	
training:	Epoch: [57][108/204]	Loss 0.0087 (0.0245)	
training:	Epoch: [57][109/204]	Loss 0.1452 (0.0256)	
training:	Epoch: [57][110/204]	Loss 0.0059 (0.0254)	
training:	Epoch: [57][111/204]	Loss 0.0060 (0.0252)	
training:	Epoch: [57][112/204]	Loss 0.0070 (0.0251)	
training:	Epoch: [57][113/204]	Loss 0.0109 (0.0249)	
training:	Epoch: [57][114/204]	Loss 0.0054 (0.0248)	
training:	Epoch: [57][115/204]	Loss 0.0055 (0.0246)	
training:	Epoch: [57][116/204]	Loss 0.0062 (0.0245)	
training:	Epoch: [57][117/204]	Loss 0.0062 (0.0243)	
training:	Epoch: [57][118/204]	Loss 0.0057 (0.0241)	
training:	Epoch: [57][119/204]	Loss 0.0054 (0.0240)	
training:	Epoch: [57][120/204]	Loss 0.0071 (0.0238)	
training:	Epoch: [57][121/204]	Loss 0.0056 (0.0237)	
training:	Epoch: [57][122/204]	Loss 0.0053 (0.0235)	
training:	Epoch: [57][123/204]	Loss 0.0059 (0.0234)	
training:	Epoch: [57][124/204]	Loss 0.0055 (0.0233)	
training:	Epoch: [57][125/204]	Loss 0.0055 (0.0231)	
training:	Epoch: [57][126/204]	Loss 0.0067 (0.0230)	
training:	Epoch: [57][127/204]	Loss 0.0057 (0.0228)	
training:	Epoch: [57][128/204]	Loss 0.0057 (0.0227)	
training:	Epoch: [57][129/204]	Loss 0.0061 (0.0226)	
training:	Epoch: [57][130/204]	Loss 0.0051 (0.0224)	
training:	Epoch: [57][131/204]	Loss 0.0045 (0.0223)	
training:	Epoch: [57][132/204]	Loss 0.0094 (0.0222)	
training:	Epoch: [57][133/204]	Loss 0.0056 (0.0221)	
training:	Epoch: [57][134/204]	Loss 0.1477 (0.0230)	
training:	Epoch: [57][135/204]	Loss 0.0064 (0.0229)	
training:	Epoch: [57][136/204]	Loss 0.0060 (0.0228)	
training:	Epoch: [57][137/204]	Loss 0.0052 (0.0226)	
training:	Epoch: [57][138/204]	Loss 0.0057 (0.0225)	
training:	Epoch: [57][139/204]	Loss 0.1496 (0.0234)	
training:	Epoch: [57][140/204]	Loss 0.3000 (0.0254)	
training:	Epoch: [57][141/204]	Loss 0.0053 (0.0253)	
training:	Epoch: [57][142/204]	Loss 0.0056 (0.0251)	
training:	Epoch: [57][143/204]	Loss 0.0052 (0.0250)	
training:	Epoch: [57][144/204]	Loss 0.1513 (0.0259)	
training:	Epoch: [57][145/204]	Loss 0.0056 (0.0257)	
training:	Epoch: [57][146/204]	Loss 0.0051 (0.0256)	
training:	Epoch: [57][147/204]	Loss 0.1434 (0.0264)	
training:	Epoch: [57][148/204]	Loss 0.0158 (0.0263)	
training:	Epoch: [57][149/204]	Loss 0.0047 (0.0262)	
training:	Epoch: [57][150/204]	Loss 0.0057 (0.0260)	
training:	Epoch: [57][151/204]	Loss 0.0055 (0.0259)	
training:	Epoch: [57][152/204]	Loss 0.0057 (0.0258)	
training:	Epoch: [57][153/204]	Loss 0.0056 (0.0256)	
training:	Epoch: [57][154/204]	Loss 0.0059 (0.0255)	
training:	Epoch: [57][155/204]	Loss 0.0785 (0.0259)	
training:	Epoch: [57][156/204]	Loss 0.1449 (0.0266)	
training:	Epoch: [57][157/204]	Loss 0.0389 (0.0267)	
training:	Epoch: [57][158/204]	Loss 0.0063 (0.0266)	
training:	Epoch: [57][159/204]	Loss 0.0063 (0.0264)	
training:	Epoch: [57][160/204]	Loss 0.0075 (0.0263)	
training:	Epoch: [57][161/204]	Loss 0.0082 (0.0262)	
training:	Epoch: [57][162/204]	Loss 0.0131 (0.0261)	
training:	Epoch: [57][163/204]	Loss 0.1238 (0.0267)	
training:	Epoch: [57][164/204]	Loss 0.0061 (0.0266)	
training:	Epoch: [57][165/204]	Loss 0.0077 (0.0265)	
training:	Epoch: [57][166/204]	Loss 0.1528 (0.0272)	
training:	Epoch: [57][167/204]	Loss 0.0067 (0.0271)	
training:	Epoch: [57][168/204]	Loss 0.2642 (0.0285)	
training:	Epoch: [57][169/204]	Loss 0.0172 (0.0285)	
training:	Epoch: [57][170/204]	Loss 0.0080 (0.0283)	
training:	Epoch: [57][171/204]	Loss 0.0078 (0.0282)	
training:	Epoch: [57][172/204]	Loss 0.0164 (0.0282)	
training:	Epoch: [57][173/204]	Loss 0.0053 (0.0280)	
training:	Epoch: [57][174/204]	Loss 0.1451 (0.0287)	
training:	Epoch: [57][175/204]	Loss 0.0072 (0.0286)	
training:	Epoch: [57][176/204]	Loss 0.0086 (0.0285)	
training:	Epoch: [57][177/204]	Loss 0.0092 (0.0284)	
training:	Epoch: [57][178/204]	Loss 0.0078 (0.0282)	
training:	Epoch: [57][179/204]	Loss 0.0169 (0.0282)	
training:	Epoch: [57][180/204]	Loss 0.0066 (0.0281)	
training:	Epoch: [57][181/204]	Loss 0.0075 (0.0279)	
training:	Epoch: [57][182/204]	Loss 0.0077 (0.0278)	
training:	Epoch: [57][183/204]	Loss 0.0072 (0.0277)	
training:	Epoch: [57][184/204]	Loss 0.0095 (0.0276)	
training:	Epoch: [57][185/204]	Loss 0.0054 (0.0275)	
training:	Epoch: [57][186/204]	Loss 0.1650 (0.0282)	
training:	Epoch: [57][187/204]	Loss 0.0058 (0.0281)	
training:	Epoch: [57][188/204]	Loss 0.0056 (0.0280)	
training:	Epoch: [57][189/204]	Loss 0.0066 (0.0279)	
training:	Epoch: [57][190/204]	Loss 0.1657 (0.0286)	
training:	Epoch: [57][191/204]	Loss 0.0072 (0.0285)	
training:	Epoch: [57][192/204]	Loss 0.0063 (0.0284)	
training:	Epoch: [57][193/204]	Loss 0.0075 (0.0283)	
training:	Epoch: [57][194/204]	Loss 0.0064 (0.0282)	
training:	Epoch: [57][195/204]	Loss 0.0053 (0.0280)	
training:	Epoch: [57][196/204]	Loss 0.0067 (0.0279)	
training:	Epoch: [57][197/204]	Loss 0.0061 (0.0278)	
training:	Epoch: [57][198/204]	Loss 0.1696 (0.0285)	
training:	Epoch: [57][199/204]	Loss 0.0065 (0.0284)	
training:	Epoch: [57][200/204]	Loss 0.0185 (0.0284)	
training:	Epoch: [57][201/204]	Loss 0.0069 (0.0283)	
training:	Epoch: [57][202/204]	Loss 0.0086 (0.0282)	
training:	Epoch: [57][203/204]	Loss 0.0058 (0.0281)	
training:	Epoch: [57][204/204]	Loss 0.0051 (0.0280)	
Training:	 Loss: 0.0279

Training:	 ACC: 0.9954 0.9954 0.9959 0.9949
Validation:	 ACC: 0.7818 0.7817 0.7789 0.7848
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0363
Pretraining:	Epoch 58/500
----------
training:	Epoch: [58][1/204]	Loss 0.0064 (0.0064)	
training:	Epoch: [58][2/204]	Loss 0.0111 (0.0088)	
training:	Epoch: [58][3/204]	Loss 0.0093 (0.0089)	
training:	Epoch: [58][4/204]	Loss 0.0076 (0.0086)	
training:	Epoch: [58][5/204]	Loss 0.0055 (0.0080)	
training:	Epoch: [58][6/204]	Loss 0.0079 (0.0080)	
training:	Epoch: [58][7/204]	Loss 0.0062 (0.0077)	
training:	Epoch: [58][8/204]	Loss 0.0054 (0.0074)	
training:	Epoch: [58][9/204]	Loss 0.0068 (0.0074)	
training:	Epoch: [58][10/204]	Loss 0.0065 (0.0073)	
training:	Epoch: [58][11/204]	Loss 0.0072 (0.0073)	
training:	Epoch: [58][12/204]	Loss 0.1673 (0.0206)	
training:	Epoch: [58][13/204]	Loss 0.1136 (0.0278)	
training:	Epoch: [58][14/204]	Loss 0.0060 (0.0262)	
training:	Epoch: [58][15/204]	Loss 0.0050 (0.0248)	
training:	Epoch: [58][16/204]	Loss 0.0057 (0.0236)	
training:	Epoch: [58][17/204]	Loss 0.0062 (0.0226)	
training:	Epoch: [58][18/204]	Loss 0.0065 (0.0217)	
training:	Epoch: [58][19/204]	Loss 0.0058 (0.0208)	
training:	Epoch: [58][20/204]	Loss 0.0051 (0.0201)	
training:	Epoch: [58][21/204]	Loss 0.0052 (0.0194)	
training:	Epoch: [58][22/204]	Loss 0.2987 (0.0320)	
training:	Epoch: [58][23/204]	Loss 0.0055 (0.0309)	
training:	Epoch: [58][24/204]	Loss 0.0073 (0.0299)	
training:	Epoch: [58][25/204]	Loss 0.0066 (0.0290)	
training:	Epoch: [58][26/204]	Loss 0.0063 (0.0281)	
training:	Epoch: [58][27/204]	Loss 0.0053 (0.0273)	
training:	Epoch: [58][28/204]	Loss 0.0070 (0.0265)	
training:	Epoch: [58][29/204]	Loss 0.1007 (0.0291)	
training:	Epoch: [58][30/204]	Loss 0.0064 (0.0283)	
training:	Epoch: [58][31/204]	Loss 0.0063 (0.0276)	
training:	Epoch: [58][32/204]	Loss 0.0068 (0.0270)	
training:	Epoch: [58][33/204]	Loss 0.0060 (0.0263)	
training:	Epoch: [58][34/204]	Loss 0.0060 (0.0257)	
training:	Epoch: [58][35/204]	Loss 0.0060 (0.0252)	
training:	Epoch: [58][36/204]	Loss 0.0098 (0.0248)	
training:	Epoch: [58][37/204]	Loss 0.0072 (0.0243)	
training:	Epoch: [58][38/204]	Loss 0.0056 (0.0238)	
training:	Epoch: [58][39/204]	Loss 0.1626 (0.0273)	
training:	Epoch: [58][40/204]	Loss 0.0422 (0.0277)	
training:	Epoch: [58][41/204]	Loss 0.1083 (0.0297)	
training:	Epoch: [58][42/204]	Loss 0.0086 (0.0292)	
training:	Epoch: [58][43/204]	Loss 0.0561 (0.0298)	
training:	Epoch: [58][44/204]	Loss 0.0048 (0.0292)	
training:	Epoch: [58][45/204]	Loss 0.0056 (0.0287)	
training:	Epoch: [58][46/204]	Loss 0.1561 (0.0315)	
training:	Epoch: [58][47/204]	Loss 0.0059 (0.0309)	
training:	Epoch: [58][48/204]	Loss 0.0185 (0.0307)	
training:	Epoch: [58][49/204]	Loss 0.0164 (0.0304)	
training:	Epoch: [58][50/204]	Loss 0.0261 (0.0303)	
training:	Epoch: [58][51/204]	Loss 0.0210 (0.0301)	
training:	Epoch: [58][52/204]	Loss 0.3323 (0.0359)	
training:	Epoch: [58][53/204]	Loss 0.0056 (0.0354)	
training:	Epoch: [58][54/204]	Loss 0.1574 (0.0376)	
training:	Epoch: [58][55/204]	Loss 0.2705 (0.0418)	
training:	Epoch: [58][56/204]	Loss 0.0481 (0.0420)	
training:	Epoch: [58][57/204]	Loss 0.0062 (0.0413)	
training:	Epoch: [58][58/204]	Loss 0.0051 (0.0407)	
training:	Epoch: [58][59/204]	Loss 0.0062 (0.0401)	
training:	Epoch: [58][60/204]	Loss 0.0064 (0.0396)	
training:	Epoch: [58][61/204]	Loss 0.0062 (0.0390)	
training:	Epoch: [58][62/204]	Loss 0.0057 (0.0385)	
training:	Epoch: [58][63/204]	Loss 0.0070 (0.0380)	
training:	Epoch: [58][64/204]	Loss 0.0047 (0.0375)	
training:	Epoch: [58][65/204]	Loss 0.0061 (0.0370)	
training:	Epoch: [58][66/204]	Loss 0.0068 (0.0365)	
training:	Epoch: [58][67/204]	Loss 0.0828 (0.0372)	
training:	Epoch: [58][68/204]	Loss 0.0352 (0.0372)	
training:	Epoch: [58][69/204]	Loss 0.0052 (0.0367)	
training:	Epoch: [58][70/204]	Loss 0.0055 (0.0363)	
training:	Epoch: [58][71/204]	Loss 0.0057 (0.0358)	
training:	Epoch: [58][72/204]	Loss 0.0050 (0.0354)	
training:	Epoch: [58][73/204]	Loss 0.0056 (0.0350)	
training:	Epoch: [58][74/204]	Loss 0.1486 (0.0365)	
training:	Epoch: [58][75/204]	Loss 0.0134 (0.0362)	
training:	Epoch: [58][76/204]	Loss 0.0097 (0.0359)	
training:	Epoch: [58][77/204]	Loss 0.0065 (0.0355)	
training:	Epoch: [58][78/204]	Loss 0.0057 (0.0351)	
training:	Epoch: [58][79/204]	Loss 0.0064 (0.0348)	
training:	Epoch: [58][80/204]	Loss 0.0948 (0.0355)	
training:	Epoch: [58][81/204]	Loss 0.0059 (0.0351)	
training:	Epoch: [58][82/204]	Loss 0.1524 (0.0366)	
training:	Epoch: [58][83/204]	Loss 0.0064 (0.0362)	
training:	Epoch: [58][84/204]	Loss 0.1223 (0.0372)	
training:	Epoch: [58][85/204]	Loss 0.0054 (0.0369)	
training:	Epoch: [58][86/204]	Loss 0.0065 (0.0365)	
training:	Epoch: [58][87/204]	Loss 0.1391 (0.0377)	
training:	Epoch: [58][88/204]	Loss 0.0459 (0.0378)	
training:	Epoch: [58][89/204]	Loss 0.0087 (0.0375)	
training:	Epoch: [58][90/204]	Loss 0.0055 (0.0371)	
training:	Epoch: [58][91/204]	Loss 0.0080 (0.0368)	
training:	Epoch: [58][92/204]	Loss 0.0077 (0.0365)	
training:	Epoch: [58][93/204]	Loss 0.0063 (0.0361)	
training:	Epoch: [58][94/204]	Loss 0.0065 (0.0358)	
training:	Epoch: [58][95/204]	Loss 0.0069 (0.0355)	
training:	Epoch: [58][96/204]	Loss 0.1716 (0.0369)	
training:	Epoch: [58][97/204]	Loss 0.0064 (0.0366)	
training:	Epoch: [58][98/204]	Loss 0.0065 (0.0363)	
training:	Epoch: [58][99/204]	Loss 0.0070 (0.0360)	
training:	Epoch: [58][100/204]	Loss 0.1267 (0.0369)	
training:	Epoch: [58][101/204]	Loss 0.0054 (0.0366)	
training:	Epoch: [58][102/204]	Loss 0.0058 (0.0363)	
training:	Epoch: [58][103/204]	Loss 0.0666 (0.0366)	
training:	Epoch: [58][104/204]	Loss 0.0088 (0.0363)	
training:	Epoch: [58][105/204]	Loss 0.0068 (0.0361)	
training:	Epoch: [58][106/204]	Loss 0.0255 (0.0360)	
training:	Epoch: [58][107/204]	Loss 0.1399 (0.0369)	
training:	Epoch: [58][108/204]	Loss 0.0096 (0.0367)	
training:	Epoch: [58][109/204]	Loss 0.0071 (0.0364)	
training:	Epoch: [58][110/204]	Loss 0.0058 (0.0361)	
training:	Epoch: [58][111/204]	Loss 0.0074 (0.0359)	
training:	Epoch: [58][112/204]	Loss 0.0149 (0.0357)	
training:	Epoch: [58][113/204]	Loss 0.1336 (0.0365)	
training:	Epoch: [58][114/204]	Loss 0.1868 (0.0379)	
training:	Epoch: [58][115/204]	Loss 0.0206 (0.0377)	
training:	Epoch: [58][116/204]	Loss 0.0069 (0.0374)	
training:	Epoch: [58][117/204]	Loss 0.0069 (0.0372)	
training:	Epoch: [58][118/204]	Loss 0.1480 (0.0381)	
training:	Epoch: [58][119/204]	Loss 0.0078 (0.0379)	
training:	Epoch: [58][120/204]	Loss 0.1292 (0.0386)	
training:	Epoch: [58][121/204]	Loss 0.0060 (0.0384)	
training:	Epoch: [58][122/204]	Loss 0.0058 (0.0381)	
training:	Epoch: [58][123/204]	Loss 0.1817 (0.0393)	
training:	Epoch: [58][124/204]	Loss 0.0085 (0.0390)	
training:	Epoch: [58][125/204]	Loss 0.0069 (0.0388)	
training:	Epoch: [58][126/204]	Loss 0.0064 (0.0385)	
training:	Epoch: [58][127/204]	Loss 0.0097 (0.0383)	
training:	Epoch: [58][128/204]	Loss 0.0071 (0.0380)	
training:	Epoch: [58][129/204]	Loss 0.0058 (0.0378)	
training:	Epoch: [58][130/204]	Loss 0.0071 (0.0375)	
training:	Epoch: [58][131/204]	Loss 0.0534 (0.0377)	
training:	Epoch: [58][132/204]	Loss 0.1422 (0.0385)	
training:	Epoch: [58][133/204]	Loss 0.0086 (0.0382)	
training:	Epoch: [58][134/204]	Loss 0.0063 (0.0380)	
training:	Epoch: [58][135/204]	Loss 0.0730 (0.0383)	
training:	Epoch: [58][136/204]	Loss 0.0059 (0.0380)	
training:	Epoch: [58][137/204]	Loss 0.0060 (0.0378)	
training:	Epoch: [58][138/204]	Loss 0.0087 (0.0376)	
training:	Epoch: [58][139/204]	Loss 0.0065 (0.0373)	
training:	Epoch: [58][140/204]	Loss 0.0065 (0.0371)	
training:	Epoch: [58][141/204]	Loss 0.1312 (0.0378)	
training:	Epoch: [58][142/204]	Loss 0.0071 (0.0376)	
training:	Epoch: [58][143/204]	Loss 0.0368 (0.0376)	
training:	Epoch: [58][144/204]	Loss 0.1591 (0.0384)	
training:	Epoch: [58][145/204]	Loss 0.0078 (0.0382)	
training:	Epoch: [58][146/204]	Loss 0.0164 (0.0381)	
training:	Epoch: [58][147/204]	Loss 0.0078 (0.0378)	
training:	Epoch: [58][148/204]	Loss 0.1349 (0.0385)	
training:	Epoch: [58][149/204]	Loss 0.0087 (0.0383)	
training:	Epoch: [58][150/204]	Loss 0.1488 (0.0390)	
training:	Epoch: [58][151/204]	Loss 0.0070 (0.0388)	
training:	Epoch: [58][152/204]	Loss 0.0156 (0.0387)	
training:	Epoch: [58][153/204]	Loss 0.0088 (0.0385)	
training:	Epoch: [58][154/204]	Loss 0.0075 (0.0383)	
training:	Epoch: [58][155/204]	Loss 0.0662 (0.0385)	
training:	Epoch: [58][156/204]	Loss 0.0069 (0.0383)	
training:	Epoch: [58][157/204]	Loss 0.0066 (0.0381)	
training:	Epoch: [58][158/204]	Loss 0.0614 (0.0382)	
training:	Epoch: [58][159/204]	Loss 0.0082 (0.0380)	
training:	Epoch: [58][160/204]	Loss 0.0082 (0.0378)	
training:	Epoch: [58][161/204]	Loss 0.0080 (0.0376)	
training:	Epoch: [58][162/204]	Loss 0.0262 (0.0376)	
training:	Epoch: [58][163/204]	Loss 0.0069 (0.0374)	
training:	Epoch: [58][164/204]	Loss 0.0062 (0.0372)	
training:	Epoch: [58][165/204]	Loss 0.0101 (0.0370)	
training:	Epoch: [58][166/204]	Loss 0.0457 (0.0371)	
training:	Epoch: [58][167/204]	Loss 0.0059 (0.0369)	
training:	Epoch: [58][168/204]	Loss 0.0079 (0.0367)	
training:	Epoch: [58][169/204]	Loss 0.0064 (0.0365)	
training:	Epoch: [58][170/204]	Loss 0.0063 (0.0364)	
training:	Epoch: [58][171/204]	Loss 0.0057 (0.0362)	
training:	Epoch: [58][172/204]	Loss 0.0071 (0.0360)	
training:	Epoch: [58][173/204]	Loss 0.0417 (0.0361)	
training:	Epoch: [58][174/204]	Loss 0.0069 (0.0359)	
training:	Epoch: [58][175/204]	Loss 0.0105 (0.0357)	
training:	Epoch: [58][176/204]	Loss 0.0058 (0.0356)	
training:	Epoch: [58][177/204]	Loss 0.0108 (0.0354)	
training:	Epoch: [58][178/204]	Loss 0.1855 (0.0363)	
training:	Epoch: [58][179/204]	Loss 0.0060 (0.0361)	
training:	Epoch: [58][180/204]	Loss 0.0065 (0.0359)	
training:	Epoch: [58][181/204]	Loss 0.0070 (0.0358)	
training:	Epoch: [58][182/204]	Loss 0.0087 (0.0356)	
training:	Epoch: [58][183/204]	Loss 0.0067 (0.0355)	
training:	Epoch: [58][184/204]	Loss 0.0067 (0.0353)	
training:	Epoch: [58][185/204]	Loss 0.0142 (0.0352)	
training:	Epoch: [58][186/204]	Loss 0.0067 (0.0350)	
training:	Epoch: [58][187/204]	Loss 0.0065 (0.0349)	
training:	Epoch: [58][188/204]	Loss 0.0346 (0.0349)	
training:	Epoch: [58][189/204]	Loss 0.0067 (0.0347)	
training:	Epoch: [58][190/204]	Loss 0.0057 (0.0346)	
training:	Epoch: [58][191/204]	Loss 0.0077 (0.0345)	
training:	Epoch: [58][192/204]	Loss 0.0054 (0.0343)	
training:	Epoch: [58][193/204]	Loss 0.0061 (0.0342)	
training:	Epoch: [58][194/204]	Loss 0.0064 (0.0340)	
training:	Epoch: [58][195/204]	Loss 0.0077 (0.0339)	
training:	Epoch: [58][196/204]	Loss 0.0278 (0.0338)	
training:	Epoch: [58][197/204]	Loss 0.0071 (0.0337)	
training:	Epoch: [58][198/204]	Loss 0.0068 (0.0336)	
training:	Epoch: [58][199/204]	Loss 0.0053 (0.0334)	
training:	Epoch: [58][200/204]	Loss 0.0055 (0.0333)	
training:	Epoch: [58][201/204]	Loss 0.0076 (0.0332)	
training:	Epoch: [58][202/204]	Loss 0.1568 (0.0338)	
training:	Epoch: [58][203/204]	Loss 0.0056 (0.0336)	
training:	Epoch: [58][204/204]	Loss 0.0140 (0.0335)	
Training:	 Loss: 0.0335

Training:	 ACC: 0.9938 0.9937 0.9927 0.9949
Validation:	 ACC: 0.7789 0.7780 0.7574 0.8004
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0525
Pretraining:	Epoch 59/500
----------
training:	Epoch: [59][1/204]	Loss 0.0054 (0.0054)	
training:	Epoch: [59][2/204]	Loss 0.0063 (0.0058)	
training:	Epoch: [59][3/204]	Loss 0.1466 (0.0528)	
training:	Epoch: [59][4/204]	Loss 0.0083 (0.0417)	
training:	Epoch: [59][5/204]	Loss 0.0059 (0.0345)	
training:	Epoch: [59][6/204]	Loss 0.0108 (0.0306)	
training:	Epoch: [59][7/204]	Loss 0.0047 (0.0269)	
training:	Epoch: [59][8/204]	Loss 0.2069 (0.0494)	
training:	Epoch: [59][9/204]	Loss 0.0102 (0.0450)	
training:	Epoch: [59][10/204]	Loss 0.0085 (0.0414)	
training:	Epoch: [59][11/204]	Loss 0.0071 (0.0382)	
training:	Epoch: [59][12/204]	Loss 0.1574 (0.0482)	
training:	Epoch: [59][13/204]	Loss 0.1242 (0.0540)	
training:	Epoch: [59][14/204]	Loss 0.0051 (0.0505)	
training:	Epoch: [59][15/204]	Loss 0.0059 (0.0475)	
training:	Epoch: [59][16/204]	Loss 0.0056 (0.0449)	
training:	Epoch: [59][17/204]	Loss 0.0061 (0.0426)	
training:	Epoch: [59][18/204]	Loss 0.1512 (0.0487)	
training:	Epoch: [59][19/204]	Loss 0.0058 (0.0464)	
training:	Epoch: [59][20/204]	Loss 0.1320 (0.0507)	
training:	Epoch: [59][21/204]	Loss 0.0066 (0.0486)	
training:	Epoch: [59][22/204]	Loss 0.0071 (0.0467)	
training:	Epoch: [59][23/204]	Loss 0.0205 (0.0456)	
training:	Epoch: [59][24/204]	Loss 0.0062 (0.0439)	
training:	Epoch: [59][25/204]	Loss 0.0054 (0.0424)	
training:	Epoch: [59][26/204]	Loss 0.0056 (0.0410)	
training:	Epoch: [59][27/204]	Loss 0.0064 (0.0397)	
training:	Epoch: [59][28/204]	Loss 0.0081 (0.0386)	
training:	Epoch: [59][29/204]	Loss 0.0275 (0.0382)	
training:	Epoch: [59][30/204]	Loss 0.0091 (0.0372)	
training:	Epoch: [59][31/204]	Loss 0.0062 (0.0362)	
training:	Epoch: [59][32/204]	Loss 0.0232 (0.0358)	
training:	Epoch: [59][33/204]	Loss 0.0072 (0.0349)	
training:	Epoch: [59][34/204]	Loss 0.0060 (0.0341)	
training:	Epoch: [59][35/204]	Loss 0.0057 (0.0333)	
training:	Epoch: [59][36/204]	Loss 0.0072 (0.0326)	
training:	Epoch: [59][37/204]	Loss 0.0046 (0.0318)	
training:	Epoch: [59][38/204]	Loss 0.0074 (0.0312)	
training:	Epoch: [59][39/204]	Loss 0.1265 (0.0336)	
training:	Epoch: [59][40/204]	Loss 0.0052 (0.0329)	
training:	Epoch: [59][41/204]	Loss 0.0056 (0.0322)	
training:	Epoch: [59][42/204]	Loss 0.0062 (0.0316)	
training:	Epoch: [59][43/204]	Loss 0.2904 (0.0376)	
training:	Epoch: [59][44/204]	Loss 0.0091 (0.0370)	
training:	Epoch: [59][45/204]	Loss 0.0061 (0.0363)	
training:	Epoch: [59][46/204]	Loss 0.1133 (0.0380)	
training:	Epoch: [59][47/204]	Loss 0.0076 (0.0373)	
training:	Epoch: [59][48/204]	Loss 0.0076 (0.0367)	
training:	Epoch: [59][49/204]	Loss 0.0090 (0.0361)	
training:	Epoch: [59][50/204]	Loss 0.0051 (0.0355)	
training:	Epoch: [59][51/204]	Loss 0.0152 (0.0351)	
training:	Epoch: [59][52/204]	Loss 0.0051 (0.0345)	
training:	Epoch: [59][53/204]	Loss 0.0055 (0.0340)	
training:	Epoch: [59][54/204]	Loss 0.0063 (0.0335)	
training:	Epoch: [59][55/204]	Loss 0.0061 (0.0330)	
training:	Epoch: [59][56/204]	Loss 0.0067 (0.0325)	
training:	Epoch: [59][57/204]	Loss 0.0072 (0.0321)	
training:	Epoch: [59][58/204]	Loss 0.1663 (0.0344)	
training:	Epoch: [59][59/204]	Loss 0.0059 (0.0339)	
training:	Epoch: [59][60/204]	Loss 0.0079 (0.0335)	
training:	Epoch: [59][61/204]	Loss 0.0070 (0.0330)	
training:	Epoch: [59][62/204]	Loss 0.0076 (0.0326)	
training:	Epoch: [59][63/204]	Loss 0.0924 (0.0336)	
training:	Epoch: [59][64/204]	Loss 0.0064 (0.0331)	
training:	Epoch: [59][65/204]	Loss 0.0063 (0.0327)	
training:	Epoch: [59][66/204]	Loss 0.0050 (0.0323)	
training:	Epoch: [59][67/204]	Loss 0.0062 (0.0319)	
training:	Epoch: [59][68/204]	Loss 0.0095 (0.0316)	
training:	Epoch: [59][69/204]	Loss 0.0051 (0.0312)	
training:	Epoch: [59][70/204]	Loss 0.0069 (0.0309)	
training:	Epoch: [59][71/204]	Loss 0.0055 (0.0305)	
training:	Epoch: [59][72/204]	Loss 0.0404 (0.0306)	
training:	Epoch: [59][73/204]	Loss 0.0061 (0.0303)	
training:	Epoch: [59][74/204]	Loss 0.0067 (0.0300)	
training:	Epoch: [59][75/204]	Loss 0.0070 (0.0297)	
training:	Epoch: [59][76/204]	Loss 0.0060 (0.0294)	
training:	Epoch: [59][77/204]	Loss 0.0061 (0.0291)	
training:	Epoch: [59][78/204]	Loss 0.0226 (0.0290)	
training:	Epoch: [59][79/204]	Loss 0.0063 (0.0287)	
training:	Epoch: [59][80/204]	Loss 0.0057 (0.0284)	
training:	Epoch: [59][81/204]	Loss 0.0065 (0.0281)	
training:	Epoch: [59][82/204]	Loss 0.1491 (0.0296)	
training:	Epoch: [59][83/204]	Loss 0.0063 (0.0293)	
training:	Epoch: [59][84/204]	Loss 0.0050 (0.0290)	
training:	Epoch: [59][85/204]	Loss 0.0070 (0.0288)	
training:	Epoch: [59][86/204]	Loss 0.0051 (0.0285)	
training:	Epoch: [59][87/204]	Loss 0.0072 (0.0283)	
training:	Epoch: [59][88/204]	Loss 0.0313 (0.0283)	
training:	Epoch: [59][89/204]	Loss 0.0056 (0.0280)	
training:	Epoch: [59][90/204]	Loss 0.1706 (0.0296)	
training:	Epoch: [59][91/204]	Loss 0.0072 (0.0294)	
training:	Epoch: [59][92/204]	Loss 0.0422 (0.0295)	
training:	Epoch: [59][93/204]	Loss 0.0048 (0.0293)	
training:	Epoch: [59][94/204]	Loss 0.0062 (0.0290)	
training:	Epoch: [59][95/204]	Loss 0.0073 (0.0288)	
training:	Epoch: [59][96/204]	Loss 0.1184 (0.0297)	
training:	Epoch: [59][97/204]	Loss 0.0052 (0.0295)	
training:	Epoch: [59][98/204]	Loss 0.0053 (0.0292)	
training:	Epoch: [59][99/204]	Loss 0.0056 (0.0290)	
training:	Epoch: [59][100/204]	Loss 0.0275 (0.0290)	
training:	Epoch: [59][101/204]	Loss 0.0050 (0.0287)	
training:	Epoch: [59][102/204]	Loss 0.0051 (0.0285)	
training:	Epoch: [59][103/204]	Loss 0.0053 (0.0283)	
training:	Epoch: [59][104/204]	Loss 0.0060 (0.0281)	
training:	Epoch: [59][105/204]	Loss 0.0072 (0.0279)	
training:	Epoch: [59][106/204]	Loss 0.0061 (0.0277)	
training:	Epoch: [59][107/204]	Loss 0.0063 (0.0275)	
training:	Epoch: [59][108/204]	Loss 0.0051 (0.0272)	
training:	Epoch: [59][109/204]	Loss 0.0189 (0.0272)	
training:	Epoch: [59][110/204]	Loss 0.0050 (0.0270)	
training:	Epoch: [59][111/204]	Loss 0.0050 (0.0268)	
training:	Epoch: [59][112/204]	Loss 0.1459 (0.0278)	
training:	Epoch: [59][113/204]	Loss 0.1709 (0.0291)	
training:	Epoch: [59][114/204]	Loss 0.0054 (0.0289)	
training:	Epoch: [59][115/204]	Loss 0.0057 (0.0287)	
training:	Epoch: [59][116/204]	Loss 0.2143 (0.0303)	
training:	Epoch: [59][117/204]	Loss 0.0059 (0.0301)	
training:	Epoch: [59][118/204]	Loss 0.0060 (0.0299)	
training:	Epoch: [59][119/204]	Loss 0.0071 (0.0297)	
training:	Epoch: [59][120/204]	Loss 0.0054 (0.0295)	
training:	Epoch: [59][121/204]	Loss 0.0062 (0.0293)	
training:	Epoch: [59][122/204]	Loss 0.1392 (0.0302)	
training:	Epoch: [59][123/204]	Loss 0.0060 (0.0300)	
training:	Epoch: [59][124/204]	Loss 0.1418 (0.0309)	
training:	Epoch: [59][125/204]	Loss 0.0063 (0.0307)	
training:	Epoch: [59][126/204]	Loss 0.0085 (0.0305)	
training:	Epoch: [59][127/204]	Loss 0.0070 (0.0303)	
training:	Epoch: [59][128/204]	Loss 0.0246 (0.0303)	
training:	Epoch: [59][129/204]	Loss 0.0084 (0.0301)	
training:	Epoch: [59][130/204]	Loss 0.0062 (0.0299)	
training:	Epoch: [59][131/204]	Loss 0.0061 (0.0298)	
training:	Epoch: [59][132/204]	Loss 0.0297 (0.0298)	
training:	Epoch: [59][133/204]	Loss 0.0052 (0.0296)	
training:	Epoch: [59][134/204]	Loss 0.0061 (0.0294)	
training:	Epoch: [59][135/204]	Loss 0.0058 (0.0292)	
training:	Epoch: [59][136/204]	Loss 0.1610 (0.0302)	
training:	Epoch: [59][137/204]	Loss 0.0064 (0.0300)	
training:	Epoch: [59][138/204]	Loss 0.2700 (0.0318)	
training:	Epoch: [59][139/204]	Loss 0.0053 (0.0316)	
training:	Epoch: [59][140/204]	Loss 0.1737 (0.0326)	
training:	Epoch: [59][141/204]	Loss 0.0113 (0.0324)	
training:	Epoch: [59][142/204]	Loss 0.0077 (0.0323)	
training:	Epoch: [59][143/204]	Loss 0.0070 (0.0321)	
training:	Epoch: [59][144/204]	Loss 0.0098 (0.0319)	
training:	Epoch: [59][145/204]	Loss 0.0067 (0.0318)	
training:	Epoch: [59][146/204]	Loss 0.0067 (0.0316)	
training:	Epoch: [59][147/204]	Loss 0.0075 (0.0314)	
training:	Epoch: [59][148/204]	Loss 0.0146 (0.0313)	
training:	Epoch: [59][149/204]	Loss 0.0074 (0.0311)	
training:	Epoch: [59][150/204]	Loss 0.0084 (0.0310)	
training:	Epoch: [59][151/204]	Loss 0.0582 (0.0312)	
training:	Epoch: [59][152/204]	Loss 0.0084 (0.0310)	
training:	Epoch: [59][153/204]	Loss 0.0086 (0.0309)	
training:	Epoch: [59][154/204]	Loss 0.0078 (0.0307)	
training:	Epoch: [59][155/204]	Loss 0.0066 (0.0306)	
training:	Epoch: [59][156/204]	Loss 0.0071 (0.0304)	
training:	Epoch: [59][157/204]	Loss 0.0052 (0.0303)	
training:	Epoch: [59][158/204]	Loss 0.0136 (0.0302)	
training:	Epoch: [59][159/204]	Loss 0.1504 (0.0309)	
training:	Epoch: [59][160/204]	Loss 0.0064 (0.0308)	
training:	Epoch: [59][161/204]	Loss 0.0066 (0.0306)	
training:	Epoch: [59][162/204]	Loss 0.0053 (0.0304)	
training:	Epoch: [59][163/204]	Loss 0.0062 (0.0303)	
training:	Epoch: [59][164/204]	Loss 0.0058 (0.0302)	
training:	Epoch: [59][165/204]	Loss 0.0068 (0.0300)	
training:	Epoch: [59][166/204]	Loss 0.0083 (0.0299)	
training:	Epoch: [59][167/204]	Loss 0.1585 (0.0307)	
training:	Epoch: [59][168/204]	Loss 0.1607 (0.0314)	
training:	Epoch: [59][169/204]	Loss 0.0072 (0.0313)	
training:	Epoch: [59][170/204]	Loss 0.0072 (0.0311)	
training:	Epoch: [59][171/204]	Loss 0.0057 (0.0310)	
training:	Epoch: [59][172/204]	Loss 0.0061 (0.0308)	
training:	Epoch: [59][173/204]	Loss 0.0063 (0.0307)	
training:	Epoch: [59][174/204]	Loss 0.1269 (0.0313)	
training:	Epoch: [59][175/204]	Loss 0.0059 (0.0311)	
training:	Epoch: [59][176/204]	Loss 0.0401 (0.0312)	
training:	Epoch: [59][177/204]	Loss 0.0151 (0.0311)	
training:	Epoch: [59][178/204]	Loss 0.0057 (0.0309)	
training:	Epoch: [59][179/204]	Loss 0.0058 (0.0308)	
training:	Epoch: [59][180/204]	Loss 0.0049 (0.0306)	
training:	Epoch: [59][181/204]	Loss 0.0072 (0.0305)	
training:	Epoch: [59][182/204]	Loss 0.0068 (0.0304)	
training:	Epoch: [59][183/204]	Loss 0.0053 (0.0302)	
training:	Epoch: [59][184/204]	Loss 0.0065 (0.0301)	
training:	Epoch: [59][185/204]	Loss 0.0061 (0.0300)	
training:	Epoch: [59][186/204]	Loss 0.0051 (0.0299)	
training:	Epoch: [59][187/204]	Loss 0.1064 (0.0303)	
training:	Epoch: [59][188/204]	Loss 0.0044 (0.0301)	
training:	Epoch: [59][189/204]	Loss 0.0063 (0.0300)	
training:	Epoch: [59][190/204]	Loss 0.0227 (0.0300)	
training:	Epoch: [59][191/204]	Loss 0.0067 (0.0298)	
training:	Epoch: [59][192/204]	Loss 0.0138 (0.0298)	
training:	Epoch: [59][193/204]	Loss 0.0053 (0.0296)	
training:	Epoch: [59][194/204]	Loss 0.0060 (0.0295)	
training:	Epoch: [59][195/204]	Loss 0.0067 (0.0294)	
training:	Epoch: [59][196/204]	Loss 0.0057 (0.0293)	
training:	Epoch: [59][197/204]	Loss 0.0054 (0.0292)	
training:	Epoch: [59][198/204]	Loss 0.0060 (0.0290)	
training:	Epoch: [59][199/204]	Loss 0.0088 (0.0289)	
training:	Epoch: [59][200/204]	Loss 0.0061 (0.0288)	
training:	Epoch: [59][201/204]	Loss 0.0068 (0.0287)	
training:	Epoch: [59][202/204]	Loss 0.0061 (0.0286)	
training:	Epoch: [59][203/204]	Loss 0.0079 (0.0285)	
training:	Epoch: [59][204/204]	Loss 0.0063 (0.0284)	
Training:	 Loss: 0.0283

Training:	 ACC: 0.9954 0.9954 0.9962 0.9946
Validation:	 ACC: 0.7793 0.7806 0.8076 0.7511
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0767
Pretraining:	Epoch 60/500
----------
training:	Epoch: [60][1/204]	Loss 0.0056 (0.0056)	
training:	Epoch: [60][2/204]	Loss 0.0051 (0.0053)	
training:	Epoch: [60][3/204]	Loss 0.0059 (0.0055)	
training:	Epoch: [60][4/204]	Loss 0.0048 (0.0053)	
training:	Epoch: [60][5/204]	Loss 0.0054 (0.0053)	
training:	Epoch: [60][6/204]	Loss 0.0068 (0.0056)	
training:	Epoch: [60][7/204]	Loss 0.0058 (0.0056)	
training:	Epoch: [60][8/204]	Loss 0.0055 (0.0056)	
training:	Epoch: [60][9/204]	Loss 0.0051 (0.0055)	
training:	Epoch: [60][10/204]	Loss 0.0062 (0.0056)	
training:	Epoch: [60][11/204]	Loss 0.0048 (0.0055)	
training:	Epoch: [60][12/204]	Loss 0.1484 (0.0174)	
training:	Epoch: [60][13/204]	Loss 0.0062 (0.0166)	
training:	Epoch: [60][14/204]	Loss 0.0085 (0.0160)	
training:	Epoch: [60][15/204]	Loss 0.0056 (0.0153)	
training:	Epoch: [60][16/204]	Loss 0.1309 (0.0225)	
training:	Epoch: [60][17/204]	Loss 0.0044 (0.0215)	
training:	Epoch: [60][18/204]	Loss 0.1413 (0.0281)	
training:	Epoch: [60][19/204]	Loss 0.0047 (0.0269)	
training:	Epoch: [60][20/204]	Loss 0.0044 (0.0258)	
training:	Epoch: [60][21/204]	Loss 0.0070 (0.0249)	
training:	Epoch: [60][22/204]	Loss 0.1374 (0.0300)	
training:	Epoch: [60][23/204]	Loss 0.0064 (0.0290)	
training:	Epoch: [60][24/204]	Loss 0.0074 (0.0281)	
training:	Epoch: [60][25/204]	Loss 0.1222 (0.0318)	
training:	Epoch: [60][26/204]	Loss 0.1140 (0.0350)	
training:	Epoch: [60][27/204]	Loss 0.0108 (0.0341)	
training:	Epoch: [60][28/204]	Loss 0.0051 (0.0331)	
training:	Epoch: [60][29/204]	Loss 0.1623 (0.0375)	
training:	Epoch: [60][30/204]	Loss 0.0052 (0.0364)	
training:	Epoch: [60][31/204]	Loss 0.0069 (0.0355)	
training:	Epoch: [60][32/204]	Loss 0.0058 (0.0346)	
training:	Epoch: [60][33/204]	Loss 0.0053 (0.0337)	
training:	Epoch: [60][34/204]	Loss 0.0061 (0.0329)	
training:	Epoch: [60][35/204]	Loss 0.0043 (0.0320)	
training:	Epoch: [60][36/204]	Loss 0.0057 (0.0313)	
training:	Epoch: [60][37/204]	Loss 0.0064 (0.0306)	
training:	Epoch: [60][38/204]	Loss 0.0877 (0.0321)	
training:	Epoch: [60][39/204]	Loss 0.0064 (0.0315)	
training:	Epoch: [60][40/204]	Loss 0.0053 (0.0308)	
training:	Epoch: [60][41/204]	Loss 0.0046 (0.0302)	
training:	Epoch: [60][42/204]	Loss 0.0065 (0.0296)	
training:	Epoch: [60][43/204]	Loss 0.0113 (0.0292)	
training:	Epoch: [60][44/204]	Loss 0.0068 (0.0287)	
training:	Epoch: [60][45/204]	Loss 0.1685 (0.0318)	
training:	Epoch: [60][46/204]	Loss 0.0058 (0.0312)	
training:	Epoch: [60][47/204]	Loss 0.0057 (0.0307)	
training:	Epoch: [60][48/204]	Loss 0.0056 (0.0302)	
training:	Epoch: [60][49/204]	Loss 0.1591 (0.0328)	
training:	Epoch: [60][50/204]	Loss 0.0062 (0.0323)	
training:	Epoch: [60][51/204]	Loss 0.0081 (0.0318)	
training:	Epoch: [60][52/204]	Loss 0.0058 (0.0313)	
training:	Epoch: [60][53/204]	Loss 0.0053 (0.0308)	
training:	Epoch: [60][54/204]	Loss 0.0161 (0.0305)	
training:	Epoch: [60][55/204]	Loss 0.0065 (0.0301)	
training:	Epoch: [60][56/204]	Loss 0.0050 (0.0296)	
training:	Epoch: [60][57/204]	Loss 0.0063 (0.0292)	
training:	Epoch: [60][58/204]	Loss 0.0062 (0.0288)	
training:	Epoch: [60][59/204]	Loss 0.0056 (0.0284)	
training:	Epoch: [60][60/204]	Loss 0.0711 (0.0292)	
training:	Epoch: [60][61/204]	Loss 0.0050 (0.0288)	
training:	Epoch: [60][62/204]	Loss 0.0082 (0.0284)	
training:	Epoch: [60][63/204]	Loss 0.0069 (0.0281)	
training:	Epoch: [60][64/204]	Loss 0.0173 (0.0279)	
training:	Epoch: [60][65/204]	Loss 0.0069 (0.0276)	
training:	Epoch: [60][66/204]	Loss 0.0063 (0.0273)	
training:	Epoch: [60][67/204]	Loss 0.1080 (0.0285)	
training:	Epoch: [60][68/204]	Loss 0.0050 (0.0281)	
training:	Epoch: [60][69/204]	Loss 0.0069 (0.0278)	
training:	Epoch: [60][70/204]	Loss 0.1274 (0.0292)	
training:	Epoch: [60][71/204]	Loss 0.0067 (0.0289)	
training:	Epoch: [60][72/204]	Loss 0.1400 (0.0305)	
training:	Epoch: [60][73/204]	Loss 0.0053 (0.0301)	
training:	Epoch: [60][74/204]	Loss 0.0068 (0.0298)	
training:	Epoch: [60][75/204]	Loss 0.0066 (0.0295)	
training:	Epoch: [60][76/204]	Loss 0.0069 (0.0292)	
training:	Epoch: [60][77/204]	Loss 0.0054 (0.0289)	
training:	Epoch: [60][78/204]	Loss 0.0075 (0.0286)	
training:	Epoch: [60][79/204]	Loss 0.0065 (0.0283)	
training:	Epoch: [60][80/204]	Loss 0.0080 (0.0281)	
training:	Epoch: [60][81/204]	Loss 0.0074 (0.0278)	
training:	Epoch: [60][82/204]	Loss 0.0065 (0.0276)	
training:	Epoch: [60][83/204]	Loss 0.0067 (0.0273)	
training:	Epoch: [60][84/204]	Loss 0.0068 (0.0271)	
training:	Epoch: [60][85/204]	Loss 0.0059 (0.0268)	
training:	Epoch: [60][86/204]	Loss 0.0072 (0.0266)	
training:	Epoch: [60][87/204]	Loss 0.0061 (0.0264)	
training:	Epoch: [60][88/204]	Loss 0.2793 (0.0292)	
training:	Epoch: [60][89/204]	Loss 0.0073 (0.0290)	
training:	Epoch: [60][90/204]	Loss 0.0074 (0.0288)	
training:	Epoch: [60][91/204]	Loss 0.1480 (0.0301)	
training:	Epoch: [60][92/204]	Loss 0.0090 (0.0298)	
training:	Epoch: [60][93/204]	Loss 0.1329 (0.0309)	
training:	Epoch: [60][94/204]	Loss 0.0065 (0.0307)	
training:	Epoch: [60][95/204]	Loss 0.0068 (0.0304)	
training:	Epoch: [60][96/204]	Loss 0.0416 (0.0305)	
training:	Epoch: [60][97/204]	Loss 0.0063 (0.0303)	
training:	Epoch: [60][98/204]	Loss 0.0060 (0.0300)	
training:	Epoch: [60][99/204]	Loss 0.0042 (0.0298)	
training:	Epoch: [60][100/204]	Loss 0.0068 (0.0296)	
training:	Epoch: [60][101/204]	Loss 0.0062 (0.0293)	
training:	Epoch: [60][102/204]	Loss 0.0074 (0.0291)	
training:	Epoch: [60][103/204]	Loss 0.0069 (0.0289)	
training:	Epoch: [60][104/204]	Loss 0.0062 (0.0287)	
training:	Epoch: [60][105/204]	Loss 0.0065 (0.0285)	
training:	Epoch: [60][106/204]	Loss 0.2916 (0.0309)	
training:	Epoch: [60][107/204]	Loss 0.2558 (0.0330)	
training:	Epoch: [60][108/204]	Loss 0.0070 (0.0328)	
training:	Epoch: [60][109/204]	Loss 0.0090 (0.0326)	
training:	Epoch: [60][110/204]	Loss 0.0074 (0.0324)	
training:	Epoch: [60][111/204]	Loss 0.0071 (0.0321)	
training:	Epoch: [60][112/204]	Loss 0.0068 (0.0319)	
training:	Epoch: [60][113/204]	Loss 0.0063 (0.0317)	
training:	Epoch: [60][114/204]	Loss 0.0136 (0.0315)	
training:	Epoch: [60][115/204]	Loss 0.0092 (0.0313)	
training:	Epoch: [60][116/204]	Loss 0.0082 (0.0311)	
training:	Epoch: [60][117/204]	Loss 0.0062 (0.0309)	
training:	Epoch: [60][118/204]	Loss 0.0062 (0.0307)	
training:	Epoch: [60][119/204]	Loss 0.0611 (0.0310)	
training:	Epoch: [60][120/204]	Loss 0.0082 (0.0308)	
training:	Epoch: [60][121/204]	Loss 0.0080 (0.0306)	
training:	Epoch: [60][122/204]	Loss 0.0060 (0.0304)	
training:	Epoch: [60][123/204]	Loss 0.0094 (0.0302)	
training:	Epoch: [60][124/204]	Loss 0.0055 (0.0300)	
training:	Epoch: [60][125/204]	Loss 0.0069 (0.0298)	
training:	Epoch: [60][126/204]	Loss 0.0134 (0.0297)	
training:	Epoch: [60][127/204]	Loss 0.0085 (0.0295)	
training:	Epoch: [60][128/204]	Loss 0.0081 (0.0294)	
training:	Epoch: [60][129/204]	Loss 0.0056 (0.0292)	
training:	Epoch: [60][130/204]	Loss 0.0083 (0.0290)	
training:	Epoch: [60][131/204]	Loss 0.0105 (0.0289)	
training:	Epoch: [60][132/204]	Loss 0.0053 (0.0287)	
training:	Epoch: [60][133/204]	Loss 0.0056 (0.0285)	
training:	Epoch: [60][134/204]	Loss 0.0064 (0.0284)	
training:	Epoch: [60][135/204]	Loss 0.0061 (0.0282)	
training:	Epoch: [60][136/204]	Loss 0.0089 (0.0281)	
training:	Epoch: [60][137/204]	Loss 0.0061 (0.0279)	
training:	Epoch: [60][138/204]	Loss 0.0053 (0.0277)	
training:	Epoch: [60][139/204]	Loss 0.0058 (0.0276)	
training:	Epoch: [60][140/204]	Loss 0.0046 (0.0274)	
training:	Epoch: [60][141/204]	Loss 0.0056 (0.0273)	
training:	Epoch: [60][142/204]	Loss 0.0058 (0.0271)	
training:	Epoch: [60][143/204]	Loss 0.1544 (0.0280)	
training:	Epoch: [60][144/204]	Loss 0.0068 (0.0278)	
training:	Epoch: [60][145/204]	Loss 0.0077 (0.0277)	
training:	Epoch: [60][146/204]	Loss 0.0061 (0.0276)	
training:	Epoch: [60][147/204]	Loss 0.0049 (0.0274)	
training:	Epoch: [60][148/204]	Loss 0.0063 (0.0273)	
training:	Epoch: [60][149/204]	Loss 0.1333 (0.0280)	
training:	Epoch: [60][150/204]	Loss 0.0837 (0.0283)	
training:	Epoch: [60][151/204]	Loss 0.0088 (0.0282)	
training:	Epoch: [60][152/204]	Loss 0.0068 (0.0281)	
training:	Epoch: [60][153/204]	Loss 0.0058 (0.0279)	
training:	Epoch: [60][154/204]	Loss 0.0086 (0.0278)	
training:	Epoch: [60][155/204]	Loss 0.1292 (0.0285)	
training:	Epoch: [60][156/204]	Loss 0.0051 (0.0283)	
training:	Epoch: [60][157/204]	Loss 0.0062 (0.0282)	
training:	Epoch: [60][158/204]	Loss 0.0063 (0.0280)	
training:	Epoch: [60][159/204]	Loss 0.0162 (0.0280)	
training:	Epoch: [60][160/204]	Loss 0.0058 (0.0278)	
training:	Epoch: [60][161/204]	Loss 0.0058 (0.0277)	
training:	Epoch: [60][162/204]	Loss 0.0052 (0.0275)	
training:	Epoch: [60][163/204]	Loss 0.1346 (0.0282)	
training:	Epoch: [60][164/204]	Loss 0.0053 (0.0281)	
training:	Epoch: [60][165/204]	Loss 0.0057 (0.0279)	
training:	Epoch: [60][166/204]	Loss 0.0059 (0.0278)	
training:	Epoch: [60][167/204]	Loss 0.0054 (0.0277)	
training:	Epoch: [60][168/204]	Loss 0.0074 (0.0275)	
training:	Epoch: [60][169/204]	Loss 0.0177 (0.0275)	
training:	Epoch: [60][170/204]	Loss 0.0053 (0.0273)	
training:	Epoch: [60][171/204]	Loss 0.0051 (0.0272)	
training:	Epoch: [60][172/204]	Loss 0.1743 (0.0281)	
training:	Epoch: [60][173/204]	Loss 0.1762 (0.0289)	
training:	Epoch: [60][174/204]	Loss 0.0054 (0.0288)	
training:	Epoch: [60][175/204]	Loss 0.0101 (0.0287)	
training:	Epoch: [60][176/204]	Loss 0.0083 (0.0286)	
training:	Epoch: [60][177/204]	Loss 0.0085 (0.0285)	
training:	Epoch: [60][178/204]	Loss 0.0055 (0.0283)	
training:	Epoch: [60][179/204]	Loss 0.0063 (0.0282)	
training:	Epoch: [60][180/204]	Loss 0.0056 (0.0281)	
training:	Epoch: [60][181/204]	Loss 0.0063 (0.0280)	
training:	Epoch: [60][182/204]	Loss 0.0066 (0.0278)	
training:	Epoch: [60][183/204]	Loss 0.0059 (0.0277)	
training:	Epoch: [60][184/204]	Loss 0.0060 (0.0276)	
training:	Epoch: [60][185/204]	Loss 0.0050 (0.0275)	
training:	Epoch: [60][186/204]	Loss 0.0050 (0.0274)	
training:	Epoch: [60][187/204]	Loss 0.0059 (0.0272)	
training:	Epoch: [60][188/204]	Loss 0.0130 (0.0272)	
training:	Epoch: [60][189/204]	Loss 0.0065 (0.0271)	
training:	Epoch: [60][190/204]	Loss 0.0066 (0.0270)	
training:	Epoch: [60][191/204]	Loss 0.0105 (0.0269)	
training:	Epoch: [60][192/204]	Loss 0.1699 (0.0276)	
training:	Epoch: [60][193/204]	Loss 0.0056 (0.0275)	
training:	Epoch: [60][194/204]	Loss 0.0062 (0.0274)	
training:	Epoch: [60][195/204]	Loss 0.0055 (0.0273)	
training:	Epoch: [60][196/204]	Loss 0.0055 (0.0272)	
training:	Epoch: [60][197/204]	Loss 0.0057 (0.0271)	
training:	Epoch: [60][198/204]	Loss 0.0043 (0.0269)	
training:	Epoch: [60][199/204]	Loss 0.0053 (0.0268)	
training:	Epoch: [60][200/204]	Loss 0.0051 (0.0267)	
training:	Epoch: [60][201/204]	Loss 0.0092 (0.0266)	
training:	Epoch: [60][202/204]	Loss 0.0061 (0.0265)	
training:	Epoch: [60][203/204]	Loss 0.0063 (0.0264)	
training:	Epoch: [60][204/204]	Loss 0.0047 (0.0263)	
Training:	 Loss: 0.0263

Training:	 ACC: 0.9955 0.9956 0.9962 0.9949
Validation:	 ACC: 0.7793 0.7806 0.8096 0.7489
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0818
Pretraining:	Epoch 61/500
----------
training:	Epoch: [61][1/204]	Loss 0.0053 (0.0053)	
training:	Epoch: [61][2/204]	Loss 0.0052 (0.0053)	
training:	Epoch: [61][3/204]	Loss 0.1201 (0.0435)	
training:	Epoch: [61][4/204]	Loss 0.0052 (0.0339)	
training:	Epoch: [61][5/204]	Loss 0.0056 (0.0283)	
training:	Epoch: [61][6/204]	Loss 0.0074 (0.0248)	
training:	Epoch: [61][7/204]	Loss 0.0066 (0.0222)	
training:	Epoch: [61][8/204]	Loss 0.0046 (0.0200)	
training:	Epoch: [61][9/204]	Loss 0.0044 (0.0183)	
training:	Epoch: [61][10/204]	Loss 0.0055 (0.0170)	
training:	Epoch: [61][11/204]	Loss 0.0045 (0.0159)	
training:	Epoch: [61][12/204]	Loss 0.0050 (0.0149)	
training:	Epoch: [61][13/204]	Loss 0.0052 (0.0142)	
training:	Epoch: [61][14/204]	Loss 0.0062 (0.0136)	
training:	Epoch: [61][15/204]	Loss 0.1437 (0.0223)	
training:	Epoch: [61][16/204]	Loss 0.1339 (0.0293)	
training:	Epoch: [61][17/204]	Loss 0.0059 (0.0279)	
training:	Epoch: [61][18/204]	Loss 0.0042 (0.0266)	
training:	Epoch: [61][19/204]	Loss 0.1605 (0.0336)	
training:	Epoch: [61][20/204]	Loss 0.0056 (0.0322)	
training:	Epoch: [61][21/204]	Loss 0.0063 (0.0310)	
training:	Epoch: [61][22/204]	Loss 0.0051 (0.0298)	
training:	Epoch: [61][23/204]	Loss 0.0055 (0.0288)	
training:	Epoch: [61][24/204]	Loss 0.0051 (0.0278)	
training:	Epoch: [61][25/204]	Loss 0.0051 (0.0269)	
training:	Epoch: [61][26/204]	Loss 0.0068 (0.0261)	
training:	Epoch: [61][27/204]	Loss 0.0056 (0.0253)	
training:	Epoch: [61][28/204]	Loss 0.0047 (0.0246)	
training:	Epoch: [61][29/204]	Loss 0.0054 (0.0239)	
training:	Epoch: [61][30/204]	Loss 0.1791 (0.0291)	
training:	Epoch: [61][31/204]	Loss 0.0057 (0.0284)	
training:	Epoch: [61][32/204]	Loss 0.0057 (0.0276)	
training:	Epoch: [61][33/204]	Loss 0.0063 (0.0270)	
training:	Epoch: [61][34/204]	Loss 0.0045 (0.0263)	
training:	Epoch: [61][35/204]	Loss 0.1115 (0.0288)	
training:	Epoch: [61][36/204]	Loss 0.0054 (0.0281)	
training:	Epoch: [61][37/204]	Loss 0.0054 (0.0275)	
training:	Epoch: [61][38/204]	Loss 0.0061 (0.0269)	
training:	Epoch: [61][39/204]	Loss 0.2752 (0.0333)	
training:	Epoch: [61][40/204]	Loss 0.0062 (0.0326)	
training:	Epoch: [61][41/204]	Loss 0.0073 (0.0320)	
training:	Epoch: [61][42/204]	Loss 0.0048 (0.0314)	
training:	Epoch: [61][43/204]	Loss 0.0061 (0.0308)	
training:	Epoch: [61][44/204]	Loss 0.0059 (0.0302)	
training:	Epoch: [61][45/204]	Loss 0.1176 (0.0322)	
training:	Epoch: [61][46/204]	Loss 0.0107 (0.0317)	
training:	Epoch: [61][47/204]	Loss 0.0154 (0.0313)	
training:	Epoch: [61][48/204]	Loss 0.1155 (0.0331)	
training:	Epoch: [61][49/204]	Loss 0.0997 (0.0345)	
training:	Epoch: [61][50/204]	Loss 0.0082 (0.0339)	
training:	Epoch: [61][51/204]	Loss 0.0073 (0.0334)	
training:	Epoch: [61][52/204]	Loss 0.0067 (0.0329)	
training:	Epoch: [61][53/204]	Loss 0.1199 (0.0345)	
training:	Epoch: [61][54/204]	Loss 0.0059 (0.0340)	
training:	Epoch: [61][55/204]	Loss 0.0058 (0.0335)	
training:	Epoch: [61][56/204]	Loss 0.0062 (0.0330)	
training:	Epoch: [61][57/204]	Loss 0.0060 (0.0325)	
training:	Epoch: [61][58/204]	Loss 0.0086 (0.0321)	
training:	Epoch: [61][59/204]	Loss 0.0060 (0.0317)	
training:	Epoch: [61][60/204]	Loss 0.0057 (0.0312)	
training:	Epoch: [61][61/204]	Loss 0.0062 (0.0308)	
training:	Epoch: [61][62/204]	Loss 0.0054 (0.0304)	
training:	Epoch: [61][63/204]	Loss 0.0057 (0.0300)	
training:	Epoch: [61][64/204]	Loss 0.0071 (0.0297)	
training:	Epoch: [61][65/204]	Loss 0.0058 (0.0293)	
training:	Epoch: [61][66/204]	Loss 0.3248 (0.0338)	
training:	Epoch: [61][67/204]	Loss 0.0091 (0.0334)	
training:	Epoch: [61][68/204]	Loss 0.1331 (0.0349)	
training:	Epoch: [61][69/204]	Loss 0.0079 (0.0345)	
training:	Epoch: [61][70/204]	Loss 0.0055 (0.0341)	
training:	Epoch: [61][71/204]	Loss 0.0063 (0.0337)	
training:	Epoch: [61][72/204]	Loss 0.0050 (0.0333)	
training:	Epoch: [61][73/204]	Loss 0.0055 (0.0329)	
training:	Epoch: [61][74/204]	Loss 0.0049 (0.0325)	
training:	Epoch: [61][75/204]	Loss 0.0068 (0.0322)	
training:	Epoch: [61][76/204]	Loss 0.0051 (0.0318)	
training:	Epoch: [61][77/204]	Loss 0.0064 (0.0315)	
training:	Epoch: [61][78/204]	Loss 0.0058 (0.0312)	
training:	Epoch: [61][79/204]	Loss 0.0053 (0.0308)	
training:	Epoch: [61][80/204]	Loss 0.0056 (0.0305)	
training:	Epoch: [61][81/204]	Loss 0.0059 (0.0302)	
training:	Epoch: [61][82/204]	Loss 0.0075 (0.0299)	
training:	Epoch: [61][83/204]	Loss 0.0062 (0.0297)	
training:	Epoch: [61][84/204]	Loss 0.0050 (0.0294)	
training:	Epoch: [61][85/204]	Loss 0.0062 (0.0291)	
training:	Epoch: [61][86/204]	Loss 0.0056 (0.0288)	
training:	Epoch: [61][87/204]	Loss 0.0064 (0.0286)	
training:	Epoch: [61][88/204]	Loss 0.0056 (0.0283)	
training:	Epoch: [61][89/204]	Loss 0.0063 (0.0281)	
training:	Epoch: [61][90/204]	Loss 0.0052 (0.0278)	
training:	Epoch: [61][91/204]	Loss 0.0068 (0.0276)	
training:	Epoch: [61][92/204]	Loss 0.3403 (0.0310)	
training:	Epoch: [61][93/204]	Loss 0.1498 (0.0322)	
training:	Epoch: [61][94/204]	Loss 0.0053 (0.0320)	
training:	Epoch: [61][95/204]	Loss 0.0071 (0.0317)	
training:	Epoch: [61][96/204]	Loss 0.0057 (0.0314)	
training:	Epoch: [61][97/204]	Loss 0.1582 (0.0327)	
training:	Epoch: [61][98/204]	Loss 0.0058 (0.0325)	
training:	Epoch: [61][99/204]	Loss 0.0048 (0.0322)	
training:	Epoch: [61][100/204]	Loss 0.0053 (0.0319)	
training:	Epoch: [61][101/204]	Loss 0.1101 (0.0327)	
training:	Epoch: [61][102/204]	Loss 0.0069 (0.0324)	
training:	Epoch: [61][103/204]	Loss 0.0049 (0.0322)	
training:	Epoch: [61][104/204]	Loss 0.0058 (0.0319)	
training:	Epoch: [61][105/204]	Loss 0.0056 (0.0317)	
training:	Epoch: [61][106/204]	Loss 0.0039 (0.0314)	
training:	Epoch: [61][107/204]	Loss 0.0053 (0.0312)	
training:	Epoch: [61][108/204]	Loss 0.0057 (0.0309)	
training:	Epoch: [61][109/204]	Loss 0.0059 (0.0307)	
training:	Epoch: [61][110/204]	Loss 0.0053 (0.0305)	
training:	Epoch: [61][111/204]	Loss 0.0068 (0.0302)	
training:	Epoch: [61][112/204]	Loss 0.0058 (0.0300)	
training:	Epoch: [61][113/204]	Loss 0.0061 (0.0298)	
training:	Epoch: [61][114/204]	Loss 0.0045 (0.0296)	
training:	Epoch: [61][115/204]	Loss 0.0054 (0.0294)	
training:	Epoch: [61][116/204]	Loss 0.0070 (0.0292)	
training:	Epoch: [61][117/204]	Loss 0.0049 (0.0290)	
training:	Epoch: [61][118/204]	Loss 0.0051 (0.0288)	
training:	Epoch: [61][119/204]	Loss 0.0045 (0.0286)	
training:	Epoch: [61][120/204]	Loss 0.0057 (0.0284)	
training:	Epoch: [61][121/204]	Loss 0.0043 (0.0282)	
training:	Epoch: [61][122/204]	Loss 0.0055 (0.0280)	
training:	Epoch: [61][123/204]	Loss 0.0047 (0.0278)	
training:	Epoch: [61][124/204]	Loss 0.1654 (0.0289)	
training:	Epoch: [61][125/204]	Loss 0.0065 (0.0287)	
training:	Epoch: [61][126/204]	Loss 0.1271 (0.0295)	
training:	Epoch: [61][127/204]	Loss 0.1219 (0.0302)	
training:	Epoch: [61][128/204]	Loss 0.0062 (0.0301)	
training:	Epoch: [61][129/204]	Loss 0.0076 (0.0299)	
training:	Epoch: [61][130/204]	Loss 0.0049 (0.0297)	
training:	Epoch: [61][131/204]	Loss 0.0067 (0.0295)	
training:	Epoch: [61][132/204]	Loss 0.0061 (0.0293)	
training:	Epoch: [61][133/204]	Loss 0.0055 (0.0292)	
training:	Epoch: [61][134/204]	Loss 0.0063 (0.0290)	
training:	Epoch: [61][135/204]	Loss 0.1216 (0.0297)	
training:	Epoch: [61][136/204]	Loss 0.1259 (0.0304)	
training:	Epoch: [61][137/204]	Loss 0.0054 (0.0302)	
training:	Epoch: [61][138/204]	Loss 0.0056 (0.0300)	
training:	Epoch: [61][139/204]	Loss 0.0059 (0.0298)	
training:	Epoch: [61][140/204]	Loss 0.0059 (0.0297)	
training:	Epoch: [61][141/204]	Loss 0.2406 (0.0312)	
training:	Epoch: [61][142/204]	Loss 0.0044 (0.0310)	
training:	Epoch: [61][143/204]	Loss 0.0062 (0.0308)	
training:	Epoch: [61][144/204]	Loss 0.0071 (0.0306)	
training:	Epoch: [61][145/204]	Loss 0.0046 (0.0305)	
training:	Epoch: [61][146/204]	Loss 0.0070 (0.0303)	
training:	Epoch: [61][147/204]	Loss 0.0089 (0.0302)	
training:	Epoch: [61][148/204]	Loss 0.0051 (0.0300)	
training:	Epoch: [61][149/204]	Loss 0.0078 (0.0298)	
training:	Epoch: [61][150/204]	Loss 0.0069 (0.0297)	
training:	Epoch: [61][151/204]	Loss 0.0046 (0.0295)	
training:	Epoch: [61][152/204]	Loss 0.0066 (0.0294)	
training:	Epoch: [61][153/204]	Loss 0.0079 (0.0292)	
training:	Epoch: [61][154/204]	Loss 0.0058 (0.0291)	
training:	Epoch: [61][155/204]	Loss 0.0060 (0.0289)	
training:	Epoch: [61][156/204]	Loss 0.0054 (0.0288)	
training:	Epoch: [61][157/204]	Loss 0.0063 (0.0286)	
training:	Epoch: [61][158/204]	Loss 0.0053 (0.0285)	
training:	Epoch: [61][159/204]	Loss 0.0059 (0.0283)	
training:	Epoch: [61][160/204]	Loss 0.0065 (0.0282)	
training:	Epoch: [61][161/204]	Loss 0.0063 (0.0281)	
training:	Epoch: [61][162/204]	Loss 0.0069 (0.0279)	
training:	Epoch: [61][163/204]	Loss 0.0114 (0.0278)	
training:	Epoch: [61][164/204]	Loss 0.0056 (0.0277)	
training:	Epoch: [61][165/204]	Loss 0.0053 (0.0276)	
training:	Epoch: [61][166/204]	Loss 0.0059 (0.0274)	
training:	Epoch: [61][167/204]	Loss 0.1289 (0.0281)	
training:	Epoch: [61][168/204]	Loss 0.0054 (0.0279)	
training:	Epoch: [61][169/204]	Loss 0.0064 (0.0278)	
training:	Epoch: [61][170/204]	Loss 0.0047 (0.0277)	
training:	Epoch: [61][171/204]	Loss 0.0094 (0.0275)	
training:	Epoch: [61][172/204]	Loss 0.0057 (0.0274)	
training:	Epoch: [61][173/204]	Loss 0.0130 (0.0273)	
training:	Epoch: [61][174/204]	Loss 0.0061 (0.0272)	
training:	Epoch: [61][175/204]	Loss 0.0059 (0.0271)	
training:	Epoch: [61][176/204]	Loss 0.0052 (0.0270)	
training:	Epoch: [61][177/204]	Loss 0.0050 (0.0268)	
training:	Epoch: [61][178/204]	Loss 0.0085 (0.0267)	
training:	Epoch: [61][179/204]	Loss 0.0045 (0.0266)	
training:	Epoch: [61][180/204]	Loss 0.0064 (0.0265)	
training:	Epoch: [61][181/204]	Loss 0.0062 (0.0264)	
training:	Epoch: [61][182/204]	Loss 0.0057 (0.0263)	
training:	Epoch: [61][183/204]	Loss 0.0056 (0.0262)	
training:	Epoch: [61][184/204]	Loss 0.0054 (0.0261)	
training:	Epoch: [61][185/204]	Loss 0.0056 (0.0259)	
training:	Epoch: [61][186/204]	Loss 0.0043 (0.0258)	
training:	Epoch: [61][187/204]	Loss 0.0071 (0.0257)	
training:	Epoch: [61][188/204]	Loss 0.0063 (0.0256)	
training:	Epoch: [61][189/204]	Loss 0.0048 (0.0255)	
training:	Epoch: [61][190/204]	Loss 0.0046 (0.0254)	
training:	Epoch: [61][191/204]	Loss 0.0055 (0.0253)	
training:	Epoch: [61][192/204]	Loss 0.0047 (0.0252)	
training:	Epoch: [61][193/204]	Loss 0.0060 (0.0251)	
training:	Epoch: [61][194/204]	Loss 0.0053 (0.0250)	
training:	Epoch: [61][195/204]	Loss 0.0065 (0.0249)	
training:	Epoch: [61][196/204]	Loss 0.0774 (0.0252)	
training:	Epoch: [61][197/204]	Loss 0.0049 (0.0251)	
training:	Epoch: [61][198/204]	Loss 0.0047 (0.0250)	
training:	Epoch: [61][199/204]	Loss 0.0054 (0.0249)	
training:	Epoch: [61][200/204]	Loss 0.0049 (0.0248)	
training:	Epoch: [61][201/204]	Loss 0.0040 (0.0247)	
training:	Epoch: [61][202/204]	Loss 0.0078 (0.0246)	
training:	Epoch: [61][203/204]	Loss 0.0071 (0.0245)	
training:	Epoch: [61][204/204]	Loss 0.0041 (0.0244)	
Training:	 Loss: 0.0243

Training:	 ACC: 0.9955 0.9956 0.9962 0.9949
Validation:	 ACC: 0.7783 0.7796 0.8066 0.7500
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0797
Pretraining:	Epoch 62/500
----------
training:	Epoch: [62][1/204]	Loss 0.0039 (0.0039)	
training:	Epoch: [62][2/204]	Loss 0.0053 (0.0046)	
training:	Epoch: [62][3/204]	Loss 0.0045 (0.0046)	
training:	Epoch: [62][4/204]	Loss 0.0042 (0.0045)	
training:	Epoch: [62][5/204]	Loss 0.1274 (0.0291)	
training:	Epoch: [62][6/204]	Loss 0.0041 (0.0249)	
training:	Epoch: [62][7/204]	Loss 0.0047 (0.0220)	
training:	Epoch: [62][8/204]	Loss 0.0055 (0.0200)	
training:	Epoch: [62][9/204]	Loss 0.0051 (0.0183)	
training:	Epoch: [62][10/204]	Loss 0.1756 (0.0340)	
training:	Epoch: [62][11/204]	Loss 0.0038 (0.0313)	
training:	Epoch: [62][12/204]	Loss 0.0048 (0.0291)	
training:	Epoch: [62][13/204]	Loss 0.0049 (0.0272)	
training:	Epoch: [62][14/204]	Loss 0.0056 (0.0257)	
training:	Epoch: [62][15/204]	Loss 0.0055 (0.0243)	
training:	Epoch: [62][16/204]	Loss 0.0053 (0.0231)	
training:	Epoch: [62][17/204]	Loss 0.0060 (0.0221)	
training:	Epoch: [62][18/204]	Loss 0.0040 (0.0211)	
training:	Epoch: [62][19/204]	Loss 0.0038 (0.0202)	
training:	Epoch: [62][20/204]	Loss 0.0054 (0.0195)	
training:	Epoch: [62][21/204]	Loss 0.0060 (0.0188)	
training:	Epoch: [62][22/204]	Loss 0.0054 (0.0182)	
training:	Epoch: [62][23/204]	Loss 0.0049 (0.0176)	
training:	Epoch: [62][24/204]	Loss 0.0049 (0.0171)	
training:	Epoch: [62][25/204]	Loss 0.0047 (0.0166)	
training:	Epoch: [62][26/204]	Loss 0.0049 (0.0162)	
training:	Epoch: [62][27/204]	Loss 0.0064 (0.0158)	
training:	Epoch: [62][28/204]	Loss 0.0053 (0.0154)	
training:	Epoch: [62][29/204]	Loss 0.0053 (0.0151)	
training:	Epoch: [62][30/204]	Loss 0.1404 (0.0193)	
training:	Epoch: [62][31/204]	Loss 0.0049 (0.0188)	
training:	Epoch: [62][32/204]	Loss 0.0055 (0.0184)	
training:	Epoch: [62][33/204]	Loss 0.0052 (0.0180)	
training:	Epoch: [62][34/204]	Loss 0.0038 (0.0176)	
training:	Epoch: [62][35/204]	Loss 0.0048 (0.0172)	
training:	Epoch: [62][36/204]	Loss 0.0041 (0.0168)	
training:	Epoch: [62][37/204]	Loss 0.0043 (0.0165)	
training:	Epoch: [62][38/204]	Loss 0.1632 (0.0204)	
training:	Epoch: [62][39/204]	Loss 0.0052 (0.0200)	
training:	Epoch: [62][40/204]	Loss 0.0051 (0.0196)	
training:	Epoch: [62][41/204]	Loss 0.0044 (0.0192)	
training:	Epoch: [62][42/204]	Loss 0.0048 (0.0189)	
training:	Epoch: [62][43/204]	Loss 0.0044 (0.0185)	
training:	Epoch: [62][44/204]	Loss 0.0050 (0.0182)	
training:	Epoch: [62][45/204]	Loss 0.0048 (0.0179)	
training:	Epoch: [62][46/204]	Loss 0.0048 (0.0177)	
training:	Epoch: [62][47/204]	Loss 0.0049 (0.0174)	
training:	Epoch: [62][48/204]	Loss 0.1531 (0.0202)	
training:	Epoch: [62][49/204]	Loss 0.1759 (0.0234)	
training:	Epoch: [62][50/204]	Loss 0.0044 (0.0230)	
training:	Epoch: [62][51/204]	Loss 0.0039 (0.0226)	
training:	Epoch: [62][52/204]	Loss 0.0052 (0.0223)	
training:	Epoch: [62][53/204]	Loss 0.0045 (0.0220)	
training:	Epoch: [62][54/204]	Loss 0.0045 (0.0216)	
training:	Epoch: [62][55/204]	Loss 0.0040 (0.0213)	
training:	Epoch: [62][56/204]	Loss 0.0049 (0.0210)	
training:	Epoch: [62][57/204]	Loss 0.0045 (0.0207)	
training:	Epoch: [62][58/204]	Loss 0.0074 (0.0205)	
training:	Epoch: [62][59/204]	Loss 0.0051 (0.0202)	
training:	Epoch: [62][60/204]	Loss 0.0056 (0.0200)	
training:	Epoch: [62][61/204]	Loss 0.0047 (0.0197)	
training:	Epoch: [62][62/204]	Loss 0.0045 (0.0195)	
training:	Epoch: [62][63/204]	Loss 0.0044 (0.0193)	
training:	Epoch: [62][64/204]	Loss 0.0045 (0.0190)	
training:	Epoch: [62][65/204]	Loss 0.0044 (0.0188)	
training:	Epoch: [62][66/204]	Loss 0.0055 (0.0186)	
training:	Epoch: [62][67/204]	Loss 0.0040 (0.0184)	
training:	Epoch: [62][68/204]	Loss 0.0053 (0.0182)	
training:	Epoch: [62][69/204]	Loss 0.0052 (0.0180)	
training:	Epoch: [62][70/204]	Loss 0.0049 (0.0178)	
training:	Epoch: [62][71/204]	Loss 0.0051 (0.0176)	
training:	Epoch: [62][72/204]	Loss 0.0041 (0.0175)	
training:	Epoch: [62][73/204]	Loss 0.0050 (0.0173)	
training:	Epoch: [62][74/204]	Loss 0.0042 (0.0171)	
training:	Epoch: [62][75/204]	Loss 0.0043 (0.0169)	
training:	Epoch: [62][76/204]	Loss 0.0045 (0.0168)	
training:	Epoch: [62][77/204]	Loss 0.1450 (0.0184)	
training:	Epoch: [62][78/204]	Loss 0.0035 (0.0182)	
training:	Epoch: [62][79/204]	Loss 0.0048 (0.0181)	
training:	Epoch: [62][80/204]	Loss 0.0044 (0.0179)	
training:	Epoch: [62][81/204]	Loss 0.3128 (0.0215)	
training:	Epoch: [62][82/204]	Loss 0.0050 (0.0213)	
training:	Epoch: [62][83/204]	Loss 0.0926 (0.0222)	
training:	Epoch: [62][84/204]	Loss 0.0048 (0.0220)	
training:	Epoch: [62][85/204]	Loss 0.0042 (0.0218)	
training:	Epoch: [62][86/204]	Loss 0.0041 (0.0216)	
training:	Epoch: [62][87/204]	Loss 0.0056 (0.0214)	
training:	Epoch: [62][88/204]	Loss 0.0044 (0.0212)	
training:	Epoch: [62][89/204]	Loss 0.0036 (0.0210)	
training:	Epoch: [62][90/204]	Loss 0.0054 (0.0208)	
training:	Epoch: [62][91/204]	Loss 0.0058 (0.0207)	
training:	Epoch: [62][92/204]	Loss 0.0058 (0.0205)	
training:	Epoch: [62][93/204]	Loss 0.1289 (0.0217)	
training:	Epoch: [62][94/204]	Loss 0.0059 (0.0215)	
training:	Epoch: [62][95/204]	Loss 0.0053 (0.0213)	
training:	Epoch: [62][96/204]	Loss 0.1038 (0.0222)	
training:	Epoch: [62][97/204]	Loss 0.0057 (0.0220)	
training:	Epoch: [62][98/204]	Loss 0.0047 (0.0218)	
training:	Epoch: [62][99/204]	Loss 0.0048 (0.0217)	
training:	Epoch: [62][100/204]	Loss 0.0045 (0.0215)	
training:	Epoch: [62][101/204]	Loss 0.0048 (0.0213)	
training:	Epoch: [62][102/204]	Loss 0.1351 (0.0224)	
training:	Epoch: [62][103/204]	Loss 0.0057 (0.0223)	
training:	Epoch: [62][104/204]	Loss 0.0051 (0.0221)	
training:	Epoch: [62][105/204]	Loss 0.0050 (0.0220)	
training:	Epoch: [62][106/204]	Loss 0.1589 (0.0233)	
training:	Epoch: [62][107/204]	Loss 0.0051 (0.0231)	
training:	Epoch: [62][108/204]	Loss 0.0047 (0.0229)	
training:	Epoch: [62][109/204]	Loss 0.0058 (0.0228)	
training:	Epoch: [62][110/204]	Loss 0.0058 (0.0226)	
training:	Epoch: [62][111/204]	Loss 0.0066 (0.0225)	
training:	Epoch: [62][112/204]	Loss 0.0067 (0.0223)	
training:	Epoch: [62][113/204]	Loss 0.0049 (0.0222)	
training:	Epoch: [62][114/204]	Loss 0.0057 (0.0220)	
training:	Epoch: [62][115/204]	Loss 0.1622 (0.0232)	
training:	Epoch: [62][116/204]	Loss 0.0051 (0.0231)	
training:	Epoch: [62][117/204]	Loss 0.0055 (0.0229)	
training:	Epoch: [62][118/204]	Loss 0.0076 (0.0228)	
training:	Epoch: [62][119/204]	Loss 0.0044 (0.0226)	
training:	Epoch: [62][120/204]	Loss 0.0050 (0.0225)	
training:	Epoch: [62][121/204]	Loss 0.0049 (0.0224)	
training:	Epoch: [62][122/204]	Loss 0.2610 (0.0243)	
training:	Epoch: [62][123/204]	Loss 0.0056 (0.0242)	
training:	Epoch: [62][124/204]	Loss 0.0064 (0.0240)	
training:	Epoch: [62][125/204]	Loss 0.0047 (0.0239)	
training:	Epoch: [62][126/204]	Loss 0.0046 (0.0237)	
training:	Epoch: [62][127/204]	Loss 0.0043 (0.0236)	
training:	Epoch: [62][128/204]	Loss 0.0071 (0.0234)	
training:	Epoch: [62][129/204]	Loss 0.0061 (0.0233)	
training:	Epoch: [62][130/204]	Loss 0.0042 (0.0231)	
training:	Epoch: [62][131/204]	Loss 0.0086 (0.0230)	
training:	Epoch: [62][132/204]	Loss 0.0071 (0.0229)	
training:	Epoch: [62][133/204]	Loss 0.0063 (0.0228)	
training:	Epoch: [62][134/204]	Loss 0.0060 (0.0227)	
training:	Epoch: [62][135/204]	Loss 0.0060 (0.0225)	
training:	Epoch: [62][136/204]	Loss 0.1256 (0.0233)	
training:	Epoch: [62][137/204]	Loss 0.0079 (0.0232)	
training:	Epoch: [62][138/204]	Loss 0.1172 (0.0239)	
training:	Epoch: [62][139/204]	Loss 0.0060 (0.0237)	
training:	Epoch: [62][140/204]	Loss 0.0045 (0.0236)	
training:	Epoch: [62][141/204]	Loss 0.0038 (0.0235)	
training:	Epoch: [62][142/204]	Loss 0.0050 (0.0233)	
training:	Epoch: [62][143/204]	Loss 0.0161 (0.0233)	
training:	Epoch: [62][144/204]	Loss 0.0040 (0.0231)	
training:	Epoch: [62][145/204]	Loss 0.0057 (0.0230)	
training:	Epoch: [62][146/204]	Loss 0.0040 (0.0229)	
training:	Epoch: [62][147/204]	Loss 0.0057 (0.0228)	
training:	Epoch: [62][148/204]	Loss 0.0923 (0.0232)	
training:	Epoch: [62][149/204]	Loss 0.0052 (0.0231)	
training:	Epoch: [62][150/204]	Loss 0.0048 (0.0230)	
training:	Epoch: [62][151/204]	Loss 0.0051 (0.0229)	
training:	Epoch: [62][152/204]	Loss 0.1240 (0.0235)	
training:	Epoch: [62][153/204]	Loss 0.0058 (0.0234)	
training:	Epoch: [62][154/204]	Loss 0.0043 (0.0233)	
training:	Epoch: [62][155/204]	Loss 0.0184 (0.0233)	
training:	Epoch: [62][156/204]	Loss 0.0061 (0.0232)	
training:	Epoch: [62][157/204]	Loss 0.0074 (0.0231)	
training:	Epoch: [62][158/204]	Loss 0.1518 (0.0239)	
training:	Epoch: [62][159/204]	Loss 0.1190 (0.0245)	
training:	Epoch: [62][160/204]	Loss 0.0067 (0.0244)	
training:	Epoch: [62][161/204]	Loss 0.0061 (0.0243)	
training:	Epoch: [62][162/204]	Loss 0.0047 (0.0241)	
training:	Epoch: [62][163/204]	Loss 0.0055 (0.0240)	
training:	Epoch: [62][164/204]	Loss 0.0062 (0.0239)	
training:	Epoch: [62][165/204]	Loss 0.0065 (0.0238)	
training:	Epoch: [62][166/204]	Loss 0.0068 (0.0237)	
training:	Epoch: [62][167/204]	Loss 0.0058 (0.0236)	
training:	Epoch: [62][168/204]	Loss 0.0939 (0.0240)	
training:	Epoch: [62][169/204]	Loss 0.0069 (0.0239)	
training:	Epoch: [62][170/204]	Loss 0.0053 (0.0238)	
training:	Epoch: [62][171/204]	Loss 0.0062 (0.0237)	
training:	Epoch: [62][172/204]	Loss 0.0080 (0.0236)	
training:	Epoch: [62][173/204]	Loss 0.0070 (0.0235)	
training:	Epoch: [62][174/204]	Loss 0.0072 (0.0234)	
training:	Epoch: [62][175/204]	Loss 0.1125 (0.0239)	
training:	Epoch: [62][176/204]	Loss 0.1562 (0.0247)	
training:	Epoch: [62][177/204]	Loss 0.0063 (0.0246)	
training:	Epoch: [62][178/204]	Loss 0.0054 (0.0245)	
training:	Epoch: [62][179/204]	Loss 0.0460 (0.0246)	
training:	Epoch: [62][180/204]	Loss 0.0052 (0.0245)	
training:	Epoch: [62][181/204]	Loss 0.0066 (0.0244)	
training:	Epoch: [62][182/204]	Loss 0.1122 (0.0249)	
training:	Epoch: [62][183/204]	Loss 0.0087 (0.0248)	
training:	Epoch: [62][184/204]	Loss 0.1190 (0.0253)	
training:	Epoch: [62][185/204]	Loss 0.0064 (0.0252)	
training:	Epoch: [62][186/204]	Loss 0.0061 (0.0251)	
training:	Epoch: [62][187/204]	Loss 0.0088 (0.0250)	
training:	Epoch: [62][188/204]	Loss 0.0061 (0.0249)	
training:	Epoch: [62][189/204]	Loss 0.0059 (0.0248)	
training:	Epoch: [62][190/204]	Loss 0.0068 (0.0247)	
training:	Epoch: [62][191/204]	Loss 0.0053 (0.0246)	
training:	Epoch: [62][192/204]	Loss 0.0076 (0.0245)	
training:	Epoch: [62][193/204]	Loss 0.0069 (0.0244)	
training:	Epoch: [62][194/204]	Loss 0.0064 (0.0243)	
training:	Epoch: [62][195/204]	Loss 0.0073 (0.0242)	
training:	Epoch: [62][196/204]	Loss 0.0057 (0.0241)	
training:	Epoch: [62][197/204]	Loss 0.0136 (0.0241)	
training:	Epoch: [62][198/204]	Loss 0.0082 (0.0240)	
training:	Epoch: [62][199/204]	Loss 0.0058 (0.0239)	
training:	Epoch: [62][200/204]	Loss 0.0094 (0.0238)	
training:	Epoch: [62][201/204]	Loss 0.0122 (0.0238)	
training:	Epoch: [62][202/204]	Loss 0.0063 (0.0237)	
training:	Epoch: [62][203/204]	Loss 0.0060 (0.0236)	
training:	Epoch: [62][204/204]	Loss 0.0071 (0.0235)	
Training:	 Loss: 0.0235

Training:	 ACC: 0.9955 0.9956 0.9962 0.9949
Validation:	 ACC: 0.7836 0.7838 0.7892 0.7780
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.0677
Pretraining:	Epoch 63/500
----------
training:	Epoch: [63][1/204]	Loss 0.1004 (0.1004)	
training:	Epoch: [63][2/204]	Loss 0.1137 (0.1070)	
training:	Epoch: [63][3/204]	Loss 0.0077 (0.0739)	
training:	Epoch: [63][4/204]	Loss 0.1101 (0.0830)	
training:	Epoch: [63][5/204]	Loss 0.0073 (0.0678)	
training:	Epoch: [63][6/204]	Loss 0.0054 (0.0574)	
training:	Epoch: [63][7/204]	Loss 0.0087 (0.0505)	
training:	Epoch: [63][8/204]	Loss 0.0086 (0.0452)	
training:	Epoch: [63][9/204]	Loss 0.0067 (0.0409)	
training:	Epoch: [63][10/204]	Loss 0.0061 (0.0375)	
training:	Epoch: [63][11/204]	Loss 0.0067 (0.0347)	
training:	Epoch: [63][12/204]	Loss 0.0044 (0.0321)	
training:	Epoch: [63][13/204]	Loss 0.0043 (0.0300)	
training:	Epoch: [63][14/204]	Loss 0.0053 (0.0282)	
training:	Epoch: [63][15/204]	Loss 0.0073 (0.0268)	
training:	Epoch: [63][16/204]	Loss 0.0054 (0.0255)	
training:	Epoch: [63][17/204]	Loss 0.0060 (0.0243)	
training:	Epoch: [63][18/204]	Loss 0.0065 (0.0234)	
training:	Epoch: [63][19/204]	Loss 0.0116 (0.0227)	
training:	Epoch: [63][20/204]	Loss 0.0038 (0.0218)	
training:	Epoch: [63][21/204]	Loss 0.1369 (0.0273)	
training:	Epoch: [63][22/204]	Loss 0.0064 (0.0263)	
training:	Epoch: [63][23/204]	Loss 0.0062 (0.0254)	
training:	Epoch: [63][24/204]	Loss 0.0061 (0.0246)	
training:	Epoch: [63][25/204]	Loss 0.0060 (0.0239)	
training:	Epoch: [63][26/204]	Loss 0.0064 (0.0232)	
training:	Epoch: [63][27/204]	Loss 0.1181 (0.0267)	
training:	Epoch: [63][28/204]	Loss 0.0062 (0.0260)	
training:	Epoch: [63][29/204]	Loss 0.0063 (0.0253)	
training:	Epoch: [63][30/204]	Loss 0.0064 (0.0247)	
training:	Epoch: [63][31/204]	Loss 0.0054 (0.0241)	
training:	Epoch: [63][32/204]	Loss 0.0065 (0.0235)	
training:	Epoch: [63][33/204]	Loss 0.0089 (0.0231)	
training:	Epoch: [63][34/204]	Loss 0.0100 (0.0227)	
training:	Epoch: [63][35/204]	Loss 0.0072 (0.0223)	
training:	Epoch: [63][36/204]	Loss 0.0485 (0.0230)	
training:	Epoch: [63][37/204]	Loss 0.0057 (0.0225)	
training:	Epoch: [63][38/204]	Loss 0.0078 (0.0221)	
training:	Epoch: [63][39/204]	Loss 0.0055 (0.0217)	
training:	Epoch: [63][40/204]	Loss 0.1017 (0.0237)	
training:	Epoch: [63][41/204]	Loss 0.0050 (0.0232)	
training:	Epoch: [63][42/204]	Loss 0.0079 (0.0229)	
training:	Epoch: [63][43/204]	Loss 0.0054 (0.0225)	
training:	Epoch: [63][44/204]	Loss 0.0060 (0.0221)	
training:	Epoch: [63][45/204]	Loss 0.0045 (0.0217)	
training:	Epoch: [63][46/204]	Loss 0.0045 (0.0213)	
training:	Epoch: [63][47/204]	Loss 0.0063 (0.0210)	
training:	Epoch: [63][48/204]	Loss 0.0051 (0.0207)	
training:	Epoch: [63][49/204]	Loss 0.1683 (0.0237)	
training:	Epoch: [63][50/204]	Loss 0.0129 (0.0235)	
training:	Epoch: [63][51/204]	Loss 0.0068 (0.0232)	
training:	Epoch: [63][52/204]	Loss 0.0061 (0.0228)	
training:	Epoch: [63][53/204]	Loss 0.0087 (0.0226)	
training:	Epoch: [63][54/204]	Loss 0.0065 (0.0223)	
training:	Epoch: [63][55/204]	Loss 0.0053 (0.0219)	
training:	Epoch: [63][56/204]	Loss 0.0110 (0.0218)	
training:	Epoch: [63][57/204]	Loss 0.0060 (0.0215)	
training:	Epoch: [63][58/204]	Loss 0.0061 (0.0212)	
training:	Epoch: [63][59/204]	Loss 0.0062 (0.0210)	
training:	Epoch: [63][60/204]	Loss 0.1153 (0.0225)	
training:	Epoch: [63][61/204]	Loss 0.0059 (0.0223)	
training:	Epoch: [63][62/204]	Loss 0.0066 (0.0220)	
training:	Epoch: [63][63/204]	Loss 0.0060 (0.0217)	
training:	Epoch: [63][64/204]	Loss 0.0045 (0.0215)	
training:	Epoch: [63][65/204]	Loss 0.0053 (0.0212)	
training:	Epoch: [63][66/204]	Loss 0.0051 (0.0210)	
training:	Epoch: [63][67/204]	Loss 0.0066 (0.0208)	
training:	Epoch: [63][68/204]	Loss 0.0048 (0.0205)	
training:	Epoch: [63][69/204]	Loss 0.0045 (0.0203)	
training:	Epoch: [63][70/204]	Loss 0.0057 (0.0201)	
training:	Epoch: [63][71/204]	Loss 0.0041 (0.0199)	
training:	Epoch: [63][72/204]	Loss 0.0044 (0.0197)	
training:	Epoch: [63][73/204]	Loss 0.0046 (0.0195)	
training:	Epoch: [63][74/204]	Loss 0.0063 (0.0193)	
training:	Epoch: [63][75/204]	Loss 0.0041 (0.0191)	
training:	Epoch: [63][76/204]	Loss 0.0049 (0.0189)	
training:	Epoch: [63][77/204]	Loss 0.0071 (0.0187)	
training:	Epoch: [63][78/204]	Loss 0.1334 (0.0202)	
training:	Epoch: [63][79/204]	Loss 0.0063 (0.0200)	
training:	Epoch: [63][80/204]	Loss 0.0047 (0.0198)	
training:	Epoch: [63][81/204]	Loss 0.0055 (0.0197)	
training:	Epoch: [63][82/204]	Loss 0.0047 (0.0195)	
training:	Epoch: [63][83/204]	Loss 0.0060 (0.0193)	
training:	Epoch: [63][84/204]	Loss 0.0043 (0.0191)	
training:	Epoch: [63][85/204]	Loss 0.0042 (0.0190)	
training:	Epoch: [63][86/204]	Loss 0.0063 (0.0188)	
training:	Epoch: [63][87/204]	Loss 0.1458 (0.0203)	
training:	Epoch: [63][88/204]	Loss 0.0071 (0.0201)	
training:	Epoch: [63][89/204]	Loss 0.0037 (0.0199)	
training:	Epoch: [63][90/204]	Loss 0.1259 (0.0211)	
training:	Epoch: [63][91/204]	Loss 0.0039 (0.0209)	
training:	Epoch: [63][92/204]	Loss 0.0045 (0.0207)	
training:	Epoch: [63][93/204]	Loss 0.0049 (0.0206)	
training:	Epoch: [63][94/204]	Loss 0.0052 (0.0204)	
training:	Epoch: [63][95/204]	Loss 0.0044 (0.0202)	
training:	Epoch: [63][96/204]	Loss 0.0054 (0.0201)	
training:	Epoch: [63][97/204]	Loss 0.0046 (0.0199)	
training:	Epoch: [63][98/204]	Loss 0.0933 (0.0207)	
training:	Epoch: [63][99/204]	Loss 0.0051 (0.0205)	
training:	Epoch: [63][100/204]	Loss 0.0044 (0.0204)	
training:	Epoch: [63][101/204]	Loss 0.0941 (0.0211)	
training:	Epoch: [63][102/204]	Loss 0.0047 (0.0209)	
training:	Epoch: [63][103/204]	Loss 0.0079 (0.0208)	
training:	Epoch: [63][104/204]	Loss 0.1247 (0.0218)	
training:	Epoch: [63][105/204]	Loss 0.0063 (0.0216)	
training:	Epoch: [63][106/204]	Loss 0.0045 (0.0215)	
training:	Epoch: [63][107/204]	Loss 0.0045 (0.0213)	
training:	Epoch: [63][108/204]	Loss 0.0052 (0.0212)	
training:	Epoch: [63][109/204]	Loss 0.0053 (0.0210)	
training:	Epoch: [63][110/204]	Loss 0.0065 (0.0209)	
training:	Epoch: [63][111/204]	Loss 0.0064 (0.0208)	
training:	Epoch: [63][112/204]	Loss 0.0060 (0.0206)	
training:	Epoch: [63][113/204]	Loss 0.0057 (0.0205)	
training:	Epoch: [63][114/204]	Loss 0.1138 (0.0213)	
training:	Epoch: [63][115/204]	Loss 0.0053 (0.0212)	
training:	Epoch: [63][116/204]	Loss 0.0061 (0.0211)	
training:	Epoch: [63][117/204]	Loss 0.0054 (0.0209)	
training:	Epoch: [63][118/204]	Loss 0.0038 (0.0208)	
training:	Epoch: [63][119/204]	Loss 0.0061 (0.0207)	
training:	Epoch: [63][120/204]	Loss 0.1601 (0.0218)	
training:	Epoch: [63][121/204]	Loss 0.0057 (0.0217)	
training:	Epoch: [63][122/204]	Loss 0.0051 (0.0215)	
training:	Epoch: [63][123/204]	Loss 0.0068 (0.0214)	
training:	Epoch: [63][124/204]	Loss 0.0074 (0.0213)	
training:	Epoch: [63][125/204]	Loss 0.1025 (0.0220)	
training:	Epoch: [63][126/204]	Loss 0.0068 (0.0218)	
training:	Epoch: [63][127/204]	Loss 0.0047 (0.0217)	
training:	Epoch: [63][128/204]	Loss 0.0071 (0.0216)	
training:	Epoch: [63][129/204]	Loss 0.0043 (0.0215)	
training:	Epoch: [63][130/204]	Loss 0.0063 (0.0213)	
training:	Epoch: [63][131/204]	Loss 0.0070 (0.0212)	
training:	Epoch: [63][132/204]	Loss 0.0064 (0.0211)	
training:	Epoch: [63][133/204]	Loss 0.0065 (0.0210)	
training:	Epoch: [63][134/204]	Loss 0.0058 (0.0209)	
training:	Epoch: [63][135/204]	Loss 0.0067 (0.0208)	
training:	Epoch: [63][136/204]	Loss 0.0714 (0.0212)	
training:	Epoch: [63][137/204]	Loss 0.0057 (0.0211)	
training:	Epoch: [63][138/204]	Loss 0.0047 (0.0209)	
training:	Epoch: [63][139/204]	Loss 0.0046 (0.0208)	
training:	Epoch: [63][140/204]	Loss 0.0075 (0.0207)	
training:	Epoch: [63][141/204]	Loss 0.0043 (0.0206)	
training:	Epoch: [63][142/204]	Loss 0.0081 (0.0205)	
training:	Epoch: [63][143/204]	Loss 0.1446 (0.0214)	
training:	Epoch: [63][144/204]	Loss 0.0056 (0.0213)	
training:	Epoch: [63][145/204]	Loss 0.0036 (0.0212)	
training:	Epoch: [63][146/204]	Loss 0.1685 (0.0222)	
training:	Epoch: [63][147/204]	Loss 0.0062 (0.0221)	
training:	Epoch: [63][148/204]	Loss 0.0073 (0.0220)	
training:	Epoch: [63][149/204]	Loss 0.0057 (0.0218)	
training:	Epoch: [63][150/204]	Loss 0.0049 (0.0217)	
training:	Epoch: [63][151/204]	Loss 0.0054 (0.0216)	
training:	Epoch: [63][152/204]	Loss 0.0076 (0.0215)	
training:	Epoch: [63][153/204]	Loss 0.0055 (0.0214)	
training:	Epoch: [63][154/204]	Loss 0.0083 (0.0213)	
training:	Epoch: [63][155/204]	Loss 0.0054 (0.0212)	
training:	Epoch: [63][156/204]	Loss 0.0066 (0.0211)	
training:	Epoch: [63][157/204]	Loss 0.0056 (0.0210)	
training:	Epoch: [63][158/204]	Loss 0.1473 (0.0218)	
training:	Epoch: [63][159/204]	Loss 0.0068 (0.0217)	
training:	Epoch: [63][160/204]	Loss 0.0076 (0.0217)	
training:	Epoch: [63][161/204]	Loss 0.0050 (0.0216)	
training:	Epoch: [63][162/204]	Loss 0.0056 (0.0215)	
training:	Epoch: [63][163/204]	Loss 0.0066 (0.0214)	
training:	Epoch: [63][164/204]	Loss 0.0061 (0.0213)	
training:	Epoch: [63][165/204]	Loss 0.1148 (0.0218)	
training:	Epoch: [63][166/204]	Loss 0.0101 (0.0218)	
training:	Epoch: [63][167/204]	Loss 0.0205 (0.0218)	
training:	Epoch: [63][168/204]	Loss 0.0123 (0.0217)	
training:	Epoch: [63][169/204]	Loss 0.0059 (0.0216)	
training:	Epoch: [63][170/204]	Loss 0.0057 (0.0215)	
training:	Epoch: [63][171/204]	Loss 0.0072 (0.0214)	
training:	Epoch: [63][172/204]	Loss 0.0053 (0.0213)	
training:	Epoch: [63][173/204]	Loss 0.0063 (0.0213)	
training:	Epoch: [63][174/204]	Loss 0.0052 (0.0212)	
training:	Epoch: [63][175/204]	Loss 0.0033 (0.0211)	
training:	Epoch: [63][176/204]	Loss 0.0055 (0.0210)	
training:	Epoch: [63][177/204]	Loss 0.0042 (0.0209)	
training:	Epoch: [63][178/204]	Loss 0.0049 (0.0208)	
training:	Epoch: [63][179/204]	Loss 0.1319 (0.0214)	
training:	Epoch: [63][180/204]	Loss 0.0063 (0.0213)	
training:	Epoch: [63][181/204]	Loss 0.0066 (0.0212)	
training:	Epoch: [63][182/204]	Loss 0.1100 (0.0217)	
training:	Epoch: [63][183/204]	Loss 0.0044 (0.0216)	
training:	Epoch: [63][184/204]	Loss 0.0044 (0.0215)	
training:	Epoch: [63][185/204]	Loss 0.0055 (0.0215)	
training:	Epoch: [63][186/204]	Loss 0.0045 (0.0214)	
training:	Epoch: [63][187/204]	Loss 0.1694 (0.0222)	
training:	Epoch: [63][188/204]	Loss 0.0066 (0.0221)	
training:	Epoch: [63][189/204]	Loss 0.0039 (0.0220)	
training:	Epoch: [63][190/204]	Loss 0.0051 (0.0219)	
training:	Epoch: [63][191/204]	Loss 0.0073 (0.0218)	
training:	Epoch: [63][192/204]	Loss 0.0040 (0.0217)	
training:	Epoch: [63][193/204]	Loss 0.0036 (0.0216)	
training:	Epoch: [63][194/204]	Loss 0.0045 (0.0215)	
training:	Epoch: [63][195/204]	Loss 0.1247 (0.0221)	
training:	Epoch: [63][196/204]	Loss 0.0077 (0.0220)	
training:	Epoch: [63][197/204]	Loss 0.0061 (0.0219)	
training:	Epoch: [63][198/204]	Loss 0.0843 (0.0222)	
training:	Epoch: [63][199/204]	Loss 0.0041 (0.0221)	
training:	Epoch: [63][200/204]	Loss 0.0050 (0.0221)	
training:	Epoch: [63][201/204]	Loss 0.0074 (0.0220)	
training:	Epoch: [63][202/204]	Loss 0.1795 (0.0228)	
training:	Epoch: [63][203/204]	Loss 0.0042 (0.0227)	
training:	Epoch: [63][204/204]	Loss 0.0038 (0.0226)	
Training:	 Loss: 0.0225

Training:	 ACC: 0.9957 0.9957 0.9965 0.9949
Validation:	 ACC: 0.7794 0.7801 0.7953 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1039
Pretraining:	Epoch 64/500
----------
training:	Epoch: [64][1/204]	Loss 0.1231 (0.1231)	
training:	Epoch: [64][2/204]	Loss 0.1013 (0.1122)	
training:	Epoch: [64][3/204]	Loss 0.0039 (0.0761)	
training:	Epoch: [64][4/204]	Loss 0.0042 (0.0581)	
training:	Epoch: [64][5/204]	Loss 0.0048 (0.0474)	
training:	Epoch: [64][6/204]	Loss 0.0053 (0.0404)	
training:	Epoch: [64][7/204]	Loss 0.0054 (0.0354)	
training:	Epoch: [64][8/204]	Loss 0.0036 (0.0314)	
training:	Epoch: [64][9/204]	Loss 0.0037 (0.0284)	
training:	Epoch: [64][10/204]	Loss 0.0060 (0.0261)	
training:	Epoch: [64][11/204]	Loss 0.0053 (0.0242)	
training:	Epoch: [64][12/204]	Loss 0.0061 (0.0227)	
training:	Epoch: [64][13/204]	Loss 0.0059 (0.0214)	
training:	Epoch: [64][14/204]	Loss 0.0061 (0.0203)	
training:	Epoch: [64][15/204]	Loss 0.0039 (0.0192)	
training:	Epoch: [64][16/204]	Loss 0.0044 (0.0183)	
training:	Epoch: [64][17/204]	Loss 0.0036 (0.0174)	
training:	Epoch: [64][18/204]	Loss 0.0058 (0.0168)	
training:	Epoch: [64][19/204]	Loss 0.0053 (0.0162)	
training:	Epoch: [64][20/204]	Loss 0.0062 (0.0157)	
training:	Epoch: [64][21/204]	Loss 0.0043 (0.0151)	
training:	Epoch: [64][22/204]	Loss 0.0046 (0.0147)	
training:	Epoch: [64][23/204]	Loss 0.0057 (0.0143)	
training:	Epoch: [64][24/204]	Loss 0.0041 (0.0139)	
training:	Epoch: [64][25/204]	Loss 0.1660 (0.0199)	
training:	Epoch: [64][26/204]	Loss 0.0045 (0.0193)	
training:	Epoch: [64][27/204]	Loss 0.0049 (0.0188)	
training:	Epoch: [64][28/204]	Loss 0.0050 (0.0183)	
training:	Epoch: [64][29/204]	Loss 0.0055 (0.0179)	
training:	Epoch: [64][30/204]	Loss 0.0065 (0.0175)	
training:	Epoch: [64][31/204]	Loss 0.0039 (0.0171)	
training:	Epoch: [64][32/204]	Loss 0.0058 (0.0167)	
training:	Epoch: [64][33/204]	Loss 0.0066 (0.0164)	
training:	Epoch: [64][34/204]	Loss 0.0044 (0.0160)	
training:	Epoch: [64][35/204]	Loss 0.0056 (0.0157)	
training:	Epoch: [64][36/204]	Loss 0.1520 (0.0195)	
training:	Epoch: [64][37/204]	Loss 0.0048 (0.0191)	
training:	Epoch: [64][38/204]	Loss 0.0044 (0.0187)	
training:	Epoch: [64][39/204]	Loss 0.0039 (0.0184)	
training:	Epoch: [64][40/204]	Loss 0.0051 (0.0180)	
training:	Epoch: [64][41/204]	Loss 0.0036 (0.0177)	
training:	Epoch: [64][42/204]	Loss 0.0048 (0.0174)	
training:	Epoch: [64][43/204]	Loss 0.0292 (0.0176)	
training:	Epoch: [64][44/204]	Loss 0.0057 (0.0174)	
training:	Epoch: [64][45/204]	Loss 0.0050 (0.0171)	
training:	Epoch: [64][46/204]	Loss 0.0053 (0.0168)	
training:	Epoch: [64][47/204]	Loss 0.1671 (0.0200)	
training:	Epoch: [64][48/204]	Loss 0.0062 (0.0198)	
training:	Epoch: [64][49/204]	Loss 0.0069 (0.0195)	
training:	Epoch: [64][50/204]	Loss 0.0042 (0.0192)	
training:	Epoch: [64][51/204]	Loss 0.0050 (0.0189)	
training:	Epoch: [64][52/204]	Loss 0.0044 (0.0186)	
training:	Epoch: [64][53/204]	Loss 0.0087 (0.0184)	
training:	Epoch: [64][54/204]	Loss 0.0053 (0.0182)	
training:	Epoch: [64][55/204]	Loss 0.0046 (0.0179)	
training:	Epoch: [64][56/204]	Loss 0.0047 (0.0177)	
training:	Epoch: [64][57/204]	Loss 0.0045 (0.0175)	
training:	Epoch: [64][58/204]	Loss 0.0040 (0.0172)	
training:	Epoch: [64][59/204]	Loss 0.0044 (0.0170)	
training:	Epoch: [64][60/204]	Loss 0.0050 (0.0168)	
training:	Epoch: [64][61/204]	Loss 0.0041 (0.0166)	
training:	Epoch: [64][62/204]	Loss 0.0055 (0.0164)	
training:	Epoch: [64][63/204]	Loss 0.0049 (0.0163)	
training:	Epoch: [64][64/204]	Loss 0.0043 (0.0161)	
training:	Epoch: [64][65/204]	Loss 0.1278 (0.0178)	
training:	Epoch: [64][66/204]	Loss 0.1214 (0.0194)	
training:	Epoch: [64][67/204]	Loss 0.0042 (0.0191)	
training:	Epoch: [64][68/204]	Loss 0.0044 (0.0189)	
training:	Epoch: [64][69/204]	Loss 0.0057 (0.0187)	
training:	Epoch: [64][70/204]	Loss 0.0061 (0.0185)	
training:	Epoch: [64][71/204]	Loss 0.0048 (0.0184)	
training:	Epoch: [64][72/204]	Loss 0.0038 (0.0182)	
training:	Epoch: [64][73/204]	Loss 0.0042 (0.0180)	
training:	Epoch: [64][74/204]	Loss 0.0788 (0.0188)	
training:	Epoch: [64][75/204]	Loss 0.0052 (0.0186)	
training:	Epoch: [64][76/204]	Loss 0.0038 (0.0184)	
training:	Epoch: [64][77/204]	Loss 0.0058 (0.0182)	
training:	Epoch: [64][78/204]	Loss 0.0040 (0.0181)	
training:	Epoch: [64][79/204]	Loss 0.0056 (0.0179)	
training:	Epoch: [64][80/204]	Loss 0.0047 (0.0177)	
training:	Epoch: [64][81/204]	Loss 0.0052 (0.0176)	
training:	Epoch: [64][82/204]	Loss 0.0034 (0.0174)	
training:	Epoch: [64][83/204]	Loss 0.0710 (0.0181)	
training:	Epoch: [64][84/204]	Loss 0.0039 (0.0179)	
training:	Epoch: [64][85/204]	Loss 0.0043 (0.0177)	
training:	Epoch: [64][86/204]	Loss 0.0053 (0.0176)	
training:	Epoch: [64][87/204]	Loss 0.0055 (0.0174)	
training:	Epoch: [64][88/204]	Loss 0.1102 (0.0185)	
training:	Epoch: [64][89/204]	Loss 0.0056 (0.0184)	
training:	Epoch: [64][90/204]	Loss 0.0050 (0.0182)	
training:	Epoch: [64][91/204]	Loss 0.1147 (0.0193)	
training:	Epoch: [64][92/204]	Loss 0.0058 (0.0191)	
training:	Epoch: [64][93/204]	Loss 0.0049 (0.0190)	
training:	Epoch: [64][94/204]	Loss 0.0040 (0.0188)	
training:	Epoch: [64][95/204]	Loss 0.0202 (0.0188)	
training:	Epoch: [64][96/204]	Loss 0.0057 (0.0187)	
training:	Epoch: [64][97/204]	Loss 0.0069 (0.0186)	
training:	Epoch: [64][98/204]	Loss 0.0045 (0.0184)	
training:	Epoch: [64][99/204]	Loss 0.1796 (0.0200)	
training:	Epoch: [64][100/204]	Loss 0.0082 (0.0199)	
training:	Epoch: [64][101/204]	Loss 0.0058 (0.0198)	
training:	Epoch: [64][102/204]	Loss 0.1026 (0.0206)	
training:	Epoch: [64][103/204]	Loss 0.0053 (0.0205)	
training:	Epoch: [64][104/204]	Loss 0.0064 (0.0203)	
training:	Epoch: [64][105/204]	Loss 0.0059 (0.0202)	
training:	Epoch: [64][106/204]	Loss 0.0045 (0.0200)	
training:	Epoch: [64][107/204]	Loss 0.0075 (0.0199)	
training:	Epoch: [64][108/204]	Loss 0.0061 (0.0198)	
training:	Epoch: [64][109/204]	Loss 0.1123 (0.0206)	
training:	Epoch: [64][110/204]	Loss 0.0050 (0.0205)	
training:	Epoch: [64][111/204]	Loss 0.0043 (0.0203)	
training:	Epoch: [64][112/204]	Loss 0.0110 (0.0203)	
training:	Epoch: [64][113/204]	Loss 0.0800 (0.0208)	
training:	Epoch: [64][114/204]	Loss 0.0043 (0.0206)	
training:	Epoch: [64][115/204]	Loss 0.0067 (0.0205)	
training:	Epoch: [64][116/204]	Loss 0.1582 (0.0217)	
training:	Epoch: [64][117/204]	Loss 0.0052 (0.0216)	
training:	Epoch: [64][118/204]	Loss 0.0049 (0.0214)	
training:	Epoch: [64][119/204]	Loss 0.0069 (0.0213)	
training:	Epoch: [64][120/204]	Loss 0.0053 (0.0212)	
training:	Epoch: [64][121/204]	Loss 0.0091 (0.0211)	
training:	Epoch: [64][122/204]	Loss 0.0040 (0.0209)	
training:	Epoch: [64][123/204]	Loss 0.1731 (0.0222)	
training:	Epoch: [64][124/204]	Loss 0.0080 (0.0221)	
training:	Epoch: [64][125/204]	Loss 0.0066 (0.0219)	
training:	Epoch: [64][126/204]	Loss 0.0104 (0.0218)	
training:	Epoch: [64][127/204]	Loss 0.0061 (0.0217)	
training:	Epoch: [64][128/204]	Loss 0.0054 (0.0216)	
training:	Epoch: [64][129/204]	Loss 0.0049 (0.0215)	
training:	Epoch: [64][130/204]	Loss 0.0056 (0.0213)	
training:	Epoch: [64][131/204]	Loss 0.0059 (0.0212)	
training:	Epoch: [64][132/204]	Loss 0.0054 (0.0211)	
training:	Epoch: [64][133/204]	Loss 0.0051 (0.0210)	
training:	Epoch: [64][134/204]	Loss 0.0036 (0.0209)	
training:	Epoch: [64][135/204]	Loss 0.0063 (0.0207)	
training:	Epoch: [64][136/204]	Loss 0.0064 (0.0206)	
training:	Epoch: [64][137/204]	Loss 0.0054 (0.0205)	
training:	Epoch: [64][138/204]	Loss 0.0456 (0.0207)	
training:	Epoch: [64][139/204]	Loss 0.0043 (0.0206)	
training:	Epoch: [64][140/204]	Loss 0.0053 (0.0205)	
training:	Epoch: [64][141/204]	Loss 0.0048 (0.0204)	
training:	Epoch: [64][142/204]	Loss 0.1539 (0.0213)	
training:	Epoch: [64][143/204]	Loss 0.0077 (0.0212)	
training:	Epoch: [64][144/204]	Loss 0.0062 (0.0211)	
training:	Epoch: [64][145/204]	Loss 0.0680 (0.0214)	
training:	Epoch: [64][146/204]	Loss 0.0055 (0.0213)	
training:	Epoch: [64][147/204]	Loss 0.1414 (0.0221)	
training:	Epoch: [64][148/204]	Loss 0.0060 (0.0220)	
training:	Epoch: [64][149/204]	Loss 0.0072 (0.0219)	
training:	Epoch: [64][150/204]	Loss 0.0095 (0.0219)	
training:	Epoch: [64][151/204]	Loss 0.0061 (0.0217)	
training:	Epoch: [64][152/204]	Loss 0.0076 (0.0217)	
training:	Epoch: [64][153/204]	Loss 0.0157 (0.0216)	
training:	Epoch: [64][154/204]	Loss 0.0186 (0.0216)	
training:	Epoch: [64][155/204]	Loss 0.0046 (0.0215)	
training:	Epoch: [64][156/204]	Loss 0.0057 (0.0214)	
training:	Epoch: [64][157/204]	Loss 0.0054 (0.0213)	
training:	Epoch: [64][158/204]	Loss 0.0044 (0.0212)	
training:	Epoch: [64][159/204]	Loss 0.0056 (0.0211)	
training:	Epoch: [64][160/204]	Loss 0.0058 (0.0210)	
training:	Epoch: [64][161/204]	Loss 0.0066 (0.0209)	
training:	Epoch: [64][162/204]	Loss 0.0043 (0.0208)	
training:	Epoch: [64][163/204]	Loss 0.0052 (0.0207)	
training:	Epoch: [64][164/204]	Loss 0.0061 (0.0206)	
training:	Epoch: [64][165/204]	Loss 0.0057 (0.0205)	
training:	Epoch: [64][166/204]	Loss 0.0050 (0.0204)	
training:	Epoch: [64][167/204]	Loss 0.0053 (0.0203)	
training:	Epoch: [64][168/204]	Loss 0.0051 (0.0202)	
training:	Epoch: [64][169/204]	Loss 0.0062 (0.0202)	
training:	Epoch: [64][170/204]	Loss 0.0059 (0.0201)	
training:	Epoch: [64][171/204]	Loss 0.0048 (0.0200)	
training:	Epoch: [64][172/204]	Loss 0.0179 (0.0200)	
training:	Epoch: [64][173/204]	Loss 0.0041 (0.0199)	
training:	Epoch: [64][174/204]	Loss 0.0046 (0.0198)	
training:	Epoch: [64][175/204]	Loss 0.0048 (0.0197)	
training:	Epoch: [64][176/204]	Loss 0.0041 (0.0196)	
training:	Epoch: [64][177/204]	Loss 0.0045 (0.0195)	
training:	Epoch: [64][178/204]	Loss 0.0048 (0.0195)	
training:	Epoch: [64][179/204]	Loss 0.0050 (0.0194)	
training:	Epoch: [64][180/204]	Loss 0.0894 (0.0198)	
training:	Epoch: [64][181/204]	Loss 0.0042 (0.0197)	
training:	Epoch: [64][182/204]	Loss 0.0045 (0.0196)	
training:	Epoch: [64][183/204]	Loss 0.0048 (0.0195)	
training:	Epoch: [64][184/204]	Loss 0.1300 (0.0201)	
training:	Epoch: [64][185/204]	Loss 0.0028 (0.0200)	
training:	Epoch: [64][186/204]	Loss 0.0037 (0.0199)	
training:	Epoch: [64][187/204]	Loss 0.0045 (0.0198)	
training:	Epoch: [64][188/204]	Loss 0.0037 (0.0198)	
training:	Epoch: [64][189/204]	Loss 0.0932 (0.0201)	
training:	Epoch: [64][190/204]	Loss 0.0041 (0.0201)	
training:	Epoch: [64][191/204]	Loss 0.1415 (0.0207)	
training:	Epoch: [64][192/204]	Loss 0.0038 (0.0206)	
training:	Epoch: [64][193/204]	Loss 0.0040 (0.0205)	
training:	Epoch: [64][194/204]	Loss 0.0033 (0.0204)	
training:	Epoch: [64][195/204]	Loss 0.0042 (0.0204)	
training:	Epoch: [64][196/204]	Loss 0.0725 (0.0206)	
training:	Epoch: [64][197/204]	Loss 0.0034 (0.0205)	
training:	Epoch: [64][198/204]	Loss 0.0050 (0.0205)	
training:	Epoch: [64][199/204]	Loss 0.1014 (0.0209)	
training:	Epoch: [64][200/204]	Loss 0.0036 (0.0208)	
training:	Epoch: [64][201/204]	Loss 0.0048 (0.0207)	
training:	Epoch: [64][202/204]	Loss 0.1370 (0.0213)	
training:	Epoch: [64][203/204]	Loss 0.0050 (0.0212)	
training:	Epoch: [64][204/204]	Loss 0.0056 (0.0211)	
Training:	 Loss: 0.0211

Training:	 ACC: 0.9963 0.9963 0.9976 0.9949
Validation:	 ACC: 0.7764 0.7780 0.8096 0.7433
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1188
Pretraining:	Epoch 65/500
----------
training:	Epoch: [65][1/204]	Loss 0.0041 (0.0041)	
training:	Epoch: [65][2/204]	Loss 0.0146 (0.0093)	
training:	Epoch: [65][3/204]	Loss 0.1387 (0.0524)	
training:	Epoch: [65][4/204]	Loss 0.0064 (0.0409)	
training:	Epoch: [65][5/204]	Loss 0.0068 (0.0341)	
training:	Epoch: [65][6/204]	Loss 0.0039 (0.0291)	
training:	Epoch: [65][7/204]	Loss 0.0052 (0.0257)	
training:	Epoch: [65][8/204]	Loss 0.0050 (0.0231)	
training:	Epoch: [65][9/204]	Loss 0.0070 (0.0213)	
training:	Epoch: [65][10/204]	Loss 0.0056 (0.0197)	
training:	Epoch: [65][11/204]	Loss 0.0067 (0.0185)	
training:	Epoch: [65][12/204]	Loss 0.0040 (0.0173)	
training:	Epoch: [65][13/204]	Loss 0.0062 (0.0165)	
training:	Epoch: [65][14/204]	Loss 0.1181 (0.0237)	
training:	Epoch: [65][15/204]	Loss 0.0101 (0.0228)	
training:	Epoch: [65][16/204]	Loss 0.0057 (0.0218)	
training:	Epoch: [65][17/204]	Loss 0.0063 (0.0208)	
training:	Epoch: [65][18/204]	Loss 0.0057 (0.0200)	
training:	Epoch: [65][19/204]	Loss 0.0054 (0.0192)	
training:	Epoch: [65][20/204]	Loss 0.0071 (0.0186)	
training:	Epoch: [65][21/204]	Loss 0.0036 (0.0179)	
training:	Epoch: [65][22/204]	Loss 0.0071 (0.0174)	
training:	Epoch: [65][23/204]	Loss 0.0052 (0.0169)	
training:	Epoch: [65][24/204]	Loss 0.0066 (0.0165)	
training:	Epoch: [65][25/204]	Loss 0.0040 (0.0160)	
training:	Epoch: [65][26/204]	Loss 0.0053 (0.0156)	
training:	Epoch: [65][27/204]	Loss 0.0056 (0.0152)	
training:	Epoch: [65][28/204]	Loss 0.0048 (0.0148)	
training:	Epoch: [65][29/204]	Loss 0.0054 (0.0145)	
training:	Epoch: [65][30/204]	Loss 0.0048 (0.0142)	
training:	Epoch: [65][31/204]	Loss 0.0043 (0.0139)	
training:	Epoch: [65][32/204]	Loss 0.0051 (0.0136)	
training:	Epoch: [65][33/204]	Loss 0.0054 (0.0133)	
training:	Epoch: [65][34/204]	Loss 0.0050 (0.0131)	
training:	Epoch: [65][35/204]	Loss 0.0044 (0.0128)	
training:	Epoch: [65][36/204]	Loss 0.0054 (0.0126)	
training:	Epoch: [65][37/204]	Loss 0.1044 (0.0151)	
training:	Epoch: [65][38/204]	Loss 0.0067 (0.0149)	
training:	Epoch: [65][39/204]	Loss 0.0199 (0.0150)	
training:	Epoch: [65][40/204]	Loss 0.0050 (0.0148)	
training:	Epoch: [65][41/204]	Loss 0.0040 (0.0145)	
training:	Epoch: [65][42/204]	Loss 0.0038 (0.0143)	
training:	Epoch: [65][43/204]	Loss 0.0043 (0.0140)	
training:	Epoch: [65][44/204]	Loss 0.0053 (0.0138)	
training:	Epoch: [65][45/204]	Loss 0.0048 (0.0136)	
training:	Epoch: [65][46/204]	Loss 0.0042 (0.0134)	
training:	Epoch: [65][47/204]	Loss 0.0056 (0.0132)	
training:	Epoch: [65][48/204]	Loss 0.0049 (0.0131)	
training:	Epoch: [65][49/204]	Loss 0.0039 (0.0129)	
training:	Epoch: [65][50/204]	Loss 0.0045 (0.0127)	
training:	Epoch: [65][51/204]	Loss 0.1384 (0.0152)	
training:	Epoch: [65][52/204]	Loss 0.2650 (0.0200)	
training:	Epoch: [65][53/204]	Loss 0.0034 (0.0197)	
training:	Epoch: [65][54/204]	Loss 0.0030 (0.0194)	
training:	Epoch: [65][55/204]	Loss 0.0057 (0.0191)	
training:	Epoch: [65][56/204]	Loss 0.0050 (0.0189)	
training:	Epoch: [65][57/204]	Loss 0.0044 (0.0186)	
training:	Epoch: [65][58/204]	Loss 0.0046 (0.0184)	
training:	Epoch: [65][59/204]	Loss 0.0049 (0.0181)	
training:	Epoch: [65][60/204]	Loss 0.0054 (0.0179)	
training:	Epoch: [65][61/204]	Loss 0.0050 (0.0177)	
training:	Epoch: [65][62/204]	Loss 0.0075 (0.0176)	
training:	Epoch: [65][63/204]	Loss 0.0042 (0.0173)	
training:	Epoch: [65][64/204]	Loss 0.0037 (0.0171)	
training:	Epoch: [65][65/204]	Loss 0.0066 (0.0170)	
training:	Epoch: [65][66/204]	Loss 0.0042 (0.0168)	
training:	Epoch: [65][67/204]	Loss 0.0056 (0.0166)	
training:	Epoch: [65][68/204]	Loss 0.0049 (0.0164)	
training:	Epoch: [65][69/204]	Loss 0.0075 (0.0163)	
training:	Epoch: [65][70/204]	Loss 0.0101 (0.0162)	
training:	Epoch: [65][71/204]	Loss 0.0255 (0.0163)	
training:	Epoch: [65][72/204]	Loss 0.0069 (0.0162)	
training:	Epoch: [65][73/204]	Loss 0.0035 (0.0160)	
training:	Epoch: [65][74/204]	Loss 0.0053 (0.0159)	
training:	Epoch: [65][75/204]	Loss 0.0066 (0.0158)	
training:	Epoch: [65][76/204]	Loss 0.0036 (0.0156)	
training:	Epoch: [65][77/204]	Loss 0.0038 (0.0155)	
training:	Epoch: [65][78/204]	Loss 0.0080 (0.0154)	
training:	Epoch: [65][79/204]	Loss 0.0051 (0.0152)	
training:	Epoch: [65][80/204]	Loss 0.0040 (0.0151)	
training:	Epoch: [65][81/204]	Loss 0.0053 (0.0150)	
training:	Epoch: [65][82/204]	Loss 0.1797 (0.0170)	
training:	Epoch: [65][83/204]	Loss 0.0057 (0.0168)	
training:	Epoch: [65][84/204]	Loss 0.0055 (0.0167)	
training:	Epoch: [65][85/204]	Loss 0.0062 (0.0166)	
training:	Epoch: [65][86/204]	Loss 0.0063 (0.0165)	
training:	Epoch: [65][87/204]	Loss 0.0053 (0.0163)	
training:	Epoch: [65][88/204]	Loss 0.0038 (0.0162)	
training:	Epoch: [65][89/204]	Loss 0.0032 (0.0160)	
training:	Epoch: [65][90/204]	Loss 0.0911 (0.0169)	
training:	Epoch: [65][91/204]	Loss 0.0043 (0.0167)	
training:	Epoch: [65][92/204]	Loss 0.0050 (0.0166)	
training:	Epoch: [65][93/204]	Loss 0.1031 (0.0175)	
training:	Epoch: [65][94/204]	Loss 0.1654 (0.0191)	
training:	Epoch: [65][95/204]	Loss 0.0040 (0.0190)	
training:	Epoch: [65][96/204]	Loss 0.0039 (0.0188)	
training:	Epoch: [65][97/204]	Loss 0.0047 (0.0187)	
training:	Epoch: [65][98/204]	Loss 0.0028 (0.0185)	
training:	Epoch: [65][99/204]	Loss 0.0055 (0.0184)	
training:	Epoch: [65][100/204]	Loss 0.0059 (0.0182)	
training:	Epoch: [65][101/204]	Loss 0.1513 (0.0196)	
training:	Epoch: [65][102/204]	Loss 0.0041 (0.0194)	
training:	Epoch: [65][103/204]	Loss 0.0031 (0.0192)	
training:	Epoch: [65][104/204]	Loss 0.0035 (0.0191)	
training:	Epoch: [65][105/204]	Loss 0.0040 (0.0190)	
training:	Epoch: [65][106/204]	Loss 0.0049 (0.0188)	
training:	Epoch: [65][107/204]	Loss 0.0047 (0.0187)	
training:	Epoch: [65][108/204]	Loss 0.0039 (0.0185)	
training:	Epoch: [65][109/204]	Loss 0.0054 (0.0184)	
training:	Epoch: [65][110/204]	Loss 0.0066 (0.0183)	
training:	Epoch: [65][111/204]	Loss 0.0709 (0.0188)	
training:	Epoch: [65][112/204]	Loss 0.0058 (0.0187)	
training:	Epoch: [65][113/204]	Loss 0.0050 (0.0186)	
training:	Epoch: [65][114/204]	Loss 0.0035 (0.0184)	
training:	Epoch: [65][115/204]	Loss 0.0038 (0.0183)	
training:	Epoch: [65][116/204]	Loss 0.0606 (0.0187)	
training:	Epoch: [65][117/204]	Loss 0.0058 (0.0186)	
training:	Epoch: [65][118/204]	Loss 0.0037 (0.0184)	
training:	Epoch: [65][119/204]	Loss 0.0034 (0.0183)	
training:	Epoch: [65][120/204]	Loss 0.0079 (0.0182)	
training:	Epoch: [65][121/204]	Loss 0.0031 (0.0181)	
training:	Epoch: [65][122/204]	Loss 0.0044 (0.0180)	
training:	Epoch: [65][123/204]	Loss 0.0045 (0.0179)	
training:	Epoch: [65][124/204]	Loss 0.0047 (0.0178)	
training:	Epoch: [65][125/204]	Loss 0.0053 (0.0177)	
training:	Epoch: [65][126/204]	Loss 0.0039 (0.0176)	
training:	Epoch: [65][127/204]	Loss 0.0034 (0.0174)	
training:	Epoch: [65][128/204]	Loss 0.0095 (0.0174)	
training:	Epoch: [65][129/204]	Loss 0.0044 (0.0173)	
training:	Epoch: [65][130/204]	Loss 0.0066 (0.0172)	
training:	Epoch: [65][131/204]	Loss 0.0044 (0.0171)	
training:	Epoch: [65][132/204]	Loss 0.0061 (0.0170)	
training:	Epoch: [65][133/204]	Loss 0.0063 (0.0169)	
training:	Epoch: [65][134/204]	Loss 0.1136 (0.0177)	
training:	Epoch: [65][135/204]	Loss 0.0049 (0.0176)	
training:	Epoch: [65][136/204]	Loss 0.0034 (0.0175)	
training:	Epoch: [65][137/204]	Loss 0.0043 (0.0174)	
training:	Epoch: [65][138/204]	Loss 0.0064 (0.0173)	
training:	Epoch: [65][139/204]	Loss 0.0241 (0.0173)	
training:	Epoch: [65][140/204]	Loss 0.0065 (0.0173)	
training:	Epoch: [65][141/204]	Loss 0.0034 (0.0172)	
training:	Epoch: [65][142/204]	Loss 0.0066 (0.0171)	
training:	Epoch: [65][143/204]	Loss 0.0046 (0.0170)	
training:	Epoch: [65][144/204]	Loss 0.0042 (0.0169)	
training:	Epoch: [65][145/204]	Loss 0.0046 (0.0168)	
training:	Epoch: [65][146/204]	Loss 0.0037 (0.0167)	
training:	Epoch: [65][147/204]	Loss 0.0051 (0.0166)	
training:	Epoch: [65][148/204]	Loss 0.0060 (0.0166)	
training:	Epoch: [65][149/204]	Loss 0.0037 (0.0165)	
training:	Epoch: [65][150/204]	Loss 0.1085 (0.0171)	
training:	Epoch: [65][151/204]	Loss 0.0030 (0.0170)	
training:	Epoch: [65][152/204]	Loss 0.1039 (0.0176)	
training:	Epoch: [65][153/204]	Loss 0.0059 (0.0175)	
training:	Epoch: [65][154/204]	Loss 0.0044 (0.0174)	
training:	Epoch: [65][155/204]	Loss 0.1358 (0.0182)	
training:	Epoch: [65][156/204]	Loss 0.0058 (0.0181)	
training:	Epoch: [65][157/204]	Loss 0.1486 (0.0189)	
training:	Epoch: [65][158/204]	Loss 0.0042 (0.0188)	
training:	Epoch: [65][159/204]	Loss 0.0042 (0.0188)	
training:	Epoch: [65][160/204]	Loss 0.0048 (0.0187)	
training:	Epoch: [65][161/204]	Loss 0.0053 (0.0186)	
training:	Epoch: [65][162/204]	Loss 0.0102 (0.0185)	
training:	Epoch: [65][163/204]	Loss 0.0042 (0.0184)	
training:	Epoch: [65][164/204]	Loss 0.1051 (0.0190)	
training:	Epoch: [65][165/204]	Loss 0.0049 (0.0189)	
training:	Epoch: [65][166/204]	Loss 0.0059 (0.0188)	
training:	Epoch: [65][167/204]	Loss 0.0067 (0.0187)	
training:	Epoch: [65][168/204]	Loss 0.0099 (0.0187)	
training:	Epoch: [65][169/204]	Loss 0.1144 (0.0192)	
training:	Epoch: [65][170/204]	Loss 0.0048 (0.0192)	
training:	Epoch: [65][171/204]	Loss 0.0101 (0.0191)	
training:	Epoch: [65][172/204]	Loss 0.0076 (0.0190)	
training:	Epoch: [65][173/204]	Loss 0.0061 (0.0190)	
training:	Epoch: [65][174/204]	Loss 0.0037 (0.0189)	
training:	Epoch: [65][175/204]	Loss 0.0099 (0.0188)	
training:	Epoch: [65][176/204]	Loss 0.0074 (0.0188)	
training:	Epoch: [65][177/204]	Loss 0.0061 (0.0187)	
training:	Epoch: [65][178/204]	Loss 0.0061 (0.0186)	
training:	Epoch: [65][179/204]	Loss 0.0191 (0.0186)	
training:	Epoch: [65][180/204]	Loss 0.0067 (0.0186)	
training:	Epoch: [65][181/204]	Loss 0.0040 (0.0185)	
training:	Epoch: [65][182/204]	Loss 0.0041 (0.0184)	
training:	Epoch: [65][183/204]	Loss 0.0069 (0.0183)	
training:	Epoch: [65][184/204]	Loss 0.0058 (0.0183)	
training:	Epoch: [65][185/204]	Loss 0.1667 (0.0191)	
training:	Epoch: [65][186/204]	Loss 0.0073 (0.0190)	
training:	Epoch: [65][187/204]	Loss 0.0068 (0.0189)	
training:	Epoch: [65][188/204]	Loss 0.0083 (0.0189)	
training:	Epoch: [65][189/204]	Loss 0.0046 (0.0188)	
training:	Epoch: [65][190/204]	Loss 0.0043 (0.0187)	
training:	Epoch: [65][191/204]	Loss 0.0058 (0.0187)	
training:	Epoch: [65][192/204]	Loss 0.0074 (0.0186)	
training:	Epoch: [65][193/204]	Loss 0.0037 (0.0185)	
training:	Epoch: [65][194/204]	Loss 0.0655 (0.0188)	
training:	Epoch: [65][195/204]	Loss 0.0815 (0.0191)	
training:	Epoch: [65][196/204]	Loss 0.0031 (0.0190)	
training:	Epoch: [65][197/204]	Loss 0.0049 (0.0189)	
training:	Epoch: [65][198/204]	Loss 0.0051 (0.0189)	
training:	Epoch: [65][199/204]	Loss 0.0922 (0.0192)	
training:	Epoch: [65][200/204]	Loss 0.0040 (0.0192)	
training:	Epoch: [65][201/204]	Loss 0.0042 (0.0191)	
training:	Epoch: [65][202/204]	Loss 0.0073 (0.0190)	
training:	Epoch: [65][203/204]	Loss 0.0042 (0.0190)	
training:	Epoch: [65][204/204]	Loss 0.0052 (0.0189)	
Training:	 Loss: 0.0189

Training:	 ACC: 0.9963 0.9963 0.9976 0.9949
Validation:	 ACC: 0.7743 0.7753 0.7953 0.7534
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1285
Pretraining:	Epoch 66/500
----------
training:	Epoch: [66][1/204]	Loss 0.0072 (0.0072)	
training:	Epoch: [66][2/204]	Loss 0.0052 (0.0062)	
training:	Epoch: [66][3/204]	Loss 0.1019 (0.0381)	
training:	Epoch: [66][4/204]	Loss 0.1592 (0.0684)	
training:	Epoch: [66][5/204]	Loss 0.0060 (0.0559)	
training:	Epoch: [66][6/204]	Loss 0.0078 (0.0479)	
training:	Epoch: [66][7/204]	Loss 0.0038 (0.0416)	
training:	Epoch: [66][8/204]	Loss 0.0074 (0.0373)	
training:	Epoch: [66][9/204]	Loss 0.0049 (0.0337)	
training:	Epoch: [66][10/204]	Loss 0.0060 (0.0310)	
training:	Epoch: [66][11/204]	Loss 0.0072 (0.0288)	
training:	Epoch: [66][12/204]	Loss 0.0045 (0.0268)	
training:	Epoch: [66][13/204]	Loss 0.2318 (0.0425)	
training:	Epoch: [66][14/204]	Loss 0.0054 (0.0399)	
training:	Epoch: [66][15/204]	Loss 0.0064 (0.0377)	
training:	Epoch: [66][16/204]	Loss 0.0065 (0.0357)	
training:	Epoch: [66][17/204]	Loss 0.0050 (0.0339)	
training:	Epoch: [66][18/204]	Loss 0.0030 (0.0322)	
training:	Epoch: [66][19/204]	Loss 0.0040 (0.0307)	
training:	Epoch: [66][20/204]	Loss 0.0972 (0.0340)	
training:	Epoch: [66][21/204]	Loss 0.0085 (0.0328)	
training:	Epoch: [66][22/204]	Loss 0.0077 (0.0317)	
training:	Epoch: [66][23/204]	Loss 0.0062 (0.0306)	
training:	Epoch: [66][24/204]	Loss 0.0091 (0.0297)	
training:	Epoch: [66][25/204]	Loss 0.0068 (0.0288)	
training:	Epoch: [66][26/204]	Loss 0.0038 (0.0278)	
training:	Epoch: [66][27/204]	Loss 0.0110 (0.0272)	
training:	Epoch: [66][28/204]	Loss 0.0066 (0.0264)	
training:	Epoch: [66][29/204]	Loss 0.0064 (0.0257)	
training:	Epoch: [66][30/204]	Loss 0.0038 (0.0250)	
training:	Epoch: [66][31/204]	Loss 0.0758 (0.0266)	
training:	Epoch: [66][32/204]	Loss 0.0102 (0.0261)	
training:	Epoch: [66][33/204]	Loss 0.0043 (0.0255)	
training:	Epoch: [66][34/204]	Loss 0.1784 (0.0300)	
training:	Epoch: [66][35/204]	Loss 0.0077 (0.0293)	
training:	Epoch: [66][36/204]	Loss 0.0776 (0.0307)	
training:	Epoch: [66][37/204]	Loss 0.0041 (0.0300)	
training:	Epoch: [66][38/204]	Loss 0.1626 (0.0334)	
training:	Epoch: [66][39/204]	Loss 0.0041 (0.0327)	
training:	Epoch: [66][40/204]	Loss 0.0994 (0.0344)	
training:	Epoch: [66][41/204]	Loss 0.0063 (0.0337)	
training:	Epoch: [66][42/204]	Loss 0.0058 (0.0330)	
training:	Epoch: [66][43/204]	Loss 0.0050 (0.0324)	
training:	Epoch: [66][44/204]	Loss 0.0069 (0.0318)	
training:	Epoch: [66][45/204]	Loss 0.0091 (0.0313)	
training:	Epoch: [66][46/204]	Loss 0.0073 (0.0308)	
training:	Epoch: [66][47/204]	Loss 0.0031 (0.0302)	
training:	Epoch: [66][48/204]	Loss 0.0082 (0.0297)	
training:	Epoch: [66][49/204]	Loss 0.0078 (0.0293)	
training:	Epoch: [66][50/204]	Loss 0.0107 (0.0289)	
training:	Epoch: [66][51/204]	Loss 0.0033 (0.0284)	
training:	Epoch: [66][52/204]	Loss 0.0042 (0.0279)	
training:	Epoch: [66][53/204]	Loss 0.0044 (0.0275)	
training:	Epoch: [66][54/204]	Loss 0.0052 (0.0271)	
training:	Epoch: [66][55/204]	Loss 0.0079 (0.0267)	
training:	Epoch: [66][56/204]	Loss 0.0132 (0.0265)	
training:	Epoch: [66][57/204]	Loss 0.0064 (0.0261)	
training:	Epoch: [66][58/204]	Loss 0.0070 (0.0258)	
training:	Epoch: [66][59/204]	Loss 0.0048 (0.0254)	
training:	Epoch: [66][60/204]	Loss 0.0672 (0.0261)	
training:	Epoch: [66][61/204]	Loss 0.0034 (0.0258)	
training:	Epoch: [66][62/204]	Loss 0.0455 (0.0261)	
training:	Epoch: [66][63/204]	Loss 0.0061 (0.0258)	
training:	Epoch: [66][64/204]	Loss 0.0052 (0.0254)	
training:	Epoch: [66][65/204]	Loss 0.0034 (0.0251)	
training:	Epoch: [66][66/204]	Loss 0.0080 (0.0248)	
training:	Epoch: [66][67/204]	Loss 0.0034 (0.0245)	
training:	Epoch: [66][68/204]	Loss 0.0032 (0.0242)	
training:	Epoch: [66][69/204]	Loss 0.0030 (0.0239)	
training:	Epoch: [66][70/204]	Loss 0.0061 (0.0237)	
training:	Epoch: [66][71/204]	Loss 0.0047 (0.0234)	
training:	Epoch: [66][72/204]	Loss 0.0069 (0.0232)	
training:	Epoch: [66][73/204]	Loss 0.0039 (0.0229)	
training:	Epoch: [66][74/204]	Loss 0.0040 (0.0226)	
training:	Epoch: [66][75/204]	Loss 0.1676 (0.0246)	
training:	Epoch: [66][76/204]	Loss 0.0061 (0.0243)	
training:	Epoch: [66][77/204]	Loss 0.0061 (0.0241)	
training:	Epoch: [66][78/204]	Loss 0.1197 (0.0253)	
training:	Epoch: [66][79/204]	Loss 0.0044 (0.0251)	
training:	Epoch: [66][80/204]	Loss 0.0080 (0.0248)	
training:	Epoch: [66][81/204]	Loss 0.0066 (0.0246)	
training:	Epoch: [66][82/204]	Loss 0.0042 (0.0244)	
training:	Epoch: [66][83/204]	Loss 0.0823 (0.0251)	
training:	Epoch: [66][84/204]	Loss 0.0069 (0.0248)	
training:	Epoch: [66][85/204]	Loss 0.0064 (0.0246)	
training:	Epoch: [66][86/204]	Loss 0.0045 (0.0244)	
training:	Epoch: [66][87/204]	Loss 0.0045 (0.0242)	
training:	Epoch: [66][88/204]	Loss 0.0081 (0.0240)	
training:	Epoch: [66][89/204]	Loss 0.0317 (0.0241)	
training:	Epoch: [66][90/204]	Loss 0.0043 (0.0239)	
training:	Epoch: [66][91/204]	Loss 0.0052 (0.0236)	
training:	Epoch: [66][92/204]	Loss 0.0056 (0.0235)	
training:	Epoch: [66][93/204]	Loss 0.0097 (0.0233)	
training:	Epoch: [66][94/204]	Loss 0.0036 (0.0231)	
training:	Epoch: [66][95/204]	Loss 0.0166 (0.0230)	
training:	Epoch: [66][96/204]	Loss 0.0044 (0.0228)	
training:	Epoch: [66][97/204]	Loss 0.0106 (0.0227)	
training:	Epoch: [66][98/204]	Loss 0.0234 (0.0227)	
training:	Epoch: [66][99/204]	Loss 0.0042 (0.0225)	
training:	Epoch: [66][100/204]	Loss 0.0030 (0.0223)	
training:	Epoch: [66][101/204]	Loss 0.0429 (0.0225)	
training:	Epoch: [66][102/204]	Loss 0.0035 (0.0223)	
training:	Epoch: [66][103/204]	Loss 0.0964 (0.0231)	
training:	Epoch: [66][104/204]	Loss 0.0046 (0.0229)	
training:	Epoch: [66][105/204]	Loss 0.0053 (0.0227)	
training:	Epoch: [66][106/204]	Loss 0.0145 (0.0226)	
training:	Epoch: [66][107/204]	Loss 0.0061 (0.0225)	
training:	Epoch: [66][108/204]	Loss 0.0873 (0.0231)	
training:	Epoch: [66][109/204]	Loss 0.0074 (0.0229)	
training:	Epoch: [66][110/204]	Loss 0.0047 (0.0228)	
training:	Epoch: [66][111/204]	Loss 0.0060 (0.0226)	
training:	Epoch: [66][112/204]	Loss 0.0104 (0.0225)	
training:	Epoch: [66][113/204]	Loss 0.1263 (0.0234)	
training:	Epoch: [66][114/204]	Loss 0.0035 (0.0233)	
training:	Epoch: [66][115/204]	Loss 0.0063 (0.0231)	
training:	Epoch: [66][116/204]	Loss 0.0066 (0.0230)	
training:	Epoch: [66][117/204]	Loss 0.0077 (0.0228)	
training:	Epoch: [66][118/204]	Loss 0.0028 (0.0227)	
training:	Epoch: [66][119/204]	Loss 0.0054 (0.0225)	
training:	Epoch: [66][120/204]	Loss 0.0058 (0.0224)	
training:	Epoch: [66][121/204]	Loss 0.0038 (0.0222)	
training:	Epoch: [66][122/204]	Loss 0.0059 (0.0221)	
training:	Epoch: [66][123/204]	Loss 0.0084 (0.0220)	
training:	Epoch: [66][124/204]	Loss 0.0250 (0.0220)	
training:	Epoch: [66][125/204]	Loss 0.0117 (0.0219)	
training:	Epoch: [66][126/204]	Loss 0.0037 (0.0218)	
training:	Epoch: [66][127/204]	Loss 0.0040 (0.0216)	
training:	Epoch: [66][128/204]	Loss 0.0058 (0.0215)	
training:	Epoch: [66][129/204]	Loss 0.0053 (0.0214)	
training:	Epoch: [66][130/204]	Loss 0.0048 (0.0213)	
training:	Epoch: [66][131/204]	Loss 0.0030 (0.0211)	
training:	Epoch: [66][132/204]	Loss 0.0056 (0.0210)	
training:	Epoch: [66][133/204]	Loss 0.1417 (0.0219)	
training:	Epoch: [66][134/204]	Loss 0.0047 (0.0218)	
training:	Epoch: [66][135/204]	Loss 0.0052 (0.0217)	
training:	Epoch: [66][136/204]	Loss 0.0035 (0.0215)	
training:	Epoch: [66][137/204]	Loss 0.0035 (0.0214)	
training:	Epoch: [66][138/204]	Loss 0.0184 (0.0214)	
training:	Epoch: [66][139/204]	Loss 0.0032 (0.0212)	
training:	Epoch: [66][140/204]	Loss 0.0053 (0.0211)	
training:	Epoch: [66][141/204]	Loss 0.0065 (0.0210)	
training:	Epoch: [66][142/204]	Loss 0.0046 (0.0209)	
training:	Epoch: [66][143/204]	Loss 0.0033 (0.0208)	
training:	Epoch: [66][144/204]	Loss 0.0075 (0.0207)	
training:	Epoch: [66][145/204]	Loss 0.0033 (0.0206)	
training:	Epoch: [66][146/204]	Loss 0.0052 (0.0205)	
training:	Epoch: [66][147/204]	Loss 0.0094 (0.0204)	
training:	Epoch: [66][148/204]	Loss 0.0039 (0.0203)	
training:	Epoch: [66][149/204]	Loss 0.0044 (0.0202)	
training:	Epoch: [66][150/204]	Loss 0.0058 (0.0201)	
training:	Epoch: [66][151/204]	Loss 0.0054 (0.0200)	
training:	Epoch: [66][152/204]	Loss 0.0037 (0.0199)	
training:	Epoch: [66][153/204]	Loss 0.0049 (0.0198)	
training:	Epoch: [66][154/204]	Loss 0.0038 (0.0197)	
training:	Epoch: [66][155/204]	Loss 0.0042 (0.0196)	
training:	Epoch: [66][156/204]	Loss 0.0033 (0.0195)	
training:	Epoch: [66][157/204]	Loss 0.0054 (0.0194)	
training:	Epoch: [66][158/204]	Loss 0.0056 (0.0193)	
training:	Epoch: [66][159/204]	Loss 0.0049 (0.0192)	
training:	Epoch: [66][160/204]	Loss 0.0041 (0.0191)	
training:	Epoch: [66][161/204]	Loss 0.0049 (0.0190)	
training:	Epoch: [66][162/204]	Loss 0.0034 (0.0189)	
training:	Epoch: [66][163/204]	Loss 0.0025 (0.0188)	
training:	Epoch: [66][164/204]	Loss 0.0063 (0.0188)	
training:	Epoch: [66][165/204]	Loss 0.0047 (0.0187)	
training:	Epoch: [66][166/204]	Loss 0.0038 (0.0186)	
training:	Epoch: [66][167/204]	Loss 0.0043 (0.0185)	
training:	Epoch: [66][168/204]	Loss 0.0031 (0.0184)	
training:	Epoch: [66][169/204]	Loss 0.0030 (0.0183)	
training:	Epoch: [66][170/204]	Loss 0.0037 (0.0182)	
training:	Epoch: [66][171/204]	Loss 0.1129 (0.0188)	
training:	Epoch: [66][172/204]	Loss 0.0029 (0.0187)	
training:	Epoch: [66][173/204]	Loss 0.0053 (0.0186)	
training:	Epoch: [66][174/204]	Loss 0.0064 (0.0185)	
training:	Epoch: [66][175/204]	Loss 0.0050 (0.0185)	
training:	Epoch: [66][176/204]	Loss 0.0047 (0.0184)	
training:	Epoch: [66][177/204]	Loss 0.0057 (0.0183)	
training:	Epoch: [66][178/204]	Loss 0.0029 (0.0182)	
training:	Epoch: [66][179/204]	Loss 0.0040 (0.0181)	
training:	Epoch: [66][180/204]	Loss 0.0627 (0.0184)	
training:	Epoch: [66][181/204]	Loss 0.0177 (0.0184)	
training:	Epoch: [66][182/204]	Loss 0.0032 (0.0183)	
training:	Epoch: [66][183/204]	Loss 0.0030 (0.0182)	
training:	Epoch: [66][184/204]	Loss 0.0034 (0.0181)	
training:	Epoch: [66][185/204]	Loss 0.0038 (0.0181)	
training:	Epoch: [66][186/204]	Loss 0.0043 (0.0180)	
training:	Epoch: [66][187/204]	Loss 0.0052 (0.0179)	
training:	Epoch: [66][188/204]	Loss 0.0058 (0.0179)	
training:	Epoch: [66][189/204]	Loss 0.0032 (0.0178)	
training:	Epoch: [66][190/204]	Loss 0.0053 (0.0177)	
training:	Epoch: [66][191/204]	Loss 0.0095 (0.0177)	
training:	Epoch: [66][192/204]	Loss 0.0068 (0.0176)	
training:	Epoch: [66][193/204]	Loss 0.0047 (0.0175)	
training:	Epoch: [66][194/204]	Loss 0.0038 (0.0175)	
training:	Epoch: [66][195/204]	Loss 0.0036 (0.0174)	
training:	Epoch: [66][196/204]	Loss 0.0039 (0.0173)	
training:	Epoch: [66][197/204]	Loss 0.0057 (0.0173)	
training:	Epoch: [66][198/204]	Loss 0.0031 (0.0172)	
training:	Epoch: [66][199/204]	Loss 0.0551 (0.0174)	
training:	Epoch: [66][200/204]	Loss 0.0048 (0.0173)	
training:	Epoch: [66][201/204]	Loss 0.0838 (0.0177)	
training:	Epoch: [66][202/204]	Loss 0.0051 (0.0176)	
training:	Epoch: [66][203/204]	Loss 0.1471 (0.0182)	
training:	Epoch: [66][204/204]	Loss 0.0042 (0.0182)	
Training:	 Loss: 0.0181

Training:	 ACC: 0.9960 0.9960 0.9971 0.9949
Validation:	 ACC: 0.7762 0.7747 0.7451 0.8072
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1320
Pretraining:	Epoch 67/500
----------
training:	Epoch: [67][1/204]	Loss 0.0036 (0.0036)	
training:	Epoch: [67][2/204]	Loss 0.0055 (0.0046)	
training:	Epoch: [67][3/204]	Loss 0.0040 (0.0044)	
training:	Epoch: [67][4/204]	Loss 0.0997 (0.0282)	
training:	Epoch: [67][5/204]	Loss 0.0173 (0.0260)	
training:	Epoch: [67][6/204]	Loss 0.2292 (0.0599)	
training:	Epoch: [67][7/204]	Loss 0.0035 (0.0519)	
training:	Epoch: [67][8/204]	Loss 0.0040 (0.0459)	
training:	Epoch: [67][9/204]	Loss 0.0445 (0.0457)	
training:	Epoch: [67][10/204]	Loss 0.0037 (0.0415)	
training:	Epoch: [67][11/204]	Loss 0.1566 (0.0520)	
training:	Epoch: [67][12/204]	Loss 0.0064 (0.0482)	
training:	Epoch: [67][13/204]	Loss 0.0056 (0.0449)	
training:	Epoch: [67][14/204]	Loss 0.0111 (0.0425)	
training:	Epoch: [67][15/204]	Loss 0.0365 (0.0421)	
training:	Epoch: [67][16/204]	Loss 0.0031 (0.0396)	
training:	Epoch: [67][17/204]	Loss 0.0487 (0.0402)	
training:	Epoch: [67][18/204]	Loss 0.0048 (0.0382)	
training:	Epoch: [67][19/204]	Loss 0.0445 (0.0385)	
training:	Epoch: [67][20/204]	Loss 0.0147 (0.0374)	
training:	Epoch: [67][21/204]	Loss 0.0438 (0.0377)	
training:	Epoch: [67][22/204]	Loss 0.0062 (0.0362)	
training:	Epoch: [67][23/204]	Loss 0.0051 (0.0349)	
training:	Epoch: [67][24/204]	Loss 0.0055 (0.0337)	
training:	Epoch: [67][25/204]	Loss 0.0198 (0.0331)	
training:	Epoch: [67][26/204]	Loss 0.0149 (0.0324)	
training:	Epoch: [67][27/204]	Loss 0.0042 (0.0314)	
training:	Epoch: [67][28/204]	Loss 0.0049 (0.0304)	
training:	Epoch: [67][29/204]	Loss 0.0063 (0.0296)	
training:	Epoch: [67][30/204]	Loss 0.0046 (0.0287)	
training:	Epoch: [67][31/204]	Loss 0.0036 (0.0279)	
training:	Epoch: [67][32/204]	Loss 0.0075 (0.0273)	
training:	Epoch: [67][33/204]	Loss 0.0038 (0.0266)	
training:	Epoch: [67][34/204]	Loss 0.0037 (0.0259)	
training:	Epoch: [67][35/204]	Loss 0.0087 (0.0254)	
training:	Epoch: [67][36/204]	Loss 0.0037 (0.0248)	
training:	Epoch: [67][37/204]	Loss 0.0338 (0.0251)	
training:	Epoch: [67][38/204]	Loss 0.0065 (0.0246)	
training:	Epoch: [67][39/204]	Loss 0.0498 (0.0252)	
training:	Epoch: [67][40/204]	Loss 0.0077 (0.0248)	
training:	Epoch: [67][41/204]	Loss 0.0058 (0.0243)	
training:	Epoch: [67][42/204]	Loss 0.0099 (0.0240)	
training:	Epoch: [67][43/204]	Loss 0.0057 (0.0235)	
training:	Epoch: [67][44/204]	Loss 0.0132 (0.0233)	
training:	Epoch: [67][45/204]	Loss 0.0068 (0.0229)	
training:	Epoch: [67][46/204]	Loss 0.0875 (0.0243)	
training:	Epoch: [67][47/204]	Loss 0.2949 (0.0301)	
training:	Epoch: [67][48/204]	Loss 0.0129 (0.0297)	
training:	Epoch: [67][49/204]	Loss 0.0087 (0.0293)	
training:	Epoch: [67][50/204]	Loss 0.1728 (0.0322)	
training:	Epoch: [67][51/204]	Loss 0.0050 (0.0317)	
training:	Epoch: [67][52/204]	Loss 0.0034 (0.0311)	
training:	Epoch: [67][53/204]	Loss 0.0036 (0.0306)	
training:	Epoch: [67][54/204]	Loss 0.0037 (0.0301)	
training:	Epoch: [67][55/204]	Loss 0.0039 (0.0296)	
training:	Epoch: [67][56/204]	Loss 0.0043 (0.0292)	
training:	Epoch: [67][57/204]	Loss 0.0790 (0.0300)	
training:	Epoch: [67][58/204]	Loss 0.0056 (0.0296)	
training:	Epoch: [67][59/204]	Loss 0.0116 (0.0293)	
training:	Epoch: [67][60/204]	Loss 0.0059 (0.0289)	
training:	Epoch: [67][61/204]	Loss 0.1283 (0.0306)	
training:	Epoch: [67][62/204]	Loss 0.0041 (0.0301)	
training:	Epoch: [67][63/204]	Loss 0.0090 (0.0298)	
training:	Epoch: [67][64/204]	Loss 0.0665 (0.0304)	
training:	Epoch: [67][65/204]	Loss 0.0044 (0.0300)	
training:	Epoch: [67][66/204]	Loss 0.0065 (0.0296)	
training:	Epoch: [67][67/204]	Loss 0.0047 (0.0292)	
training:	Epoch: [67][68/204]	Loss 0.0048 (0.0289)	
training:	Epoch: [67][69/204]	Loss 0.0039 (0.0285)	
training:	Epoch: [67][70/204]	Loss 0.0618 (0.0290)	
training:	Epoch: [67][71/204]	Loss 0.0058 (0.0287)	
training:	Epoch: [67][72/204]	Loss 0.0654 (0.0292)	
training:	Epoch: [67][73/204]	Loss 0.0049 (0.0288)	
training:	Epoch: [67][74/204]	Loss 0.0161 (0.0287)	
training:	Epoch: [67][75/204]	Loss 0.1259 (0.0300)	
training:	Epoch: [67][76/204]	Loss 0.0125 (0.0297)	
training:	Epoch: [67][77/204]	Loss 0.0062 (0.0294)	
training:	Epoch: [67][78/204]	Loss 0.0064 (0.0291)	
training:	Epoch: [67][79/204]	Loss 0.0133 (0.0289)	
training:	Epoch: [67][80/204]	Loss 0.0952 (0.0298)	
training:	Epoch: [67][81/204]	Loss 0.0040 (0.0294)	
training:	Epoch: [67][82/204]	Loss 0.0066 (0.0292)	
training:	Epoch: [67][83/204]	Loss 0.0107 (0.0289)	
training:	Epoch: [67][84/204]	Loss 0.0048 (0.0287)	
training:	Epoch: [67][85/204]	Loss 0.0051 (0.0284)	
training:	Epoch: [67][86/204]	Loss 0.0034 (0.0281)	
training:	Epoch: [67][87/204]	Loss 0.1807 (0.0298)	
training:	Epoch: [67][88/204]	Loss 0.0037 (0.0295)	
training:	Epoch: [67][89/204]	Loss 0.0434 (0.0297)	
training:	Epoch: [67][90/204]	Loss 0.0078 (0.0295)	
training:	Epoch: [67][91/204]	Loss 0.0061 (0.0292)	
training:	Epoch: [67][92/204]	Loss 0.1945 (0.0310)	
training:	Epoch: [67][93/204]	Loss 0.0074 (0.0307)	
training:	Epoch: [67][94/204]	Loss 0.0067 (0.0305)	
training:	Epoch: [67][95/204]	Loss 0.1136 (0.0314)	
training:	Epoch: [67][96/204]	Loss 0.0099 (0.0311)	
training:	Epoch: [67][97/204]	Loss 0.0040 (0.0309)	
training:	Epoch: [67][98/204]	Loss 0.0028 (0.0306)	
training:	Epoch: [67][99/204]	Loss 0.0045 (0.0303)	
training:	Epoch: [67][100/204]	Loss 0.0067 (0.0301)	
training:	Epoch: [67][101/204]	Loss 0.0030 (0.0298)	
training:	Epoch: [67][102/204]	Loss 0.0059 (0.0296)	
training:	Epoch: [67][103/204]	Loss 0.0066 (0.0293)	
training:	Epoch: [67][104/204]	Loss 0.0098 (0.0292)	
training:	Epoch: [67][105/204]	Loss 0.0055 (0.0289)	
training:	Epoch: [67][106/204]	Loss 0.0065 (0.0287)	
training:	Epoch: [67][107/204]	Loss 0.0052 (0.0285)	
training:	Epoch: [67][108/204]	Loss 0.0071 (0.0283)	
training:	Epoch: [67][109/204]	Loss 0.0737 (0.0287)	
training:	Epoch: [67][110/204]	Loss 0.1071 (0.0294)	
training:	Epoch: [67][111/204]	Loss 0.0078 (0.0292)	
training:	Epoch: [67][112/204]	Loss 0.0084 (0.0291)	
training:	Epoch: [67][113/204]	Loss 0.0028 (0.0288)	
training:	Epoch: [67][114/204]	Loss 0.0302 (0.0288)	
training:	Epoch: [67][115/204]	Loss 0.0042 (0.0286)	
training:	Epoch: [67][116/204]	Loss 0.0411 (0.0287)	
training:	Epoch: [67][117/204]	Loss 0.0038 (0.0285)	
training:	Epoch: [67][118/204]	Loss 0.0038 (0.0283)	
training:	Epoch: [67][119/204]	Loss 0.0106 (0.0282)	
training:	Epoch: [67][120/204]	Loss 0.0046 (0.0280)	
training:	Epoch: [67][121/204]	Loss 0.0086 (0.0278)	
training:	Epoch: [67][122/204]	Loss 0.0035 (0.0276)	
training:	Epoch: [67][123/204]	Loss 0.0061 (0.0274)	
training:	Epoch: [67][124/204]	Loss 0.0310 (0.0275)	
training:	Epoch: [67][125/204]	Loss 0.0828 (0.0279)	
training:	Epoch: [67][126/204]	Loss 0.0048 (0.0277)	
training:	Epoch: [67][127/204]	Loss 0.0097 (0.0276)	
training:	Epoch: [67][128/204]	Loss 0.0039 (0.0274)	
training:	Epoch: [67][129/204]	Loss 0.0048 (0.0272)	
training:	Epoch: [67][130/204]	Loss 0.0038 (0.0270)	
training:	Epoch: [67][131/204]	Loss 0.0053 (0.0269)	
training:	Epoch: [67][132/204]	Loss 0.0697 (0.0272)	
training:	Epoch: [67][133/204]	Loss 0.0053 (0.0270)	
training:	Epoch: [67][134/204]	Loss 0.0052 (0.0269)	
training:	Epoch: [67][135/204]	Loss 0.0057 (0.0267)	
training:	Epoch: [67][136/204]	Loss 0.0101 (0.0266)	
training:	Epoch: [67][137/204]	Loss 0.0063 (0.0264)	
training:	Epoch: [67][138/204]	Loss 0.0029 (0.0263)	
training:	Epoch: [67][139/204]	Loss 0.0050 (0.0261)	
training:	Epoch: [67][140/204]	Loss 0.0044 (0.0260)	
training:	Epoch: [67][141/204]	Loss 0.0038 (0.0258)	
training:	Epoch: [67][142/204]	Loss 0.0043 (0.0256)	
training:	Epoch: [67][143/204]	Loss 0.0035 (0.0255)	
training:	Epoch: [67][144/204]	Loss 0.0031 (0.0253)	
training:	Epoch: [67][145/204]	Loss 0.0032 (0.0252)	
training:	Epoch: [67][146/204]	Loss 0.0041 (0.0250)	
training:	Epoch: [67][147/204]	Loss 0.0161 (0.0250)	
training:	Epoch: [67][148/204]	Loss 0.0041 (0.0248)	
training:	Epoch: [67][149/204]	Loss 0.0039 (0.0247)	
training:	Epoch: [67][150/204]	Loss 0.1402 (0.0255)	
training:	Epoch: [67][151/204]	Loss 0.0068 (0.0253)	
training:	Epoch: [67][152/204]	Loss 0.0033 (0.0252)	
training:	Epoch: [67][153/204]	Loss 0.0034 (0.0251)	
training:	Epoch: [67][154/204]	Loss 0.0042 (0.0249)	
training:	Epoch: [67][155/204]	Loss 0.0124 (0.0248)	
training:	Epoch: [67][156/204]	Loss 0.0035 (0.0247)	
training:	Epoch: [67][157/204]	Loss 0.0058 (0.0246)	
training:	Epoch: [67][158/204]	Loss 0.0041 (0.0245)	
training:	Epoch: [67][159/204]	Loss 0.0059 (0.0243)	
training:	Epoch: [67][160/204]	Loss 0.0027 (0.0242)	
training:	Epoch: [67][161/204]	Loss 0.0129 (0.0241)	
training:	Epoch: [67][162/204]	Loss 0.0042 (0.0240)	
training:	Epoch: [67][163/204]	Loss 0.0038 (0.0239)	
training:	Epoch: [67][164/204]	Loss 0.0053 (0.0238)	
training:	Epoch: [67][165/204]	Loss 0.0055 (0.0237)	
training:	Epoch: [67][166/204]	Loss 0.0043 (0.0235)	
training:	Epoch: [67][167/204]	Loss 0.0110 (0.0235)	
training:	Epoch: [67][168/204]	Loss 0.1639 (0.0243)	
training:	Epoch: [67][169/204]	Loss 0.0030 (0.0242)	
training:	Epoch: [67][170/204]	Loss 0.0043 (0.0241)	
training:	Epoch: [67][171/204]	Loss 0.0032 (0.0239)	
training:	Epoch: [67][172/204]	Loss 0.0035 (0.0238)	
training:	Epoch: [67][173/204]	Loss 0.0030 (0.0237)	
training:	Epoch: [67][174/204]	Loss 0.0037 (0.0236)	
training:	Epoch: [67][175/204]	Loss 0.0046 (0.0235)	
training:	Epoch: [67][176/204]	Loss 0.0057 (0.0234)	
training:	Epoch: [67][177/204]	Loss 0.0060 (0.0233)	
training:	Epoch: [67][178/204]	Loss 0.0472 (0.0234)	
training:	Epoch: [67][179/204]	Loss 0.0028 (0.0233)	
training:	Epoch: [67][180/204]	Loss 0.0727 (0.0236)	
training:	Epoch: [67][181/204]	Loss 0.0028 (0.0235)	
training:	Epoch: [67][182/204]	Loss 0.0037 (0.0233)	
training:	Epoch: [67][183/204]	Loss 0.0059 (0.0233)	
training:	Epoch: [67][184/204]	Loss 0.1314 (0.0238)	
training:	Epoch: [67][185/204]	Loss 0.0657 (0.0241)	
training:	Epoch: [67][186/204]	Loss 0.0040 (0.0240)	
training:	Epoch: [67][187/204]	Loss 0.1710 (0.0247)	
training:	Epoch: [67][188/204]	Loss 0.0039 (0.0246)	
training:	Epoch: [67][189/204]	Loss 0.0066 (0.0245)	
training:	Epoch: [67][190/204]	Loss 0.0063 (0.0244)	
training:	Epoch: [67][191/204]	Loss 0.0344 (0.0245)	
training:	Epoch: [67][192/204]	Loss 0.0028 (0.0244)	
training:	Epoch: [67][193/204]	Loss 0.1166 (0.0249)	
training:	Epoch: [67][194/204]	Loss 0.0056 (0.0248)	
training:	Epoch: [67][195/204]	Loss 0.0107 (0.0247)	
training:	Epoch: [67][196/204]	Loss 0.0867 (0.0250)	
training:	Epoch: [67][197/204]	Loss 0.0041 (0.0249)	
training:	Epoch: [67][198/204]	Loss 0.0040 (0.0248)	
training:	Epoch: [67][199/204]	Loss 0.0077 (0.0247)	
training:	Epoch: [67][200/204]	Loss 0.0040 (0.0246)	
training:	Epoch: [67][201/204]	Loss 0.0038 (0.0245)	
training:	Epoch: [67][202/204]	Loss 0.0054 (0.0244)	
training:	Epoch: [67][203/204]	Loss 0.0031 (0.0243)	
training:	Epoch: [67][204/204]	Loss 0.0069 (0.0242)	
Training:	 Loss: 0.0242

Training:	 ACC: 0.9961 0.9962 0.9974 0.9949
Validation:	 ACC: 0.7827 0.7828 0.7840 0.7814
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1022
Pretraining:	Epoch 68/500
----------
training:	Epoch: [68][1/204]	Loss 0.0072 (0.0072)	
training:	Epoch: [68][2/204]	Loss 0.0078 (0.0075)	
training:	Epoch: [68][3/204]	Loss 0.0044 (0.0065)	
training:	Epoch: [68][4/204]	Loss 0.0074 (0.0067)	
training:	Epoch: [68][5/204]	Loss 0.0045 (0.0063)	
training:	Epoch: [68][6/204]	Loss 0.0074 (0.0064)	
training:	Epoch: [68][7/204]	Loss 0.0070 (0.0065)	
training:	Epoch: [68][8/204]	Loss 0.0082 (0.0067)	
training:	Epoch: [68][9/204]	Loss 0.0057 (0.0066)	
training:	Epoch: [68][10/204]	Loss 0.0035 (0.0063)	
training:	Epoch: [68][11/204]	Loss 0.0035 (0.0060)	
training:	Epoch: [68][12/204]	Loss 0.0162 (0.0069)	
training:	Epoch: [68][13/204]	Loss 0.0049 (0.0067)	
training:	Epoch: [68][14/204]	Loss 0.0647 (0.0109)	
training:	Epoch: [68][15/204]	Loss 0.0082 (0.0107)	
training:	Epoch: [68][16/204]	Loss 0.0829 (0.0152)	
training:	Epoch: [68][17/204]	Loss 0.0085 (0.0148)	
training:	Epoch: [68][18/204]	Loss 0.0035 (0.0142)	
training:	Epoch: [68][19/204]	Loss 0.0032 (0.0136)	
training:	Epoch: [68][20/204]	Loss 0.0036 (0.0131)	
training:	Epoch: [68][21/204]	Loss 0.0038 (0.0127)	
training:	Epoch: [68][22/204]	Loss 0.0027 (0.0122)	
training:	Epoch: [68][23/204]	Loss 0.0047 (0.0119)	
training:	Epoch: [68][24/204]	Loss 0.0044 (0.0116)	
training:	Epoch: [68][25/204]	Loss 0.0033 (0.0112)	
training:	Epoch: [68][26/204]	Loss 0.0108 (0.0112)	
training:	Epoch: [68][27/204]	Loss 0.0087 (0.0111)	
training:	Epoch: [68][28/204]	Loss 0.0723 (0.0133)	
training:	Epoch: [68][29/204]	Loss 0.0075 (0.0131)	
training:	Epoch: [68][30/204]	Loss 0.0036 (0.0128)	
training:	Epoch: [68][31/204]	Loss 0.0397 (0.0137)	
training:	Epoch: [68][32/204]	Loss 0.0037 (0.0134)	
training:	Epoch: [68][33/204]	Loss 0.0046 (0.0131)	
training:	Epoch: [68][34/204]	Loss 0.0074 (0.0129)	
training:	Epoch: [68][35/204]	Loss 0.0088 (0.0128)	
training:	Epoch: [68][36/204]	Loss 0.0052 (0.0126)	
training:	Epoch: [68][37/204]	Loss 0.0040 (0.0124)	
training:	Epoch: [68][38/204]	Loss 0.0033 (0.0121)	
training:	Epoch: [68][39/204]	Loss 0.0859 (0.0140)	
training:	Epoch: [68][40/204]	Loss 0.0037 (0.0138)	
training:	Epoch: [68][41/204]	Loss 0.0051 (0.0135)	
training:	Epoch: [68][42/204]	Loss 0.0061 (0.0134)	
training:	Epoch: [68][43/204]	Loss 0.0027 (0.0131)	
training:	Epoch: [68][44/204]	Loss 0.0084 (0.0130)	
training:	Epoch: [68][45/204]	Loss 0.0902 (0.0147)	
training:	Epoch: [68][46/204]	Loss 0.0043 (0.0145)	
training:	Epoch: [68][47/204]	Loss 0.0078 (0.0144)	
training:	Epoch: [68][48/204]	Loss 0.0107 (0.0143)	
training:	Epoch: [68][49/204]	Loss 0.0274 (0.0146)	
training:	Epoch: [68][50/204]	Loss 0.0032 (0.0143)	
training:	Epoch: [68][51/204]	Loss 0.0036 (0.0141)	
training:	Epoch: [68][52/204]	Loss 0.0918 (0.0156)	
training:	Epoch: [68][53/204]	Loss 0.0033 (0.0154)	
training:	Epoch: [68][54/204]	Loss 0.0033 (0.0152)	
training:	Epoch: [68][55/204]	Loss 0.0037 (0.0149)	
training:	Epoch: [68][56/204]	Loss 0.0031 (0.0147)	
training:	Epoch: [68][57/204]	Loss 0.0054 (0.0146)	
training:	Epoch: [68][58/204]	Loss 0.0337 (0.0149)	
training:	Epoch: [68][59/204]	Loss 0.0043 (0.0147)	
training:	Epoch: [68][60/204]	Loss 0.0056 (0.0146)	
training:	Epoch: [68][61/204]	Loss 0.0054 (0.0144)	
training:	Epoch: [68][62/204]	Loss 0.0033 (0.0142)	
training:	Epoch: [68][63/204]	Loss 0.0033 (0.0141)	
training:	Epoch: [68][64/204]	Loss 0.0051 (0.0139)	
training:	Epoch: [68][65/204]	Loss 0.0040 (0.0138)	
training:	Epoch: [68][66/204]	Loss 0.0060 (0.0137)	
training:	Epoch: [68][67/204]	Loss 0.1250 (0.0153)	
training:	Epoch: [68][68/204]	Loss 0.0037 (0.0151)	
training:	Epoch: [68][69/204]	Loss 0.0040 (0.0150)	
training:	Epoch: [68][70/204]	Loss 0.0027 (0.0148)	
training:	Epoch: [68][71/204]	Loss 0.0035 (0.0146)	
training:	Epoch: [68][72/204]	Loss 0.0038 (0.0145)	
training:	Epoch: [68][73/204]	Loss 0.0027 (0.0143)	
training:	Epoch: [68][74/204]	Loss 0.0120 (0.0143)	
training:	Epoch: [68][75/204]	Loss 0.0029 (0.0142)	
training:	Epoch: [68][76/204]	Loss 0.0027 (0.0140)	
training:	Epoch: [68][77/204]	Loss 0.0033 (0.0139)	
training:	Epoch: [68][78/204]	Loss 0.0040 (0.0137)	
training:	Epoch: [68][79/204]	Loss 0.0047 (0.0136)	
training:	Epoch: [68][80/204]	Loss 0.0036 (0.0135)	
training:	Epoch: [68][81/204]	Loss 0.0065 (0.0134)	
training:	Epoch: [68][82/204]	Loss 0.0036 (0.0133)	
training:	Epoch: [68][83/204]	Loss 0.0275 (0.0135)	
training:	Epoch: [68][84/204]	Loss 0.0038 (0.0133)	
training:	Epoch: [68][85/204]	Loss 0.0173 (0.0134)	
training:	Epoch: [68][86/204]	Loss 0.0034 (0.0133)	
training:	Epoch: [68][87/204]	Loss 0.0043 (0.0132)	
training:	Epoch: [68][88/204]	Loss 0.0036 (0.0131)	
training:	Epoch: [68][89/204]	Loss 0.0034 (0.0130)	
training:	Epoch: [68][90/204]	Loss 0.1838 (0.0149)	
training:	Epoch: [68][91/204]	Loss 0.0038 (0.0147)	
training:	Epoch: [68][92/204]	Loss 0.0023 (0.0146)	
training:	Epoch: [68][93/204]	Loss 0.0059 (0.0145)	
training:	Epoch: [68][94/204]	Loss 0.0025 (0.0144)	
training:	Epoch: [68][95/204]	Loss 0.0398 (0.0146)	
training:	Epoch: [68][96/204]	Loss 0.0030 (0.0145)	
training:	Epoch: [68][97/204]	Loss 0.0032 (0.0144)	
training:	Epoch: [68][98/204]	Loss 0.1299 (0.0156)	
training:	Epoch: [68][99/204]	Loss 0.0035 (0.0155)	
training:	Epoch: [68][100/204]	Loss 0.0027 (0.0153)	
training:	Epoch: [68][101/204]	Loss 0.0029 (0.0152)	
training:	Epoch: [68][102/204]	Loss 0.0054 (0.0151)	
training:	Epoch: [68][103/204]	Loss 0.0061 (0.0150)	
training:	Epoch: [68][104/204]	Loss 0.0042 (0.0149)	
training:	Epoch: [68][105/204]	Loss 0.0024 (0.0148)	
training:	Epoch: [68][106/204]	Loss 0.1611 (0.0162)	
training:	Epoch: [68][107/204]	Loss 0.0033 (0.0161)	
training:	Epoch: [68][108/204]	Loss 0.0031 (0.0159)	
training:	Epoch: [68][109/204]	Loss 0.0040 (0.0158)	
training:	Epoch: [68][110/204]	Loss 0.0533 (0.0162)	
training:	Epoch: [68][111/204]	Loss 0.1640 (0.0175)	
training:	Epoch: [68][112/204]	Loss 0.0026 (0.0174)	
training:	Epoch: [68][113/204]	Loss 0.0046 (0.0173)	
training:	Epoch: [68][114/204]	Loss 0.0033 (0.0171)	
training:	Epoch: [68][115/204]	Loss 0.0090 (0.0171)	
training:	Epoch: [68][116/204]	Loss 0.0046 (0.0170)	
training:	Epoch: [68][117/204]	Loss 0.0596 (0.0173)	
training:	Epoch: [68][118/204]	Loss 0.0027 (0.0172)	
training:	Epoch: [68][119/204]	Loss 0.0060 (0.0171)	
training:	Epoch: [68][120/204]	Loss 0.0062 (0.0170)	
training:	Epoch: [68][121/204]	Loss 0.0028 (0.0169)	
training:	Epoch: [68][122/204]	Loss 0.0031 (0.0168)	
training:	Epoch: [68][123/204]	Loss 0.0038 (0.0167)	
training:	Epoch: [68][124/204]	Loss 0.0077 (0.0166)	
training:	Epoch: [68][125/204]	Loss 0.0031 (0.0165)	
training:	Epoch: [68][126/204]	Loss 0.0031 (0.0164)	
training:	Epoch: [68][127/204]	Loss 0.0135 (0.0164)	
training:	Epoch: [68][128/204]	Loss 0.0066 (0.0163)	
training:	Epoch: [68][129/204]	Loss 0.0057 (0.0162)	
training:	Epoch: [68][130/204]	Loss 0.0048 (0.0161)	
training:	Epoch: [68][131/204]	Loss 0.0046 (0.0160)	
training:	Epoch: [68][132/204]	Loss 0.0031 (0.0159)	
training:	Epoch: [68][133/204]	Loss 0.0036 (0.0158)	
training:	Epoch: [68][134/204]	Loss 0.0024 (0.0157)	
training:	Epoch: [68][135/204]	Loss 0.0040 (0.0157)	
training:	Epoch: [68][136/204]	Loss 0.0048 (0.0156)	
training:	Epoch: [68][137/204]	Loss 0.0034 (0.0155)	
training:	Epoch: [68][138/204]	Loss 0.1070 (0.0162)	
training:	Epoch: [68][139/204]	Loss 0.1208 (0.0169)	
training:	Epoch: [68][140/204]	Loss 0.0033 (0.0168)	
training:	Epoch: [68][141/204]	Loss 0.1536 (0.0178)	
training:	Epoch: [68][142/204]	Loss 0.0111 (0.0177)	
training:	Epoch: [68][143/204]	Loss 0.0142 (0.0177)	
training:	Epoch: [68][144/204]	Loss 0.0354 (0.0178)	
training:	Epoch: [68][145/204]	Loss 0.0042 (0.0177)	
training:	Epoch: [68][146/204]	Loss 0.1856 (0.0189)	
training:	Epoch: [68][147/204]	Loss 0.1615 (0.0199)	
training:	Epoch: [68][148/204]	Loss 0.0038 (0.0197)	
training:	Epoch: [68][149/204]	Loss 0.0060 (0.0197)	
training:	Epoch: [68][150/204]	Loss 0.0045 (0.0196)	
training:	Epoch: [68][151/204]	Loss 0.0110 (0.0195)	
training:	Epoch: [68][152/204]	Loss 0.0093 (0.0194)	
training:	Epoch: [68][153/204]	Loss 0.0045 (0.0193)	
training:	Epoch: [68][154/204]	Loss 0.0042 (0.0192)	
training:	Epoch: [68][155/204]	Loss 0.0053 (0.0191)	
training:	Epoch: [68][156/204]	Loss 0.0040 (0.0190)	
training:	Epoch: [68][157/204]	Loss 0.0120 (0.0190)	
training:	Epoch: [68][158/204]	Loss 0.0043 (0.0189)	
training:	Epoch: [68][159/204]	Loss 0.0074 (0.0188)	
training:	Epoch: [68][160/204]	Loss 0.0052 (0.0188)	
training:	Epoch: [68][161/204]	Loss 0.0054 (0.0187)	
training:	Epoch: [68][162/204]	Loss 0.0057 (0.0186)	
training:	Epoch: [68][163/204]	Loss 0.0041 (0.0185)	
training:	Epoch: [68][164/204]	Loss 0.0682 (0.0188)	
training:	Epoch: [68][165/204]	Loss 0.0101 (0.0188)	
training:	Epoch: [68][166/204]	Loss 0.0053 (0.0187)	
training:	Epoch: [68][167/204]	Loss 0.0074 (0.0186)	
training:	Epoch: [68][168/204]	Loss 0.0079 (0.0185)	
training:	Epoch: [68][169/204]	Loss 0.0068 (0.0185)	
training:	Epoch: [68][170/204]	Loss 0.0030 (0.0184)	
training:	Epoch: [68][171/204]	Loss 0.0332 (0.0185)	
training:	Epoch: [68][172/204]	Loss 0.0709 (0.0188)	
training:	Epoch: [68][173/204]	Loss 0.0102 (0.0187)	
training:	Epoch: [68][174/204]	Loss 0.0040 (0.0186)	
training:	Epoch: [68][175/204]	Loss 0.0038 (0.0186)	
training:	Epoch: [68][176/204]	Loss 0.1200 (0.0191)	
training:	Epoch: [68][177/204]	Loss 0.0079 (0.0191)	
training:	Epoch: [68][178/204]	Loss 0.0031 (0.0190)	
training:	Epoch: [68][179/204]	Loss 0.0049 (0.0189)	
training:	Epoch: [68][180/204]	Loss 0.1008 (0.0194)	
training:	Epoch: [68][181/204]	Loss 0.0127 (0.0193)	
training:	Epoch: [68][182/204]	Loss 0.0101 (0.0193)	
training:	Epoch: [68][183/204]	Loss 0.0747 (0.0196)	
training:	Epoch: [68][184/204]	Loss 0.0051 (0.0195)	
training:	Epoch: [68][185/204]	Loss 0.0065 (0.0194)	
training:	Epoch: [68][186/204]	Loss 0.1517 (0.0201)	
training:	Epoch: [68][187/204]	Loss 0.0063 (0.0201)	
training:	Epoch: [68][188/204]	Loss 0.0076 (0.0200)	
training:	Epoch: [68][189/204]	Loss 0.0062 (0.0199)	
training:	Epoch: [68][190/204]	Loss 0.0103 (0.0199)	
training:	Epoch: [68][191/204]	Loss 0.0125 (0.0198)	
training:	Epoch: [68][192/204]	Loss 0.0060 (0.0198)	
training:	Epoch: [68][193/204]	Loss 0.0818 (0.0201)	
training:	Epoch: [68][194/204]	Loss 0.0345 (0.0202)	
training:	Epoch: [68][195/204]	Loss 0.0554 (0.0203)	
training:	Epoch: [68][196/204]	Loss 0.1424 (0.0210)	
training:	Epoch: [68][197/204]	Loss 0.0658 (0.0212)	
training:	Epoch: [68][198/204]	Loss 0.0042 (0.0211)	
training:	Epoch: [68][199/204]	Loss 0.0039 (0.0210)	
training:	Epoch: [68][200/204]	Loss 0.0186 (0.0210)	
training:	Epoch: [68][201/204]	Loss 0.0032 (0.0209)	
training:	Epoch: [68][202/204]	Loss 0.0063 (0.0208)	
training:	Epoch: [68][203/204]	Loss 0.0057 (0.0208)	
training:	Epoch: [68][204/204]	Loss 0.0084 (0.0207)	
Training:	 Loss: 0.0207

Training:	 ACC: 0.9936 0.9937 0.9976 0.9895
Validation:	 ACC: 0.7743 0.7774 0.8434 0.7052
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1261
Pretraining:	Epoch 69/500
----------
training:	Epoch: [69][1/204]	Loss 0.0096 (0.0096)	
training:	Epoch: [69][2/204]	Loss 0.0076 (0.0086)	
training:	Epoch: [69][3/204]	Loss 0.0043 (0.0072)	
training:	Epoch: [69][4/204]	Loss 0.0070 (0.0071)	
training:	Epoch: [69][5/204]	Loss 0.1418 (0.0341)	
training:	Epoch: [69][6/204]	Loss 0.0190 (0.0315)	
training:	Epoch: [69][7/204]	Loss 0.0085 (0.0282)	
training:	Epoch: [69][8/204]	Loss 0.0026 (0.0250)	
training:	Epoch: [69][9/204]	Loss 0.0194 (0.0244)	
training:	Epoch: [69][10/204]	Loss 0.0054 (0.0225)	
training:	Epoch: [69][11/204]	Loss 0.0067 (0.0211)	
training:	Epoch: [69][12/204]	Loss 0.0039 (0.0196)	
training:	Epoch: [69][13/204]	Loss 0.0044 (0.0185)	
training:	Epoch: [69][14/204]	Loss 0.0035 (0.0174)	
training:	Epoch: [69][15/204]	Loss 0.0405 (0.0189)	
training:	Epoch: [69][16/204]	Loss 0.0063 (0.0182)	
training:	Epoch: [69][17/204]	Loss 0.0048 (0.0174)	
training:	Epoch: [69][18/204]	Loss 0.0408 (0.0187)	
training:	Epoch: [69][19/204]	Loss 0.1036 (0.0231)	
training:	Epoch: [69][20/204]	Loss 0.0113 (0.0225)	
training:	Epoch: [69][21/204]	Loss 0.0064 (0.0218)	
training:	Epoch: [69][22/204]	Loss 0.0100 (0.0212)	
training:	Epoch: [69][23/204]	Loss 0.0295 (0.0216)	
training:	Epoch: [69][24/204]	Loss 0.0068 (0.0210)	
training:	Epoch: [69][25/204]	Loss 0.0051 (0.0203)	
training:	Epoch: [69][26/204]	Loss 0.0060 (0.0198)	
training:	Epoch: [69][27/204]	Loss 0.0061 (0.0193)	
training:	Epoch: [69][28/204]	Loss 0.0072 (0.0189)	
training:	Epoch: [69][29/204]	Loss 0.0041 (0.0183)	
training:	Epoch: [69][30/204]	Loss 0.0034 (0.0178)	
training:	Epoch: [69][31/204]	Loss 0.0027 (0.0174)	
training:	Epoch: [69][32/204]	Loss 0.0025 (0.0169)	
training:	Epoch: [69][33/204]	Loss 0.0043 (0.0165)	
training:	Epoch: [69][34/204]	Loss 0.0037 (0.0161)	
training:	Epoch: [69][35/204]	Loss 0.0681 (0.0176)	
training:	Epoch: [69][36/204]	Loss 0.0058 (0.0173)	
training:	Epoch: [69][37/204]	Loss 0.0039 (0.0169)	
training:	Epoch: [69][38/204]	Loss 0.0037 (0.0166)	
training:	Epoch: [69][39/204]	Loss 0.0033 (0.0162)	
training:	Epoch: [69][40/204]	Loss 0.0707 (0.0176)	
training:	Epoch: [69][41/204]	Loss 0.0033 (0.0173)	
training:	Epoch: [69][42/204]	Loss 0.0031 (0.0169)	
training:	Epoch: [69][43/204]	Loss 0.0098 (0.0168)	
training:	Epoch: [69][44/204]	Loss 0.0075 (0.0165)	
training:	Epoch: [69][45/204]	Loss 0.1056 (0.0185)	
training:	Epoch: [69][46/204]	Loss 0.0027 (0.0182)	
training:	Epoch: [69][47/204]	Loss 0.0043 (0.0179)	
training:	Epoch: [69][48/204]	Loss 0.0055 (0.0176)	
training:	Epoch: [69][49/204]	Loss 0.0041 (0.0173)	
training:	Epoch: [69][50/204]	Loss 0.0033 (0.0171)	
training:	Epoch: [69][51/204]	Loss 0.0047 (0.0168)	
training:	Epoch: [69][52/204]	Loss 0.0535 (0.0175)	
training:	Epoch: [69][53/204]	Loss 0.0038 (0.0173)	
training:	Epoch: [69][54/204]	Loss 0.0041 (0.0170)	
training:	Epoch: [69][55/204]	Loss 0.0041 (0.0168)	
training:	Epoch: [69][56/204]	Loss 0.0044 (0.0166)	
training:	Epoch: [69][57/204]	Loss 0.0028 (0.0163)	
training:	Epoch: [69][58/204]	Loss 0.0935 (0.0177)	
training:	Epoch: [69][59/204]	Loss 0.0031 (0.0174)	
training:	Epoch: [69][60/204]	Loss 0.0052 (0.0172)	
training:	Epoch: [69][61/204]	Loss 0.0056 (0.0170)	
training:	Epoch: [69][62/204]	Loss 0.0122 (0.0169)	
training:	Epoch: [69][63/204]	Loss 0.0064 (0.0168)	
training:	Epoch: [69][64/204]	Loss 0.0047 (0.0166)	
training:	Epoch: [69][65/204]	Loss 0.0051 (0.0164)	
training:	Epoch: [69][66/204]	Loss 0.0060 (0.0163)	
training:	Epoch: [69][67/204]	Loss 0.0036 (0.0161)	
training:	Epoch: [69][68/204]	Loss 0.0043 (0.0159)	
training:	Epoch: [69][69/204]	Loss 0.0027 (0.0157)	
training:	Epoch: [69][70/204]	Loss 0.0087 (0.0156)	
training:	Epoch: [69][71/204]	Loss 0.0157 (0.0156)	
training:	Epoch: [69][72/204]	Loss 0.0040 (0.0154)	
training:	Epoch: [69][73/204]	Loss 0.0112 (0.0154)	
training:	Epoch: [69][74/204]	Loss 0.0097 (0.0153)	
training:	Epoch: [69][75/204]	Loss 0.0079 (0.0152)	
training:	Epoch: [69][76/204]	Loss 0.0077 (0.0151)	
training:	Epoch: [69][77/204]	Loss 0.0039 (0.0150)	
training:	Epoch: [69][78/204]	Loss 0.0059 (0.0148)	
training:	Epoch: [69][79/204]	Loss 0.0448 (0.0152)	
training:	Epoch: [69][80/204]	Loss 0.0038 (0.0151)	
training:	Epoch: [69][81/204]	Loss 0.0063 (0.0150)	
training:	Epoch: [69][82/204]	Loss 0.0028 (0.0148)	
training:	Epoch: [69][83/204]	Loss 0.0043 (0.0147)	
training:	Epoch: [69][84/204]	Loss 0.0026 (0.0146)	
training:	Epoch: [69][85/204]	Loss 0.0032 (0.0144)	
training:	Epoch: [69][86/204]	Loss 0.0052 (0.0143)	
training:	Epoch: [69][87/204]	Loss 0.0046 (0.0142)	
training:	Epoch: [69][88/204]	Loss 0.0041 (0.0141)	
training:	Epoch: [69][89/204]	Loss 0.0062 (0.0140)	
training:	Epoch: [69][90/204]	Loss 0.0056 (0.0139)	
training:	Epoch: [69][91/204]	Loss 0.0301 (0.0141)	
training:	Epoch: [69][92/204]	Loss 0.0067 (0.0140)	
training:	Epoch: [69][93/204]	Loss 0.0948 (0.0149)	
training:	Epoch: [69][94/204]	Loss 0.0024 (0.0147)	
training:	Epoch: [69][95/204]	Loss 0.0048 (0.0146)	
training:	Epoch: [69][96/204]	Loss 0.0869 (0.0154)	
training:	Epoch: [69][97/204]	Loss 0.0037 (0.0153)	
training:	Epoch: [69][98/204]	Loss 0.0044 (0.0152)	
training:	Epoch: [69][99/204]	Loss 0.0066 (0.0151)	
training:	Epoch: [69][100/204]	Loss 0.0044 (0.0150)	
training:	Epoch: [69][101/204]	Loss 0.0081 (0.0149)	
training:	Epoch: [69][102/204]	Loss 0.0309 (0.0151)	
training:	Epoch: [69][103/204]	Loss 0.0040 (0.0149)	
training:	Epoch: [69][104/204]	Loss 0.0028 (0.0148)	
training:	Epoch: [69][105/204]	Loss 0.0071 (0.0148)	
training:	Epoch: [69][106/204]	Loss 0.0052 (0.0147)	
training:	Epoch: [69][107/204]	Loss 0.0039 (0.0146)	
training:	Epoch: [69][108/204]	Loss 0.0473 (0.0149)	
training:	Epoch: [69][109/204]	Loss 0.0111 (0.0148)	
training:	Epoch: [69][110/204]	Loss 0.0098 (0.0148)	
training:	Epoch: [69][111/204]	Loss 0.0037 (0.0147)	
training:	Epoch: [69][112/204]	Loss 0.1227 (0.0157)	
training:	Epoch: [69][113/204]	Loss 0.0095 (0.0156)	
training:	Epoch: [69][114/204]	Loss 0.0030 (0.0155)	
training:	Epoch: [69][115/204]	Loss 0.0025 (0.0154)	
training:	Epoch: [69][116/204]	Loss 0.0031 (0.0153)	
training:	Epoch: [69][117/204]	Loss 0.0043 (0.0152)	
training:	Epoch: [69][118/204]	Loss 0.0126 (0.0152)	
training:	Epoch: [69][119/204]	Loss 0.0077 (0.0151)	
training:	Epoch: [69][120/204]	Loss 0.0041 (0.0150)	
training:	Epoch: [69][121/204]	Loss 0.0243 (0.0151)	
training:	Epoch: [69][122/204]	Loss 0.0074 (0.0150)	
training:	Epoch: [69][123/204]	Loss 0.0033 (0.0149)	
training:	Epoch: [69][124/204]	Loss 0.0047 (0.0148)	
training:	Epoch: [69][125/204]	Loss 0.0061 (0.0148)	
training:	Epoch: [69][126/204]	Loss 0.0029 (0.0147)	
training:	Epoch: [69][127/204]	Loss 0.0029 (0.0146)	
training:	Epoch: [69][128/204]	Loss 0.0025 (0.0145)	
training:	Epoch: [69][129/204]	Loss 0.0026 (0.0144)	
training:	Epoch: [69][130/204]	Loss 0.0031 (0.0143)	
training:	Epoch: [69][131/204]	Loss 0.1998 (0.0157)	
training:	Epoch: [69][132/204]	Loss 0.0034 (0.0156)	
training:	Epoch: [69][133/204]	Loss 0.0029 (0.0155)	
training:	Epoch: [69][134/204]	Loss 0.0030 (0.0154)	
training:	Epoch: [69][135/204]	Loss 0.0029 (0.0153)	
training:	Epoch: [69][136/204]	Loss 0.0029 (0.0153)	
training:	Epoch: [69][137/204]	Loss 0.0034 (0.0152)	
training:	Epoch: [69][138/204]	Loss 0.0029 (0.0151)	
training:	Epoch: [69][139/204]	Loss 0.0027 (0.0150)	
training:	Epoch: [69][140/204]	Loss 0.0023 (0.0149)	
training:	Epoch: [69][141/204]	Loss 0.0028 (0.0148)	
training:	Epoch: [69][142/204]	Loss 0.0021 (0.0147)	
training:	Epoch: [69][143/204]	Loss 0.0024 (0.0146)	
training:	Epoch: [69][144/204]	Loss 0.0023 (0.0146)	
training:	Epoch: [69][145/204]	Loss 0.0034 (0.0145)	
training:	Epoch: [69][146/204]	Loss 0.0792 (0.0149)	
training:	Epoch: [69][147/204]	Loss 0.0036 (0.0148)	
training:	Epoch: [69][148/204]	Loss 0.0246 (0.0149)	
training:	Epoch: [69][149/204]	Loss 0.0021 (0.0148)	
training:	Epoch: [69][150/204]	Loss 0.0033 (0.0147)	
training:	Epoch: [69][151/204]	Loss 0.0030 (0.0147)	
training:	Epoch: [69][152/204]	Loss 0.0037 (0.0146)	
training:	Epoch: [69][153/204]	Loss 0.0025 (0.0145)	
training:	Epoch: [69][154/204]	Loss 0.0043 (0.0145)	
training:	Epoch: [69][155/204]	Loss 0.0031 (0.0144)	
training:	Epoch: [69][156/204]	Loss 0.1493 (0.0152)	
training:	Epoch: [69][157/204]	Loss 0.0046 (0.0152)	
training:	Epoch: [69][158/204]	Loss 0.0023 (0.0151)	
training:	Epoch: [69][159/204]	Loss 0.0667 (0.0154)	
training:	Epoch: [69][160/204]	Loss 0.0043 (0.0153)	
training:	Epoch: [69][161/204]	Loss 0.0026 (0.0153)	
training:	Epoch: [69][162/204]	Loss 0.0095 (0.0152)	
training:	Epoch: [69][163/204]	Loss 0.0038 (0.0152)	
training:	Epoch: [69][164/204]	Loss 0.0488 (0.0154)	
training:	Epoch: [69][165/204]	Loss 0.0700 (0.0157)	
training:	Epoch: [69][166/204]	Loss 0.0043 (0.0156)	
training:	Epoch: [69][167/204]	Loss 0.0040 (0.0156)	
training:	Epoch: [69][168/204]	Loss 0.0033 (0.0155)	
training:	Epoch: [69][169/204]	Loss 0.0106 (0.0155)	
training:	Epoch: [69][170/204]	Loss 0.0058 (0.0154)	
training:	Epoch: [69][171/204]	Loss 0.0106 (0.0154)	
training:	Epoch: [69][172/204]	Loss 0.0056 (0.0153)	
training:	Epoch: [69][173/204]	Loss 0.0051 (0.0153)	
training:	Epoch: [69][174/204]	Loss 0.0090 (0.0152)	
training:	Epoch: [69][175/204]	Loss 0.0128 (0.0152)	
training:	Epoch: [69][176/204]	Loss 0.0411 (0.0154)	
training:	Epoch: [69][177/204]	Loss 0.0038 (0.0153)	
training:	Epoch: [69][178/204]	Loss 0.0028 (0.0152)	
training:	Epoch: [69][179/204]	Loss 0.0037 (0.0152)	
training:	Epoch: [69][180/204]	Loss 0.0028 (0.0151)	
training:	Epoch: [69][181/204]	Loss 0.0070 (0.0150)	
training:	Epoch: [69][182/204]	Loss 0.0033 (0.0150)	
training:	Epoch: [69][183/204]	Loss 0.0046 (0.0149)	
training:	Epoch: [69][184/204]	Loss 0.0067 (0.0149)	
training:	Epoch: [69][185/204]	Loss 0.0040 (0.0148)	
training:	Epoch: [69][186/204]	Loss 0.0043 (0.0148)	
training:	Epoch: [69][187/204]	Loss 0.0037 (0.0147)	
training:	Epoch: [69][188/204]	Loss 0.0112 (0.0147)	
training:	Epoch: [69][189/204]	Loss 0.0363 (0.0148)	
training:	Epoch: [69][190/204]	Loss 0.0082 (0.0148)	
training:	Epoch: [69][191/204]	Loss 0.0025 (0.0147)	
training:	Epoch: [69][192/204]	Loss 0.0034 (0.0146)	
training:	Epoch: [69][193/204]	Loss 0.0037 (0.0146)	
training:	Epoch: [69][194/204]	Loss 0.0051 (0.0145)	
training:	Epoch: [69][195/204]	Loss 0.0691 (0.0148)	
training:	Epoch: [69][196/204]	Loss 0.0064 (0.0148)	
training:	Epoch: [69][197/204]	Loss 0.2064 (0.0157)	
training:	Epoch: [69][198/204]	Loss 0.0043 (0.0157)	
training:	Epoch: [69][199/204]	Loss 0.0030 (0.0156)	
training:	Epoch: [69][200/204]	Loss 0.1786 (0.0164)	
training:	Epoch: [69][201/204]	Loss 0.0106 (0.0164)	
training:	Epoch: [69][202/204]	Loss 0.0027 (0.0163)	
training:	Epoch: [69][203/204]	Loss 0.1590 (0.0170)	
training:	Epoch: [69][204/204]	Loss 0.0030 (0.0170)	
Training:	 Loss: 0.0169

Training:	 ACC: 0.9967 0.9968 0.9979 0.9955
Validation:	 ACC: 0.7787 0.7801 0.8096 0.7478
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1293
Pretraining:	Epoch 70/500
----------
training:	Epoch: [70][1/204]	Loss 0.0223 (0.0223)	
training:	Epoch: [70][2/204]	Loss 0.0032 (0.0127)	
training:	Epoch: [70][3/204]	Loss 0.0038 (0.0098)	
training:	Epoch: [70][4/204]	Loss 0.0029 (0.0081)	
training:	Epoch: [70][5/204]	Loss 0.0046 (0.0074)	
training:	Epoch: [70][6/204]	Loss 0.0030 (0.0066)	
training:	Epoch: [70][7/204]	Loss 0.0032 (0.0062)	
training:	Epoch: [70][8/204]	Loss 0.0124 (0.0069)	
training:	Epoch: [70][9/204]	Loss 0.0052 (0.0068)	
training:	Epoch: [70][10/204]	Loss 0.0061 (0.0067)	
training:	Epoch: [70][11/204]	Loss 0.0066 (0.0067)	
training:	Epoch: [70][12/204]	Loss 0.0034 (0.0064)	
training:	Epoch: [70][13/204]	Loss 0.0548 (0.0101)	
training:	Epoch: [70][14/204]	Loss 0.0042 (0.0097)	
training:	Epoch: [70][15/204]	Loss 0.0029 (0.0092)	
training:	Epoch: [70][16/204]	Loss 0.1167 (0.0160)	
training:	Epoch: [70][17/204]	Loss 0.0026 (0.0152)	
training:	Epoch: [70][18/204]	Loss 0.0036 (0.0145)	
training:	Epoch: [70][19/204]	Loss 0.0372 (0.0157)	
training:	Epoch: [70][20/204]	Loss 0.0035 (0.0151)	
training:	Epoch: [70][21/204]	Loss 0.0030 (0.0145)	
training:	Epoch: [70][22/204]	Loss 0.0026 (0.0140)	
training:	Epoch: [70][23/204]	Loss 0.0032 (0.0135)	
training:	Epoch: [70][24/204]	Loss 0.0077 (0.0133)	
training:	Epoch: [70][25/204]	Loss 0.0111 (0.0132)	
training:	Epoch: [70][26/204]	Loss 0.0035 (0.0128)	
training:	Epoch: [70][27/204]	Loss 0.0088 (0.0127)	
training:	Epoch: [70][28/204]	Loss 0.0641 (0.0145)	
training:	Epoch: [70][29/204]	Loss 0.0024 (0.0141)	
training:	Epoch: [70][30/204]	Loss 0.0030 (0.0137)	
training:	Epoch: [70][31/204]	Loss 0.0027 (0.0134)	
training:	Epoch: [70][32/204]	Loss 0.0074 (0.0132)	
training:	Epoch: [70][33/204]	Loss 0.0025 (0.0129)	
training:	Epoch: [70][34/204]	Loss 0.1376 (0.0165)	
training:	Epoch: [70][35/204]	Loss 0.0084 (0.0163)	
training:	Epoch: [70][36/204]	Loss 0.0265 (0.0166)	
training:	Epoch: [70][37/204]	Loss 0.0077 (0.0163)	
training:	Epoch: [70][38/204]	Loss 0.0057 (0.0161)	
training:	Epoch: [70][39/204]	Loss 0.0036 (0.0157)	
training:	Epoch: [70][40/204]	Loss 0.0049 (0.0155)	
training:	Epoch: [70][41/204]	Loss 0.1454 (0.0186)	
training:	Epoch: [70][42/204]	Loss 0.0084 (0.0184)	
training:	Epoch: [70][43/204]	Loss 0.0046 (0.0181)	
training:	Epoch: [70][44/204]	Loss 0.0061 (0.0178)	
training:	Epoch: [70][45/204]	Loss 0.0054 (0.0175)	
training:	Epoch: [70][46/204]	Loss 0.0031 (0.0172)	
training:	Epoch: [70][47/204]	Loss 0.0094 (0.0170)	
training:	Epoch: [70][48/204]	Loss 0.0027 (0.0167)	
training:	Epoch: [70][49/204]	Loss 0.0178 (0.0168)	
training:	Epoch: [70][50/204]	Loss 0.0151 (0.0167)	
training:	Epoch: [70][51/204]	Loss 0.0039 (0.0165)	
training:	Epoch: [70][52/204]	Loss 0.0033 (0.0162)	
training:	Epoch: [70][53/204]	Loss 0.1103 (0.0180)	
training:	Epoch: [70][54/204]	Loss 0.0286 (0.0182)	
training:	Epoch: [70][55/204]	Loss 0.0046 (0.0180)	
training:	Epoch: [70][56/204]	Loss 0.0318 (0.0182)	
training:	Epoch: [70][57/204]	Loss 0.0046 (0.0180)	
training:	Epoch: [70][58/204]	Loss 0.0078 (0.0178)	
training:	Epoch: [70][59/204]	Loss 0.0856 (0.0189)	
training:	Epoch: [70][60/204]	Loss 0.0065 (0.0187)	
training:	Epoch: [70][61/204]	Loss 0.0052 (0.0185)	
training:	Epoch: [70][62/204]	Loss 0.0058 (0.0183)	
training:	Epoch: [70][63/204]	Loss 0.0037 (0.0181)	
training:	Epoch: [70][64/204]	Loss 0.0072 (0.0179)	
training:	Epoch: [70][65/204]	Loss 0.0019 (0.0177)	
training:	Epoch: [70][66/204]	Loss 0.0030 (0.0174)	
training:	Epoch: [70][67/204]	Loss 0.1861 (0.0199)	
training:	Epoch: [70][68/204]	Loss 0.0041 (0.0197)	
training:	Epoch: [70][69/204]	Loss 0.0102 (0.0196)	
training:	Epoch: [70][70/204]	Loss 0.0646 (0.0202)	
training:	Epoch: [70][71/204]	Loss 0.0036 (0.0200)	
training:	Epoch: [70][72/204]	Loss 0.0063 (0.0198)	
training:	Epoch: [70][73/204]	Loss 0.0074 (0.0196)	
training:	Epoch: [70][74/204]	Loss 0.0036 (0.0194)	
training:	Epoch: [70][75/204]	Loss 0.0036 (0.0192)	
training:	Epoch: [70][76/204]	Loss 0.0041 (0.0190)	
training:	Epoch: [70][77/204]	Loss 0.0041 (0.0188)	
training:	Epoch: [70][78/204]	Loss 0.0063 (0.0186)	
training:	Epoch: [70][79/204]	Loss 0.0040 (0.0185)	
training:	Epoch: [70][80/204]	Loss 0.0065 (0.0183)	
training:	Epoch: [70][81/204]	Loss 0.0024 (0.0181)	
training:	Epoch: [70][82/204]	Loss 0.0034 (0.0179)	
training:	Epoch: [70][83/204]	Loss 0.0070 (0.0178)	
training:	Epoch: [70][84/204]	Loss 0.0053 (0.0177)	
training:	Epoch: [70][85/204]	Loss 0.0057 (0.0175)	
training:	Epoch: [70][86/204]	Loss 0.0056 (0.0174)	
training:	Epoch: [70][87/204]	Loss 0.0024 (0.0172)	
training:	Epoch: [70][88/204]	Loss 0.1023 (0.0182)	
training:	Epoch: [70][89/204]	Loss 0.0023 (0.0180)	
training:	Epoch: [70][90/204]	Loss 0.0026 (0.0178)	
training:	Epoch: [70][91/204]	Loss 0.0748 (0.0184)	
training:	Epoch: [70][92/204]	Loss 0.0062 (0.0183)	
training:	Epoch: [70][93/204]	Loss 0.0095 (0.0182)	
training:	Epoch: [70][94/204]	Loss 0.0025 (0.0181)	
training:	Epoch: [70][95/204]	Loss 0.0033 (0.0179)	
training:	Epoch: [70][96/204]	Loss 0.0034 (0.0177)	
training:	Epoch: [70][97/204]	Loss 0.0065 (0.0176)	
training:	Epoch: [70][98/204]	Loss 0.0063 (0.0175)	
training:	Epoch: [70][99/204]	Loss 0.0048 (0.0174)	
training:	Epoch: [70][100/204]	Loss 0.0043 (0.0173)	
training:	Epoch: [70][101/204]	Loss 0.0037 (0.0171)	
training:	Epoch: [70][102/204]	Loss 0.0072 (0.0170)	
training:	Epoch: [70][103/204]	Loss 0.0042 (0.0169)	
training:	Epoch: [70][104/204]	Loss 0.0042 (0.0168)	
training:	Epoch: [70][105/204]	Loss 0.0232 (0.0168)	
training:	Epoch: [70][106/204]	Loss 0.0044 (0.0167)	
training:	Epoch: [70][107/204]	Loss 0.0035 (0.0166)	
training:	Epoch: [70][108/204]	Loss 0.0029 (0.0165)	
training:	Epoch: [70][109/204]	Loss 0.0028 (0.0163)	
training:	Epoch: [70][110/204]	Loss 0.0043 (0.0162)	
training:	Epoch: [70][111/204]	Loss 0.0054 (0.0161)	
training:	Epoch: [70][112/204]	Loss 0.0031 (0.0160)	
training:	Epoch: [70][113/204]	Loss 0.0183 (0.0160)	
training:	Epoch: [70][114/204]	Loss 0.0035 (0.0159)	
training:	Epoch: [70][115/204]	Loss 0.0031 (0.0158)	
training:	Epoch: [70][116/204]	Loss 0.0033 (0.0157)	
training:	Epoch: [70][117/204]	Loss 0.0029 (0.0156)	
training:	Epoch: [70][118/204]	Loss 0.0032 (0.0155)	
training:	Epoch: [70][119/204]	Loss 0.0092 (0.0154)	
training:	Epoch: [70][120/204]	Loss 0.0026 (0.0153)	
training:	Epoch: [70][121/204]	Loss 0.0028 (0.0152)	
training:	Epoch: [70][122/204]	Loss 0.0026 (0.0151)	
training:	Epoch: [70][123/204]	Loss 0.0027 (0.0150)	
training:	Epoch: [70][124/204]	Loss 0.0607 (0.0154)	
training:	Epoch: [70][125/204]	Loss 0.0029 (0.0153)	
training:	Epoch: [70][126/204]	Loss 0.0032 (0.0152)	
training:	Epoch: [70][127/204]	Loss 0.0028 (0.0151)	
training:	Epoch: [70][128/204]	Loss 0.0028 (0.0150)	
training:	Epoch: [70][129/204]	Loss 0.0034 (0.0149)	
training:	Epoch: [70][130/204]	Loss 0.0030 (0.0148)	
training:	Epoch: [70][131/204]	Loss 0.0033 (0.0147)	
training:	Epoch: [70][132/204]	Loss 0.0069 (0.0147)	
training:	Epoch: [70][133/204]	Loss 0.0031 (0.0146)	
training:	Epoch: [70][134/204]	Loss 0.1363 (0.0155)	
training:	Epoch: [70][135/204]	Loss 0.0043 (0.0154)	
training:	Epoch: [70][136/204]	Loss 0.0026 (0.0153)	
training:	Epoch: [70][137/204]	Loss 0.0037 (0.0152)	
training:	Epoch: [70][138/204]	Loss 0.0024 (0.0151)	
training:	Epoch: [70][139/204]	Loss 0.0044 (0.0151)	
training:	Epoch: [70][140/204]	Loss 0.0031 (0.0150)	
training:	Epoch: [70][141/204]	Loss 0.0026 (0.0149)	
training:	Epoch: [70][142/204]	Loss 0.0038 (0.0148)	
training:	Epoch: [70][143/204]	Loss 0.0023 (0.0147)	
training:	Epoch: [70][144/204]	Loss 0.0038 (0.0147)	
training:	Epoch: [70][145/204]	Loss 0.0061 (0.0146)	
training:	Epoch: [70][146/204]	Loss 0.0045 (0.0145)	
training:	Epoch: [70][147/204]	Loss 0.0026 (0.0144)	
training:	Epoch: [70][148/204]	Loss 0.0051 (0.0144)	
training:	Epoch: [70][149/204]	Loss 0.0643 (0.0147)	
training:	Epoch: [70][150/204]	Loss 0.0042 (0.0146)	
training:	Epoch: [70][151/204]	Loss 0.0028 (0.0146)	
training:	Epoch: [70][152/204]	Loss 0.0341 (0.0147)	
training:	Epoch: [70][153/204]	Loss 0.0027 (0.0146)	
training:	Epoch: [70][154/204]	Loss 0.0033 (0.0145)	
training:	Epoch: [70][155/204]	Loss 0.0024 (0.0145)	
training:	Epoch: [70][156/204]	Loss 0.0040 (0.0144)	
training:	Epoch: [70][157/204]	Loss 0.0028 (0.0143)	
training:	Epoch: [70][158/204]	Loss 0.0033 (0.0143)	
training:	Epoch: [70][159/204]	Loss 0.0036 (0.0142)	
training:	Epoch: [70][160/204]	Loss 0.0035 (0.0141)	
training:	Epoch: [70][161/204]	Loss 0.0023 (0.0140)	
training:	Epoch: [70][162/204]	Loss 0.0026 (0.0140)	
training:	Epoch: [70][163/204]	Loss 0.0632 (0.0143)	
training:	Epoch: [70][164/204]	Loss 0.0033 (0.0142)	
training:	Epoch: [70][165/204]	Loss 0.0024 (0.0141)	
training:	Epoch: [70][166/204]	Loss 0.0041 (0.0141)	
training:	Epoch: [70][167/204]	Loss 0.0047 (0.0140)	
training:	Epoch: [70][168/204]	Loss 0.0658 (0.0143)	
training:	Epoch: [70][169/204]	Loss 0.0768 (0.0147)	
training:	Epoch: [70][170/204]	Loss 0.1490 (0.0155)	
training:	Epoch: [70][171/204]	Loss 0.0037 (0.0154)	
training:	Epoch: [70][172/204]	Loss 0.0056 (0.0154)	
training:	Epoch: [70][173/204]	Loss 0.0029 (0.0153)	
training:	Epoch: [70][174/204]	Loss 0.0039 (0.0152)	
training:	Epoch: [70][175/204]	Loss 0.0083 (0.0152)	
training:	Epoch: [70][176/204]	Loss 0.0028 (0.0151)	
training:	Epoch: [70][177/204]	Loss 0.0058 (0.0151)	
training:	Epoch: [70][178/204]	Loss 0.0591 (0.0153)	
training:	Epoch: [70][179/204]	Loss 0.0055 (0.0153)	
training:	Epoch: [70][180/204]	Loss 0.0777 (0.0156)	
training:	Epoch: [70][181/204]	Loss 0.0056 (0.0155)	
training:	Epoch: [70][182/204]	Loss 0.0107 (0.0155)	
training:	Epoch: [70][183/204]	Loss 0.0093 (0.0155)	
training:	Epoch: [70][184/204]	Loss 0.0049 (0.0154)	
training:	Epoch: [70][185/204]	Loss 0.0033 (0.0154)	
training:	Epoch: [70][186/204]	Loss 0.0046 (0.0153)	
training:	Epoch: [70][187/204]	Loss 0.0036 (0.0152)	
training:	Epoch: [70][188/204]	Loss 0.0044 (0.0152)	
training:	Epoch: [70][189/204]	Loss 0.0700 (0.0155)	
training:	Epoch: [70][190/204]	Loss 0.0055 (0.0154)	
training:	Epoch: [70][191/204]	Loss 0.0122 (0.0154)	
training:	Epoch: [70][192/204]	Loss 0.0056 (0.0154)	
training:	Epoch: [70][193/204]	Loss 0.0103 (0.0153)	
training:	Epoch: [70][194/204]	Loss 0.0042 (0.0153)	
training:	Epoch: [70][195/204]	Loss 0.0062 (0.0152)	
training:	Epoch: [70][196/204]	Loss 0.0222 (0.0153)	
training:	Epoch: [70][197/204]	Loss 0.0030 (0.0152)	
training:	Epoch: [70][198/204]	Loss 0.0146 (0.0152)	
training:	Epoch: [70][199/204]	Loss 0.0038 (0.0151)	
training:	Epoch: [70][200/204]	Loss 0.0047 (0.0151)	
training:	Epoch: [70][201/204]	Loss 0.0085 (0.0151)	
training:	Epoch: [70][202/204]	Loss 0.0037 (0.0150)	
training:	Epoch: [70][203/204]	Loss 0.0034 (0.0149)	
training:	Epoch: [70][204/204]	Loss 0.0126 (0.0149)	
Training:	 Loss: 0.0149

Training:	 ACC: 0.9969 0.9969 0.9979 0.9959
Validation:	 ACC: 0.7781 0.7790 0.7984 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1351
Pretraining:	Epoch 71/500
----------
training:	Epoch: [71][1/204]	Loss 0.0034 (0.0034)	
training:	Epoch: [71][2/204]	Loss 0.0030 (0.0032)	
training:	Epoch: [71][3/204]	Loss 0.0042 (0.0035)	
training:	Epoch: [71][4/204]	Loss 0.1388 (0.0374)	
training:	Epoch: [71][5/204]	Loss 0.0032 (0.0305)	
training:	Epoch: [71][6/204]	Loss 0.0090 (0.0269)	
training:	Epoch: [71][7/204]	Loss 0.0440 (0.0294)	
training:	Epoch: [71][8/204]	Loss 0.0027 (0.0260)	
training:	Epoch: [71][9/204]	Loss 0.0075 (0.0240)	
training:	Epoch: [71][10/204]	Loss 0.0040 (0.0220)	
training:	Epoch: [71][11/204]	Loss 0.0037 (0.0203)	
training:	Epoch: [71][12/204]	Loss 0.0022 (0.0188)	
training:	Epoch: [71][13/204]	Loss 0.0040 (0.0177)	
training:	Epoch: [71][14/204]	Loss 0.0072 (0.0169)	
training:	Epoch: [71][15/204]	Loss 0.0030 (0.0160)	
training:	Epoch: [71][16/204]	Loss 0.0024 (0.0151)	
training:	Epoch: [71][17/204]	Loss 0.0078 (0.0147)	
training:	Epoch: [71][18/204]	Loss 0.0029 (0.0141)	
training:	Epoch: [71][19/204]	Loss 0.0046 (0.0136)	
training:	Epoch: [71][20/204]	Loss 0.0024 (0.0130)	
training:	Epoch: [71][21/204]	Loss 0.0038 (0.0126)	
training:	Epoch: [71][22/204]	Loss 0.0032 (0.0121)	
training:	Epoch: [71][23/204]	Loss 0.0040 (0.0118)	
training:	Epoch: [71][24/204]	Loss 0.0033 (0.0114)	
training:	Epoch: [71][25/204]	Loss 0.0025 (0.0111)	
training:	Epoch: [71][26/204]	Loss 0.0039 (0.0108)	
training:	Epoch: [71][27/204]	Loss 0.0021 (0.0105)	
training:	Epoch: [71][28/204]	Loss 0.0042 (0.0102)	
training:	Epoch: [71][29/204]	Loss 0.0028 (0.0100)	
training:	Epoch: [71][30/204]	Loss 0.0040 (0.0098)	
training:	Epoch: [71][31/204]	Loss 0.0149 (0.0100)	
training:	Epoch: [71][32/204]	Loss 0.0031 (0.0097)	
training:	Epoch: [71][33/204]	Loss 0.0062 (0.0096)	
training:	Epoch: [71][34/204]	Loss 0.0020 (0.0094)	
training:	Epoch: [71][35/204]	Loss 0.0027 (0.0092)	
training:	Epoch: [71][36/204]	Loss 0.0026 (0.0090)	
training:	Epoch: [71][37/204]	Loss 0.0029 (0.0089)	
training:	Epoch: [71][38/204]	Loss 0.0034 (0.0087)	
training:	Epoch: [71][39/204]	Loss 0.0036 (0.0086)	
training:	Epoch: [71][40/204]	Loss 0.0056 (0.0085)	
training:	Epoch: [71][41/204]	Loss 0.0083 (0.0085)	
training:	Epoch: [71][42/204]	Loss 0.0029 (0.0084)	
training:	Epoch: [71][43/204]	Loss 0.0032 (0.0083)	
training:	Epoch: [71][44/204]	Loss 0.0031 (0.0081)	
training:	Epoch: [71][45/204]	Loss 0.0022 (0.0080)	
training:	Epoch: [71][46/204]	Loss 0.0053 (0.0080)	
training:	Epoch: [71][47/204]	Loss 0.0026 (0.0078)	
training:	Epoch: [71][48/204]	Loss 0.1452 (0.0107)	
training:	Epoch: [71][49/204]	Loss 0.0037 (0.0106)	
training:	Epoch: [71][50/204]	Loss 0.0680 (0.0117)	
training:	Epoch: [71][51/204]	Loss 0.0031 (0.0115)	
training:	Epoch: [71][52/204]	Loss 0.0035 (0.0114)	
training:	Epoch: [71][53/204]	Loss 0.0067 (0.0113)	
training:	Epoch: [71][54/204]	Loss 0.1701 (0.0142)	
training:	Epoch: [71][55/204]	Loss 0.0038 (0.0141)	
training:	Epoch: [71][56/204]	Loss 0.0052 (0.0139)	
training:	Epoch: [71][57/204]	Loss 0.0024 (0.0137)	
training:	Epoch: [71][58/204]	Loss 0.0050 (0.0135)	
training:	Epoch: [71][59/204]	Loss 0.0038 (0.0134)	
training:	Epoch: [71][60/204]	Loss 0.0040 (0.0132)	
training:	Epoch: [71][61/204]	Loss 0.0346 (0.0136)	
training:	Epoch: [71][62/204]	Loss 0.0047 (0.0134)	
training:	Epoch: [71][63/204]	Loss 0.0055 (0.0133)	
training:	Epoch: [71][64/204]	Loss 0.0066 (0.0132)	
training:	Epoch: [71][65/204]	Loss 0.0650 (0.0140)	
training:	Epoch: [71][66/204]	Loss 0.0052 (0.0139)	
training:	Epoch: [71][67/204]	Loss 0.0019 (0.0137)	
training:	Epoch: [71][68/204]	Loss 0.0029 (0.0135)	
training:	Epoch: [71][69/204]	Loss 0.0063 (0.0134)	
training:	Epoch: [71][70/204]	Loss 0.0029 (0.0133)	
training:	Epoch: [71][71/204]	Loss 0.0026 (0.0131)	
training:	Epoch: [71][72/204]	Loss 0.0492 (0.0136)	
training:	Epoch: [71][73/204]	Loss 0.0066 (0.0135)	
training:	Epoch: [71][74/204]	Loss 0.0033 (0.0134)	
training:	Epoch: [71][75/204]	Loss 0.0068 (0.0133)	
training:	Epoch: [71][76/204]	Loss 0.0029 (0.0132)	
training:	Epoch: [71][77/204]	Loss 0.0027 (0.0130)	
training:	Epoch: [71][78/204]	Loss 0.0037 (0.0129)	
training:	Epoch: [71][79/204]	Loss 0.0066 (0.0128)	
training:	Epoch: [71][80/204]	Loss 0.0084 (0.0128)	
training:	Epoch: [71][81/204]	Loss 0.0037 (0.0127)	
training:	Epoch: [71][82/204]	Loss 0.0055 (0.0126)	
training:	Epoch: [71][83/204]	Loss 0.0033 (0.0125)	
training:	Epoch: [71][84/204]	Loss 0.0062 (0.0124)	
training:	Epoch: [71][85/204]	Loss 0.0024 (0.0123)	
training:	Epoch: [71][86/204]	Loss 0.0039 (0.0122)	
training:	Epoch: [71][87/204]	Loss 0.0073 (0.0121)	
training:	Epoch: [71][88/204]	Loss 0.0034 (0.0120)	
training:	Epoch: [71][89/204]	Loss 0.0033 (0.0119)	
training:	Epoch: [71][90/204]	Loss 0.0044 (0.0118)	
training:	Epoch: [71][91/204]	Loss 0.0030 (0.0117)	
training:	Epoch: [71][92/204]	Loss 0.2329 (0.0141)	
training:	Epoch: [71][93/204]	Loss 0.0038 (0.0140)	
training:	Epoch: [71][94/204]	Loss 0.0022 (0.0139)	
training:	Epoch: [71][95/204]	Loss 0.0026 (0.0138)	
training:	Epoch: [71][96/204]	Loss 0.0059 (0.0137)	
training:	Epoch: [71][97/204]	Loss 0.0155 (0.0137)	
training:	Epoch: [71][98/204]	Loss 0.0028 (0.0136)	
training:	Epoch: [71][99/204]	Loss 0.0042 (0.0135)	
training:	Epoch: [71][100/204]	Loss 0.0031 (0.0134)	
training:	Epoch: [71][101/204]	Loss 0.0047 (0.0133)	
training:	Epoch: [71][102/204]	Loss 0.0038 (0.0132)	
training:	Epoch: [71][103/204]	Loss 0.0026 (0.0131)	
training:	Epoch: [71][104/204]	Loss 0.0019 (0.0130)	
training:	Epoch: [71][105/204]	Loss 0.0392 (0.0133)	
training:	Epoch: [71][106/204]	Loss 0.0039 (0.0132)	
training:	Epoch: [71][107/204]	Loss 0.0050 (0.0131)	
training:	Epoch: [71][108/204]	Loss 0.0237 (0.0132)	
training:	Epoch: [71][109/204]	Loss 0.0022 (0.0131)	
training:	Epoch: [71][110/204]	Loss 0.0088 (0.0131)	
training:	Epoch: [71][111/204]	Loss 0.0054 (0.0130)	
training:	Epoch: [71][112/204]	Loss 0.0033 (0.0129)	
training:	Epoch: [71][113/204]	Loss 0.0032 (0.0128)	
training:	Epoch: [71][114/204]	Loss 0.0043 (0.0128)	
training:	Epoch: [71][115/204]	Loss 0.0028 (0.0127)	
training:	Epoch: [71][116/204]	Loss 0.0587 (0.0131)	
training:	Epoch: [71][117/204]	Loss 0.0048 (0.0130)	
training:	Epoch: [71][118/204]	Loss 0.0032 (0.0129)	
training:	Epoch: [71][119/204]	Loss 0.0020 (0.0128)	
training:	Epoch: [71][120/204]	Loss 0.0034 (0.0127)	
training:	Epoch: [71][121/204]	Loss 0.0034 (0.0127)	
training:	Epoch: [71][122/204]	Loss 0.0044 (0.0126)	
training:	Epoch: [71][123/204]	Loss 0.0025 (0.0125)	
training:	Epoch: [71][124/204]	Loss 0.0035 (0.0124)	
training:	Epoch: [71][125/204]	Loss 0.0019 (0.0124)	
training:	Epoch: [71][126/204]	Loss 0.0039 (0.0123)	
training:	Epoch: [71][127/204]	Loss 0.0023 (0.0122)	
training:	Epoch: [71][128/204]	Loss 0.0035 (0.0121)	
training:	Epoch: [71][129/204]	Loss 0.0048 (0.0121)	
training:	Epoch: [71][130/204]	Loss 0.0028 (0.0120)	
training:	Epoch: [71][131/204]	Loss 0.0030 (0.0119)	
training:	Epoch: [71][132/204]	Loss 0.1185 (0.0128)	
training:	Epoch: [71][133/204]	Loss 0.0023 (0.0127)	
training:	Epoch: [71][134/204]	Loss 0.0189 (0.0127)	
training:	Epoch: [71][135/204]	Loss 0.0058 (0.0127)	
training:	Epoch: [71][136/204]	Loss 0.0026 (0.0126)	
training:	Epoch: [71][137/204]	Loss 0.0055 (0.0125)	
training:	Epoch: [71][138/204]	Loss 0.0036 (0.0125)	
training:	Epoch: [71][139/204]	Loss 0.1318 (0.0133)	
training:	Epoch: [71][140/204]	Loss 0.0043 (0.0133)	
training:	Epoch: [71][141/204]	Loss 0.0836 (0.0138)	
training:	Epoch: [71][142/204]	Loss 0.0084 (0.0137)	
training:	Epoch: [71][143/204]	Loss 0.0041 (0.0137)	
training:	Epoch: [71][144/204]	Loss 0.0220 (0.0137)	
training:	Epoch: [71][145/204]	Loss 0.0023 (0.0136)	
training:	Epoch: [71][146/204]	Loss 0.0057 (0.0136)	
training:	Epoch: [71][147/204]	Loss 0.0023 (0.0135)	
training:	Epoch: [71][148/204]	Loss 0.0042 (0.0135)	
training:	Epoch: [71][149/204]	Loss 0.0053 (0.0134)	
training:	Epoch: [71][150/204]	Loss 0.0078 (0.0134)	
training:	Epoch: [71][151/204]	Loss 0.0044 (0.0133)	
training:	Epoch: [71][152/204]	Loss 0.0049 (0.0132)	
training:	Epoch: [71][153/204]	Loss 0.0053 (0.0132)	
training:	Epoch: [71][154/204]	Loss 0.0025 (0.0131)	
training:	Epoch: [71][155/204]	Loss 0.0034 (0.0131)	
training:	Epoch: [71][156/204]	Loss 0.0030 (0.0130)	
training:	Epoch: [71][157/204]	Loss 0.0023 (0.0129)	
training:	Epoch: [71][158/204]	Loss 0.0028 (0.0129)	
training:	Epoch: [71][159/204]	Loss 0.0070 (0.0128)	
training:	Epoch: [71][160/204]	Loss 0.0118 (0.0128)	
training:	Epoch: [71][161/204]	Loss 0.0060 (0.0128)	
training:	Epoch: [71][162/204]	Loss 0.0028 (0.0127)	
training:	Epoch: [71][163/204]	Loss 0.0025 (0.0127)	
training:	Epoch: [71][164/204]	Loss 0.0039 (0.0126)	
training:	Epoch: [71][165/204]	Loss 0.0028 (0.0125)	
training:	Epoch: [71][166/204]	Loss 0.0020 (0.0125)	
training:	Epoch: [71][167/204]	Loss 0.0042 (0.0124)	
training:	Epoch: [71][168/204]	Loss 0.0586 (0.0127)	
training:	Epoch: [71][169/204]	Loss 0.0042 (0.0127)	
training:	Epoch: [71][170/204]	Loss 0.0053 (0.0126)	
training:	Epoch: [71][171/204]	Loss 0.0031 (0.0126)	
training:	Epoch: [71][172/204]	Loss 0.0068 (0.0125)	
training:	Epoch: [71][173/204]	Loss 0.0478 (0.0127)	
training:	Epoch: [71][174/204]	Loss 0.0029 (0.0127)	
training:	Epoch: [71][175/204]	Loss 0.0054 (0.0126)	
training:	Epoch: [71][176/204]	Loss 0.0083 (0.0126)	
training:	Epoch: [71][177/204]	Loss 0.0031 (0.0125)	
training:	Epoch: [71][178/204]	Loss 0.0047 (0.0125)	
training:	Epoch: [71][179/204]	Loss 0.0024 (0.0124)	
training:	Epoch: [71][180/204]	Loss 0.0027 (0.0124)	
training:	Epoch: [71][181/204]	Loss 0.0042 (0.0123)	
training:	Epoch: [71][182/204]	Loss 0.1036 (0.0128)	
training:	Epoch: [71][183/204]	Loss 0.0390 (0.0130)	
training:	Epoch: [71][184/204]	Loss 0.0032 (0.0129)	
training:	Epoch: [71][185/204]	Loss 0.0036 (0.0129)	
training:	Epoch: [71][186/204]	Loss 0.0035 (0.0128)	
training:	Epoch: [71][187/204]	Loss 0.0163 (0.0129)	
training:	Epoch: [71][188/204]	Loss 0.0023 (0.0128)	
training:	Epoch: [71][189/204]	Loss 0.0021 (0.0127)	
training:	Epoch: [71][190/204]	Loss 0.0063 (0.0127)	
training:	Epoch: [71][191/204]	Loss 0.0126 (0.0127)	
training:	Epoch: [71][192/204]	Loss 0.0048 (0.0127)	
training:	Epoch: [71][193/204]	Loss 0.0027 (0.0126)	
training:	Epoch: [71][194/204]	Loss 0.0096 (0.0126)	
training:	Epoch: [71][195/204]	Loss 0.0053 (0.0126)	
training:	Epoch: [71][196/204]	Loss 0.0054 (0.0125)	
training:	Epoch: [71][197/204]	Loss 0.0039 (0.0125)	
training:	Epoch: [71][198/204]	Loss 0.0041 (0.0124)	
training:	Epoch: [71][199/204]	Loss 0.0044 (0.0124)	
training:	Epoch: [71][200/204]	Loss 0.0021 (0.0123)	
training:	Epoch: [71][201/204]	Loss 0.0067 (0.0123)	
training:	Epoch: [71][202/204]	Loss 0.0040 (0.0123)	
training:	Epoch: [71][203/204]	Loss 0.0033 (0.0122)	
training:	Epoch: [71][204/204]	Loss 0.0030 (0.0122)	
Training:	 Loss: 0.0122

Training:	 ACC: 0.9972 0.9972 0.9982 0.9962
Validation:	 ACC: 0.7775 0.7785 0.7984 0.7567
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1478
Pretraining:	Epoch 72/500
----------
training:	Epoch: [72][1/204]	Loss 0.0027 (0.0027)	
training:	Epoch: [72][2/204]	Loss 0.0137 (0.0082)	
training:	Epoch: [72][3/204]	Loss 0.0482 (0.0216)	
training:	Epoch: [72][4/204]	Loss 0.0137 (0.0196)	
training:	Epoch: [72][5/204]	Loss 0.0030 (0.0163)	
training:	Epoch: [72][6/204]	Loss 0.0022 (0.0139)	
training:	Epoch: [72][7/204]	Loss 0.0036 (0.0125)	
training:	Epoch: [72][8/204]	Loss 0.0029 (0.0113)	
training:	Epoch: [72][9/204]	Loss 0.0024 (0.0103)	
training:	Epoch: [72][10/204]	Loss 0.0020 (0.0094)	
training:	Epoch: [72][11/204]	Loss 0.0023 (0.0088)	
training:	Epoch: [72][12/204]	Loss 0.0060 (0.0086)	
training:	Epoch: [72][13/204]	Loss 0.0073 (0.0085)	
training:	Epoch: [72][14/204]	Loss 0.0030 (0.0081)	
training:	Epoch: [72][15/204]	Loss 0.0031 (0.0077)	
training:	Epoch: [72][16/204]	Loss 0.0026 (0.0074)	
training:	Epoch: [72][17/204]	Loss 0.0020 (0.0071)	
training:	Epoch: [72][18/204]	Loss 0.0022 (0.0068)	
training:	Epoch: [72][19/204]	Loss 0.0317 (0.0081)	
training:	Epoch: [72][20/204]	Loss 0.0062 (0.0080)	
training:	Epoch: [72][21/204]	Loss 0.0025 (0.0078)	
training:	Epoch: [72][22/204]	Loss 0.0019 (0.0075)	
training:	Epoch: [72][23/204]	Loss 0.0031 (0.0073)	
training:	Epoch: [72][24/204]	Loss 0.0022 (0.0071)	
training:	Epoch: [72][25/204]	Loss 0.1345 (0.0122)	
training:	Epoch: [72][26/204]	Loss 0.0043 (0.0119)	
training:	Epoch: [72][27/204]	Loss 0.0027 (0.0116)	
training:	Epoch: [72][28/204]	Loss 0.0019 (0.0112)	
training:	Epoch: [72][29/204]	Loss 0.0023 (0.0109)	
training:	Epoch: [72][30/204]	Loss 0.0031 (0.0106)	
training:	Epoch: [72][31/204]	Loss 0.0027 (0.0104)	
training:	Epoch: [72][32/204]	Loss 0.0030 (0.0102)	
training:	Epoch: [72][33/204]	Loss 0.0023 (0.0099)	
training:	Epoch: [72][34/204]	Loss 0.0018 (0.0097)	
training:	Epoch: [72][35/204]	Loss 0.0070 (0.0096)	
training:	Epoch: [72][36/204]	Loss 0.0028 (0.0094)	
training:	Epoch: [72][37/204]	Loss 0.0931 (0.0117)	
training:	Epoch: [72][38/204]	Loss 0.0020 (0.0114)	
training:	Epoch: [72][39/204]	Loss 0.0024 (0.0112)	
training:	Epoch: [72][40/204]	Loss 0.0023 (0.0110)	
training:	Epoch: [72][41/204]	Loss 0.0021 (0.0108)	
training:	Epoch: [72][42/204]	Loss 0.0036 (0.0106)	
training:	Epoch: [72][43/204]	Loss 0.0029 (0.0104)	
training:	Epoch: [72][44/204]	Loss 0.0035 (0.0102)	
training:	Epoch: [72][45/204]	Loss 0.0026 (0.0101)	
training:	Epoch: [72][46/204]	Loss 0.0029 (0.0099)	
training:	Epoch: [72][47/204]	Loss 0.0032 (0.0098)	
training:	Epoch: [72][48/204]	Loss 0.0082 (0.0097)	
training:	Epoch: [72][49/204]	Loss 0.0027 (0.0096)	
training:	Epoch: [72][50/204]	Loss 0.0055 (0.0095)	
training:	Epoch: [72][51/204]	Loss 0.0035 (0.0094)	
training:	Epoch: [72][52/204]	Loss 0.0123 (0.0095)	
training:	Epoch: [72][53/204]	Loss 0.0024 (0.0093)	
training:	Epoch: [72][54/204]	Loss 0.0131 (0.0094)	
training:	Epoch: [72][55/204]	Loss 0.0035 (0.0093)	
training:	Epoch: [72][56/204]	Loss 0.0057 (0.0092)	
training:	Epoch: [72][57/204]	Loss 0.0615 (0.0101)	
training:	Epoch: [72][58/204]	Loss 0.0020 (0.0100)	
training:	Epoch: [72][59/204]	Loss 0.0018 (0.0099)	
training:	Epoch: [72][60/204]	Loss 0.0043 (0.0098)	
training:	Epoch: [72][61/204]	Loss 0.0066 (0.0097)	
training:	Epoch: [72][62/204]	Loss 0.0028 (0.0096)	
training:	Epoch: [72][63/204]	Loss 0.0020 (0.0095)	
training:	Epoch: [72][64/204]	Loss 0.1331 (0.0114)	
training:	Epoch: [72][65/204]	Loss 0.0024 (0.0113)	
training:	Epoch: [72][66/204]	Loss 0.0040 (0.0112)	
training:	Epoch: [72][67/204]	Loss 0.0024 (0.0110)	
training:	Epoch: [72][68/204]	Loss 0.0061 (0.0110)	
training:	Epoch: [72][69/204]	Loss 0.0065 (0.0109)	
training:	Epoch: [72][70/204]	Loss 0.0025 (0.0108)	
training:	Epoch: [72][71/204]	Loss 0.0445 (0.0113)	
training:	Epoch: [72][72/204]	Loss 0.0028 (0.0111)	
training:	Epoch: [72][73/204]	Loss 0.0395 (0.0115)	
training:	Epoch: [72][74/204]	Loss 0.0024 (0.0114)	
training:	Epoch: [72][75/204]	Loss 0.1999 (0.0139)	
training:	Epoch: [72][76/204]	Loss 0.0051 (0.0138)	
training:	Epoch: [72][77/204]	Loss 0.0033 (0.0137)	
training:	Epoch: [72][78/204]	Loss 0.0041 (0.0135)	
training:	Epoch: [72][79/204]	Loss 0.0034 (0.0134)	
training:	Epoch: [72][80/204]	Loss 0.0040 (0.0133)	
training:	Epoch: [72][81/204]	Loss 0.0036 (0.0132)	
training:	Epoch: [72][82/204]	Loss 0.0021 (0.0130)	
training:	Epoch: [72][83/204]	Loss 0.0087 (0.0130)	
training:	Epoch: [72][84/204]	Loss 0.0200 (0.0131)	
training:	Epoch: [72][85/204]	Loss 0.0894 (0.0140)	
training:	Epoch: [72][86/204]	Loss 0.0046 (0.0139)	
training:	Epoch: [72][87/204]	Loss 0.0391 (0.0141)	
training:	Epoch: [72][88/204]	Loss 0.0055 (0.0141)	
training:	Epoch: [72][89/204]	Loss 0.0059 (0.0140)	
training:	Epoch: [72][90/204]	Loss 0.0028 (0.0138)	
training:	Epoch: [72][91/204]	Loss 0.0269 (0.0140)	
training:	Epoch: [72][92/204]	Loss 0.0607 (0.0145)	
training:	Epoch: [72][93/204]	Loss 0.0170 (0.0145)	
training:	Epoch: [72][94/204]	Loss 0.0078 (0.0144)	
training:	Epoch: [72][95/204]	Loss 0.0032 (0.0143)	
training:	Epoch: [72][96/204]	Loss 0.0051 (0.0142)	
training:	Epoch: [72][97/204]	Loss 0.0061 (0.0141)	
training:	Epoch: [72][98/204]	Loss 0.0097 (0.0141)	
training:	Epoch: [72][99/204]	Loss 0.0033 (0.0140)	
training:	Epoch: [72][100/204]	Loss 0.0035 (0.0139)	
training:	Epoch: [72][101/204]	Loss 0.0049 (0.0138)	
training:	Epoch: [72][102/204]	Loss 0.0030 (0.0137)	
training:	Epoch: [72][103/204]	Loss 0.0057 (0.0136)	
training:	Epoch: [72][104/204]	Loss 0.0095 (0.0136)	
training:	Epoch: [72][105/204]	Loss 0.0096 (0.0135)	
training:	Epoch: [72][106/204]	Loss 0.0047 (0.0135)	
training:	Epoch: [72][107/204]	Loss 0.0029 (0.0134)	
training:	Epoch: [72][108/204]	Loss 0.0022 (0.0132)	
training:	Epoch: [72][109/204]	Loss 0.0034 (0.0132)	
training:	Epoch: [72][110/204]	Loss 0.0065 (0.0131)	
training:	Epoch: [72][111/204]	Loss 0.0148 (0.0131)	
training:	Epoch: [72][112/204]	Loss 0.0030 (0.0130)	
training:	Epoch: [72][113/204]	Loss 0.0060 (0.0130)	
training:	Epoch: [72][114/204]	Loss 0.0064 (0.0129)	
training:	Epoch: [72][115/204]	Loss 0.0050 (0.0128)	
training:	Epoch: [72][116/204]	Loss 0.0064 (0.0128)	
training:	Epoch: [72][117/204]	Loss 0.0024 (0.0127)	
training:	Epoch: [72][118/204]	Loss 0.0040 (0.0126)	
training:	Epoch: [72][119/204]	Loss 0.0059 (0.0126)	
training:	Epoch: [72][120/204]	Loss 0.0191 (0.0126)	
training:	Epoch: [72][121/204]	Loss 0.0027 (0.0125)	
training:	Epoch: [72][122/204]	Loss 0.0076 (0.0125)	
training:	Epoch: [72][123/204]	Loss 0.0035 (0.0124)	
training:	Epoch: [72][124/204]	Loss 0.0022 (0.0123)	
training:	Epoch: [72][125/204]	Loss 0.0076 (0.0123)	
training:	Epoch: [72][126/204]	Loss 0.0029 (0.0122)	
training:	Epoch: [72][127/204]	Loss 0.0415 (0.0125)	
training:	Epoch: [72][128/204]	Loss 0.0040 (0.0124)	
training:	Epoch: [72][129/204]	Loss 0.0042 (0.0123)	
training:	Epoch: [72][130/204]	Loss 0.0331 (0.0125)	
training:	Epoch: [72][131/204]	Loss 0.0038 (0.0124)	
training:	Epoch: [72][132/204]	Loss 0.0028 (0.0123)	
training:	Epoch: [72][133/204]	Loss 0.0057 (0.0123)	
training:	Epoch: [72][134/204]	Loss 0.0091 (0.0123)	
training:	Epoch: [72][135/204]	Loss 0.0044 (0.0122)	
training:	Epoch: [72][136/204]	Loss 0.0024 (0.0121)	
training:	Epoch: [72][137/204]	Loss 0.0065 (0.0121)	
training:	Epoch: [72][138/204]	Loss 0.0034 (0.0120)	
training:	Epoch: [72][139/204]	Loss 0.0029 (0.0120)	
training:	Epoch: [72][140/204]	Loss 0.0027 (0.0119)	
training:	Epoch: [72][141/204]	Loss 0.0024 (0.0118)	
training:	Epoch: [72][142/204]	Loss 0.0029 (0.0118)	
training:	Epoch: [72][143/204]	Loss 0.0029 (0.0117)	
training:	Epoch: [72][144/204]	Loss 0.0329 (0.0119)	
training:	Epoch: [72][145/204]	Loss 0.0068 (0.0118)	
training:	Epoch: [72][146/204]	Loss 0.0032 (0.0118)	
training:	Epoch: [72][147/204]	Loss 0.0020 (0.0117)	
training:	Epoch: [72][148/204]	Loss 0.0026 (0.0116)	
training:	Epoch: [72][149/204]	Loss 0.0074 (0.0116)	
training:	Epoch: [72][150/204]	Loss 0.0069 (0.0116)	
training:	Epoch: [72][151/204]	Loss 0.0035 (0.0115)	
training:	Epoch: [72][152/204]	Loss 0.0046 (0.0115)	
training:	Epoch: [72][153/204]	Loss 0.0024 (0.0114)	
training:	Epoch: [72][154/204]	Loss 0.0073 (0.0114)	
training:	Epoch: [72][155/204]	Loss 0.0032 (0.0113)	
training:	Epoch: [72][156/204]	Loss 0.0028 (0.0113)	
training:	Epoch: [72][157/204]	Loss 0.0021 (0.0112)	
training:	Epoch: [72][158/204]	Loss 0.0025 (0.0112)	
training:	Epoch: [72][159/204]	Loss 0.0033 (0.0111)	
training:	Epoch: [72][160/204]	Loss 0.0048 (0.0111)	
training:	Epoch: [72][161/204]	Loss 0.0018 (0.0110)	
training:	Epoch: [72][162/204]	Loss 0.0017 (0.0110)	
training:	Epoch: [72][163/204]	Loss 0.0019 (0.0109)	
training:	Epoch: [72][164/204]	Loss 0.0208 (0.0110)	
training:	Epoch: [72][165/204]	Loss 0.0301 (0.0111)	
training:	Epoch: [72][166/204]	Loss 0.0217 (0.0112)	
training:	Epoch: [72][167/204]	Loss 0.0025 (0.0111)	
training:	Epoch: [72][168/204]	Loss 0.0019 (0.0110)	
training:	Epoch: [72][169/204]	Loss 0.0058 (0.0110)	
training:	Epoch: [72][170/204]	Loss 0.0028 (0.0110)	
training:	Epoch: [72][171/204]	Loss 0.0030 (0.0109)	
training:	Epoch: [72][172/204]	Loss 0.0033 (0.0109)	
training:	Epoch: [72][173/204]	Loss 0.0052 (0.0108)	
training:	Epoch: [72][174/204]	Loss 0.0066 (0.0108)	
training:	Epoch: [72][175/204]	Loss 0.0146 (0.0108)	
training:	Epoch: [72][176/204]	Loss 0.0020 (0.0108)	
training:	Epoch: [72][177/204]	Loss 0.0359 (0.0109)	
training:	Epoch: [72][178/204]	Loss 0.0020 (0.0109)	
training:	Epoch: [72][179/204]	Loss 0.0022 (0.0108)	
training:	Epoch: [72][180/204]	Loss 0.0026 (0.0108)	
training:	Epoch: [72][181/204]	Loss 0.0023 (0.0107)	
training:	Epoch: [72][182/204]	Loss 0.2178 (0.0119)	
training:	Epoch: [72][183/204]	Loss 0.0029 (0.0118)	
training:	Epoch: [72][184/204]	Loss 0.0019 (0.0118)	
training:	Epoch: [72][185/204]	Loss 0.0032 (0.0117)	
training:	Epoch: [72][186/204]	Loss 0.0029 (0.0117)	
training:	Epoch: [72][187/204]	Loss 0.0031 (0.0116)	
training:	Epoch: [72][188/204]	Loss 0.0023 (0.0116)	
training:	Epoch: [72][189/204]	Loss 0.0040 (0.0115)	
training:	Epoch: [72][190/204]	Loss 0.0017 (0.0115)	
training:	Epoch: [72][191/204]	Loss 0.0060 (0.0115)	
training:	Epoch: [72][192/204]	Loss 0.0047 (0.0114)	
training:	Epoch: [72][193/204]	Loss 0.0037 (0.0114)	
training:	Epoch: [72][194/204]	Loss 0.0019 (0.0113)	
training:	Epoch: [72][195/204]	Loss 0.0085 (0.0113)	
training:	Epoch: [72][196/204]	Loss 0.0021 (0.0113)	
training:	Epoch: [72][197/204]	Loss 0.0079 (0.0113)	
training:	Epoch: [72][198/204]	Loss 0.0026 (0.0112)	
training:	Epoch: [72][199/204]	Loss 0.0031 (0.0112)	
training:	Epoch: [72][200/204]	Loss 0.0039 (0.0111)	
training:	Epoch: [72][201/204]	Loss 0.0025 (0.0111)	
training:	Epoch: [72][202/204]	Loss 0.0054 (0.0111)	
training:	Epoch: [72][203/204]	Loss 0.0032 (0.0110)	
training:	Epoch: [72][204/204]	Loss 0.0015 (0.0110)	
Training:	 Loss: 0.0110

Training:	 ACC: 0.9977 0.9977 0.9985 0.9968
Validation:	 ACC: 0.7819 0.7828 0.8004 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1588
Pretraining:	Epoch 73/500
----------
training:	Epoch: [73][1/204]	Loss 0.0018 (0.0018)	
training:	Epoch: [73][2/204]	Loss 0.0035 (0.0026)	
training:	Epoch: [73][3/204]	Loss 0.0028 (0.0027)	
training:	Epoch: [73][4/204]	Loss 0.0023 (0.0026)	
training:	Epoch: [73][5/204]	Loss 0.0018 (0.0024)	
training:	Epoch: [73][6/204]	Loss 0.0030 (0.0025)	
training:	Epoch: [73][7/204]	Loss 0.0023 (0.0025)	
training:	Epoch: [73][8/204]	Loss 0.0018 (0.0024)	
training:	Epoch: [73][9/204]	Loss 0.0019 (0.0023)	
training:	Epoch: [73][10/204]	Loss 0.0023 (0.0023)	
training:	Epoch: [73][11/204]	Loss 0.0031 (0.0024)	
training:	Epoch: [73][12/204]	Loss 0.0032 (0.0025)	
training:	Epoch: [73][13/204]	Loss 0.0025 (0.0025)	
training:	Epoch: [73][14/204]	Loss 0.0019 (0.0024)	
training:	Epoch: [73][15/204]	Loss 0.0026 (0.0024)	
training:	Epoch: [73][16/204]	Loss 0.1020 (0.0087)	
training:	Epoch: [73][17/204]	Loss 0.0031 (0.0083)	
training:	Epoch: [73][18/204]	Loss 0.0031 (0.0080)	
training:	Epoch: [73][19/204]	Loss 0.0023 (0.0077)	
training:	Epoch: [73][20/204]	Loss 0.0025 (0.0075)	
training:	Epoch: [73][21/204]	Loss 0.0020 (0.0072)	
training:	Epoch: [73][22/204]	Loss 0.0410 (0.0088)	
training:	Epoch: [73][23/204]	Loss 0.0149 (0.0090)	
training:	Epoch: [73][24/204]	Loss 0.0034 (0.0088)	
training:	Epoch: [73][25/204]	Loss 0.0039 (0.0086)	
training:	Epoch: [73][26/204]	Loss 0.0118 (0.0087)	
training:	Epoch: [73][27/204]	Loss 0.0035 (0.0085)	
training:	Epoch: [73][28/204]	Loss 0.0024 (0.0083)	
training:	Epoch: [73][29/204]	Loss 0.0026 (0.0081)	
training:	Epoch: [73][30/204]	Loss 0.0035 (0.0080)	
training:	Epoch: [73][31/204]	Loss 0.0016 (0.0077)	
training:	Epoch: [73][32/204]	Loss 0.0032 (0.0076)	
training:	Epoch: [73][33/204]	Loss 0.0021 (0.0074)	
training:	Epoch: [73][34/204]	Loss 0.0057 (0.0074)	
training:	Epoch: [73][35/204]	Loss 0.0024 (0.0072)	
training:	Epoch: [73][36/204]	Loss 0.0018 (0.0071)	
training:	Epoch: [73][37/204]	Loss 0.0057 (0.0071)	
training:	Epoch: [73][38/204]	Loss 0.0036 (0.0070)	
training:	Epoch: [73][39/204]	Loss 0.0028 (0.0069)	
training:	Epoch: [73][40/204]	Loss 0.0026 (0.0068)	
training:	Epoch: [73][41/204]	Loss 0.0051 (0.0067)	
training:	Epoch: [73][42/204]	Loss 0.0024 (0.0066)	
training:	Epoch: [73][43/204]	Loss 0.0067 (0.0066)	
training:	Epoch: [73][44/204]	Loss 0.0017 (0.0065)	
training:	Epoch: [73][45/204]	Loss 0.0025 (0.0064)	
training:	Epoch: [73][46/204]	Loss 0.0023 (0.0063)	
training:	Epoch: [73][47/204]	Loss 0.1920 (0.0103)	
training:	Epoch: [73][48/204]	Loss 0.0076 (0.0102)	
training:	Epoch: [73][49/204]	Loss 0.0027 (0.0101)	
training:	Epoch: [73][50/204]	Loss 0.0019 (0.0099)	
training:	Epoch: [73][51/204]	Loss 0.0018 (0.0097)	
training:	Epoch: [73][52/204]	Loss 0.0020 (0.0096)	
training:	Epoch: [73][53/204]	Loss 0.0181 (0.0098)	
training:	Epoch: [73][54/204]	Loss 0.0585 (0.0107)	
training:	Epoch: [73][55/204]	Loss 0.0025 (0.0105)	
training:	Epoch: [73][56/204]	Loss 0.0100 (0.0105)	
training:	Epoch: [73][57/204]	Loss 0.0017 (0.0103)	
training:	Epoch: [73][58/204]	Loss 0.0022 (0.0102)	
training:	Epoch: [73][59/204]	Loss 0.0020 (0.0101)	
training:	Epoch: [73][60/204]	Loss 0.0020 (0.0099)	
training:	Epoch: [73][61/204]	Loss 0.0023 (0.0098)	
training:	Epoch: [73][62/204]	Loss 0.1294 (0.0117)	
training:	Epoch: [73][63/204]	Loss 0.0027 (0.0116)	
training:	Epoch: [73][64/204]	Loss 0.0551 (0.0123)	
training:	Epoch: [73][65/204]	Loss 0.0782 (0.0133)	
training:	Epoch: [73][66/204]	Loss 0.0029 (0.0131)	
training:	Epoch: [73][67/204]	Loss 0.0023 (0.0130)	
training:	Epoch: [73][68/204]	Loss 0.0804 (0.0140)	
training:	Epoch: [73][69/204]	Loss 0.0031 (0.0138)	
training:	Epoch: [73][70/204]	Loss 0.0063 (0.0137)	
training:	Epoch: [73][71/204]	Loss 0.0033 (0.0135)	
training:	Epoch: [73][72/204]	Loss 0.0028 (0.0134)	
training:	Epoch: [73][73/204]	Loss 0.0046 (0.0133)	
training:	Epoch: [73][74/204]	Loss 0.0023 (0.0131)	
training:	Epoch: [73][75/204]	Loss 0.0074 (0.0131)	
training:	Epoch: [73][76/204]	Loss 0.0048 (0.0129)	
training:	Epoch: [73][77/204]	Loss 0.0040 (0.0128)	
training:	Epoch: [73][78/204]	Loss 0.0179 (0.0129)	
training:	Epoch: [73][79/204]	Loss 0.0128 (0.0129)	
training:	Epoch: [73][80/204]	Loss 0.0039 (0.0128)	
training:	Epoch: [73][81/204]	Loss 0.0066 (0.0127)	
training:	Epoch: [73][82/204]	Loss 0.0031 (0.0126)	
training:	Epoch: [73][83/204]	Loss 0.0031 (0.0125)	
training:	Epoch: [73][84/204]	Loss 0.0149 (0.0125)	
training:	Epoch: [73][85/204]	Loss 0.0308 (0.0127)	
training:	Epoch: [73][86/204]	Loss 0.0029 (0.0126)	
training:	Epoch: [73][87/204]	Loss 0.0028 (0.0125)	
training:	Epoch: [73][88/204]	Loss 0.0087 (0.0124)	
training:	Epoch: [73][89/204]	Loss 0.0023 (0.0123)	
training:	Epoch: [73][90/204]	Loss 0.0020 (0.0122)	
training:	Epoch: [73][91/204]	Loss 0.0031 (0.0121)	
training:	Epoch: [73][92/204]	Loss 0.1049 (0.0131)	
training:	Epoch: [73][93/204]	Loss 0.0020 (0.0130)	
training:	Epoch: [73][94/204]	Loss 0.0024 (0.0129)	
training:	Epoch: [73][95/204]	Loss 0.0039 (0.0128)	
training:	Epoch: [73][96/204]	Loss 0.0034 (0.0127)	
training:	Epoch: [73][97/204]	Loss 0.0027 (0.0126)	
training:	Epoch: [73][98/204]	Loss 0.0039 (0.0125)	
training:	Epoch: [73][99/204]	Loss 0.0034 (0.0124)	
training:	Epoch: [73][100/204]	Loss 0.0034 (0.0123)	
training:	Epoch: [73][101/204]	Loss 0.0067 (0.0123)	
training:	Epoch: [73][102/204]	Loss 0.0060 (0.0122)	
training:	Epoch: [73][103/204]	Loss 0.0038 (0.0121)	
training:	Epoch: [73][104/204]	Loss 0.0037 (0.0120)	
training:	Epoch: [73][105/204]	Loss 0.0311 (0.0122)	
training:	Epoch: [73][106/204]	Loss 0.0067 (0.0122)	
training:	Epoch: [73][107/204]	Loss 0.0056 (0.0121)	
training:	Epoch: [73][108/204]	Loss 0.0020 (0.0120)	
training:	Epoch: [73][109/204]	Loss 0.0055 (0.0120)	
training:	Epoch: [73][110/204]	Loss 0.0017 (0.0119)	
training:	Epoch: [73][111/204]	Loss 0.0034 (0.0118)	
training:	Epoch: [73][112/204]	Loss 0.0090 (0.0118)	
training:	Epoch: [73][113/204]	Loss 0.0020 (0.0117)	
training:	Epoch: [73][114/204]	Loss 0.0018 (0.0116)	
training:	Epoch: [73][115/204]	Loss 0.0015 (0.0115)	
training:	Epoch: [73][116/204]	Loss 0.0046 (0.0114)	
training:	Epoch: [73][117/204]	Loss 0.0041 (0.0114)	
training:	Epoch: [73][118/204]	Loss 0.0060 (0.0113)	
training:	Epoch: [73][119/204]	Loss 0.0090 (0.0113)	
training:	Epoch: [73][120/204]	Loss 0.1057 (0.0121)	
training:	Epoch: [73][121/204]	Loss 0.0041 (0.0120)	
training:	Epoch: [73][122/204]	Loss 0.0062 (0.0120)	
training:	Epoch: [73][123/204]	Loss 0.0028 (0.0119)	
training:	Epoch: [73][124/204]	Loss 0.0240 (0.0120)	
training:	Epoch: [73][125/204]	Loss 0.0614 (0.0124)	
training:	Epoch: [73][126/204]	Loss 0.0031 (0.0123)	
training:	Epoch: [73][127/204]	Loss 0.0022 (0.0123)	
training:	Epoch: [73][128/204]	Loss 0.0082 (0.0122)	
training:	Epoch: [73][129/204]	Loss 0.0048 (0.0122)	
training:	Epoch: [73][130/204]	Loss 0.0020 (0.0121)	
training:	Epoch: [73][131/204]	Loss 0.0019 (0.0120)	
training:	Epoch: [73][132/204]	Loss 0.0434 (0.0122)	
training:	Epoch: [73][133/204]	Loss 0.0039 (0.0122)	
training:	Epoch: [73][134/204]	Loss 0.0029 (0.0121)	
training:	Epoch: [73][135/204]	Loss 0.0024 (0.0120)	
training:	Epoch: [73][136/204]	Loss 0.0277 (0.0122)	
training:	Epoch: [73][137/204]	Loss 0.0023 (0.0121)	
training:	Epoch: [73][138/204]	Loss 0.0103 (0.0121)	
training:	Epoch: [73][139/204]	Loss 0.0054 (0.0120)	
training:	Epoch: [73][140/204]	Loss 0.0027 (0.0120)	
training:	Epoch: [73][141/204]	Loss 0.0019 (0.0119)	
training:	Epoch: [73][142/204]	Loss 0.0050 (0.0118)	
training:	Epoch: [73][143/204]	Loss 0.0033 (0.0118)	
training:	Epoch: [73][144/204]	Loss 0.0033 (0.0117)	
training:	Epoch: [73][145/204]	Loss 0.0043 (0.0117)	
training:	Epoch: [73][146/204]	Loss 0.0490 (0.0119)	
training:	Epoch: [73][147/204]	Loss 0.0016 (0.0119)	
training:	Epoch: [73][148/204]	Loss 0.0048 (0.0118)	
training:	Epoch: [73][149/204]	Loss 0.0025 (0.0117)	
training:	Epoch: [73][150/204]	Loss 0.0025 (0.0117)	
training:	Epoch: [73][151/204]	Loss 0.0042 (0.0116)	
training:	Epoch: [73][152/204]	Loss 0.0020 (0.0116)	
training:	Epoch: [73][153/204]	Loss 0.0072 (0.0115)	
training:	Epoch: [73][154/204]	Loss 0.0218 (0.0116)	
training:	Epoch: [73][155/204]	Loss 0.0089 (0.0116)	
training:	Epoch: [73][156/204]	Loss 0.0032 (0.0115)	
training:	Epoch: [73][157/204]	Loss 0.0018 (0.0115)	
training:	Epoch: [73][158/204]	Loss 0.0015 (0.0114)	
training:	Epoch: [73][159/204]	Loss 0.0022 (0.0114)	
training:	Epoch: [73][160/204]	Loss 0.0022 (0.0113)	
training:	Epoch: [73][161/204]	Loss 0.0072 (0.0113)	
training:	Epoch: [73][162/204]	Loss 0.0089 (0.0113)	
training:	Epoch: [73][163/204]	Loss 0.0022 (0.0112)	
training:	Epoch: [73][164/204]	Loss 0.0016 (0.0111)	
training:	Epoch: [73][165/204]	Loss 0.0023 (0.0111)	
training:	Epoch: [73][166/204]	Loss 0.0032 (0.0110)	
training:	Epoch: [73][167/204]	Loss 0.0024 (0.0110)	
training:	Epoch: [73][168/204]	Loss 0.0041 (0.0109)	
training:	Epoch: [73][169/204]	Loss 0.0020 (0.0109)	
training:	Epoch: [73][170/204]	Loss 0.0062 (0.0109)	
training:	Epoch: [73][171/204]	Loss 0.0126 (0.0109)	
training:	Epoch: [73][172/204]	Loss 0.0053 (0.0108)	
training:	Epoch: [73][173/204]	Loss 0.0020 (0.0108)	
training:	Epoch: [73][174/204]	Loss 0.0019 (0.0107)	
training:	Epoch: [73][175/204]	Loss 0.0026 (0.0107)	
training:	Epoch: [73][176/204]	Loss 0.0029 (0.0107)	
training:	Epoch: [73][177/204]	Loss 0.0038 (0.0106)	
training:	Epoch: [73][178/204]	Loss 0.0053 (0.0106)	
training:	Epoch: [73][179/204]	Loss 0.0020 (0.0105)	
training:	Epoch: [73][180/204]	Loss 0.0030 (0.0105)	
training:	Epoch: [73][181/204]	Loss 0.0020 (0.0104)	
training:	Epoch: [73][182/204]	Loss 0.0185 (0.0105)	
training:	Epoch: [73][183/204]	Loss 0.0018 (0.0104)	
training:	Epoch: [73][184/204]	Loss 0.0445 (0.0106)	
training:	Epoch: [73][185/204]	Loss 0.0029 (0.0106)	
training:	Epoch: [73][186/204]	Loss 0.0018 (0.0105)	
training:	Epoch: [73][187/204]	Loss 0.0017 (0.0105)	
training:	Epoch: [73][188/204]	Loss 0.0030 (0.0105)	
training:	Epoch: [73][189/204]	Loss 0.0021 (0.0104)	
training:	Epoch: [73][190/204]	Loss 0.0042 (0.0104)	
training:	Epoch: [73][191/204]	Loss 0.0073 (0.0104)	
training:	Epoch: [73][192/204]	Loss 0.0034 (0.0103)	
training:	Epoch: [73][193/204]	Loss 0.0028 (0.0103)	
training:	Epoch: [73][194/204]	Loss 0.0022 (0.0102)	
training:	Epoch: [73][195/204]	Loss 0.0028 (0.0102)	
training:	Epoch: [73][196/204]	Loss 0.0024 (0.0102)	
training:	Epoch: [73][197/204]	Loss 0.0027 (0.0101)	
training:	Epoch: [73][198/204]	Loss 0.0022 (0.0101)	
training:	Epoch: [73][199/204]	Loss 0.0364 (0.0102)	
training:	Epoch: [73][200/204]	Loss 0.0212 (0.0103)	
training:	Epoch: [73][201/204]	Loss 0.0035 (0.0102)	
training:	Epoch: [73][202/204]	Loss 0.0055 (0.0102)	
training:	Epoch: [73][203/204]	Loss 0.0060 (0.0102)	
training:	Epoch: [73][204/204]	Loss 0.0018 (0.0102)	
Training:	 Loss: 0.0101

Training:	 ACC: 0.9981 0.9982 0.9988 0.9974
Validation:	 ACC: 0.7786 0.7796 0.7994 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.1897
Pretraining:	Epoch 74/500
----------
training:	Epoch: [74][1/204]	Loss 0.0018 (0.0018)	
training:	Epoch: [74][2/204]	Loss 0.0079 (0.0049)	
training:	Epoch: [74][3/204]	Loss 0.0032 (0.0043)	
training:	Epoch: [74][4/204]	Loss 0.0025 (0.0039)	
training:	Epoch: [74][5/204]	Loss 0.0023 (0.0036)	
training:	Epoch: [74][6/204]	Loss 0.0019 (0.0033)	
training:	Epoch: [74][7/204]	Loss 0.0080 (0.0040)	
training:	Epoch: [74][8/204]	Loss 0.0036 (0.0039)	
training:	Epoch: [74][9/204]	Loss 0.0086 (0.0044)	
training:	Epoch: [74][10/204]	Loss 0.0025 (0.0042)	
training:	Epoch: [74][11/204]	Loss 0.0036 (0.0042)	
training:	Epoch: [74][12/204]	Loss 0.0024 (0.0040)	
training:	Epoch: [74][13/204]	Loss 0.0018 (0.0039)	
training:	Epoch: [74][14/204]	Loss 0.0020 (0.0037)	
training:	Epoch: [74][15/204]	Loss 0.0029 (0.0037)	
training:	Epoch: [74][16/204]	Loss 0.0020 (0.0036)	
training:	Epoch: [74][17/204]	Loss 0.0025 (0.0035)	
training:	Epoch: [74][18/204]	Loss 0.0021 (0.0034)	
training:	Epoch: [74][19/204]	Loss 0.0030 (0.0034)	
training:	Epoch: [74][20/204]	Loss 0.0328 (0.0049)	
training:	Epoch: [74][21/204]	Loss 0.0058 (0.0049)	
training:	Epoch: [74][22/204]	Loss 0.0046 (0.0049)	
training:	Epoch: [74][23/204]	Loss 0.0016 (0.0048)	
training:	Epoch: [74][24/204]	Loss 0.0026 (0.0047)	
training:	Epoch: [74][25/204]	Loss 0.0036 (0.0046)	
training:	Epoch: [74][26/204]	Loss 0.0016 (0.0045)	
training:	Epoch: [74][27/204]	Loss 0.0132 (0.0048)	
training:	Epoch: [74][28/204]	Loss 0.0036 (0.0048)	
training:	Epoch: [74][29/204]	Loss 0.0072 (0.0049)	
training:	Epoch: [74][30/204]	Loss 0.0018 (0.0048)	
training:	Epoch: [74][31/204]	Loss 0.0054 (0.0048)	
training:	Epoch: [74][32/204]	Loss 0.0059 (0.0048)	
training:	Epoch: [74][33/204]	Loss 0.0019 (0.0047)	
training:	Epoch: [74][34/204]	Loss 0.0019 (0.0047)	
training:	Epoch: [74][35/204]	Loss 0.0026 (0.0046)	
training:	Epoch: [74][36/204]	Loss 0.0032 (0.0046)	
training:	Epoch: [74][37/204]	Loss 0.0037 (0.0045)	
training:	Epoch: [74][38/204]	Loss 0.0016 (0.0045)	
training:	Epoch: [74][39/204]	Loss 0.0017 (0.0044)	
training:	Epoch: [74][40/204]	Loss 0.0099 (0.0045)	
training:	Epoch: [74][41/204]	Loss 0.0023 (0.0045)	
training:	Epoch: [74][42/204]	Loss 0.0018 (0.0044)	
training:	Epoch: [74][43/204]	Loss 0.0021 (0.0044)	
training:	Epoch: [74][44/204]	Loss 0.0016 (0.0043)	
training:	Epoch: [74][45/204]	Loss 0.0016 (0.0042)	
training:	Epoch: [74][46/204]	Loss 0.0019 (0.0042)	
training:	Epoch: [74][47/204]	Loss 0.0023 (0.0041)	
training:	Epoch: [74][48/204]	Loss 0.0028 (0.0041)	
training:	Epoch: [74][49/204]	Loss 0.0185 (0.0044)	
training:	Epoch: [74][50/204]	Loss 0.0022 (0.0044)	
training:	Epoch: [74][51/204]	Loss 0.0020 (0.0043)	
training:	Epoch: [74][52/204]	Loss 0.0028 (0.0043)	
training:	Epoch: [74][53/204]	Loss 0.0020 (0.0042)	
training:	Epoch: [74][54/204]	Loss 0.0029 (0.0042)	
training:	Epoch: [74][55/204]	Loss 0.0101 (0.0043)	
training:	Epoch: [74][56/204]	Loss 0.0023 (0.0043)	
training:	Epoch: [74][57/204]	Loss 0.0019 (0.0043)	
training:	Epoch: [74][58/204]	Loss 0.0074 (0.0043)	
training:	Epoch: [74][59/204]	Loss 0.0048 (0.0043)	
training:	Epoch: [74][60/204]	Loss 0.0106 (0.0044)	
training:	Epoch: [74][61/204]	Loss 0.0022 (0.0044)	
training:	Epoch: [74][62/204]	Loss 0.0015 (0.0043)	
training:	Epoch: [74][63/204]	Loss 0.0027 (0.0043)	
training:	Epoch: [74][64/204]	Loss 0.0020 (0.0043)	
training:	Epoch: [74][65/204]	Loss 0.0023 (0.0042)	
training:	Epoch: [74][66/204]	Loss 0.0020 (0.0042)	
training:	Epoch: [74][67/204]	Loss 0.0017 (0.0042)	
training:	Epoch: [74][68/204]	Loss 0.0021 (0.0041)	
training:	Epoch: [74][69/204]	Loss 0.0018 (0.0041)	
training:	Epoch: [74][70/204]	Loss 0.0024 (0.0041)	
training:	Epoch: [74][71/204]	Loss 0.0052 (0.0041)	
training:	Epoch: [74][72/204]	Loss 0.0021 (0.0041)	
training:	Epoch: [74][73/204]	Loss 0.0020 (0.0040)	
training:	Epoch: [74][74/204]	Loss 0.0016 (0.0040)	
training:	Epoch: [74][75/204]	Loss 0.0024 (0.0040)	
training:	Epoch: [74][76/204]	Loss 0.0015 (0.0040)	
training:	Epoch: [74][77/204]	Loss 0.0029 (0.0039)	
training:	Epoch: [74][78/204]	Loss 0.0020 (0.0039)	
training:	Epoch: [74][79/204]	Loss 0.0017 (0.0039)	
training:	Epoch: [74][80/204]	Loss 0.0140 (0.0040)	
training:	Epoch: [74][81/204]	Loss 0.0019 (0.0040)	
training:	Epoch: [74][82/204]	Loss 0.0016 (0.0040)	
training:	Epoch: [74][83/204]	Loss 0.0033 (0.0039)	
training:	Epoch: [74][84/204]	Loss 0.0018 (0.0039)	
training:	Epoch: [74][85/204]	Loss 0.0027 (0.0039)	
training:	Epoch: [74][86/204]	Loss 0.0022 (0.0039)	
training:	Epoch: [74][87/204]	Loss 0.1858 (0.0060)	
training:	Epoch: [74][88/204]	Loss 0.0020 (0.0059)	
training:	Epoch: [74][89/204]	Loss 0.0265 (0.0062)	
training:	Epoch: [74][90/204]	Loss 0.0019 (0.0061)	
training:	Epoch: [74][91/204]	Loss 0.0816 (0.0069)	
training:	Epoch: [74][92/204]	Loss 0.1146 (0.0081)	
training:	Epoch: [74][93/204]	Loss 0.0024 (0.0081)	
training:	Epoch: [74][94/204]	Loss 0.0022 (0.0080)	
training:	Epoch: [74][95/204]	Loss 0.0024 (0.0079)	
training:	Epoch: [74][96/204]	Loss 0.0070 (0.0079)	
training:	Epoch: [74][97/204]	Loss 0.0018 (0.0079)	
training:	Epoch: [74][98/204]	Loss 0.0033 (0.0078)	
training:	Epoch: [74][99/204]	Loss 0.0022 (0.0078)	
training:	Epoch: [74][100/204]	Loss 0.0028 (0.0077)	
training:	Epoch: [74][101/204]	Loss 0.0023 (0.0077)	
training:	Epoch: [74][102/204]	Loss 0.0019 (0.0076)	
training:	Epoch: [74][103/204]	Loss 0.0221 (0.0077)	
training:	Epoch: [74][104/204]	Loss 0.0832 (0.0085)	
training:	Epoch: [74][105/204]	Loss 0.0030 (0.0084)	
training:	Epoch: [74][106/204]	Loss 0.0075 (0.0084)	
training:	Epoch: [74][107/204]	Loss 0.0022 (0.0083)	
training:	Epoch: [74][108/204]	Loss 0.0032 (0.0083)	
training:	Epoch: [74][109/204]	Loss 0.0041 (0.0083)	
training:	Epoch: [74][110/204]	Loss 0.0037 (0.0082)	
training:	Epoch: [74][111/204]	Loss 0.0034 (0.0082)	
training:	Epoch: [74][112/204]	Loss 0.0044 (0.0081)	
training:	Epoch: [74][113/204]	Loss 0.0016 (0.0081)	
training:	Epoch: [74][114/204]	Loss 0.0046 (0.0081)	
training:	Epoch: [74][115/204]	Loss 0.0045 (0.0080)	
training:	Epoch: [74][116/204]	Loss 0.0194 (0.0081)	
training:	Epoch: [74][117/204]	Loss 0.0036 (0.0081)	
training:	Epoch: [74][118/204]	Loss 0.0074 (0.0081)	
training:	Epoch: [74][119/204]	Loss 0.0032 (0.0080)	
training:	Epoch: [74][120/204]	Loss 0.0037 (0.0080)	
training:	Epoch: [74][121/204]	Loss 0.0020 (0.0080)	
training:	Epoch: [74][122/204]	Loss 0.0063 (0.0079)	
training:	Epoch: [74][123/204]	Loss 0.0024 (0.0079)	
training:	Epoch: [74][124/204]	Loss 0.0210 (0.0080)	
training:	Epoch: [74][125/204]	Loss 0.0028 (0.0080)	
training:	Epoch: [74][126/204]	Loss 0.0030 (0.0079)	
training:	Epoch: [74][127/204]	Loss 0.0247 (0.0081)	
training:	Epoch: [74][128/204]	Loss 0.0018 (0.0080)	
training:	Epoch: [74][129/204]	Loss 0.0031 (0.0080)	
training:	Epoch: [74][130/204]	Loss 0.0021 (0.0079)	
training:	Epoch: [74][131/204]	Loss 0.0358 (0.0081)	
training:	Epoch: [74][132/204]	Loss 0.0020 (0.0081)	
training:	Epoch: [74][133/204]	Loss 0.0197 (0.0082)	
training:	Epoch: [74][134/204]	Loss 0.0055 (0.0082)	
training:	Epoch: [74][135/204]	Loss 0.0021 (0.0081)	
training:	Epoch: [74][136/204]	Loss 0.0334 (0.0083)	
training:	Epoch: [74][137/204]	Loss 0.0024 (0.0083)	
training:	Epoch: [74][138/204]	Loss 0.0029 (0.0082)	
training:	Epoch: [74][139/204]	Loss 0.0016 (0.0082)	
training:	Epoch: [74][140/204]	Loss 0.0040 (0.0081)	
training:	Epoch: [74][141/204]	Loss 0.0024 (0.0081)	
training:	Epoch: [74][142/204]	Loss 0.0026 (0.0081)	
training:	Epoch: [74][143/204]	Loss 0.0035 (0.0080)	
training:	Epoch: [74][144/204]	Loss 0.0240 (0.0081)	
training:	Epoch: [74][145/204]	Loss 0.0015 (0.0081)	
training:	Epoch: [74][146/204]	Loss 0.0020 (0.0080)	
training:	Epoch: [74][147/204]	Loss 0.0021 (0.0080)	
training:	Epoch: [74][148/204]	Loss 0.0030 (0.0080)	
training:	Epoch: [74][149/204]	Loss 0.0031 (0.0079)	
training:	Epoch: [74][150/204]	Loss 0.0187 (0.0080)	
training:	Epoch: [74][151/204]	Loss 0.0015 (0.0080)	
training:	Epoch: [74][152/204]	Loss 0.0068 (0.0080)	
training:	Epoch: [74][153/204]	Loss 0.0126 (0.0080)	
training:	Epoch: [74][154/204]	Loss 0.0189 (0.0081)	
training:	Epoch: [74][155/204]	Loss 0.0020 (0.0080)	
training:	Epoch: [74][156/204]	Loss 0.0196 (0.0081)	
training:	Epoch: [74][157/204]	Loss 0.0027 (0.0081)	
training:	Epoch: [74][158/204]	Loss 0.0031 (0.0080)	
training:	Epoch: [74][159/204]	Loss 0.0058 (0.0080)	
training:	Epoch: [74][160/204]	Loss 0.0017 (0.0080)	
training:	Epoch: [74][161/204]	Loss 0.0029 (0.0079)	
training:	Epoch: [74][162/204]	Loss 0.0051 (0.0079)	
training:	Epoch: [74][163/204]	Loss 0.0044 (0.0079)	
training:	Epoch: [74][164/204]	Loss 0.0038 (0.0079)	
training:	Epoch: [74][165/204]	Loss 0.0017 (0.0078)	
training:	Epoch: [74][166/204]	Loss 0.0106 (0.0079)	
training:	Epoch: [74][167/204]	Loss 0.0118 (0.0079)	
training:	Epoch: [74][168/204]	Loss 0.0180 (0.0079)	
training:	Epoch: [74][169/204]	Loss 0.0118 (0.0080)	
training:	Epoch: [74][170/204]	Loss 0.0019 (0.0079)	
training:	Epoch: [74][171/204]	Loss 0.0019 (0.0079)	
training:	Epoch: [74][172/204]	Loss 0.0070 (0.0079)	
training:	Epoch: [74][173/204]	Loss 0.0026 (0.0079)	
training:	Epoch: [74][174/204]	Loss 0.0032 (0.0078)	
training:	Epoch: [74][175/204]	Loss 0.0017 (0.0078)	
training:	Epoch: [74][176/204]	Loss 0.0036 (0.0078)	
training:	Epoch: [74][177/204]	Loss 0.0041 (0.0078)	
training:	Epoch: [74][178/204]	Loss 0.0025 (0.0077)	
training:	Epoch: [74][179/204]	Loss 0.1065 (0.0083)	
training:	Epoch: [74][180/204]	Loss 0.0042 (0.0083)	
training:	Epoch: [74][181/204]	Loss 0.0325 (0.0084)	
training:	Epoch: [74][182/204]	Loss 0.0017 (0.0084)	
training:	Epoch: [74][183/204]	Loss 0.0018 (0.0083)	
training:	Epoch: [74][184/204]	Loss 0.0021 (0.0083)	
training:	Epoch: [74][185/204]	Loss 0.0016 (0.0082)	
training:	Epoch: [74][186/204]	Loss 0.0026 (0.0082)	
training:	Epoch: [74][187/204]	Loss 0.0026 (0.0082)	
training:	Epoch: [74][188/204]	Loss 0.0022 (0.0082)	
training:	Epoch: [74][189/204]	Loss 0.0014 (0.0081)	
training:	Epoch: [74][190/204]	Loss 0.0040 (0.0081)	
training:	Epoch: [74][191/204]	Loss 0.0016 (0.0081)	
training:	Epoch: [74][192/204]	Loss 0.0021 (0.0080)	
training:	Epoch: [74][193/204]	Loss 0.0037 (0.0080)	
training:	Epoch: [74][194/204]	Loss 0.0017 (0.0080)	
training:	Epoch: [74][195/204]	Loss 0.0049 (0.0080)	
training:	Epoch: [74][196/204]	Loss 0.0023 (0.0079)	
training:	Epoch: [74][197/204]	Loss 0.0877 (0.0083)	
training:	Epoch: [74][198/204]	Loss 0.0016 (0.0083)	
training:	Epoch: [74][199/204]	Loss 0.0022 (0.0083)	
training:	Epoch: [74][200/204]	Loss 0.0032 (0.0082)	
training:	Epoch: [74][201/204]	Loss 0.0020 (0.0082)	
training:	Epoch: [74][202/204]	Loss 0.0047 (0.0082)	
training:	Epoch: [74][203/204]	Loss 0.0066 (0.0082)	
training:	Epoch: [74][204/204]	Loss 0.0014 (0.0082)	
Training:	 Loss: 0.0081

Training:	 ACC: 0.9992 0.9992 0.9991 0.9994
Validation:	 ACC: 0.7756 0.7758 0.7810 0.7702
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.2223
Pretraining:	Epoch 75/500
----------
training:	Epoch: [75][1/204]	Loss 0.0023 (0.0023)	
training:	Epoch: [75][2/204]	Loss 0.0084 (0.0053)	
training:	Epoch: [75][3/204]	Loss 0.0023 (0.0043)	
training:	Epoch: [75][4/204]	Loss 0.0018 (0.0037)	
training:	Epoch: [75][5/204]	Loss 0.0014 (0.0032)	
training:	Epoch: [75][6/204]	Loss 0.0032 (0.0032)	
training:	Epoch: [75][7/204]	Loss 0.0016 (0.0030)	
training:	Epoch: [75][8/204]	Loss 0.0032 (0.0030)	
training:	Epoch: [75][9/204]	Loss 0.0068 (0.0034)	
training:	Epoch: [75][10/204]	Loss 0.0046 (0.0036)	
training:	Epoch: [75][11/204]	Loss 0.0031 (0.0035)	
training:	Epoch: [75][12/204]	Loss 0.0015 (0.0034)	
training:	Epoch: [75][13/204]	Loss 0.0021 (0.0033)	
training:	Epoch: [75][14/204]	Loss 0.0023 (0.0032)	
training:	Epoch: [75][15/204]	Loss 0.0027 (0.0032)	
training:	Epoch: [75][16/204]	Loss 0.0023 (0.0031)	
training:	Epoch: [75][17/204]	Loss 0.0019 (0.0030)	
training:	Epoch: [75][18/204]	Loss 0.0027 (0.0030)	
training:	Epoch: [75][19/204]	Loss 0.0024 (0.0030)	
training:	Epoch: [75][20/204]	Loss 0.0065 (0.0031)	
training:	Epoch: [75][21/204]	Loss 0.0020 (0.0031)	
training:	Epoch: [75][22/204]	Loss 0.0018 (0.0030)	
training:	Epoch: [75][23/204]	Loss 0.0055 (0.0031)	
training:	Epoch: [75][24/204]	Loss 0.0026 (0.0031)	
training:	Epoch: [75][25/204]	Loss 0.0025 (0.0031)	
training:	Epoch: [75][26/204]	Loss 0.0094 (0.0033)	
training:	Epoch: [75][27/204]	Loss 0.0015 (0.0033)	
training:	Epoch: [75][28/204]	Loss 0.0035 (0.0033)	
training:	Epoch: [75][29/204]	Loss 0.0091 (0.0035)	
training:	Epoch: [75][30/204]	Loss 0.0030 (0.0035)	
training:	Epoch: [75][31/204]	Loss 0.0016 (0.0034)	
training:	Epoch: [75][32/204]	Loss 0.0027 (0.0034)	
training:	Epoch: [75][33/204]	Loss 0.0032 (0.0034)	
training:	Epoch: [75][34/204]	Loss 0.0020 (0.0033)	
training:	Epoch: [75][35/204]	Loss 0.0037 (0.0033)	
training:	Epoch: [75][36/204]	Loss 0.0017 (0.0033)	
training:	Epoch: [75][37/204]	Loss 0.0030 (0.0033)	
training:	Epoch: [75][38/204]	Loss 0.0020 (0.0033)	
training:	Epoch: [75][39/204]	Loss 0.0019 (0.0032)	
training:	Epoch: [75][40/204]	Loss 0.0014 (0.0032)	
training:	Epoch: [75][41/204]	Loss 0.0028 (0.0032)	
training:	Epoch: [75][42/204]	Loss 0.0027 (0.0032)	
training:	Epoch: [75][43/204]	Loss 0.0098 (0.0033)	
training:	Epoch: [75][44/204]	Loss 0.0020 (0.0033)	
training:	Epoch: [75][45/204]	Loss 0.0019 (0.0032)	
training:	Epoch: [75][46/204]	Loss 0.0035 (0.0033)	
training:	Epoch: [75][47/204]	Loss 0.0022 (0.0032)	
training:	Epoch: [75][48/204]	Loss 0.0017 (0.0032)	
training:	Epoch: [75][49/204]	Loss 0.0016 (0.0032)	
training:	Epoch: [75][50/204]	Loss 0.0117 (0.0033)	
training:	Epoch: [75][51/204]	Loss 0.0029 (0.0033)	
training:	Epoch: [75][52/204]	Loss 0.0156 (0.0036)	
training:	Epoch: [75][53/204]	Loss 0.0021 (0.0035)	
training:	Epoch: [75][54/204]	Loss 0.0043 (0.0035)	
training:	Epoch: [75][55/204]	Loss 0.0029 (0.0035)	
training:	Epoch: [75][56/204]	Loss 0.0016 (0.0035)	
training:	Epoch: [75][57/204]	Loss 0.0016 (0.0035)	
training:	Epoch: [75][58/204]	Loss 0.0016 (0.0034)	
training:	Epoch: [75][59/204]	Loss 0.0055 (0.0035)	
training:	Epoch: [75][60/204]	Loss 0.0313 (0.0039)	
training:	Epoch: [75][61/204]	Loss 0.0016 (0.0039)	
training:	Epoch: [75][62/204]	Loss 0.1943 (0.0070)	
training:	Epoch: [75][63/204]	Loss 0.0021 (0.0069)	
training:	Epoch: [75][64/204]	Loss 0.0026 (0.0068)	
training:	Epoch: [75][65/204]	Loss 0.0026 (0.0068)	
training:	Epoch: [75][66/204]	Loss 0.0017 (0.0067)	
training:	Epoch: [75][67/204]	Loss 0.0053 (0.0067)	
training:	Epoch: [75][68/204]	Loss 0.0068 (0.0067)	
training:	Epoch: [75][69/204]	Loss 0.0021 (0.0066)	
training:	Epoch: [75][70/204]	Loss 0.0014 (0.0065)	
training:	Epoch: [75][71/204]	Loss 0.0018 (0.0065)	
training:	Epoch: [75][72/204]	Loss 0.0017 (0.0064)	
training:	Epoch: [75][73/204]	Loss 0.0018 (0.0063)	
training:	Epoch: [75][74/204]	Loss 0.0026 (0.0063)	
training:	Epoch: [75][75/204]	Loss 0.0021 (0.0062)	
training:	Epoch: [75][76/204]	Loss 0.0014 (0.0062)	
training:	Epoch: [75][77/204]	Loss 0.0139 (0.0063)	
training:	Epoch: [75][78/204]	Loss 0.0262 (0.0065)	
training:	Epoch: [75][79/204]	Loss 0.0016 (0.0065)	
training:	Epoch: [75][80/204]	Loss 0.0015 (0.0064)	
training:	Epoch: [75][81/204]	Loss 0.0014 (0.0063)	
training:	Epoch: [75][82/204]	Loss 0.0019 (0.0063)	
training:	Epoch: [75][83/204]	Loss 0.0015 (0.0062)	
training:	Epoch: [75][84/204]	Loss 0.0032 (0.0062)	
training:	Epoch: [75][85/204]	Loss 0.0021 (0.0061)	
training:	Epoch: [75][86/204]	Loss 0.0019 (0.0061)	
training:	Epoch: [75][87/204]	Loss 0.0025 (0.0060)	
training:	Epoch: [75][88/204]	Loss 0.0015 (0.0060)	
training:	Epoch: [75][89/204]	Loss 0.0069 (0.0060)	
training:	Epoch: [75][90/204]	Loss 0.0031 (0.0060)	
training:	Epoch: [75][91/204]	Loss 0.0022 (0.0059)	
training:	Epoch: [75][92/204]	Loss 0.0029 (0.0059)	
training:	Epoch: [75][93/204]	Loss 0.0146 (0.0060)	
training:	Epoch: [75][94/204]	Loss 0.0017 (0.0059)	
training:	Epoch: [75][95/204]	Loss 0.0016 (0.0059)	
training:	Epoch: [75][96/204]	Loss 0.0035 (0.0059)	
training:	Epoch: [75][97/204]	Loss 0.0050 (0.0059)	
training:	Epoch: [75][98/204]	Loss 0.0027 (0.0058)	
training:	Epoch: [75][99/204]	Loss 0.0017 (0.0058)	
training:	Epoch: [75][100/204]	Loss 0.0018 (0.0057)	
training:	Epoch: [75][101/204]	Loss 0.0013 (0.0057)	
training:	Epoch: [75][102/204]	Loss 0.0051 (0.0057)	
training:	Epoch: [75][103/204]	Loss 0.0016 (0.0057)	
training:	Epoch: [75][104/204]	Loss 0.0017 (0.0056)	
training:	Epoch: [75][105/204]	Loss 0.0018 (0.0056)	
training:	Epoch: [75][106/204]	Loss 0.0022 (0.0056)	
training:	Epoch: [75][107/204]	Loss 0.0597 (0.0061)	
training:	Epoch: [75][108/204]	Loss 0.0016 (0.0060)	
training:	Epoch: [75][109/204]	Loss 0.0016 (0.0060)	
training:	Epoch: [75][110/204]	Loss 0.0015 (0.0059)	
training:	Epoch: [75][111/204]	Loss 0.0027 (0.0059)	
training:	Epoch: [75][112/204]	Loss 0.0035 (0.0059)	
training:	Epoch: [75][113/204]	Loss 0.0014 (0.0058)	
training:	Epoch: [75][114/204]	Loss 0.0025 (0.0058)	
training:	Epoch: [75][115/204]	Loss 0.0078 (0.0058)	
training:	Epoch: [75][116/204]	Loss 0.0017 (0.0058)	
training:	Epoch: [75][117/204]	Loss 0.0113 (0.0058)	
training:	Epoch: [75][118/204]	Loss 0.0014 (0.0058)	
training:	Epoch: [75][119/204]	Loss 0.0017 (0.0058)	
training:	Epoch: [75][120/204]	Loss 0.0088 (0.0058)	
training:	Epoch: [75][121/204]	Loss 0.0022 (0.0058)	
training:	Epoch: [75][122/204]	Loss 0.0017 (0.0057)	
training:	Epoch: [75][123/204]	Loss 0.0184 (0.0058)	
training:	Epoch: [75][124/204]	Loss 0.0027 (0.0058)	
training:	Epoch: [75][125/204]	Loss 0.0021 (0.0058)	
training:	Epoch: [75][126/204]	Loss 0.0875 (0.0064)	
training:	Epoch: [75][127/204]	Loss 0.0024 (0.0064)	
training:	Epoch: [75][128/204]	Loss 0.0100 (0.0064)	
training:	Epoch: [75][129/204]	Loss 0.0015 (0.0064)	
training:	Epoch: [75][130/204]	Loss 0.0019 (0.0064)	
training:	Epoch: [75][131/204]	Loss 0.0032 (0.0063)	
training:	Epoch: [75][132/204]	Loss 0.0020 (0.0063)	
training:	Epoch: [75][133/204]	Loss 0.0046 (0.0063)	
training:	Epoch: [75][134/204]	Loss 0.0029 (0.0063)	
training:	Epoch: [75][135/204]	Loss 0.0014 (0.0062)	
training:	Epoch: [75][136/204]	Loss 0.0031 (0.0062)	
training:	Epoch: [75][137/204]	Loss 0.0321 (0.0064)	
training:	Epoch: [75][138/204]	Loss 0.0046 (0.0064)	
training:	Epoch: [75][139/204]	Loss 0.0016 (0.0063)	
training:	Epoch: [75][140/204]	Loss 0.0040 (0.0063)	
training:	Epoch: [75][141/204]	Loss 0.0289 (0.0065)	
training:	Epoch: [75][142/204]	Loss 0.0027 (0.0065)	
training:	Epoch: [75][143/204]	Loss 0.0019 (0.0064)	
training:	Epoch: [75][144/204]	Loss 0.0019 (0.0064)	
training:	Epoch: [75][145/204]	Loss 0.0037 (0.0064)	
training:	Epoch: [75][146/204]	Loss 0.0046 (0.0064)	
training:	Epoch: [75][147/204]	Loss 0.0028 (0.0063)	
training:	Epoch: [75][148/204]	Loss 0.0060 (0.0063)	
training:	Epoch: [75][149/204]	Loss 0.0022 (0.0063)	
training:	Epoch: [75][150/204]	Loss 0.0259 (0.0064)	
training:	Epoch: [75][151/204]	Loss 0.0153 (0.0065)	
training:	Epoch: [75][152/204]	Loss 0.0024 (0.0065)	
training:	Epoch: [75][153/204]	Loss 0.0019 (0.0064)	
training:	Epoch: [75][154/204]	Loss 0.0058 (0.0064)	
training:	Epoch: [75][155/204]	Loss 0.0602 (0.0068)	
training:	Epoch: [75][156/204]	Loss 0.0053 (0.0068)	
training:	Epoch: [75][157/204]	Loss 0.0016 (0.0067)	
training:	Epoch: [75][158/204]	Loss 0.0013 (0.0067)	
training:	Epoch: [75][159/204]	Loss 0.0054 (0.0067)	
training:	Epoch: [75][160/204]	Loss 0.0022 (0.0067)	
training:	Epoch: [75][161/204]	Loss 0.0227 (0.0068)	
training:	Epoch: [75][162/204]	Loss 0.0045 (0.0068)	
training:	Epoch: [75][163/204]	Loss 0.0072 (0.0068)	
training:	Epoch: [75][164/204]	Loss 0.0020 (0.0067)	
training:	Epoch: [75][165/204]	Loss 0.0016 (0.0067)	
training:	Epoch: [75][166/204]	Loss 0.0015 (0.0067)	
training:	Epoch: [75][167/204]	Loss 0.0032 (0.0066)	
training:	Epoch: [75][168/204]	Loss 0.0023 (0.0066)	
training:	Epoch: [75][169/204]	Loss 0.0043 (0.0066)	
training:	Epoch: [75][170/204]	Loss 0.0021 (0.0066)	
training:	Epoch: [75][171/204]	Loss 0.0037 (0.0066)	
training:	Epoch: [75][172/204]	Loss 0.0014 (0.0065)	
training:	Epoch: [75][173/204]	Loss 0.0018 (0.0065)	
training:	Epoch: [75][174/204]	Loss 0.0019 (0.0065)	
training:	Epoch: [75][175/204]	Loss 0.0083 (0.0065)	
training:	Epoch: [75][176/204]	Loss 0.0198 (0.0066)	
training:	Epoch: [75][177/204]	Loss 0.0050 (0.0066)	
training:	Epoch: [75][178/204]	Loss 0.0054 (0.0066)	
training:	Epoch: [75][179/204]	Loss 0.0022 (0.0065)	
training:	Epoch: [75][180/204]	Loss 0.0018 (0.0065)	
training:	Epoch: [75][181/204]	Loss 0.0028 (0.0065)	
training:	Epoch: [75][182/204]	Loss 0.0104 (0.0065)	
training:	Epoch: [75][183/204]	Loss 0.0177 (0.0066)	
training:	Epoch: [75][184/204]	Loss 0.0252 (0.0067)	
training:	Epoch: [75][185/204]	Loss 0.0029 (0.0066)	
training:	Epoch: [75][186/204]	Loss 0.0025 (0.0066)	
training:	Epoch: [75][187/204]	Loss 0.0155 (0.0067)	
training:	Epoch: [75][188/204]	Loss 0.0067 (0.0067)	
training:	Epoch: [75][189/204]	Loss 0.0017 (0.0066)	
training:	Epoch: [75][190/204]	Loss 0.0044 (0.0066)	
training:	Epoch: [75][191/204]	Loss 0.0025 (0.0066)	
training:	Epoch: [75][192/204]	Loss 0.0019 (0.0066)	
training:	Epoch: [75][193/204]	Loss 0.0021 (0.0066)	
training:	Epoch: [75][194/204]	Loss 0.0022 (0.0065)	
training:	Epoch: [75][195/204]	Loss 0.0020 (0.0065)	
training:	Epoch: [75][196/204]	Loss 0.0017 (0.0065)	
training:	Epoch: [75][197/204]	Loss 0.0016 (0.0065)	
training:	Epoch: [75][198/204]	Loss 0.0018 (0.0064)	
training:	Epoch: [75][199/204]	Loss 0.0016 (0.0064)	
training:	Epoch: [75][200/204]	Loss 0.0017 (0.0064)	
training:	Epoch: [75][201/204]	Loss 0.0022 (0.0064)	
training:	Epoch: [75][202/204]	Loss 0.0027 (0.0064)	
training:	Epoch: [75][203/204]	Loss 0.0016 (0.0063)	
training:	Epoch: [75][204/204]	Loss 0.0046 (0.0063)	
Training:	 Loss: 0.0063

Training:	 ACC: 0.9993 0.9992 0.9988 0.9997
Validation:	 ACC: 0.7831 0.7833 0.7881 0.7780
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.2282
Pretraining:	Epoch 76/500
----------
training:	Epoch: [76][1/204]	Loss 0.0016 (0.0016)	
training:	Epoch: [76][2/204]	Loss 0.0026 (0.0021)	
training:	Epoch: [76][3/204]	Loss 0.0062 (0.0035)	
training:	Epoch: [76][4/204]	Loss 0.0024 (0.0032)	
training:	Epoch: [76][5/204]	Loss 0.0016 (0.0029)	
training:	Epoch: [76][6/204]	Loss 0.0373 (0.0086)	
training:	Epoch: [76][7/204]	Loss 0.0159 (0.0097)	
training:	Epoch: [76][8/204]	Loss 0.0019 (0.0087)	
training:	Epoch: [76][9/204]	Loss 0.0085 (0.0087)	
training:	Epoch: [76][10/204]	Loss 0.0013 (0.0079)	
training:	Epoch: [76][11/204]	Loss 0.0043 (0.0076)	
training:	Epoch: [76][12/204]	Loss 0.0019 (0.0071)	
training:	Epoch: [76][13/204]	Loss 0.0017 (0.0067)	
training:	Epoch: [76][14/204]	Loss 0.0032 (0.0065)	
training:	Epoch: [76][15/204]	Loss 0.0051 (0.0064)	
training:	Epoch: [76][16/204]	Loss 0.0021 (0.0061)	
training:	Epoch: [76][17/204]	Loss 0.0015 (0.0058)	
training:	Epoch: [76][18/204]	Loss 0.0077 (0.0059)	
training:	Epoch: [76][19/204]	Loss 0.0022 (0.0057)	
training:	Epoch: [76][20/204]	Loss 0.0014 (0.0055)	
training:	Epoch: [76][21/204]	Loss 0.0015 (0.0053)	
training:	Epoch: [76][22/204]	Loss 0.0014 (0.0052)	
training:	Epoch: [76][23/204]	Loss 0.0024 (0.0050)	
training:	Epoch: [76][24/204]	Loss 0.0046 (0.0050)	
training:	Epoch: [76][25/204]	Loss 0.0018 (0.0049)	
training:	Epoch: [76][26/204]	Loss 0.0244 (0.0056)	
training:	Epoch: [76][27/204]	Loss 0.0014 (0.0055)	
training:	Epoch: [76][28/204]	Loss 0.0076 (0.0056)	
training:	Epoch: [76][29/204]	Loss 0.0018 (0.0054)	
training:	Epoch: [76][30/204]	Loss 0.0017 (0.0053)	
training:	Epoch: [76][31/204]	Loss 0.0660 (0.0073)	
training:	Epoch: [76][32/204]	Loss 0.0018 (0.0071)	
training:	Epoch: [76][33/204]	Loss 0.0018 (0.0069)	
training:	Epoch: [76][34/204]	Loss 0.0039 (0.0068)	
training:	Epoch: [76][35/204]	Loss 0.0023 (0.0067)	
training:	Epoch: [76][36/204]	Loss 0.0020 (0.0066)	
training:	Epoch: [76][37/204]	Loss 0.0035 (0.0065)	
training:	Epoch: [76][38/204]	Loss 0.0014 (0.0064)	
training:	Epoch: [76][39/204]	Loss 0.0034 (0.0063)	
training:	Epoch: [76][40/204]	Loss 0.0038 (0.0062)	
training:	Epoch: [76][41/204]	Loss 0.0154 (0.0065)	
training:	Epoch: [76][42/204]	Loss 0.0088 (0.0065)	
training:	Epoch: [76][43/204]	Loss 0.0016 (0.0064)	
training:	Epoch: [76][44/204]	Loss 0.0133 (0.0065)	
training:	Epoch: [76][45/204]	Loss 0.0014 (0.0064)	
training:	Epoch: [76][46/204]	Loss 0.0020 (0.0063)	
training:	Epoch: [76][47/204]	Loss 0.0024 (0.0063)	
training:	Epoch: [76][48/204]	Loss 0.0036 (0.0062)	
training:	Epoch: [76][49/204]	Loss 0.0028 (0.0061)	
training:	Epoch: [76][50/204]	Loss 0.0369 (0.0067)	
training:	Epoch: [76][51/204]	Loss 0.0013 (0.0066)	
training:	Epoch: [76][52/204]	Loss 0.0017 (0.0065)	
training:	Epoch: [76][53/204]	Loss 0.0188 (0.0068)	
training:	Epoch: [76][54/204]	Loss 0.0016 (0.0067)	
training:	Epoch: [76][55/204]	Loss 0.0041 (0.0066)	
training:	Epoch: [76][56/204]	Loss 0.0013 (0.0065)	
training:	Epoch: [76][57/204]	Loss 0.0128 (0.0066)	
training:	Epoch: [76][58/204]	Loss 0.0016 (0.0066)	
training:	Epoch: [76][59/204]	Loss 0.0105 (0.0066)	
training:	Epoch: [76][60/204]	Loss 0.0018 (0.0065)	
training:	Epoch: [76][61/204]	Loss 0.0062 (0.0065)	
training:	Epoch: [76][62/204]	Loss 0.0020 (0.0065)	
training:	Epoch: [76][63/204]	Loss 0.0183 (0.0067)	
training:	Epoch: [76][64/204]	Loss 0.0024 (0.0066)	
training:	Epoch: [76][65/204]	Loss 0.0047 (0.0066)	
training:	Epoch: [76][66/204]	Loss 0.0019 (0.0065)	
training:	Epoch: [76][67/204]	Loss 0.0023 (0.0064)	
training:	Epoch: [76][68/204]	Loss 0.0019 (0.0064)	
training:	Epoch: [76][69/204]	Loss 0.0069 (0.0064)	
training:	Epoch: [76][70/204]	Loss 0.0033 (0.0063)	
training:	Epoch: [76][71/204]	Loss 0.0018 (0.0063)	
training:	Epoch: [76][72/204]	Loss 0.0058 (0.0063)	
training:	Epoch: [76][73/204]	Loss 0.0019 (0.0062)	
training:	Epoch: [76][74/204]	Loss 0.0015 (0.0061)	
training:	Epoch: [76][75/204]	Loss 0.0018 (0.0061)	
training:	Epoch: [76][76/204]	Loss 0.0202 (0.0063)	
training:	Epoch: [76][77/204]	Loss 0.0021 (0.0062)	
training:	Epoch: [76][78/204]	Loss 0.0015 (0.0061)	
training:	Epoch: [76][79/204]	Loss 0.0018 (0.0061)	
training:	Epoch: [76][80/204]	Loss 0.0029 (0.0061)	
training:	Epoch: [76][81/204]	Loss 0.0014 (0.0060)	
training:	Epoch: [76][82/204]	Loss 0.0011 (0.0059)	
training:	Epoch: [76][83/204]	Loss 0.0016 (0.0059)	
training:	Epoch: [76][84/204]	Loss 0.0031 (0.0059)	
training:	Epoch: [76][85/204]	Loss 0.0076 (0.0059)	
training:	Epoch: [76][86/204]	Loss 0.0083 (0.0059)	
training:	Epoch: [76][87/204]	Loss 0.0044 (0.0059)	
training:	Epoch: [76][88/204]	Loss 0.0037 (0.0059)	
training:	Epoch: [76][89/204]	Loss 0.0047 (0.0058)	
training:	Epoch: [76][90/204]	Loss 0.0016 (0.0058)	
training:	Epoch: [76][91/204]	Loss 0.0028 (0.0058)	
training:	Epoch: [76][92/204]	Loss 0.0016 (0.0057)	
training:	Epoch: [76][93/204]	Loss 0.0023 (0.0057)	
training:	Epoch: [76][94/204]	Loss 0.0014 (0.0056)	
training:	Epoch: [76][95/204]	Loss 0.0011 (0.0056)	
training:	Epoch: [76][96/204]	Loss 0.0034 (0.0056)	
training:	Epoch: [76][97/204]	Loss 0.0073 (0.0056)	
training:	Epoch: [76][98/204]	Loss 0.0015 (0.0055)	
training:	Epoch: [76][99/204]	Loss 0.0017 (0.0055)	
training:	Epoch: [76][100/204]	Loss 0.0012 (0.0055)	
training:	Epoch: [76][101/204]	Loss 0.0015 (0.0054)	
training:	Epoch: [76][102/204]	Loss 0.0025 (0.0054)	
training:	Epoch: [76][103/204]	Loss 0.0013 (0.0054)	
training:	Epoch: [76][104/204]	Loss 0.0019 (0.0053)	
training:	Epoch: [76][105/204]	Loss 0.0017 (0.0053)	
training:	Epoch: [76][106/204]	Loss 0.0039 (0.0053)	
training:	Epoch: [76][107/204]	Loss 0.0031 (0.0053)	
training:	Epoch: [76][108/204]	Loss 0.0013 (0.0052)	
training:	Epoch: [76][109/204]	Loss 0.0019 (0.0052)	
training:	Epoch: [76][110/204]	Loss 0.0033 (0.0052)	
training:	Epoch: [76][111/204]	Loss 0.0026 (0.0051)	
training:	Epoch: [76][112/204]	Loss 0.0013 (0.0051)	
training:	Epoch: [76][113/204]	Loss 0.0017 (0.0051)	
training:	Epoch: [76][114/204]	Loss 0.0015 (0.0051)	
training:	Epoch: [76][115/204]	Loss 0.0013 (0.0050)	
training:	Epoch: [76][116/204]	Loss 0.0015 (0.0050)	
training:	Epoch: [76][117/204]	Loss 0.0028 (0.0050)	
training:	Epoch: [76][118/204]	Loss 0.0140 (0.0050)	
training:	Epoch: [76][119/204]	Loss 0.0037 (0.0050)	
training:	Epoch: [76][120/204]	Loss 0.0014 (0.0050)	
training:	Epoch: [76][121/204]	Loss 0.0025 (0.0050)	
training:	Epoch: [76][122/204]	Loss 0.0014 (0.0050)	
training:	Epoch: [76][123/204]	Loss 0.0040 (0.0049)	
training:	Epoch: [76][124/204]	Loss 0.0022 (0.0049)	
training:	Epoch: [76][125/204]	Loss 0.0015 (0.0049)	
training:	Epoch: [76][126/204]	Loss 0.0013 (0.0049)	
training:	Epoch: [76][127/204]	Loss 0.0015 (0.0048)	
training:	Epoch: [76][128/204]	Loss 0.0015 (0.0048)	
training:	Epoch: [76][129/204]	Loss 0.1981 (0.0063)	
training:	Epoch: [76][130/204]	Loss 0.0015 (0.0063)	
training:	Epoch: [76][131/204]	Loss 0.0023 (0.0062)	
training:	Epoch: [76][132/204]	Loss 0.0017 (0.0062)	
training:	Epoch: [76][133/204]	Loss 0.0017 (0.0062)	
training:	Epoch: [76][134/204]	Loss 0.0019 (0.0061)	
training:	Epoch: [76][135/204]	Loss 0.0017 (0.0061)	
training:	Epoch: [76][136/204]	Loss 0.0014 (0.0061)	
training:	Epoch: [76][137/204]	Loss 0.0015 (0.0060)	
training:	Epoch: [76][138/204]	Loss 0.0013 (0.0060)	
training:	Epoch: [76][139/204]	Loss 0.0022 (0.0060)	
training:	Epoch: [76][140/204]	Loss 0.0015 (0.0060)	
training:	Epoch: [76][141/204]	Loss 0.0016 (0.0059)	
training:	Epoch: [76][142/204]	Loss 0.0304 (0.0061)	
training:	Epoch: [76][143/204]	Loss 0.0410 (0.0063)	
training:	Epoch: [76][144/204]	Loss 0.0133 (0.0064)	
training:	Epoch: [76][145/204]	Loss 0.0014 (0.0064)	
training:	Epoch: [76][146/204]	Loss 0.0100 (0.0064)	
training:	Epoch: [76][147/204]	Loss 0.0023 (0.0063)	
training:	Epoch: [76][148/204]	Loss 0.0017 (0.0063)	
training:	Epoch: [76][149/204]	Loss 0.0014 (0.0063)	
training:	Epoch: [76][150/204]	Loss 0.0023 (0.0063)	
training:	Epoch: [76][151/204]	Loss 0.0013 (0.0062)	
training:	Epoch: [76][152/204]	Loss 0.0013 (0.0062)	
training:	Epoch: [76][153/204]	Loss 0.0030 (0.0062)	
training:	Epoch: [76][154/204]	Loss 0.0015 (0.0061)	
training:	Epoch: [76][155/204]	Loss 0.0013 (0.0061)	
training:	Epoch: [76][156/204]	Loss 0.0014 (0.0061)	
training:	Epoch: [76][157/204]	Loss 0.0013 (0.0061)	
training:	Epoch: [76][158/204]	Loss 0.0014 (0.0060)	
training:	Epoch: [76][159/204]	Loss 0.0050 (0.0060)	
training:	Epoch: [76][160/204]	Loss 0.0015 (0.0060)	
training:	Epoch: [76][161/204]	Loss 0.0032 (0.0060)	
training:	Epoch: [76][162/204]	Loss 0.0017 (0.0059)	
training:	Epoch: [76][163/204]	Loss 0.0030 (0.0059)	
training:	Epoch: [76][164/204]	Loss 0.0018 (0.0059)	
training:	Epoch: [76][165/204]	Loss 0.0026 (0.0059)	
training:	Epoch: [76][166/204]	Loss 0.0016 (0.0059)	
training:	Epoch: [76][167/204]	Loss 0.0038 (0.0058)	
training:	Epoch: [76][168/204]	Loss 0.0026 (0.0058)	
training:	Epoch: [76][169/204]	Loss 0.0014 (0.0058)	
training:	Epoch: [76][170/204]	Loss 0.0069 (0.0058)	
training:	Epoch: [76][171/204]	Loss 0.0018 (0.0058)	
training:	Epoch: [76][172/204]	Loss 0.0043 (0.0058)	
training:	Epoch: [76][173/204]	Loss 0.0014 (0.0057)	
training:	Epoch: [76][174/204]	Loss 0.0019 (0.0057)	
training:	Epoch: [76][175/204]	Loss 0.0019 (0.0057)	
training:	Epoch: [76][176/204]	Loss 0.0016 (0.0057)	
training:	Epoch: [76][177/204]	Loss 0.0015 (0.0057)	
training:	Epoch: [76][178/204]	Loss 0.0037 (0.0056)	
training:	Epoch: [76][179/204]	Loss 0.0035 (0.0056)	
training:	Epoch: [76][180/204]	Loss 0.0015 (0.0056)	
training:	Epoch: [76][181/204]	Loss 0.0016 (0.0056)	
training:	Epoch: [76][182/204]	Loss 0.0032 (0.0056)	
training:	Epoch: [76][183/204]	Loss 0.0150 (0.0056)	
training:	Epoch: [76][184/204]	Loss 0.0021 (0.0056)	
training:	Epoch: [76][185/204]	Loss 0.0013 (0.0056)	
training:	Epoch: [76][186/204]	Loss 0.0084 (0.0056)	
training:	Epoch: [76][187/204]	Loss 0.0014 (0.0056)	
training:	Epoch: [76][188/204]	Loss 0.0041 (0.0056)	
training:	Epoch: [76][189/204]	Loss 0.0016 (0.0055)	
training:	Epoch: [76][190/204]	Loss 0.0713 (0.0059)	
training:	Epoch: [76][191/204]	Loss 0.0029 (0.0059)	
training:	Epoch: [76][192/204]	Loss 0.0019 (0.0059)	
training:	Epoch: [76][193/204]	Loss 0.0026 (0.0058)	
training:	Epoch: [76][194/204]	Loss 0.0015 (0.0058)	
training:	Epoch: [76][195/204]	Loss 0.0376 (0.0060)	
training:	Epoch: [76][196/204]	Loss 0.0024 (0.0060)	
training:	Epoch: [76][197/204]	Loss 0.0062 (0.0060)	
training:	Epoch: [76][198/204]	Loss 0.0019 (0.0059)	
training:	Epoch: [76][199/204]	Loss 0.0013 (0.0059)	
training:	Epoch: [76][200/204]	Loss 0.0013 (0.0059)	
training:	Epoch: [76][201/204]	Loss 0.0031 (0.0059)	
training:	Epoch: [76][202/204]	Loss 0.0025 (0.0059)	
training:	Epoch: [76][203/204]	Loss 0.0017 (0.0058)	
training:	Epoch: [76][204/204]	Loss 0.0014 (0.0058)	
Training:	 Loss: 0.0058

Training:	 ACC: 0.9996 0.9995 0.9991 1.0000
Validation:	 ACC: 0.7757 0.7764 0.7902 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.2560
Pretraining:	Epoch 77/500
----------
training:	Epoch: [77][1/204]	Loss 0.0042 (0.0042)	
training:	Epoch: [77][2/204]	Loss 0.0012 (0.0027)	
training:	Epoch: [77][3/204]	Loss 0.0055 (0.0036)	
training:	Epoch: [77][4/204]	Loss 0.0020 (0.0032)	
training:	Epoch: [77][5/204]	Loss 0.0014 (0.0029)	
training:	Epoch: [77][6/204]	Loss 0.0025 (0.0028)	
training:	Epoch: [77][7/204]	Loss 0.0016 (0.0026)	
training:	Epoch: [77][8/204]	Loss 0.0046 (0.0029)	
training:	Epoch: [77][9/204]	Loss 0.0109 (0.0038)	
training:	Epoch: [77][10/204]	Loss 0.0015 (0.0035)	
training:	Epoch: [77][11/204]	Loss 0.0031 (0.0035)	
training:	Epoch: [77][12/204]	Loss 0.0022 (0.0034)	
training:	Epoch: [77][13/204]	Loss 0.0014 (0.0032)	
training:	Epoch: [77][14/204]	Loss 0.0119 (0.0039)	
training:	Epoch: [77][15/204]	Loss 0.0015 (0.0037)	
training:	Epoch: [77][16/204]	Loss 0.0023 (0.0036)	
training:	Epoch: [77][17/204]	Loss 0.0027 (0.0036)	
training:	Epoch: [77][18/204]	Loss 0.0013 (0.0034)	
training:	Epoch: [77][19/204]	Loss 0.0014 (0.0033)	
training:	Epoch: [77][20/204]	Loss 0.0053 (0.0034)	
training:	Epoch: [77][21/204]	Loss 0.0016 (0.0033)	
training:	Epoch: [77][22/204]	Loss 0.0012 (0.0032)	
training:	Epoch: [77][23/204]	Loss 0.0014 (0.0032)	
training:	Epoch: [77][24/204]	Loss 0.0014 (0.0031)	
training:	Epoch: [77][25/204]	Loss 0.0048 (0.0032)	
training:	Epoch: [77][26/204]	Loss 0.0027 (0.0031)	
training:	Epoch: [77][27/204]	Loss 0.0015 (0.0031)	
training:	Epoch: [77][28/204]	Loss 0.0025 (0.0031)	
training:	Epoch: [77][29/204]	Loss 0.1964 (0.0097)	
training:	Epoch: [77][30/204]	Loss 0.0056 (0.0096)	
training:	Epoch: [77][31/204]	Loss 0.0037 (0.0094)	
training:	Epoch: [77][32/204]	Loss 0.0015 (0.0091)	
training:	Epoch: [77][33/204]	Loss 0.0079 (0.0091)	
training:	Epoch: [77][34/204]	Loss 0.0012 (0.0089)	
training:	Epoch: [77][35/204]	Loss 0.0033 (0.0087)	
training:	Epoch: [77][36/204]	Loss 0.0013 (0.0085)	
training:	Epoch: [77][37/204]	Loss 0.0024 (0.0083)	
training:	Epoch: [77][38/204]	Loss 0.0014 (0.0082)	
training:	Epoch: [77][39/204]	Loss 0.0027 (0.0080)	
training:	Epoch: [77][40/204]	Loss 0.0016 (0.0079)	
training:	Epoch: [77][41/204]	Loss 0.0013 (0.0077)	
training:	Epoch: [77][42/204]	Loss 0.0022 (0.0076)	
training:	Epoch: [77][43/204]	Loss 0.0018 (0.0074)	
training:	Epoch: [77][44/204]	Loss 0.0014 (0.0073)	
training:	Epoch: [77][45/204]	Loss 0.0013 (0.0072)	
training:	Epoch: [77][46/204]	Loss 0.0013 (0.0070)	
training:	Epoch: [77][47/204]	Loss 0.0019 (0.0069)	
training:	Epoch: [77][48/204]	Loss 0.0135 (0.0071)	
training:	Epoch: [77][49/204]	Loss 0.0017 (0.0070)	
training:	Epoch: [77][50/204]	Loss 0.0033 (0.0069)	
training:	Epoch: [77][51/204]	Loss 0.0933 (0.0086)	
training:	Epoch: [77][52/204]	Loss 0.0085 (0.0086)	
training:	Epoch: [77][53/204]	Loss 0.0012 (0.0084)	
training:	Epoch: [77][54/204]	Loss 0.0017 (0.0083)	
training:	Epoch: [77][55/204]	Loss 0.0016 (0.0082)	
training:	Epoch: [77][56/204]	Loss 0.0027 (0.0081)	
training:	Epoch: [77][57/204]	Loss 0.0023 (0.0080)	
training:	Epoch: [77][58/204]	Loss 0.0015 (0.0079)	
training:	Epoch: [77][59/204]	Loss 0.0018 (0.0078)	
training:	Epoch: [77][60/204]	Loss 0.0013 (0.0077)	
training:	Epoch: [77][61/204]	Loss 0.0029 (0.0076)	
training:	Epoch: [77][62/204]	Loss 0.0019 (0.0075)	
training:	Epoch: [77][63/204]	Loss 0.0027 (0.0074)	
training:	Epoch: [77][64/204]	Loss 0.0091 (0.0074)	
training:	Epoch: [77][65/204]	Loss 0.0031 (0.0074)	
training:	Epoch: [77][66/204]	Loss 0.0014 (0.0073)	
training:	Epoch: [77][67/204]	Loss 0.0048 (0.0072)	
training:	Epoch: [77][68/204]	Loss 0.0025 (0.0072)	
training:	Epoch: [77][69/204]	Loss 0.0037 (0.0071)	
training:	Epoch: [77][70/204]	Loss 0.0031 (0.0071)	
training:	Epoch: [77][71/204]	Loss 0.0015 (0.0070)	
training:	Epoch: [77][72/204]	Loss 0.0023 (0.0069)	
training:	Epoch: [77][73/204]	Loss 0.0018 (0.0069)	
training:	Epoch: [77][74/204]	Loss 0.0019 (0.0068)	
training:	Epoch: [77][75/204]	Loss 0.0023 (0.0067)	
training:	Epoch: [77][76/204]	Loss 0.0012 (0.0067)	
training:	Epoch: [77][77/204]	Loss 0.0016 (0.0066)	
training:	Epoch: [77][78/204]	Loss 0.0013 (0.0065)	
training:	Epoch: [77][79/204]	Loss 0.0014 (0.0065)	
training:	Epoch: [77][80/204]	Loss 0.0020 (0.0064)	
training:	Epoch: [77][81/204]	Loss 0.0043 (0.0064)	
training:	Epoch: [77][82/204]	Loss 0.0014 (0.0063)	
training:	Epoch: [77][83/204]	Loss 0.0043 (0.0063)	
training:	Epoch: [77][84/204]	Loss 0.0011 (0.0062)	
training:	Epoch: [77][85/204]	Loss 0.0014 (0.0062)	
training:	Epoch: [77][86/204]	Loss 0.0013 (0.0061)	
training:	Epoch: [77][87/204]	Loss 0.0020 (0.0061)	
training:	Epoch: [77][88/204]	Loss 0.0378 (0.0064)	
training:	Epoch: [77][89/204]	Loss 0.0012 (0.0064)	
training:	Epoch: [77][90/204]	Loss 0.0012 (0.0063)	
training:	Epoch: [77][91/204]	Loss 0.0019 (0.0063)	
training:	Epoch: [77][92/204]	Loss 0.0022 (0.0062)	
training:	Epoch: [77][93/204]	Loss 0.0011 (0.0062)	
training:	Epoch: [77][94/204]	Loss 0.0016 (0.0061)	
training:	Epoch: [77][95/204]	Loss 0.0013 (0.0061)	
training:	Epoch: [77][96/204]	Loss 0.0013 (0.0060)	
training:	Epoch: [77][97/204]	Loss 0.0019 (0.0060)	
training:	Epoch: [77][98/204]	Loss 0.0015 (0.0059)	
training:	Epoch: [77][99/204]	Loss 0.0018 (0.0059)	
training:	Epoch: [77][100/204]	Loss 0.0012 (0.0058)	
training:	Epoch: [77][101/204]	Loss 0.0015 (0.0058)	
training:	Epoch: [77][102/204]	Loss 0.0012 (0.0058)	
training:	Epoch: [77][103/204]	Loss 0.0014 (0.0057)	
training:	Epoch: [77][104/204]	Loss 0.0018 (0.0057)	
training:	Epoch: [77][105/204]	Loss 0.0015 (0.0056)	
training:	Epoch: [77][106/204]	Loss 0.0013 (0.0056)	
training:	Epoch: [77][107/204]	Loss 0.0019 (0.0056)	
training:	Epoch: [77][108/204]	Loss 0.0012 (0.0055)	
training:	Epoch: [77][109/204]	Loss 0.0121 (0.0056)	
training:	Epoch: [77][110/204]	Loss 0.0024 (0.0055)	
training:	Epoch: [77][111/204]	Loss 0.0012 (0.0055)	
training:	Epoch: [77][112/204]	Loss 0.0014 (0.0055)	
training:	Epoch: [77][113/204]	Loss 0.0014 (0.0054)	
training:	Epoch: [77][114/204]	Loss 0.0012 (0.0054)	
training:	Epoch: [77][115/204]	Loss 0.0016 (0.0054)	
training:	Epoch: [77][116/204]	Loss 0.0105 (0.0054)	
training:	Epoch: [77][117/204]	Loss 0.0012 (0.0054)	
training:	Epoch: [77][118/204]	Loss 0.0015 (0.0053)	
training:	Epoch: [77][119/204]	Loss 0.0015 (0.0053)	
training:	Epoch: [77][120/204]	Loss 0.0014 (0.0053)	
training:	Epoch: [77][121/204]	Loss 0.0015 (0.0052)	
training:	Epoch: [77][122/204]	Loss 0.0019 (0.0052)	
training:	Epoch: [77][123/204]	Loss 0.0015 (0.0052)	
training:	Epoch: [77][124/204]	Loss 0.0012 (0.0052)	
training:	Epoch: [77][125/204]	Loss 0.0023 (0.0051)	
training:	Epoch: [77][126/204]	Loss 0.0013 (0.0051)	
training:	Epoch: [77][127/204]	Loss 0.0167 (0.0052)	
training:	Epoch: [77][128/204]	Loss 0.0012 (0.0052)	
training:	Epoch: [77][129/204]	Loss 0.0015 (0.0051)	
training:	Epoch: [77][130/204]	Loss 0.0012 (0.0051)	
training:	Epoch: [77][131/204]	Loss 0.0011 (0.0051)	
training:	Epoch: [77][132/204]	Loss 0.0011 (0.0050)	
training:	Epoch: [77][133/204]	Loss 0.0021 (0.0050)	
training:	Epoch: [77][134/204]	Loss 0.0012 (0.0050)	
training:	Epoch: [77][135/204]	Loss 0.0016 (0.0050)	
training:	Epoch: [77][136/204]	Loss 0.0023 (0.0049)	
training:	Epoch: [77][137/204]	Loss 0.0021 (0.0049)	
training:	Epoch: [77][138/204]	Loss 0.0024 (0.0049)	
training:	Epoch: [77][139/204]	Loss 0.0375 (0.0051)	
training:	Epoch: [77][140/204]	Loss 0.0016 (0.0051)	
training:	Epoch: [77][141/204]	Loss 0.0017 (0.0051)	
training:	Epoch: [77][142/204]	Loss 0.0011 (0.0051)	
training:	Epoch: [77][143/204]	Loss 0.0016 (0.0050)	
training:	Epoch: [77][144/204]	Loss 0.0017 (0.0050)	
training:	Epoch: [77][145/204]	Loss 0.0016 (0.0050)	
training:	Epoch: [77][146/204]	Loss 0.0022 (0.0050)	
training:	Epoch: [77][147/204]	Loss 0.0812 (0.0055)	
training:	Epoch: [77][148/204]	Loss 0.0016 (0.0055)	
training:	Epoch: [77][149/204]	Loss 0.0015 (0.0054)	
training:	Epoch: [77][150/204]	Loss 0.0021 (0.0054)	
training:	Epoch: [77][151/204]	Loss 0.0020 (0.0054)	
training:	Epoch: [77][152/204]	Loss 0.0013 (0.0054)	
training:	Epoch: [77][153/204]	Loss 0.0019 (0.0053)	
training:	Epoch: [77][154/204]	Loss 0.0013 (0.0053)	
training:	Epoch: [77][155/204]	Loss 0.0014 (0.0053)	
training:	Epoch: [77][156/204]	Loss 0.0016 (0.0053)	
training:	Epoch: [77][157/204]	Loss 0.0012 (0.0052)	
training:	Epoch: [77][158/204]	Loss 0.0016 (0.0052)	
training:	Epoch: [77][159/204]	Loss 0.0024 (0.0052)	
training:	Epoch: [77][160/204]	Loss 0.0017 (0.0052)	
training:	Epoch: [77][161/204]	Loss 0.0015 (0.0052)	
training:	Epoch: [77][162/204]	Loss 0.0071 (0.0052)	
training:	Epoch: [77][163/204]	Loss 0.0012 (0.0051)	
training:	Epoch: [77][164/204]	Loss 0.0087 (0.0052)	
training:	Epoch: [77][165/204]	Loss 0.0203 (0.0053)	
training:	Epoch: [77][166/204]	Loss 0.0013 (0.0052)	
training:	Epoch: [77][167/204]	Loss 0.0147 (0.0053)	
training:	Epoch: [77][168/204]	Loss 0.0022 (0.0053)	
training:	Epoch: [77][169/204]	Loss 0.0017 (0.0053)	
training:	Epoch: [77][170/204]	Loss 0.0012 (0.0052)	
training:	Epoch: [77][171/204]	Loss 0.0018 (0.0052)	
training:	Epoch: [77][172/204]	Loss 0.0014 (0.0052)	
training:	Epoch: [77][173/204]	Loss 0.0017 (0.0052)	
training:	Epoch: [77][174/204]	Loss 0.0019 (0.0051)	
training:	Epoch: [77][175/204]	Loss 0.0013 (0.0051)	
training:	Epoch: [77][176/204]	Loss 0.0012 (0.0051)	
training:	Epoch: [77][177/204]	Loss 0.0040 (0.0051)	
training:	Epoch: [77][178/204]	Loss 0.0208 (0.0052)	
training:	Epoch: [77][179/204]	Loss 0.0020 (0.0052)	
training:	Epoch: [77][180/204]	Loss 0.0022 (0.0052)	
training:	Epoch: [77][181/204]	Loss 0.0014 (0.0051)	
training:	Epoch: [77][182/204]	Loss 0.0013 (0.0051)	
training:	Epoch: [77][183/204]	Loss 0.0012 (0.0051)	
training:	Epoch: [77][184/204]	Loss 0.0021 (0.0051)	
training:	Epoch: [77][185/204]	Loss 0.0109 (0.0051)	
training:	Epoch: [77][186/204]	Loss 0.0026 (0.0051)	
training:	Epoch: [77][187/204]	Loss 0.0012 (0.0051)	
training:	Epoch: [77][188/204]	Loss 0.0038 (0.0051)	
training:	Epoch: [77][189/204]	Loss 0.0066 (0.0051)	
training:	Epoch: [77][190/204]	Loss 0.0012 (0.0051)	
training:	Epoch: [77][191/204]	Loss 0.0013 (0.0050)	
training:	Epoch: [77][192/204]	Loss 0.0064 (0.0050)	
training:	Epoch: [77][193/204]	Loss 0.0047 (0.0050)	
training:	Epoch: [77][194/204]	Loss 0.0022 (0.0050)	
training:	Epoch: [77][195/204]	Loss 0.0505 (0.0053)	
training:	Epoch: [77][196/204]	Loss 0.0015 (0.0052)	
training:	Epoch: [77][197/204]	Loss 0.0013 (0.0052)	
training:	Epoch: [77][198/204]	Loss 0.0011 (0.0052)	
training:	Epoch: [77][199/204]	Loss 0.0020 (0.0052)	
training:	Epoch: [77][200/204]	Loss 0.0011 (0.0052)	
training:	Epoch: [77][201/204]	Loss 0.0015 (0.0051)	
training:	Epoch: [77][202/204]	Loss 0.0341 (0.0053)	
training:	Epoch: [77][203/204]	Loss 0.0365 (0.0054)	
training:	Epoch: [77][204/204]	Loss 0.0043 (0.0054)	
Training:	 Loss: 0.0054

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7745 0.7758 0.8035 0.7455
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.2689
Pretraining:	Epoch 78/500
----------
training:	Epoch: [78][1/204]	Loss 0.0013 (0.0013)	
training:	Epoch: [78][2/204]	Loss 0.0016 (0.0014)	
training:	Epoch: [78][3/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [78][4/204]	Loss 0.0052 (0.0024)	
training:	Epoch: [78][5/204]	Loss 0.0091 (0.0037)	
training:	Epoch: [78][6/204]	Loss 0.0012 (0.0033)	
training:	Epoch: [78][7/204]	Loss 0.0027 (0.0032)	
training:	Epoch: [78][8/204]	Loss 0.0052 (0.0035)	
training:	Epoch: [78][9/204]	Loss 0.0014 (0.0032)	
training:	Epoch: [78][10/204]	Loss 0.0011 (0.0030)	
training:	Epoch: [78][11/204]	Loss 0.0017 (0.0029)	
training:	Epoch: [78][12/204]	Loss 0.0013 (0.0028)	
training:	Epoch: [78][13/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [78][14/204]	Loss 0.0016 (0.0026)	
training:	Epoch: [78][15/204]	Loss 0.0015 (0.0025)	
training:	Epoch: [78][16/204]	Loss 0.0031 (0.0025)	
training:	Epoch: [78][17/204]	Loss 0.0011 (0.0025)	
training:	Epoch: [78][18/204]	Loss 0.0013 (0.0024)	
training:	Epoch: [78][19/204]	Loss 0.0011 (0.0023)	
training:	Epoch: [78][20/204]	Loss 0.0011 (0.0023)	
training:	Epoch: [78][21/204]	Loss 0.0013 (0.0022)	
training:	Epoch: [78][22/204]	Loss 0.0020 (0.0022)	
training:	Epoch: [78][23/204]	Loss 0.0015 (0.0022)	
training:	Epoch: [78][24/204]	Loss 0.0020 (0.0022)	
training:	Epoch: [78][25/204]	Loss 0.0145 (0.0027)	
training:	Epoch: [78][26/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [78][27/204]	Loss 0.0015 (0.0026)	
training:	Epoch: [78][28/204]	Loss 0.0011 (0.0025)	
training:	Epoch: [78][29/204]	Loss 0.0012 (0.0025)	
training:	Epoch: [78][30/204]	Loss 0.0012 (0.0024)	
training:	Epoch: [78][31/204]	Loss 0.0013 (0.0024)	
training:	Epoch: [78][32/204]	Loss 0.0013 (0.0024)	
training:	Epoch: [78][33/204]	Loss 0.0012 (0.0023)	
training:	Epoch: [78][34/204]	Loss 0.0011 (0.0023)	
training:	Epoch: [78][35/204]	Loss 0.0012 (0.0023)	
training:	Epoch: [78][36/204]	Loss 0.0012 (0.0022)	
training:	Epoch: [78][37/204]	Loss 0.0012 (0.0022)	
training:	Epoch: [78][38/204]	Loss 0.0012 (0.0022)	
training:	Epoch: [78][39/204]	Loss 0.0013 (0.0021)	
training:	Epoch: [78][40/204]	Loss 0.0134 (0.0024)	
training:	Epoch: [78][41/204]	Loss 0.0014 (0.0024)	
training:	Epoch: [78][42/204]	Loss 0.0013 (0.0024)	
training:	Epoch: [78][43/204]	Loss 0.0015 (0.0024)	
training:	Epoch: [78][44/204]	Loss 0.0012 (0.0023)	
training:	Epoch: [78][45/204]	Loss 0.0020 (0.0023)	
training:	Epoch: [78][46/204]	Loss 0.0012 (0.0023)	
training:	Epoch: [78][47/204]	Loss 0.0132 (0.0025)	
training:	Epoch: [78][48/204]	Loss 0.0013 (0.0025)	
training:	Epoch: [78][49/204]	Loss 0.0015 (0.0025)	
training:	Epoch: [78][50/204]	Loss 0.0032 (0.0025)	
training:	Epoch: [78][51/204]	Loss 0.0018 (0.0025)	
training:	Epoch: [78][52/204]	Loss 0.0023 (0.0025)	
training:	Epoch: [78][53/204]	Loss 0.0295 (0.0030)	
training:	Epoch: [78][54/204]	Loss 0.0014 (0.0030)	
training:	Epoch: [78][55/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [78][56/204]	Loss 0.0024 (0.0029)	
training:	Epoch: [78][57/204]	Loss 0.0015 (0.0029)	
training:	Epoch: [78][58/204]	Loss 0.0074 (0.0030)	
training:	Epoch: [78][59/204]	Loss 0.0016 (0.0029)	
training:	Epoch: [78][60/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [78][61/204]	Loss 0.0017 (0.0029)	
training:	Epoch: [78][62/204]	Loss 0.0047 (0.0029)	
training:	Epoch: [78][63/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [78][64/204]	Loss 0.0018 (0.0029)	
training:	Epoch: [78][65/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [78][66/204]	Loss 0.0068 (0.0029)	
training:	Epoch: [78][67/204]	Loss 0.0014 (0.0029)	
training:	Epoch: [78][68/204]	Loss 0.0029 (0.0029)	
training:	Epoch: [78][69/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [78][70/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [78][71/204]	Loss 0.0020 (0.0028)	
training:	Epoch: [78][72/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [78][73/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [78][74/204]	Loss 0.0043 (0.0028)	
training:	Epoch: [78][75/204]	Loss 0.0014 (0.0028)	
training:	Epoch: [78][76/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [78][77/204]	Loss 0.0021 (0.0028)	
training:	Epoch: [78][78/204]	Loss 0.0020 (0.0028)	
training:	Epoch: [78][79/204]	Loss 0.0014 (0.0027)	
training:	Epoch: [78][80/204]	Loss 0.0016 (0.0027)	
training:	Epoch: [78][81/204]	Loss 0.0022 (0.0027)	
training:	Epoch: [78][82/204]	Loss 0.0070 (0.0028)	
training:	Epoch: [78][83/204]	Loss 0.0054 (0.0028)	
training:	Epoch: [78][84/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [78][85/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [78][86/204]	Loss 0.0020 (0.0028)	
training:	Epoch: [78][87/204]	Loss 0.0012 (0.0027)	
training:	Epoch: [78][88/204]	Loss 0.0016 (0.0027)	
training:	Epoch: [78][89/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [78][90/204]	Loss 0.0014 (0.0027)	
training:	Epoch: [78][91/204]	Loss 0.0018 (0.0027)	
training:	Epoch: [78][92/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [78][93/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [78][94/204]	Loss 0.0028 (0.0027)	
training:	Epoch: [78][95/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [78][96/204]	Loss 0.0022 (0.0026)	
training:	Epoch: [78][97/204]	Loss 0.0015 (0.0026)	
training:	Epoch: [78][98/204]	Loss 0.0010 (0.0026)	
training:	Epoch: [78][99/204]	Loss 0.0013 (0.0026)	
training:	Epoch: [78][100/204]	Loss 0.0011 (0.0026)	
training:	Epoch: [78][101/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [78][102/204]	Loss 0.0013 (0.0025)	
training:	Epoch: [78][103/204]	Loss 0.0045 (0.0026)	
training:	Epoch: [78][104/204]	Loss 0.0014 (0.0026)	
training:	Epoch: [78][105/204]	Loss 0.0166 (0.0027)	
training:	Epoch: [78][106/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [78][107/204]	Loss 0.0048 (0.0027)	
training:	Epoch: [78][108/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [78][109/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [78][110/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [78][111/204]	Loss 0.0013 (0.0026)	
training:	Epoch: [78][112/204]	Loss 0.0013 (0.0026)	
training:	Epoch: [78][113/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [78][114/204]	Loss 0.0020 (0.0026)	
training:	Epoch: [78][115/204]	Loss 0.0017 (0.0026)	
training:	Epoch: [78][116/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [78][117/204]	Loss 0.0186 (0.0027)	
training:	Epoch: [78][118/204]	Loss 0.0015 (0.0027)	
training:	Epoch: [78][119/204]	Loss 0.0065 (0.0028)	
training:	Epoch: [78][120/204]	Loss 0.0010 (0.0027)	
training:	Epoch: [78][121/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [78][122/204]	Loss 0.0014 (0.0027)	
training:	Epoch: [78][123/204]	Loss 0.0078 (0.0028)	
training:	Epoch: [78][124/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [78][125/204]	Loss 0.0012 (0.0027)	
training:	Epoch: [78][126/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [78][127/204]	Loss 0.0181 (0.0028)	
training:	Epoch: [78][128/204]	Loss 0.0068 (0.0029)	
training:	Epoch: [78][129/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [78][130/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [78][131/204]	Loss 0.0017 (0.0028)	
training:	Epoch: [78][132/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [78][133/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [78][134/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [78][135/204]	Loss 0.0013 (0.0028)	
training:	Epoch: [78][136/204]	Loss 0.0162 (0.0029)	
training:	Epoch: [78][137/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [78][138/204]	Loss 0.2039 (0.0043)	
training:	Epoch: [78][139/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [78][140/204]	Loss 0.0157 (0.0044)	
training:	Epoch: [78][141/204]	Loss 0.0040 (0.0044)	
training:	Epoch: [78][142/204]	Loss 0.0021 (0.0044)	
training:	Epoch: [78][143/204]	Loss 0.0019 (0.0044)	
training:	Epoch: [78][144/204]	Loss 0.0016 (0.0043)	
training:	Epoch: [78][145/204]	Loss 0.0013 (0.0043)	
training:	Epoch: [78][146/204]	Loss 0.0153 (0.0044)	
training:	Epoch: [78][147/204]	Loss 0.0016 (0.0044)	
training:	Epoch: [78][148/204]	Loss 0.0016 (0.0043)	
training:	Epoch: [78][149/204]	Loss 0.0125 (0.0044)	
training:	Epoch: [78][150/204]	Loss 0.0015 (0.0044)	
training:	Epoch: [78][151/204]	Loss 0.0010 (0.0044)	
training:	Epoch: [78][152/204]	Loss 0.0014 (0.0043)	
training:	Epoch: [78][153/204]	Loss 0.0022 (0.0043)	
training:	Epoch: [78][154/204]	Loss 0.0027 (0.0043)	
training:	Epoch: [78][155/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [78][156/204]	Loss 0.0191 (0.0044)	
training:	Epoch: [78][157/204]	Loss 0.0032 (0.0044)	
training:	Epoch: [78][158/204]	Loss 0.0011 (0.0044)	
training:	Epoch: [78][159/204]	Loss 0.0015 (0.0043)	
training:	Epoch: [78][160/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [78][161/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [78][162/204]	Loss 0.0100 (0.0043)	
training:	Epoch: [78][163/204]	Loss 0.0077 (0.0044)	
training:	Epoch: [78][164/204]	Loss 0.0013 (0.0043)	
training:	Epoch: [78][165/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [78][166/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [78][167/204]	Loss 0.0011 (0.0043)	
training:	Epoch: [78][168/204]	Loss 0.0013 (0.0043)	
training:	Epoch: [78][169/204]	Loss 0.0185 (0.0044)	
training:	Epoch: [78][170/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [78][171/204]	Loss 0.0023 (0.0043)	
training:	Epoch: [78][172/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [78][173/204]	Loss 0.0028 (0.0043)	
training:	Epoch: [78][174/204]	Loss 0.0013 (0.0043)	
training:	Epoch: [78][175/204]	Loss 0.0066 (0.0043)	
training:	Epoch: [78][176/204]	Loss 0.0025 (0.0043)	
training:	Epoch: [78][177/204]	Loss 0.0053 (0.0043)	
training:	Epoch: [78][178/204]	Loss 0.0011 (0.0043)	
training:	Epoch: [78][179/204]	Loss 0.0011 (0.0043)	
training:	Epoch: [78][180/204]	Loss 0.0018 (0.0042)	
training:	Epoch: [78][181/204]	Loss 0.0012 (0.0042)	
training:	Epoch: [78][182/204]	Loss 0.0024 (0.0042)	
training:	Epoch: [78][183/204]	Loss 0.0013 (0.0042)	
training:	Epoch: [78][184/204]	Loss 0.0012 (0.0042)	
training:	Epoch: [78][185/204]	Loss 0.0019 (0.0042)	
training:	Epoch: [78][186/204]	Loss 0.0102 (0.0042)	
training:	Epoch: [78][187/204]	Loss 0.0012 (0.0042)	
training:	Epoch: [78][188/204]	Loss 0.0023 (0.0042)	
training:	Epoch: [78][189/204]	Loss 0.0011 (0.0042)	
training:	Epoch: [78][190/204]	Loss 0.0027 (0.0041)	
training:	Epoch: [78][191/204]	Loss 0.0046 (0.0042)	
training:	Epoch: [78][192/204]	Loss 0.0017 (0.0041)	
training:	Epoch: [78][193/204]	Loss 0.0016 (0.0041)	
training:	Epoch: [78][194/204]	Loss 0.0011 (0.0041)	
training:	Epoch: [78][195/204]	Loss 0.0017 (0.0041)	
training:	Epoch: [78][196/204]	Loss 0.0016 (0.0041)	
training:	Epoch: [78][197/204]	Loss 0.0018 (0.0041)	
training:	Epoch: [78][198/204]	Loss 0.0012 (0.0041)	
training:	Epoch: [78][199/204]	Loss 0.0045 (0.0041)	
training:	Epoch: [78][200/204]	Loss 0.0014 (0.0040)	
training:	Epoch: [78][201/204]	Loss 0.0020 (0.0040)	
training:	Epoch: [78][202/204]	Loss 0.0011 (0.0040)	
training:	Epoch: [78][203/204]	Loss 0.0081 (0.0040)	
training:	Epoch: [78][204/204]	Loss 0.0012 (0.0040)	
Training:	 Loss: 0.0040

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7775 0.7774 0.7748 0.7803
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.2844
Pretraining:	Epoch 79/500
----------
training:	Epoch: [79][1/204]	Loss 0.0018 (0.0018)	
training:	Epoch: [79][2/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [79][3/204]	Loss 0.0038 (0.0022)	
training:	Epoch: [79][4/204]	Loss 0.0035 (0.0025)	
training:	Epoch: [79][5/204]	Loss 0.0025 (0.0025)	
training:	Epoch: [79][6/204]	Loss 0.0059 (0.0031)	
training:	Epoch: [79][7/204]	Loss 0.0013 (0.0028)	
training:	Epoch: [79][8/204]	Loss 0.0021 (0.0027)	
training:	Epoch: [79][9/204]	Loss 0.0013 (0.0026)	
training:	Epoch: [79][10/204]	Loss 0.0010 (0.0024)	
training:	Epoch: [79][11/204]	Loss 0.0011 (0.0023)	
training:	Epoch: [79][12/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [79][13/204]	Loss 0.0015 (0.0021)	
training:	Epoch: [79][14/204]	Loss 0.0025 (0.0022)	
training:	Epoch: [79][15/204]	Loss 0.0014 (0.0021)	
training:	Epoch: [79][16/204]	Loss 0.0020 (0.0021)	
training:	Epoch: [79][17/204]	Loss 0.0014 (0.0021)	
training:	Epoch: [79][18/204]	Loss 0.0015 (0.0020)	
training:	Epoch: [79][19/204]	Loss 0.0024 (0.0021)	
training:	Epoch: [79][20/204]	Loss 0.0017 (0.0020)	
training:	Epoch: [79][21/204]	Loss 0.0010 (0.0020)	
training:	Epoch: [79][22/204]	Loss 0.0019 (0.0020)	
training:	Epoch: [79][23/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [79][24/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [79][25/204]	Loss 0.0097 (0.0022)	
training:	Epoch: [79][26/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [79][27/204]	Loss 0.0015 (0.0021)	
training:	Epoch: [79][28/204]	Loss 0.0067 (0.0023)	
training:	Epoch: [79][29/204]	Loss 0.0069 (0.0025)	
training:	Epoch: [79][30/204]	Loss 0.0021 (0.0025)	
training:	Epoch: [79][31/204]	Loss 0.0015 (0.0024)	
training:	Epoch: [79][32/204]	Loss 0.0015 (0.0024)	
training:	Epoch: [79][33/204]	Loss 0.0011 (0.0024)	
training:	Epoch: [79][34/204]	Loss 0.0010 (0.0023)	
training:	Epoch: [79][35/204]	Loss 0.0040 (0.0024)	
training:	Epoch: [79][36/204]	Loss 0.0014 (0.0023)	
training:	Epoch: [79][37/204]	Loss 0.0226 (0.0029)	
training:	Epoch: [79][38/204]	Loss 0.0015 (0.0029)	
training:	Epoch: [79][39/204]	Loss 0.0023 (0.0028)	
training:	Epoch: [79][40/204]	Loss 0.0014 (0.0028)	
training:	Epoch: [79][41/204]	Loss 0.0014 (0.0028)	
training:	Epoch: [79][42/204]	Loss 0.0016 (0.0027)	
training:	Epoch: [79][43/204]	Loss 0.0010 (0.0027)	
training:	Epoch: [79][44/204]	Loss 0.0158 (0.0030)	
training:	Epoch: [79][45/204]	Loss 0.0011 (0.0030)	
training:	Epoch: [79][46/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [79][47/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [79][48/204]	Loss 0.0015 (0.0029)	
training:	Epoch: [79][49/204]	Loss 0.0062 (0.0029)	
training:	Epoch: [79][50/204]	Loss 0.0021 (0.0029)	
training:	Epoch: [79][51/204]	Loss 0.0022 (0.0029)	
training:	Epoch: [79][52/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [79][53/204]	Loss 0.0132 (0.0031)	
training:	Epoch: [79][54/204]	Loss 0.0019 (0.0030)	
training:	Epoch: [79][55/204]	Loss 0.0011 (0.0030)	
training:	Epoch: [79][56/204]	Loss 0.0011 (0.0030)	
training:	Epoch: [79][57/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [79][58/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [79][59/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [79][60/204]	Loss 0.0151 (0.0031)	
training:	Epoch: [79][61/204]	Loss 0.0013 (0.0030)	
training:	Epoch: [79][62/204]	Loss 0.0029 (0.0030)	
training:	Epoch: [79][63/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [79][64/204]	Loss 0.0014 (0.0030)	
training:	Epoch: [79][65/204]	Loss 0.0102 (0.0031)	
training:	Epoch: [79][66/204]	Loss 0.0014 (0.0031)	
training:	Epoch: [79][67/204]	Loss 0.0027 (0.0031)	
training:	Epoch: [79][68/204]	Loss 0.0012 (0.0030)	
training:	Epoch: [79][69/204]	Loss 0.0036 (0.0030)	
training:	Epoch: [79][70/204]	Loss 0.0013 (0.0030)	
training:	Epoch: [79][71/204]	Loss 0.0025 (0.0030)	
training:	Epoch: [79][72/204]	Loss 0.0011 (0.0030)	
training:	Epoch: [79][73/204]	Loss 0.0078 (0.0031)	
training:	Epoch: [79][74/204]	Loss 0.0021 (0.0030)	
training:	Epoch: [79][75/204]	Loss 0.0016 (0.0030)	
training:	Epoch: [79][76/204]	Loss 0.0022 (0.0030)	
training:	Epoch: [79][77/204]	Loss 0.0014 (0.0030)	
training:	Epoch: [79][78/204]	Loss 0.0014 (0.0030)	
training:	Epoch: [79][79/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [79][80/204]	Loss 0.0023 (0.0029)	
training:	Epoch: [79][81/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [79][82/204]	Loss 0.0014 (0.0029)	
training:	Epoch: [79][83/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [79][84/204]	Loss 0.0017 (0.0029)	
training:	Epoch: [79][85/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [79][86/204]	Loss 0.0020 (0.0028)	
training:	Epoch: [79][87/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [79][88/204]	Loss 0.0014 (0.0028)	
training:	Epoch: [79][89/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [79][90/204]	Loss 0.0016 (0.0028)	
training:	Epoch: [79][91/204]	Loss 0.0016 (0.0027)	
training:	Epoch: [79][92/204]	Loss 0.0012 (0.0027)	
training:	Epoch: [79][93/204]	Loss 0.0036 (0.0027)	
training:	Epoch: [79][94/204]	Loss 0.0020 (0.0027)	
training:	Epoch: [79][95/204]	Loss 0.0015 (0.0027)	
training:	Epoch: [79][96/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [79][97/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [79][98/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [79][99/204]	Loss 0.0016 (0.0027)	
training:	Epoch: [79][100/204]	Loss 0.0015 (0.0026)	
training:	Epoch: [79][101/204]	Loss 0.0206 (0.0028)	
training:	Epoch: [79][102/204]	Loss 0.0022 (0.0028)	
training:	Epoch: [79][103/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [79][104/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [79][105/204]	Loss 0.0018 (0.0028)	
training:	Epoch: [79][106/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [79][107/204]	Loss 0.0036 (0.0028)	
training:	Epoch: [79][108/204]	Loss 0.0014 (0.0028)	
training:	Epoch: [79][109/204]	Loss 0.0019 (0.0027)	
training:	Epoch: [79][110/204]	Loss 0.0023 (0.0027)	
training:	Epoch: [79][111/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [79][112/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [79][113/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [79][114/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [79][115/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [79][116/204]	Loss 0.0012 (0.0027)	
training:	Epoch: [79][117/204]	Loss 0.0011 (0.0026)	
training:	Epoch: [79][118/204]	Loss 0.0146 (0.0027)	
training:	Epoch: [79][119/204]	Loss 0.0012 (0.0027)	
training:	Epoch: [79][120/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [79][121/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [79][122/204]	Loss 0.0015 (0.0027)	
training:	Epoch: [79][123/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [79][124/204]	Loss 0.0075 (0.0027)	
training:	Epoch: [79][125/204]	Loss 0.0014 (0.0027)	
training:	Epoch: [79][126/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [79][127/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [79][128/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [79][129/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [79][130/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [79][131/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [79][132/204]	Loss 0.0035 (0.0026)	
training:	Epoch: [79][133/204]	Loss 0.0014 (0.0026)	
training:	Epoch: [79][134/204]	Loss 0.0029 (0.0026)	
training:	Epoch: [79][135/204]	Loss 0.0011 (0.0026)	
training:	Epoch: [79][136/204]	Loss 0.0088 (0.0027)	
training:	Epoch: [79][137/204]	Loss 0.0010 (0.0027)	
training:	Epoch: [79][138/204]	Loss 0.0011 (0.0026)	
training:	Epoch: [79][139/204]	Loss 0.0013 (0.0026)	
training:	Epoch: [79][140/204]	Loss 0.0037 (0.0026)	
training:	Epoch: [79][141/204]	Loss 0.0026 (0.0026)	
training:	Epoch: [79][142/204]	Loss 0.0015 (0.0026)	
training:	Epoch: [79][143/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [79][144/204]	Loss 0.0018 (0.0026)	
training:	Epoch: [79][145/204]	Loss 0.0010 (0.0026)	
training:	Epoch: [79][146/204]	Loss 0.0026 (0.0026)	
training:	Epoch: [79][147/204]	Loss 0.0010 (0.0026)	
training:	Epoch: [79][148/204]	Loss 0.0014 (0.0026)	
training:	Epoch: [79][149/204]	Loss 0.0010 (0.0026)	
training:	Epoch: [79][150/204]	Loss 0.0042 (0.0026)	
training:	Epoch: [79][151/204]	Loss 0.0016 (0.0026)	
training:	Epoch: [79][152/204]	Loss 0.0011 (0.0026)	
training:	Epoch: [79][153/204]	Loss 0.0016 (0.0026)	
training:	Epoch: [79][154/204]	Loss 0.0013 (0.0026)	
training:	Epoch: [79][155/204]	Loss 0.0013 (0.0026)	
training:	Epoch: [79][156/204]	Loss 0.0015 (0.0025)	
training:	Epoch: [79][157/204]	Loss 0.0018 (0.0025)	
training:	Epoch: [79][158/204]	Loss 0.0042 (0.0026)	
training:	Epoch: [79][159/204]	Loss 0.0015 (0.0025)	
training:	Epoch: [79][160/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [79][161/204]	Loss 0.0011 (0.0025)	
training:	Epoch: [79][162/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [79][163/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [79][164/204]	Loss 0.0046 (0.0025)	
training:	Epoch: [79][165/204]	Loss 0.0011 (0.0025)	
training:	Epoch: [79][166/204]	Loss 0.0034 (0.0025)	
training:	Epoch: [79][167/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [79][168/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [79][169/204]	Loss 0.0125 (0.0026)	
training:	Epoch: [79][170/204]	Loss 0.2028 (0.0037)	
training:	Epoch: [79][171/204]	Loss 0.0023 (0.0037)	
training:	Epoch: [79][172/204]	Loss 0.0024 (0.0037)	
training:	Epoch: [79][173/204]	Loss 0.0011 (0.0037)	
training:	Epoch: [79][174/204]	Loss 0.0011 (0.0037)	
training:	Epoch: [79][175/204]	Loss 0.0011 (0.0037)	
training:	Epoch: [79][176/204]	Loss 0.0011 (0.0037)	
training:	Epoch: [79][177/204]	Loss 0.0012 (0.0036)	
training:	Epoch: [79][178/204]	Loss 0.0010 (0.0036)	
training:	Epoch: [79][179/204]	Loss 0.0021 (0.0036)	
training:	Epoch: [79][180/204]	Loss 0.0088 (0.0037)	
training:	Epoch: [79][181/204]	Loss 0.0012 (0.0036)	
training:	Epoch: [79][182/204]	Loss 0.0028 (0.0036)	
training:	Epoch: [79][183/204]	Loss 0.0013 (0.0036)	
training:	Epoch: [79][184/204]	Loss 0.0010 (0.0036)	
training:	Epoch: [79][185/204]	Loss 0.0011 (0.0036)	
training:	Epoch: [79][186/204]	Loss 0.0026 (0.0036)	
training:	Epoch: [79][187/204]	Loss 0.0012 (0.0036)	
training:	Epoch: [79][188/204]	Loss 0.0011 (0.0036)	
training:	Epoch: [79][189/204]	Loss 0.0010 (0.0035)	
training:	Epoch: [79][190/204]	Loss 0.0011 (0.0035)	
training:	Epoch: [79][191/204]	Loss 0.0011 (0.0035)	
training:	Epoch: [79][192/204]	Loss 0.0019 (0.0035)	
training:	Epoch: [79][193/204]	Loss 0.0010 (0.0035)	
training:	Epoch: [79][194/204]	Loss 0.0030 (0.0035)	
training:	Epoch: [79][195/204]	Loss 0.0010 (0.0035)	
training:	Epoch: [79][196/204]	Loss 0.0010 (0.0035)	
training:	Epoch: [79][197/204]	Loss 0.0017 (0.0035)	
training:	Epoch: [79][198/204]	Loss 0.0013 (0.0035)	
training:	Epoch: [79][199/204]	Loss 0.0010 (0.0034)	
training:	Epoch: [79][200/204]	Loss 0.0012 (0.0034)	
training:	Epoch: [79][201/204]	Loss 0.0013 (0.0034)	
training:	Epoch: [79][202/204]	Loss 0.0016 (0.0034)	
training:	Epoch: [79][203/204]	Loss 0.0010 (0.0034)	
training:	Epoch: [79][204/204]	Loss 0.0013 (0.0034)	
Training:	 Loss: 0.0034

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7772 0.7774 0.7820 0.7724
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3039
Pretraining:	Epoch 80/500
----------
training:	Epoch: [80][1/204]	Loss 0.0009 (0.0009)	
training:	Epoch: [80][2/204]	Loss 0.0021 (0.0015)	
training:	Epoch: [80][3/204]	Loss 0.0010 (0.0013)	
training:	Epoch: [80][4/204]	Loss 0.0014 (0.0014)	
training:	Epoch: [80][5/204]	Loss 0.0050 (0.0021)	
training:	Epoch: [80][6/204]	Loss 0.0013 (0.0020)	
training:	Epoch: [80][7/204]	Loss 0.0011 (0.0018)	
training:	Epoch: [80][8/204]	Loss 0.0012 (0.0018)	
training:	Epoch: [80][9/204]	Loss 0.0012 (0.0017)	
training:	Epoch: [80][10/204]	Loss 0.0019 (0.0017)	
training:	Epoch: [80][11/204]	Loss 0.0010 (0.0017)	
training:	Epoch: [80][12/204]	Loss 0.0012 (0.0016)	
training:	Epoch: [80][13/204]	Loss 0.0011 (0.0016)	
training:	Epoch: [80][14/204]	Loss 0.0011 (0.0016)	
training:	Epoch: [80][15/204]	Loss 0.0019 (0.0016)	
training:	Epoch: [80][16/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][17/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [80][18/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][19/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [80][20/204]	Loss 0.0033 (0.0015)	
training:	Epoch: [80][21/204]	Loss 0.0016 (0.0015)	
training:	Epoch: [80][22/204]	Loss 0.0016 (0.0015)	
training:	Epoch: [80][23/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][24/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][25/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [80][26/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][27/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][28/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [80][29/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [80][30/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [80][31/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [80][32/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [80][33/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [80][34/204]	Loss 0.0043 (0.0015)	
training:	Epoch: [80][35/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][36/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [80][37/204]	Loss 0.0012 (0.0014)	
training:	Epoch: [80][38/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][39/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][40/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][41/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][42/204]	Loss 0.0014 (0.0014)	
training:	Epoch: [80][43/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][44/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [80][45/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [80][46/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [80][47/204]	Loss 0.0019 (0.0014)	
training:	Epoch: [80][48/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [80][49/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [80][50/204]	Loss 0.0016 (0.0014)	
training:	Epoch: [80][51/204]	Loss 0.0097 (0.0015)	
training:	Epoch: [80][52/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][53/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][54/204]	Loss 0.0016 (0.0015)	
training:	Epoch: [80][55/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][56/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][57/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][58/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][59/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][60/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][61/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][62/204]	Loss 0.0016 (0.0015)	
training:	Epoch: [80][63/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][64/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][65/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [80][66/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [80][67/204]	Loss 0.0012 (0.0014)	
training:	Epoch: [80][68/204]	Loss 0.0041 (0.0015)	
training:	Epoch: [80][69/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][70/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][71/204]	Loss 0.0012 (0.0015)	
training:	Epoch: [80][72/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [80][73/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [80][74/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][75/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [80][76/204]	Loss 0.0019 (0.0014)	
training:	Epoch: [80][77/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [80][78/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][79/204]	Loss 0.0057 (0.0015)	
training:	Epoch: [80][80/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][81/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][82/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][83/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][84/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][85/204]	Loss 0.0041 (0.0015)	
training:	Epoch: [80][86/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][87/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][88/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][89/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][90/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][91/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][92/204]	Loss 0.0013 (0.0015)	
training:	Epoch: [80][93/204]	Loss 0.0017 (0.0015)	
training:	Epoch: [80][94/204]	Loss 0.0012 (0.0015)	
training:	Epoch: [80][95/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][96/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [80][97/204]	Loss 0.0058 (0.0015)	
training:	Epoch: [80][98/204]	Loss 0.0029 (0.0015)	
training:	Epoch: [80][99/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][100/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][101/204]	Loss 0.0032 (0.0015)	
training:	Epoch: [80][102/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][103/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][104/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [80][105/204]	Loss 0.0022 (0.0015)	
training:	Epoch: [80][106/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][107/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][108/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][109/204]	Loss 0.0013 (0.0015)	
training:	Epoch: [80][110/204]	Loss 0.0014 (0.0015)	
training:	Epoch: [80][111/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][112/204]	Loss 0.0013 (0.0015)	
training:	Epoch: [80][113/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [80][114/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][115/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [80][116/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [80][117/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][118/204]	Loss 0.0024 (0.0015)	
training:	Epoch: [80][119/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [80][120/204]	Loss 0.0012 (0.0015)	
training:	Epoch: [80][121/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [80][122/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [80][123/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [80][124/204]	Loss 0.0015 (0.0014)	
training:	Epoch: [80][125/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [80][126/204]	Loss 0.2066 (0.0031)	
training:	Epoch: [80][127/204]	Loss 0.0012 (0.0031)	
training:	Epoch: [80][128/204]	Loss 0.0023 (0.0030)	
training:	Epoch: [80][129/204]	Loss 0.0058 (0.0031)	
training:	Epoch: [80][130/204]	Loss 0.0013 (0.0031)	
training:	Epoch: [80][131/204]	Loss 0.0020 (0.0030)	
training:	Epoch: [80][132/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [80][133/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [80][134/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [80][135/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [80][136/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [80][137/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [80][138/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [80][139/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [80][140/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [80][141/204]	Loss 0.0074 (0.0029)	
training:	Epoch: [80][142/204]	Loss 0.0018 (0.0029)	
training:	Epoch: [80][143/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [80][144/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [80][145/204]	Loss 0.0117 (0.0030)	
training:	Epoch: [80][146/204]	Loss 0.0011 (0.0030)	
training:	Epoch: [80][147/204]	Loss 0.0031 (0.0030)	
training:	Epoch: [80][148/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [80][149/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [80][150/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [80][151/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [80][152/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [80][153/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [80][154/204]	Loss 0.0040 (0.0029)	
training:	Epoch: [80][155/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [80][156/204]	Loss 0.0015 (0.0029)	
training:	Epoch: [80][157/204]	Loss 0.0071 (0.0029)	
training:	Epoch: [80][158/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [80][159/204]	Loss 0.0114 (0.0029)	
training:	Epoch: [80][160/204]	Loss 0.0021 (0.0029)	
training:	Epoch: [80][161/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [80][162/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [80][163/204]	Loss 0.0021 (0.0029)	
training:	Epoch: [80][164/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [80][165/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [80][166/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [80][167/204]	Loss 0.0032 (0.0029)	
training:	Epoch: [80][168/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [80][169/204]	Loss 0.0015 (0.0029)	
training:	Epoch: [80][170/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [80][171/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [80][172/204]	Loss 0.0021 (0.0028)	
training:	Epoch: [80][173/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [80][174/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [80][175/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [80][176/204]	Loss 0.0014 (0.0028)	
training:	Epoch: [80][177/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [80][178/204]	Loss 0.0013 (0.0028)	
training:	Epoch: [80][179/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [80][180/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [80][181/204]	Loss 0.0014 (0.0027)	
training:	Epoch: [80][182/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [80][183/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [80][184/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [80][185/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [80][186/204]	Loss 0.0029 (0.0027)	
training:	Epoch: [80][187/204]	Loss 0.0096 (0.0027)	
training:	Epoch: [80][188/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [80][189/204]	Loss 0.0010 (0.0027)	
training:	Epoch: [80][190/204]	Loss 0.0084 (0.0028)	
training:	Epoch: [80][191/204]	Loss 0.0010 (0.0027)	
training:	Epoch: [80][192/204]	Loss 0.0110 (0.0028)	
training:	Epoch: [80][193/204]	Loss 0.0030 (0.0028)	
training:	Epoch: [80][194/204]	Loss 0.0019 (0.0028)	
training:	Epoch: [80][195/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [80][196/204]	Loss 0.0105 (0.0028)	
training:	Epoch: [80][197/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [80][198/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [80][199/204]	Loss 0.0013 (0.0028)	
training:	Epoch: [80][200/204]	Loss 0.0054 (0.0028)	
training:	Epoch: [80][201/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [80][202/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [80][203/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [80][204/204]	Loss 0.0081 (0.0028)	
Training:	 Loss: 0.0028

Training:	 ACC: 0.9997 0.9997 0.9997 0.9997
Validation:	 ACC: 0.7674 0.7699 0.8229 0.7119
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3497
Pretraining:	Epoch 81/500
----------
training:	Epoch: [81][1/204]	Loss 0.0016 (0.0016)	
training:	Epoch: [81][2/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [81][3/204]	Loss 0.0010 (0.0012)	
training:	Epoch: [81][4/204]	Loss 0.0010 (0.0012)	
training:	Epoch: [81][5/204]	Loss 0.0010 (0.0011)	
training:	Epoch: [81][6/204]	Loss 0.0024 (0.0013)	
training:	Epoch: [81][7/204]	Loss 0.0011 (0.0013)	
training:	Epoch: [81][8/204]	Loss 0.0010 (0.0013)	
training:	Epoch: [81][9/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [81][10/204]	Loss 0.0014 (0.0012)	
training:	Epoch: [81][11/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [81][12/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [81][13/204]	Loss 0.0014 (0.0012)	
training:	Epoch: [81][14/204]	Loss 0.0036 (0.0014)	
training:	Epoch: [81][15/204]	Loss 0.0010 (0.0013)	
training:	Epoch: [81][16/204]	Loss 0.0008 (0.0013)	
training:	Epoch: [81][17/204]	Loss 0.0013 (0.0013)	
training:	Epoch: [81][18/204]	Loss 0.0087 (0.0017)	
training:	Epoch: [81][19/204]	Loss 0.0011 (0.0017)	
training:	Epoch: [81][20/204]	Loss 0.0010 (0.0017)	
training:	Epoch: [81][21/204]	Loss 0.0019 (0.0017)	
training:	Epoch: [81][22/204]	Loss 0.0010 (0.0016)	
training:	Epoch: [81][23/204]	Loss 0.0009 (0.0016)	
training:	Epoch: [81][24/204]	Loss 0.0011 (0.0016)	
training:	Epoch: [81][25/204]	Loss 0.0009 (0.0016)	
training:	Epoch: [81][26/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [81][27/204]	Loss 0.0122 (0.0019)	
training:	Epoch: [81][28/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [81][29/204]	Loss 0.0036 (0.0020)	
training:	Epoch: [81][30/204]	Loss 0.0009 (0.0019)	
training:	Epoch: [81][31/204]	Loss 0.0024 (0.0019)	
training:	Epoch: [81][32/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][33/204]	Loss 0.0009 (0.0019)	
training:	Epoch: [81][34/204]	Loss 0.0017 (0.0019)	
training:	Epoch: [81][35/204]	Loss 0.0010 (0.0018)	
training:	Epoch: [81][36/204]	Loss 0.0085 (0.0020)	
training:	Epoch: [81][37/204]	Loss 0.0009 (0.0020)	
training:	Epoch: [81][38/204]	Loss 0.0011 (0.0020)	
training:	Epoch: [81][39/204]	Loss 0.0009 (0.0019)	
training:	Epoch: [81][40/204]	Loss 0.0052 (0.0020)	
training:	Epoch: [81][41/204]	Loss 0.0009 (0.0020)	
training:	Epoch: [81][42/204]	Loss 0.0010 (0.0020)	
training:	Epoch: [81][43/204]	Loss 0.0023 (0.0020)	
training:	Epoch: [81][44/204]	Loss 0.0010 (0.0020)	
training:	Epoch: [81][45/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [81][46/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][47/204]	Loss 0.0028 (0.0019)	
training:	Epoch: [81][48/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][49/204]	Loss 0.0012 (0.0019)	
training:	Epoch: [81][50/204]	Loss 0.0009 (0.0019)	
training:	Epoch: [81][51/204]	Loss 0.0009 (0.0019)	
training:	Epoch: [81][52/204]	Loss 0.0031 (0.0019)	
training:	Epoch: [81][53/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [81][54/204]	Loss 0.0020 (0.0019)	
training:	Epoch: [81][55/204]	Loss 0.0009 (0.0019)	
training:	Epoch: [81][56/204]	Loss 0.0023 (0.0019)	
training:	Epoch: [81][57/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][58/204]	Loss 0.0077 (0.0020)	
training:	Epoch: [81][59/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][60/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][61/204]	Loss 0.0012 (0.0019)	
training:	Epoch: [81][62/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [81][63/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][64/204]	Loss 0.0009 (0.0019)	
training:	Epoch: [81][65/204]	Loss 0.0013 (0.0019)	
training:	Epoch: [81][66/204]	Loss 0.0020 (0.0019)	
training:	Epoch: [81][67/204]	Loss 0.0014 (0.0019)	
training:	Epoch: [81][68/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [81][69/204]	Loss 0.0013 (0.0018)	
training:	Epoch: [81][70/204]	Loss 0.0009 (0.0018)	
training:	Epoch: [81][71/204]	Loss 0.0013 (0.0018)	
training:	Epoch: [81][72/204]	Loss 0.0071 (0.0019)	
training:	Epoch: [81][73/204]	Loss 0.0015 (0.0019)	
training:	Epoch: [81][74/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][75/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [81][76/204]	Loss 0.0015 (0.0018)	
training:	Epoch: [81][77/204]	Loss 0.0013 (0.0018)	
training:	Epoch: [81][78/204]	Loss 0.0023 (0.0018)	
training:	Epoch: [81][79/204]	Loss 0.0011 (0.0018)	
training:	Epoch: [81][80/204]	Loss 0.0011 (0.0018)	
training:	Epoch: [81][81/204]	Loss 0.0009 (0.0018)	
training:	Epoch: [81][82/204]	Loss 0.0012 (0.0018)	
training:	Epoch: [81][83/204]	Loss 0.0009 (0.0018)	
training:	Epoch: [81][84/204]	Loss 0.0009 (0.0018)	
training:	Epoch: [81][85/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [81][86/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [81][87/204]	Loss 0.0009 (0.0018)	
training:	Epoch: [81][88/204]	Loss 0.0012 (0.0017)	
training:	Epoch: [81][89/204]	Loss 0.0107 (0.0018)	
training:	Epoch: [81][90/204]	Loss 0.0009 (0.0018)	
training:	Epoch: [81][91/204]	Loss 0.0009 (0.0018)	
training:	Epoch: [81][92/204]	Loss 0.0026 (0.0018)	
training:	Epoch: [81][93/204]	Loss 0.0010 (0.0018)	
training:	Epoch: [81][94/204]	Loss 0.0055 (0.0019)	
training:	Epoch: [81][95/204]	Loss 0.0046 (0.0019)	
training:	Epoch: [81][96/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][97/204]	Loss 0.0009 (0.0019)	
training:	Epoch: [81][98/204]	Loss 0.0016 (0.0019)	
training:	Epoch: [81][99/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [81][100/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [81][101/204]	Loss 0.0011 (0.0018)	
training:	Epoch: [81][102/204]	Loss 0.0012 (0.0018)	
training:	Epoch: [81][103/204]	Loss 0.0012 (0.0018)	
training:	Epoch: [81][104/204]	Loss 0.0014 (0.0018)	
training:	Epoch: [81][105/204]	Loss 0.0010 (0.0018)	
training:	Epoch: [81][106/204]	Loss 0.1176 (0.0029)	
training:	Epoch: [81][107/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [81][108/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [81][109/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [81][110/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [81][111/204]	Loss 0.0013 (0.0028)	
training:	Epoch: [81][112/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [81][113/204]	Loss 0.0028 (0.0028)	
training:	Epoch: [81][114/204]	Loss 0.0027 (0.0028)	
training:	Epoch: [81][115/204]	Loss 0.0019 (0.0028)	
training:	Epoch: [81][116/204]	Loss 0.0057 (0.0028)	
training:	Epoch: [81][117/204]	Loss 0.0273 (0.0030)	
training:	Epoch: [81][118/204]	Loss 0.0061 (0.0031)	
training:	Epoch: [81][119/204]	Loss 0.0085 (0.0031)	
training:	Epoch: [81][120/204]	Loss 0.0012 (0.0031)	
training:	Epoch: [81][121/204]	Loss 0.0010 (0.0031)	
training:	Epoch: [81][122/204]	Loss 0.0010 (0.0031)	
training:	Epoch: [81][123/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [81][124/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [81][125/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [81][126/204]	Loss 0.2055 (0.0046)	
training:	Epoch: [81][127/204]	Loss 0.0010 (0.0046)	
training:	Epoch: [81][128/204]	Loss 0.0049 (0.0046)	
training:	Epoch: [81][129/204]	Loss 0.0011 (0.0046)	
training:	Epoch: [81][130/204]	Loss 0.0046 (0.0046)	
training:	Epoch: [81][131/204]	Loss 0.0009 (0.0045)	
training:	Epoch: [81][132/204]	Loss 0.0011 (0.0045)	
training:	Epoch: [81][133/204]	Loss 0.0010 (0.0045)	
training:	Epoch: [81][134/204]	Loss 0.0011 (0.0045)	
training:	Epoch: [81][135/204]	Loss 0.0017 (0.0044)	
training:	Epoch: [81][136/204]	Loss 0.0012 (0.0044)	
training:	Epoch: [81][137/204]	Loss 0.0009 (0.0044)	
training:	Epoch: [81][138/204]	Loss 0.0011 (0.0044)	
training:	Epoch: [81][139/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [81][140/204]	Loss 0.0011 (0.0043)	
training:	Epoch: [81][141/204]	Loss 0.0009 (0.0043)	
training:	Epoch: [81][142/204]	Loss 0.0010 (0.0043)	
training:	Epoch: [81][143/204]	Loss 0.0022 (0.0043)	
training:	Epoch: [81][144/204]	Loss 0.0056 (0.0043)	
training:	Epoch: [81][145/204]	Loss 0.0010 (0.0042)	
training:	Epoch: [81][146/204]	Loss 0.0021 (0.0042)	
training:	Epoch: [81][147/204]	Loss 0.0016 (0.0042)	
training:	Epoch: [81][148/204]	Loss 0.0010 (0.0042)	
training:	Epoch: [81][149/204]	Loss 0.0019 (0.0042)	
training:	Epoch: [81][150/204]	Loss 0.0025 (0.0042)	
training:	Epoch: [81][151/204]	Loss 0.0010 (0.0041)	
training:	Epoch: [81][152/204]	Loss 0.0433 (0.0044)	
training:	Epoch: [81][153/204]	Loss 0.0008 (0.0044)	
training:	Epoch: [81][154/204]	Loss 0.0010 (0.0044)	
training:	Epoch: [81][155/204]	Loss 0.0016 (0.0043)	
training:	Epoch: [81][156/204]	Loss 0.0010 (0.0043)	
training:	Epoch: [81][157/204]	Loss 0.0013 (0.0043)	
training:	Epoch: [81][158/204]	Loss 0.0014 (0.0043)	
training:	Epoch: [81][159/204]	Loss 0.0032 (0.0043)	
training:	Epoch: [81][160/204]	Loss 0.0020 (0.0043)	
training:	Epoch: [81][161/204]	Loss 0.0010 (0.0042)	
training:	Epoch: [81][162/204]	Loss 0.0009 (0.0042)	
training:	Epoch: [81][163/204]	Loss 0.0009 (0.0042)	
training:	Epoch: [81][164/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [81][165/204]	Loss 0.0010 (0.0042)	
training:	Epoch: [81][166/204]	Loss 0.0009 (0.0041)	
training:	Epoch: [81][167/204]	Loss 0.0009 (0.0041)	
training:	Epoch: [81][168/204]	Loss 0.0014 (0.0041)	
training:	Epoch: [81][169/204]	Loss 0.0011 (0.0041)	
training:	Epoch: [81][170/204]	Loss 0.0015 (0.0041)	
training:	Epoch: [81][171/204]	Loss 0.0031 (0.0041)	
training:	Epoch: [81][172/204]	Loss 0.0011 (0.0040)	
training:	Epoch: [81][173/204]	Loss 0.0009 (0.0040)	
training:	Epoch: [81][174/204]	Loss 0.0012 (0.0040)	
training:	Epoch: [81][175/204]	Loss 0.0022 (0.0040)	
training:	Epoch: [81][176/204]	Loss 0.0013 (0.0040)	
training:	Epoch: [81][177/204]	Loss 0.0010 (0.0040)	
training:	Epoch: [81][178/204]	Loss 0.0014 (0.0040)	
training:	Epoch: [81][179/204]	Loss 0.0010 (0.0039)	
training:	Epoch: [81][180/204]	Loss 0.0011 (0.0039)	
training:	Epoch: [81][181/204]	Loss 0.0117 (0.0040)	
training:	Epoch: [81][182/204]	Loss 0.0013 (0.0039)	
training:	Epoch: [81][183/204]	Loss 0.0008 (0.0039)	
training:	Epoch: [81][184/204]	Loss 0.0009 (0.0039)	
training:	Epoch: [81][185/204]	Loss 0.0009 (0.0039)	
training:	Epoch: [81][186/204]	Loss 0.0081 (0.0039)	
training:	Epoch: [81][187/204]	Loss 0.0009 (0.0039)	
training:	Epoch: [81][188/204]	Loss 0.0014 (0.0039)	
training:	Epoch: [81][189/204]	Loss 0.0015 (0.0039)	
training:	Epoch: [81][190/204]	Loss 0.0018 (0.0039)	
training:	Epoch: [81][191/204]	Loss 0.0015 (0.0039)	
training:	Epoch: [81][192/204]	Loss 0.0014 (0.0038)	
training:	Epoch: [81][193/204]	Loss 0.0079 (0.0039)	
training:	Epoch: [81][194/204]	Loss 0.0019 (0.0039)	
training:	Epoch: [81][195/204]	Loss 0.0011 (0.0038)	
training:	Epoch: [81][196/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [81][197/204]	Loss 0.0017 (0.0038)	
training:	Epoch: [81][198/204]	Loss 0.0020 (0.0038)	
training:	Epoch: [81][199/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [81][200/204]	Loss 0.0009 (0.0038)	
training:	Epoch: [81][201/204]	Loss 0.0013 (0.0038)	
training:	Epoch: [81][202/204]	Loss 0.0009 (0.0037)	
training:	Epoch: [81][203/204]	Loss 0.0036 (0.0037)	
training:	Epoch: [81][204/204]	Loss 0.0013 (0.0037)	
Training:	 Loss: 0.0037

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7739 0.7747 0.7932 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3548
Pretraining:	Epoch 82/500
----------
training:	Epoch: [82][1/204]	Loss 0.0009 (0.0009)	
training:	Epoch: [82][2/204]	Loss 0.0010 (0.0010)	
training:	Epoch: [82][3/204]	Loss 0.0013 (0.0011)	
training:	Epoch: [82][4/204]	Loss 0.0038 (0.0018)	
training:	Epoch: [82][5/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [82][6/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [82][7/204]	Loss 0.0012 (0.0014)	
training:	Epoch: [82][8/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [82][9/204]	Loss 0.0012 (0.0014)	
training:	Epoch: [82][10/204]	Loss 0.0010 (0.0013)	
training:	Epoch: [82][11/204]	Loss 0.0009 (0.0013)	
training:	Epoch: [82][12/204]	Loss 0.0010 (0.0013)	
training:	Epoch: [82][13/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][14/204]	Loss 0.0030 (0.0014)	
training:	Epoch: [82][15/204]	Loss 0.0011 (0.0013)	
training:	Epoch: [82][16/204]	Loss 0.0010 (0.0013)	
training:	Epoch: [82][17/204]	Loss 0.0011 (0.0013)	
training:	Epoch: [82][18/204]	Loss 0.0011 (0.0013)	
training:	Epoch: [82][19/204]	Loss 0.0008 (0.0013)	
training:	Epoch: [82][20/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [82][21/204]	Loss 0.0010 (0.0012)	
training:	Epoch: [82][22/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][23/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][24/204]	Loss 0.0010 (0.0012)	
training:	Epoch: [82][25/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][26/204]	Loss 0.0017 (0.0012)	
training:	Epoch: [82][27/204]	Loss 0.0011 (0.0012)	
training:	Epoch: [82][28/204]	Loss 0.0029 (0.0013)	
training:	Epoch: [82][29/204]	Loss 0.0011 (0.0013)	
training:	Epoch: [82][30/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [82][31/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][32/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [82][33/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][34/204]	Loss 0.0010 (0.0012)	
training:	Epoch: [82][35/204]	Loss 0.0011 (0.0012)	
training:	Epoch: [82][36/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][37/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][38/204]	Loss 0.0022 (0.0012)	
training:	Epoch: [82][39/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][40/204]	Loss 0.0010 (0.0012)	
training:	Epoch: [82][41/204]	Loss 0.0014 (0.0012)	
training:	Epoch: [82][42/204]	Loss 0.0014 (0.0012)	
training:	Epoch: [82][43/204]	Loss 0.0014 (0.0012)	
training:	Epoch: [82][44/204]	Loss 0.0017 (0.0012)	
training:	Epoch: [82][45/204]	Loss 0.0012 (0.0012)	
training:	Epoch: [82][46/204]	Loss 0.0020 (0.0012)	
training:	Epoch: [82][47/204]	Loss 0.0010 (0.0012)	
training:	Epoch: [82][48/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [82][49/204]	Loss 0.0118 (0.0014)	
training:	Epoch: [82][50/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [82][51/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [82][52/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [82][53/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][54/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [82][55/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][56/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][57/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [82][58/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [82][59/204]	Loss 0.0038 (0.0014)	
training:	Epoch: [82][60/204]	Loss 0.0016 (0.0014)	
training:	Epoch: [82][61/204]	Loss 0.0060 (0.0015)	
training:	Epoch: [82][62/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][63/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][64/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [82][65/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][66/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [82][67/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [82][68/204]	Loss 0.0013 (0.0014)	
training:	Epoch: [82][69/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][70/204]	Loss 0.0095 (0.0015)	
training:	Epoch: [82][71/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][72/204]	Loss 0.0016 (0.0015)	
training:	Epoch: [82][73/204]	Loss 0.0013 (0.0015)	
training:	Epoch: [82][74/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [82][75/204]	Loss 0.0014 (0.0015)	
training:	Epoch: [82][76/204]	Loss 0.0015 (0.0015)	
training:	Epoch: [82][77/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [82][78/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][79/204]	Loss 0.0015 (0.0015)	
training:	Epoch: [82][80/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [82][81/204]	Loss 0.0017 (0.0015)	
training:	Epoch: [82][82/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [82][83/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][84/204]	Loss 0.0014 (0.0015)	
training:	Epoch: [82][85/204]	Loss 0.0016 (0.0015)	
training:	Epoch: [82][86/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][87/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][88/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][89/204]	Loss 0.0013 (0.0015)	
training:	Epoch: [82][90/204]	Loss 0.0013 (0.0015)	
training:	Epoch: [82][91/204]	Loss 0.0015 (0.0015)	
training:	Epoch: [82][92/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [82][93/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [82][94/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][95/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [82][96/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [82][97/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [82][98/204]	Loss 0.0017 (0.0014)	
training:	Epoch: [82][99/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [82][100/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [82][101/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][102/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][103/204]	Loss 0.0012 (0.0014)	
training:	Epoch: [82][104/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [82][105/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][106/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [82][107/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][108/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [82][109/204]	Loss 0.0055 (0.0014)	
training:	Epoch: [82][110/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [82][111/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [82][112/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [82][113/204]	Loss 0.0072 (0.0015)	
training:	Epoch: [82][114/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [82][115/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [82][116/204]	Loss 0.0012 (0.0014)	
training:	Epoch: [82][117/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [82][118/204]	Loss 0.0015 (0.0014)	
training:	Epoch: [82][119/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [82][120/204]	Loss 0.0073 (0.0015)	
training:	Epoch: [82][121/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][122/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [82][123/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][124/204]	Loss 0.0099 (0.0015)	
training:	Epoch: [82][125/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [82][126/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [82][127/204]	Loss 0.0017 (0.0015)	
training:	Epoch: [82][128/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [82][129/204]	Loss 0.0007 (0.0015)	
training:	Epoch: [82][130/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][131/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [82][132/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [82][133/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [82][134/204]	Loss 0.0024 (0.0015)	
training:	Epoch: [82][135/204]	Loss 0.0065 (0.0015)	
training:	Epoch: [82][136/204]	Loss 0.0036 (0.0016)	
training:	Epoch: [82][137/204]	Loss 0.0113 (0.0016)	
training:	Epoch: [82][138/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [82][139/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [82][140/204]	Loss 0.0010 (0.0016)	
training:	Epoch: [82][141/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [82][142/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [82][143/204]	Loss 0.0011 (0.0016)	
training:	Epoch: [82][144/204]	Loss 0.0010 (0.0016)	
training:	Epoch: [82][145/204]	Loss 0.0010 (0.0016)	
training:	Epoch: [82][146/204]	Loss 0.0009 (0.0016)	
training:	Epoch: [82][147/204]	Loss 0.0009 (0.0016)	
training:	Epoch: [82][148/204]	Loss 0.0064 (0.0016)	
training:	Epoch: [82][149/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [82][150/204]	Loss 0.0021 (0.0016)	
training:	Epoch: [82][151/204]	Loss 0.0017 (0.0016)	
training:	Epoch: [82][152/204]	Loss 0.0009 (0.0016)	
training:	Epoch: [82][153/204]	Loss 0.2085 (0.0030)	
training:	Epoch: [82][154/204]	Loss 0.0016 (0.0029)	
training:	Epoch: [82][155/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [82][156/204]	Loss 0.0016 (0.0029)	
training:	Epoch: [82][157/204]	Loss 0.0017 (0.0029)	
training:	Epoch: [82][158/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [82][159/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [82][160/204]	Loss 0.0017 (0.0029)	
training:	Epoch: [82][161/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [82][162/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [82][163/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [82][164/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [82][165/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [82][166/204]	Loss 0.0159 (0.0029)	
training:	Epoch: [82][167/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [82][168/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [82][169/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [82][170/204]	Loss 0.0018 (0.0029)	
training:	Epoch: [82][171/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [82][172/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [82][173/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [82][174/204]	Loss 0.0016 (0.0028)	
training:	Epoch: [82][175/204]	Loss 0.0041 (0.0028)	
training:	Epoch: [82][176/204]	Loss 0.0027 (0.0028)	
training:	Epoch: [82][177/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [82][178/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [82][179/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [82][180/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [82][181/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [82][182/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [82][183/204]	Loss 0.0013 (0.0028)	
training:	Epoch: [82][184/204]	Loss 0.0030 (0.0028)	
training:	Epoch: [82][185/204]	Loss 0.0029 (0.0028)	
training:	Epoch: [82][186/204]	Loss 0.0035 (0.0028)	
training:	Epoch: [82][187/204]	Loss 0.0135 (0.0028)	
training:	Epoch: [82][188/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [82][189/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [82][190/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [82][191/204]	Loss 0.0021 (0.0028)	
training:	Epoch: [82][192/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [82][193/204]	Loss 0.0019 (0.0028)	
training:	Epoch: [82][194/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [82][195/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [82][196/204]	Loss 0.0008 (0.0027)	
training:	Epoch: [82][197/204]	Loss 0.0025 (0.0027)	
training:	Epoch: [82][198/204]	Loss 0.0010 (0.0027)	
training:	Epoch: [82][199/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [82][200/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [82][201/204]	Loss 0.0199 (0.0028)	
training:	Epoch: [82][202/204]	Loss 0.1150 (0.0034)	
training:	Epoch: [82][203/204]	Loss 0.0024 (0.0034)	
training:	Epoch: [82][204/204]	Loss 0.0012 (0.0033)	
Training:	 Loss: 0.0033

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7673 0.7689 0.8014 0.7332
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3998
Pretraining:	Epoch 83/500
----------
training:	Epoch: [83][1/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [83][2/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [83][3/204]	Loss 0.0011 (0.0009)	
training:	Epoch: [83][4/204]	Loss 0.0034 (0.0015)	
training:	Epoch: [83][5/204]	Loss 0.0044 (0.0021)	
training:	Epoch: [83][6/204]	Loss 0.0008 (0.0019)	
training:	Epoch: [83][7/204]	Loss 0.0369 (0.0069)	
training:	Epoch: [83][8/204]	Loss 0.2112 (0.0324)	
training:	Epoch: [83][9/204]	Loss 0.0031 (0.0292)	
training:	Epoch: [83][10/204]	Loss 0.0009 (0.0263)	
training:	Epoch: [83][11/204]	Loss 0.0010 (0.0240)	
training:	Epoch: [83][12/204]	Loss 0.0009 (0.0221)	
training:	Epoch: [83][13/204]	Loss 0.0010 (0.0205)	
training:	Epoch: [83][14/204]	Loss 0.0021 (0.0192)	
training:	Epoch: [83][15/204]	Loss 0.0008 (0.0179)	
training:	Epoch: [83][16/204]	Loss 0.0203 (0.0181)	
training:	Epoch: [83][17/204]	Loss 0.0250 (0.0185)	
training:	Epoch: [83][18/204]	Loss 0.0011 (0.0175)	
training:	Epoch: [83][19/204]	Loss 0.0010 (0.0167)	
training:	Epoch: [83][20/204]	Loss 0.0008 (0.0159)	
training:	Epoch: [83][21/204]	Loss 0.0065 (0.0154)	
training:	Epoch: [83][22/204]	Loss 0.0010 (0.0148)	
training:	Epoch: [83][23/204]	Loss 0.0092 (0.0145)	
training:	Epoch: [83][24/204]	Loss 0.0009 (0.0140)	
training:	Epoch: [83][25/204]	Loss 0.0037 (0.0135)	
training:	Epoch: [83][26/204]	Loss 0.0013 (0.0131)	
training:	Epoch: [83][27/204]	Loss 0.0011 (0.0126)	
training:	Epoch: [83][28/204]	Loss 0.0011 (0.0122)	
training:	Epoch: [83][29/204]	Loss 0.0007 (0.0118)	
training:	Epoch: [83][30/204]	Loss 0.0058 (0.0116)	
training:	Epoch: [83][31/204]	Loss 0.1610 (0.0164)	
training:	Epoch: [83][32/204]	Loss 0.0023 (0.0160)	
training:	Epoch: [83][33/204]	Loss 0.0096 (0.0158)	
training:	Epoch: [83][34/204]	Loss 0.0009 (0.0154)	
training:	Epoch: [83][35/204]	Loss 0.0012 (0.0150)	
training:	Epoch: [83][36/204]	Loss 0.0021 (0.0146)	
training:	Epoch: [83][37/204]	Loss 0.0099 (0.0145)	
training:	Epoch: [83][38/204]	Loss 0.0655 (0.0158)	
training:	Epoch: [83][39/204]	Loss 0.0008 (0.0154)	
training:	Epoch: [83][40/204]	Loss 0.0011 (0.0151)	
training:	Epoch: [83][41/204]	Loss 0.0022 (0.0148)	
training:	Epoch: [83][42/204]	Loss 0.0017 (0.0145)	
training:	Epoch: [83][43/204]	Loss 0.0011 (0.0141)	
training:	Epoch: [83][44/204]	Loss 0.0008 (0.0138)	
training:	Epoch: [83][45/204]	Loss 0.0012 (0.0136)	
training:	Epoch: [83][46/204]	Loss 0.0017 (0.0133)	
training:	Epoch: [83][47/204]	Loss 0.0019 (0.0131)	
training:	Epoch: [83][48/204]	Loss 0.0009 (0.0128)	
training:	Epoch: [83][49/204]	Loss 0.0020 (0.0126)	
training:	Epoch: [83][50/204]	Loss 0.0018 (0.0124)	
training:	Epoch: [83][51/204]	Loss 0.0030 (0.0122)	
training:	Epoch: [83][52/204]	Loss 0.0012 (0.0120)	
training:	Epoch: [83][53/204]	Loss 0.0018 (0.0118)	
training:	Epoch: [83][54/204]	Loss 0.0009 (0.0116)	
training:	Epoch: [83][55/204]	Loss 0.0011 (0.0114)	
training:	Epoch: [83][56/204]	Loss 0.0013 (0.0112)	
training:	Epoch: [83][57/204]	Loss 0.0229 (0.0114)	
training:	Epoch: [83][58/204]	Loss 0.0008 (0.0112)	
training:	Epoch: [83][59/204]	Loss 0.0009 (0.0111)	
training:	Epoch: [83][60/204]	Loss 0.0012 (0.0109)	
training:	Epoch: [83][61/204]	Loss 0.0014 (0.0107)	
training:	Epoch: [83][62/204]	Loss 0.0013 (0.0106)	
training:	Epoch: [83][63/204]	Loss 0.0009 (0.0104)	
training:	Epoch: [83][64/204]	Loss 0.0010 (0.0103)	
training:	Epoch: [83][65/204]	Loss 0.0011 (0.0101)	
training:	Epoch: [83][66/204]	Loss 0.0010 (0.0100)	
training:	Epoch: [83][67/204]	Loss 0.1802 (0.0125)	
training:	Epoch: [83][68/204]	Loss 0.0014 (0.0124)	
training:	Epoch: [83][69/204]	Loss 0.0082 (0.0123)	
training:	Epoch: [83][70/204]	Loss 0.0018 (0.0122)	
training:	Epoch: [83][71/204]	Loss 0.0009 (0.0120)	
training:	Epoch: [83][72/204]	Loss 0.0010 (0.0119)	
training:	Epoch: [83][73/204]	Loss 0.0598 (0.0125)	
training:	Epoch: [83][74/204]	Loss 0.0008 (0.0124)	
training:	Epoch: [83][75/204]	Loss 0.0008 (0.0122)	
training:	Epoch: [83][76/204]	Loss 0.0008 (0.0121)	
training:	Epoch: [83][77/204]	Loss 0.0018 (0.0119)	
training:	Epoch: [83][78/204]	Loss 0.0119 (0.0119)	
training:	Epoch: [83][79/204]	Loss 0.0112 (0.0119)	
training:	Epoch: [83][80/204]	Loss 0.0857 (0.0128)	
training:	Epoch: [83][81/204]	Loss 0.0038 (0.0127)	
training:	Epoch: [83][82/204]	Loss 0.0113 (0.0127)	
training:	Epoch: [83][83/204]	Loss 0.0137 (0.0127)	
training:	Epoch: [83][84/204]	Loss 0.0007 (0.0126)	
training:	Epoch: [83][85/204]	Loss 0.0019 (0.0124)	
training:	Epoch: [83][86/204]	Loss 0.0012 (0.0123)	
training:	Epoch: [83][87/204]	Loss 0.0021 (0.0122)	
training:	Epoch: [83][88/204]	Loss 0.0020 (0.0121)	
training:	Epoch: [83][89/204]	Loss 0.0099 (0.0121)	
training:	Epoch: [83][90/204]	Loss 0.0010 (0.0119)	
training:	Epoch: [83][91/204]	Loss 0.0013 (0.0118)	
training:	Epoch: [83][92/204]	Loss 0.0009 (0.0117)	
training:	Epoch: [83][93/204]	Loss 0.0009 (0.0116)	
training:	Epoch: [83][94/204]	Loss 0.0016 (0.0115)	
training:	Epoch: [83][95/204]	Loss 0.0013 (0.0114)	
training:	Epoch: [83][96/204]	Loss 0.0031 (0.0113)	
training:	Epoch: [83][97/204]	Loss 0.0008 (0.0112)	
training:	Epoch: [83][98/204]	Loss 0.0014 (0.0111)	
training:	Epoch: [83][99/204]	Loss 0.0008 (0.0110)	
training:	Epoch: [83][100/204]	Loss 0.0015 (0.0109)	
training:	Epoch: [83][101/204]	Loss 0.0020 (0.0108)	
training:	Epoch: [83][102/204]	Loss 0.0013 (0.0107)	
training:	Epoch: [83][103/204]	Loss 0.0677 (0.0112)	
training:	Epoch: [83][104/204]	Loss 0.0010 (0.0112)	
training:	Epoch: [83][105/204]	Loss 0.0039 (0.0111)	
training:	Epoch: [83][106/204]	Loss 0.0008 (0.0110)	
training:	Epoch: [83][107/204]	Loss 0.0018 (0.0109)	
training:	Epoch: [83][108/204]	Loss 0.0009 (0.0108)	
training:	Epoch: [83][109/204]	Loss 0.0013 (0.0107)	
training:	Epoch: [83][110/204]	Loss 0.0014 (0.0106)	
training:	Epoch: [83][111/204]	Loss 0.0226 (0.0107)	
training:	Epoch: [83][112/204]	Loss 0.0147 (0.0108)	
training:	Epoch: [83][113/204]	Loss 0.0018 (0.0107)	
training:	Epoch: [83][114/204]	Loss 0.1311 (0.0118)	
training:	Epoch: [83][115/204]	Loss 0.0009 (0.0117)	
training:	Epoch: [83][116/204]	Loss 0.0015 (0.0116)	
training:	Epoch: [83][117/204]	Loss 0.0008 (0.0115)	
training:	Epoch: [83][118/204]	Loss 0.0015 (0.0114)	
training:	Epoch: [83][119/204]	Loss 0.0113 (0.0114)	
training:	Epoch: [83][120/204]	Loss 0.0018 (0.0113)	
training:	Epoch: [83][121/204]	Loss 0.0014 (0.0112)	
training:	Epoch: [83][122/204]	Loss 0.0037 (0.0112)	
training:	Epoch: [83][123/204]	Loss 0.0132 (0.0112)	
training:	Epoch: [83][124/204]	Loss 0.0479 (0.0115)	
training:	Epoch: [83][125/204]	Loss 0.0051 (0.0114)	
training:	Epoch: [83][126/204]	Loss 0.1425 (0.0125)	
training:	Epoch: [83][127/204]	Loss 0.0032 (0.0124)	
training:	Epoch: [83][128/204]	Loss 0.0866 (0.0130)	
training:	Epoch: [83][129/204]	Loss 0.0625 (0.0134)	
training:	Epoch: [83][130/204]	Loss 0.0018 (0.0133)	
training:	Epoch: [83][131/204]	Loss 0.0025 (0.0132)	
training:	Epoch: [83][132/204]	Loss 0.0033 (0.0131)	
training:	Epoch: [83][133/204]	Loss 0.0830 (0.0136)	
training:	Epoch: [83][134/204]	Loss 0.0259 (0.0137)	
training:	Epoch: [83][135/204]	Loss 0.0146 (0.0137)	
training:	Epoch: [83][136/204]	Loss 0.0031 (0.0137)	
training:	Epoch: [83][137/204]	Loss 0.0014 (0.0136)	
training:	Epoch: [83][138/204]	Loss 0.0012 (0.0135)	
training:	Epoch: [83][139/204]	Loss 0.0019 (0.0134)	
training:	Epoch: [83][140/204]	Loss 0.0010 (0.0133)	
training:	Epoch: [83][141/204]	Loss 0.0049 (0.0133)	
training:	Epoch: [83][142/204]	Loss 0.0048 (0.0132)	
training:	Epoch: [83][143/204]	Loss 0.0091 (0.0132)	
training:	Epoch: [83][144/204]	Loss 0.0065 (0.0131)	
training:	Epoch: [83][145/204]	Loss 0.0009 (0.0130)	
training:	Epoch: [83][146/204]	Loss 0.0017 (0.0130)	
training:	Epoch: [83][147/204]	Loss 0.0013 (0.0129)	
training:	Epoch: [83][148/204]	Loss 0.0016 (0.0128)	
training:	Epoch: [83][149/204]	Loss 0.0010 (0.0127)	
training:	Epoch: [83][150/204]	Loss 0.0709 (0.0131)	
training:	Epoch: [83][151/204]	Loss 0.0055 (0.0131)	
training:	Epoch: [83][152/204]	Loss 0.0012 (0.0130)	
training:	Epoch: [83][153/204]	Loss 0.0012 (0.0129)	
training:	Epoch: [83][154/204]	Loss 0.1072 (0.0135)	
training:	Epoch: [83][155/204]	Loss 0.0011 (0.0134)	
training:	Epoch: [83][156/204]	Loss 0.0009 (0.0134)	
training:	Epoch: [83][157/204]	Loss 0.0011 (0.0133)	
training:	Epoch: [83][158/204]	Loss 0.0024 (0.0132)	
training:	Epoch: [83][159/204]	Loss 0.0009 (0.0131)	
training:	Epoch: [83][160/204]	Loss 0.0018 (0.0131)	
training:	Epoch: [83][161/204]	Loss 0.1066 (0.0136)	
training:	Epoch: [83][162/204]	Loss 0.0300 (0.0137)	
training:	Epoch: [83][163/204]	Loss 0.0011 (0.0137)	
training:	Epoch: [83][164/204]	Loss 0.0260 (0.0137)	
training:	Epoch: [83][165/204]	Loss 0.0362 (0.0139)	
training:	Epoch: [83][166/204]	Loss 0.0156 (0.0139)	
training:	Epoch: [83][167/204]	Loss 0.0021 (0.0138)	
training:	Epoch: [83][168/204]	Loss 0.0162 (0.0138)	
training:	Epoch: [83][169/204]	Loss 0.0073 (0.0138)	
training:	Epoch: [83][170/204]	Loss 0.0047 (0.0137)	
training:	Epoch: [83][171/204]	Loss 0.1657 (0.0146)	
training:	Epoch: [83][172/204]	Loss 0.0011 (0.0145)	
training:	Epoch: [83][173/204]	Loss 0.0224 (0.0146)	
training:	Epoch: [83][174/204]	Loss 0.0062 (0.0145)	
training:	Epoch: [83][175/204]	Loss 0.0017 (0.0145)	
training:	Epoch: [83][176/204]	Loss 0.3620 (0.0164)	
training:	Epoch: [83][177/204]	Loss 0.0167 (0.0164)	
training:	Epoch: [83][178/204]	Loss 0.0337 (0.0165)	
training:	Epoch: [83][179/204]	Loss 0.0037 (0.0165)	
training:	Epoch: [83][180/204]	Loss 0.0010 (0.0164)	
training:	Epoch: [83][181/204]	Loss 0.0017 (0.0163)	
training:	Epoch: [83][182/204]	Loss 0.0012 (0.0162)	
training:	Epoch: [83][183/204]	Loss 0.0010 (0.0161)	
training:	Epoch: [83][184/204]	Loss 0.0015 (0.0161)	
training:	Epoch: [83][185/204]	Loss 0.0021 (0.0160)	
training:	Epoch: [83][186/204]	Loss 0.0278 (0.0160)	
training:	Epoch: [83][187/204]	Loss 0.0011 (0.0160)	
training:	Epoch: [83][188/204]	Loss 0.0266 (0.0160)	
training:	Epoch: [83][189/204]	Loss 0.0011 (0.0159)	
training:	Epoch: [83][190/204]	Loss 0.0013 (0.0159)	
training:	Epoch: [83][191/204]	Loss 0.0436 (0.0160)	
training:	Epoch: [83][192/204]	Loss 0.0037 (0.0159)	
training:	Epoch: [83][193/204]	Loss 0.0015 (0.0159)	
training:	Epoch: [83][194/204]	Loss 0.0013 (0.0158)	
training:	Epoch: [83][195/204]	Loss 0.0015 (0.0157)	
training:	Epoch: [83][196/204]	Loss 0.0016 (0.0157)	
training:	Epoch: [83][197/204]	Loss 0.0036 (0.0156)	
training:	Epoch: [83][198/204]	Loss 0.0098 (0.0156)	
training:	Epoch: [83][199/204]	Loss 0.0009 (0.0155)	
training:	Epoch: [83][200/204]	Loss 0.0022 (0.0154)	
training:	Epoch: [83][201/204]	Loss 0.0015 (0.0154)	
training:	Epoch: [83][202/204]	Loss 0.0040 (0.0153)	
training:	Epoch: [83][203/204]	Loss 0.0011 (0.0152)	
training:	Epoch: [83][204/204]	Loss 0.0035 (0.0152)	
Training:	 Loss: 0.0151

Training:	 ACC: 0.9992 0.9992 0.9997 0.9987
Validation:	 ACC: 0.7729 0.7747 0.8137 0.7321
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.2037
Pretraining:	Epoch 84/500
----------
training:	Epoch: [84][1/204]	Loss 0.0018 (0.0018)	
training:	Epoch: [84][2/204]	Loss 0.0014 (0.0016)	
training:	Epoch: [84][3/204]	Loss 0.0016 (0.0016)	
training:	Epoch: [84][4/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [84][5/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [84][6/204]	Loss 0.0020 (0.0015)	
training:	Epoch: [84][7/204]	Loss 0.0112 (0.0029)	
training:	Epoch: [84][8/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [84][9/204]	Loss 0.0019 (0.0026)	
training:	Epoch: [84][10/204]	Loss 0.0017 (0.0025)	
training:	Epoch: [84][11/204]	Loss 0.0008 (0.0023)	
training:	Epoch: [84][12/204]	Loss 0.0027 (0.0024)	
training:	Epoch: [84][13/204]	Loss 0.0030 (0.0024)	
training:	Epoch: [84][14/204]	Loss 0.0010 (0.0023)	
training:	Epoch: [84][15/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [84][16/204]	Loss 0.0039 (0.0023)	
training:	Epoch: [84][17/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [84][18/204]	Loss 0.0011 (0.0022)	
training:	Epoch: [84][19/204]	Loss 0.0028 (0.0022)	
training:	Epoch: [84][20/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [84][21/204]	Loss 0.0015 (0.0021)	
training:	Epoch: [84][22/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [84][23/204]	Loss 0.0161 (0.0027)	
training:	Epoch: [84][24/204]	Loss 0.0011 (0.0026)	
training:	Epoch: [84][25/204]	Loss 0.0009 (0.0025)	
training:	Epoch: [84][26/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [84][27/204]	Loss 0.0020 (0.0025)	
training:	Epoch: [84][28/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [84][29/204]	Loss 0.0010 (0.0024)	
training:	Epoch: [84][30/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [84][31/204]	Loss 0.0340 (0.0033)	
training:	Epoch: [84][32/204]	Loss 0.0009 (0.0033)	
training:	Epoch: [84][33/204]	Loss 0.0014 (0.0032)	
training:	Epoch: [84][34/204]	Loss 0.0050 (0.0033)	
training:	Epoch: [84][35/204]	Loss 0.0010 (0.0032)	
training:	Epoch: [84][36/204]	Loss 0.0019 (0.0032)	
training:	Epoch: [84][37/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [84][38/204]	Loss 0.0012 (0.0030)	
training:	Epoch: [84][39/204]	Loss 0.0020 (0.0030)	
training:	Epoch: [84][40/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [84][41/204]	Loss 0.0016 (0.0029)	
training:	Epoch: [84][42/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [84][43/204]	Loss 0.0029 (0.0029)	
training:	Epoch: [84][44/204]	Loss 0.0018 (0.0029)	
training:	Epoch: [84][45/204]	Loss 0.0025 (0.0028)	
training:	Epoch: [84][46/204]	Loss 0.0102 (0.0030)	
training:	Epoch: [84][47/204]	Loss 0.0022 (0.0030)	
training:	Epoch: [84][48/204]	Loss 0.0014 (0.0030)	
training:	Epoch: [84][49/204]	Loss 0.0141 (0.0032)	
training:	Epoch: [84][50/204]	Loss 0.0010 (0.0031)	
training:	Epoch: [84][51/204]	Loss 0.0011 (0.0031)	
training:	Epoch: [84][52/204]	Loss 0.0080 (0.0032)	
training:	Epoch: [84][53/204]	Loss 0.0011 (0.0032)	
training:	Epoch: [84][54/204]	Loss 0.0009 (0.0031)	
training:	Epoch: [84][55/204]	Loss 0.0047 (0.0031)	
training:	Epoch: [84][56/204]	Loss 0.0010 (0.0031)	
training:	Epoch: [84][57/204]	Loss 0.0148 (0.0033)	
training:	Epoch: [84][58/204]	Loss 0.0035 (0.0033)	
training:	Epoch: [84][59/204]	Loss 0.0009 (0.0033)	
training:	Epoch: [84][60/204]	Loss 0.0011 (0.0032)	
training:	Epoch: [84][61/204]	Loss 0.0011 (0.0032)	
training:	Epoch: [84][62/204]	Loss 0.0128 (0.0033)	
training:	Epoch: [84][63/204]	Loss 0.0470 (0.0040)	
training:	Epoch: [84][64/204]	Loss 0.0009 (0.0040)	
training:	Epoch: [84][65/204]	Loss 0.0011 (0.0039)	
training:	Epoch: [84][66/204]	Loss 0.0011 (0.0039)	
training:	Epoch: [84][67/204]	Loss 0.0016 (0.0039)	
training:	Epoch: [84][68/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [84][69/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [84][70/204]	Loss 0.0010 (0.0037)	
training:	Epoch: [84][71/204]	Loss 0.0008 (0.0037)	
training:	Epoch: [84][72/204]	Loss 0.0026 (0.0037)	
training:	Epoch: [84][73/204]	Loss 0.0012 (0.0037)	
training:	Epoch: [84][74/204]	Loss 0.0013 (0.0036)	
training:	Epoch: [84][75/204]	Loss 0.0030 (0.0036)	
training:	Epoch: [84][76/204]	Loss 0.0030 (0.0036)	
training:	Epoch: [84][77/204]	Loss 0.0009 (0.0036)	
training:	Epoch: [84][78/204]	Loss 0.0033 (0.0036)	
training:	Epoch: [84][79/204]	Loss 0.0013 (0.0035)	
training:	Epoch: [84][80/204]	Loss 0.0009 (0.0035)	
training:	Epoch: [84][81/204]	Loss 0.0028 (0.0035)	
training:	Epoch: [84][82/204]	Loss 0.0019 (0.0035)	
training:	Epoch: [84][83/204]	Loss 0.0015 (0.0035)	
training:	Epoch: [84][84/204]	Loss 0.0156 (0.0036)	
training:	Epoch: [84][85/204]	Loss 0.0017 (0.0036)	
training:	Epoch: [84][86/204]	Loss 0.0052 (0.0036)	
training:	Epoch: [84][87/204]	Loss 0.0014 (0.0036)	
training:	Epoch: [84][88/204]	Loss 0.0282 (0.0039)	
training:	Epoch: [84][89/204]	Loss 0.0013 (0.0038)	
training:	Epoch: [84][90/204]	Loss 0.0009 (0.0038)	
training:	Epoch: [84][91/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [84][92/204]	Loss 0.0073 (0.0038)	
training:	Epoch: [84][93/204]	Loss 0.0014 (0.0038)	
training:	Epoch: [84][94/204]	Loss 0.0009 (0.0037)	
training:	Epoch: [84][95/204]	Loss 0.0169 (0.0039)	
training:	Epoch: [84][96/204]	Loss 0.0008 (0.0038)	
training:	Epoch: [84][97/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [84][98/204]	Loss 0.0011 (0.0038)	
training:	Epoch: [84][99/204]	Loss 0.0030 (0.0038)	
training:	Epoch: [84][100/204]	Loss 0.0032 (0.0038)	
training:	Epoch: [84][101/204]	Loss 0.0021 (0.0038)	
training:	Epoch: [84][102/204]	Loss 0.0070 (0.0038)	
training:	Epoch: [84][103/204]	Loss 0.0033 (0.0038)	
training:	Epoch: [84][104/204]	Loss 0.0009 (0.0038)	
training:	Epoch: [84][105/204]	Loss 0.0188 (0.0039)	
training:	Epoch: [84][106/204]	Loss 0.0068 (0.0039)	
training:	Epoch: [84][107/204]	Loss 0.0028 (0.0039)	
training:	Epoch: [84][108/204]	Loss 0.0100 (0.0040)	
training:	Epoch: [84][109/204]	Loss 0.0027 (0.0040)	
training:	Epoch: [84][110/204]	Loss 0.0024 (0.0039)	
training:	Epoch: [84][111/204]	Loss 0.0022 (0.0039)	
training:	Epoch: [84][112/204]	Loss 0.0028 (0.0039)	
training:	Epoch: [84][113/204]	Loss 0.0034 (0.0039)	
training:	Epoch: [84][114/204]	Loss 0.0012 (0.0039)	
training:	Epoch: [84][115/204]	Loss 0.0009 (0.0039)	
training:	Epoch: [84][116/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [84][117/204]	Loss 0.0070 (0.0039)	
training:	Epoch: [84][118/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [84][119/204]	Loss 0.0012 (0.0038)	
training:	Epoch: [84][120/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [84][121/204]	Loss 0.0138 (0.0039)	
training:	Epoch: [84][122/204]	Loss 0.0009 (0.0039)	
training:	Epoch: [84][123/204]	Loss 0.0037 (0.0039)	
training:	Epoch: [84][124/204]	Loss 0.0011 (0.0038)	
training:	Epoch: [84][125/204]	Loss 0.0012 (0.0038)	
training:	Epoch: [84][126/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [84][127/204]	Loss 0.0020 (0.0038)	
training:	Epoch: [84][128/204]	Loss 0.0011 (0.0038)	
training:	Epoch: [84][129/204]	Loss 0.0016 (0.0037)	
training:	Epoch: [84][130/204]	Loss 0.0009 (0.0037)	
training:	Epoch: [84][131/204]	Loss 0.2114 (0.0053)	
training:	Epoch: [84][132/204]	Loss 0.0011 (0.0053)	
training:	Epoch: [84][133/204]	Loss 0.0016 (0.0052)	
training:	Epoch: [84][134/204]	Loss 0.0008 (0.0052)	
training:	Epoch: [84][135/204]	Loss 0.0008 (0.0052)	
training:	Epoch: [84][136/204]	Loss 0.0014 (0.0051)	
training:	Epoch: [84][137/204]	Loss 0.0009 (0.0051)	
training:	Epoch: [84][138/204]	Loss 0.0008 (0.0051)	
training:	Epoch: [84][139/204]	Loss 0.0030 (0.0051)	
training:	Epoch: [84][140/204]	Loss 0.0014 (0.0050)	
training:	Epoch: [84][141/204]	Loss 0.0014 (0.0050)	
training:	Epoch: [84][142/204]	Loss 0.0028 (0.0050)	
training:	Epoch: [84][143/204]	Loss 0.0008 (0.0050)	
training:	Epoch: [84][144/204]	Loss 0.0030 (0.0050)	
training:	Epoch: [84][145/204]	Loss 0.0009 (0.0049)	
training:	Epoch: [84][146/204]	Loss 0.0032 (0.0049)	
training:	Epoch: [84][147/204]	Loss 0.0008 (0.0049)	
training:	Epoch: [84][148/204]	Loss 0.0017 (0.0049)	
training:	Epoch: [84][149/204]	Loss 0.0013 (0.0048)	
training:	Epoch: [84][150/204]	Loss 0.0013 (0.0048)	
training:	Epoch: [84][151/204]	Loss 0.0023 (0.0048)	
training:	Epoch: [84][152/204]	Loss 0.0012 (0.0048)	
training:	Epoch: [84][153/204]	Loss 0.0007 (0.0048)	
training:	Epoch: [84][154/204]	Loss 0.0007 (0.0047)	
training:	Epoch: [84][155/204]	Loss 0.0011 (0.0047)	
training:	Epoch: [84][156/204]	Loss 0.0009 (0.0047)	
training:	Epoch: [84][157/204]	Loss 0.0009 (0.0047)	
training:	Epoch: [84][158/204]	Loss 0.0018 (0.0046)	
training:	Epoch: [84][159/204]	Loss 0.0009 (0.0046)	
training:	Epoch: [84][160/204]	Loss 0.0013 (0.0046)	
training:	Epoch: [84][161/204]	Loss 0.0055 (0.0046)	
training:	Epoch: [84][162/204]	Loss 0.0009 (0.0046)	
training:	Epoch: [84][163/204]	Loss 0.0008 (0.0046)	
training:	Epoch: [84][164/204]	Loss 0.0011 (0.0045)	
training:	Epoch: [84][165/204]	Loss 0.0008 (0.0045)	
training:	Epoch: [84][166/204]	Loss 0.0008 (0.0045)	
training:	Epoch: [84][167/204]	Loss 0.0012 (0.0045)	
training:	Epoch: [84][168/204]	Loss 0.0023 (0.0045)	
training:	Epoch: [84][169/204]	Loss 0.0007 (0.0044)	
training:	Epoch: [84][170/204]	Loss 0.0008 (0.0044)	
training:	Epoch: [84][171/204]	Loss 0.0009 (0.0044)	
training:	Epoch: [84][172/204]	Loss 0.0012 (0.0044)	
training:	Epoch: [84][173/204]	Loss 0.0013 (0.0044)	
training:	Epoch: [84][174/204]	Loss 0.0112 (0.0044)	
training:	Epoch: [84][175/204]	Loss 0.0013 (0.0044)	
training:	Epoch: [84][176/204]	Loss 0.0010 (0.0044)	
training:	Epoch: [84][177/204]	Loss 0.0008 (0.0043)	
training:	Epoch: [84][178/204]	Loss 0.0014 (0.0043)	
training:	Epoch: [84][179/204]	Loss 0.0012 (0.0043)	
training:	Epoch: [84][180/204]	Loss 0.0008 (0.0043)	
training:	Epoch: [84][181/204]	Loss 0.0008 (0.0043)	
training:	Epoch: [84][182/204]	Loss 0.0055 (0.0043)	
training:	Epoch: [84][183/204]	Loss 0.0017 (0.0043)	
training:	Epoch: [84][184/204]	Loss 0.0007 (0.0042)	
training:	Epoch: [84][185/204]	Loss 0.0012 (0.0042)	
training:	Epoch: [84][186/204]	Loss 0.0017 (0.0042)	
training:	Epoch: [84][187/204]	Loss 0.0012 (0.0042)	
training:	Epoch: [84][188/204]	Loss 0.0013 (0.0042)	
training:	Epoch: [84][189/204]	Loss 0.0010 (0.0042)	
training:	Epoch: [84][190/204]	Loss 0.0008 (0.0041)	
training:	Epoch: [84][191/204]	Loss 0.0008 (0.0041)	
training:	Epoch: [84][192/204]	Loss 0.0009 (0.0041)	
training:	Epoch: [84][193/204]	Loss 0.0009 (0.0041)	
training:	Epoch: [84][194/204]	Loss 0.0008 (0.0041)	
training:	Epoch: [84][195/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [84][196/204]	Loss 0.0007 (0.0040)	
training:	Epoch: [84][197/204]	Loss 0.0010 (0.0040)	
training:	Epoch: [84][198/204]	Loss 0.0008 (0.0040)	
training:	Epoch: [84][199/204]	Loss 0.0219 (0.0041)	
training:	Epoch: [84][200/204]	Loss 0.0012 (0.0041)	
training:	Epoch: [84][201/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [84][202/204]	Loss 0.0019 (0.0041)	
training:	Epoch: [84][203/204]	Loss 0.0010 (0.0040)	
training:	Epoch: [84][204/204]	Loss 0.0010 (0.0040)	
Training:	 Loss: 0.0040

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7735 0.7731 0.7666 0.7803
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3038
Pretraining:	Epoch 85/500
----------
training:	Epoch: [85][1/204]	Loss 0.0009 (0.0009)	
training:	Epoch: [85][2/204]	Loss 0.0057 (0.0033)	
training:	Epoch: [85][3/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [85][4/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [85][5/204]	Loss 0.0098 (0.0036)	
training:	Epoch: [85][6/204]	Loss 0.0010 (0.0032)	
training:	Epoch: [85][7/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [85][8/204]	Loss 0.0008 (0.0027)	
training:	Epoch: [85][9/204]	Loss 0.0036 (0.0028)	
training:	Epoch: [85][10/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [85][11/204]	Loss 0.0011 (0.0024)	
training:	Epoch: [85][12/204]	Loss 0.0037 (0.0025)	
training:	Epoch: [85][13/204]	Loss 0.0019 (0.0025)	
training:	Epoch: [85][14/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [85][15/204]	Loss 0.0008 (0.0023)	
training:	Epoch: [85][16/204]	Loss 0.0009 (0.0022)	
training:	Epoch: [85][17/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [85][18/204]	Loss 0.0007 (0.0020)	
training:	Epoch: [85][19/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [85][20/204]	Loss 0.0008 (0.0019)	
training:	Epoch: [85][21/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [85][22/204]	Loss 0.0015 (0.0018)	
training:	Epoch: [85][23/204]	Loss 0.0015 (0.0018)	
training:	Epoch: [85][24/204]	Loss 0.0011 (0.0018)	
training:	Epoch: [85][25/204]	Loss 0.0076 (0.0020)	
training:	Epoch: [85][26/204]	Loss 0.0008 (0.0020)	
training:	Epoch: [85][27/204]	Loss 0.0320 (0.0031)	
training:	Epoch: [85][28/204]	Loss 0.0012 (0.0030)	
training:	Epoch: [85][29/204]	Loss 0.0015 (0.0030)	
training:	Epoch: [85][30/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [85][31/204]	Loss 0.0019 (0.0029)	
training:	Epoch: [85][32/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [85][33/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [85][34/204]	Loss 0.0196 (0.0032)	
training:	Epoch: [85][35/204]	Loss 0.0013 (0.0032)	
training:	Epoch: [85][36/204]	Loss 0.0009 (0.0031)	
training:	Epoch: [85][37/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [85][38/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [85][39/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [85][40/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [85][41/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [85][42/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [85][43/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [85][44/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [85][45/204]	Loss 0.0023 (0.0027)	
training:	Epoch: [85][46/204]	Loss 0.0014 (0.0027)	
training:	Epoch: [85][47/204]	Loss 0.0017 (0.0027)	
training:	Epoch: [85][48/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [85][49/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [85][50/204]	Loss 0.0009 (0.0025)	
training:	Epoch: [85][51/204]	Loss 0.2141 (0.0067)	
training:	Epoch: [85][52/204]	Loss 0.0024 (0.0066)	
training:	Epoch: [85][53/204]	Loss 0.0008 (0.0065)	
training:	Epoch: [85][54/204]	Loss 0.0007 (0.0064)	
training:	Epoch: [85][55/204]	Loss 0.0013 (0.0063)	
training:	Epoch: [85][56/204]	Loss 0.0056 (0.0063)	
training:	Epoch: [85][57/204]	Loss 0.0020 (0.0062)	
training:	Epoch: [85][58/204]	Loss 0.0008 (0.0061)	
training:	Epoch: [85][59/204]	Loss 0.0009 (0.0060)	
training:	Epoch: [85][60/204]	Loss 0.0009 (0.0059)	
training:	Epoch: [85][61/204]	Loss 0.0006 (0.0059)	
training:	Epoch: [85][62/204]	Loss 0.0007 (0.0058)	
training:	Epoch: [85][63/204]	Loss 0.0009 (0.0057)	
training:	Epoch: [85][64/204]	Loss 0.0012 (0.0056)	
training:	Epoch: [85][65/204]	Loss 0.0014 (0.0056)	
training:	Epoch: [85][66/204]	Loss 0.0010 (0.0055)	
training:	Epoch: [85][67/204]	Loss 0.0016 (0.0054)	
training:	Epoch: [85][68/204]	Loss 0.0008 (0.0054)	
training:	Epoch: [85][69/204]	Loss 0.0011 (0.0053)	
training:	Epoch: [85][70/204]	Loss 0.0025 (0.0053)	
training:	Epoch: [85][71/204]	Loss 0.0008 (0.0052)	
training:	Epoch: [85][72/204]	Loss 0.0008 (0.0051)	
training:	Epoch: [85][73/204]	Loss 0.0011 (0.0051)	
training:	Epoch: [85][74/204]	Loss 0.0007 (0.0050)	
training:	Epoch: [85][75/204]	Loss 0.0009 (0.0050)	
training:	Epoch: [85][76/204]	Loss 0.0038 (0.0050)	
training:	Epoch: [85][77/204]	Loss 0.0008 (0.0049)	
training:	Epoch: [85][78/204]	Loss 0.0026 (0.0049)	
training:	Epoch: [85][79/204]	Loss 0.0007 (0.0048)	
training:	Epoch: [85][80/204]	Loss 0.0008 (0.0048)	
training:	Epoch: [85][81/204]	Loss 0.0008 (0.0047)	
training:	Epoch: [85][82/204]	Loss 0.0018 (0.0047)	
training:	Epoch: [85][83/204]	Loss 0.0007 (0.0046)	
training:	Epoch: [85][84/204]	Loss 0.0008 (0.0046)	
training:	Epoch: [85][85/204]	Loss 0.0009 (0.0045)	
training:	Epoch: [85][86/204]	Loss 0.0007 (0.0045)	
training:	Epoch: [85][87/204]	Loss 0.0007 (0.0045)	
training:	Epoch: [85][88/204]	Loss 0.0008 (0.0044)	
training:	Epoch: [85][89/204]	Loss 0.0017 (0.0044)	
training:	Epoch: [85][90/204]	Loss 0.0009 (0.0043)	
training:	Epoch: [85][91/204]	Loss 0.0053 (0.0044)	
training:	Epoch: [85][92/204]	Loss 0.0009 (0.0043)	
training:	Epoch: [85][93/204]	Loss 0.0007 (0.0043)	
training:	Epoch: [85][94/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [85][95/204]	Loss 0.0009 (0.0042)	
training:	Epoch: [85][96/204]	Loss 0.0007 (0.0042)	
training:	Epoch: [85][97/204]	Loss 0.0036 (0.0042)	
training:	Epoch: [85][98/204]	Loss 0.0008 (0.0041)	
training:	Epoch: [85][99/204]	Loss 0.0013 (0.0041)	
training:	Epoch: [85][100/204]	Loss 0.0008 (0.0041)	
training:	Epoch: [85][101/204]	Loss 0.0007 (0.0040)	
training:	Epoch: [85][102/204]	Loss 0.0009 (0.0040)	
training:	Epoch: [85][103/204]	Loss 0.0009 (0.0040)	
training:	Epoch: [85][104/204]	Loss 0.0007 (0.0039)	
training:	Epoch: [85][105/204]	Loss 0.0011 (0.0039)	
training:	Epoch: [85][106/204]	Loss 0.0016 (0.0039)	
training:	Epoch: [85][107/204]	Loss 0.0009 (0.0039)	
training:	Epoch: [85][108/204]	Loss 0.0007 (0.0038)	
training:	Epoch: [85][109/204]	Loss 0.0009 (0.0038)	
training:	Epoch: [85][110/204]	Loss 0.0008 (0.0038)	
training:	Epoch: [85][111/204]	Loss 0.0017 (0.0038)	
training:	Epoch: [85][112/204]	Loss 0.0012 (0.0037)	
training:	Epoch: [85][113/204]	Loss 0.0011 (0.0037)	
training:	Epoch: [85][114/204]	Loss 0.0009 (0.0037)	
training:	Epoch: [85][115/204]	Loss 0.0018 (0.0037)	
training:	Epoch: [85][116/204]	Loss 0.0007 (0.0037)	
training:	Epoch: [85][117/204]	Loss 0.0010 (0.0036)	
training:	Epoch: [85][118/204]	Loss 0.0013 (0.0036)	
training:	Epoch: [85][119/204]	Loss 0.0008 (0.0036)	
training:	Epoch: [85][120/204]	Loss 0.0025 (0.0036)	
training:	Epoch: [85][121/204]	Loss 0.0010 (0.0036)	
training:	Epoch: [85][122/204]	Loss 0.0022 (0.0035)	
training:	Epoch: [85][123/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [85][124/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [85][125/204]	Loss 0.0010 (0.0035)	
training:	Epoch: [85][126/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [85][127/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [85][128/204]	Loss 0.0010 (0.0034)	
training:	Epoch: [85][129/204]	Loss 0.0015 (0.0034)	
training:	Epoch: [85][130/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [85][131/204]	Loss 0.0009 (0.0034)	
training:	Epoch: [85][132/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [85][133/204]	Loss 0.0008 (0.0033)	
training:	Epoch: [85][134/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [85][135/204]	Loss 0.0008 (0.0033)	
training:	Epoch: [85][136/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [85][137/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [85][138/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [85][139/204]	Loss 0.0009 (0.0032)	
training:	Epoch: [85][140/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [85][141/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [85][142/204]	Loss 0.0019 (0.0032)	
training:	Epoch: [85][143/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [85][144/204]	Loss 0.0014 (0.0031)	
training:	Epoch: [85][145/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [85][146/204]	Loss 0.0011 (0.0031)	
training:	Epoch: [85][147/204]	Loss 0.0009 (0.0031)	
training:	Epoch: [85][148/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [85][149/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [85][150/204]	Loss 0.0018 (0.0031)	
training:	Epoch: [85][151/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [85][152/204]	Loss 0.0027 (0.0030)	
training:	Epoch: [85][153/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [85][154/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [85][155/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [85][156/204]	Loss 0.0029 (0.0030)	
training:	Epoch: [85][157/204]	Loss 0.0012 (0.0030)	
training:	Epoch: [85][158/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [85][159/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [85][160/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [85][161/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [85][162/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [85][163/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [85][164/204]	Loss 0.0017 (0.0029)	
training:	Epoch: [85][165/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [85][166/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [85][167/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [85][168/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [85][169/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [85][170/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [85][171/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [85][172/204]	Loss 0.0015 (0.0028)	
training:	Epoch: [85][173/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [85][174/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [85][175/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [85][176/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [85][177/204]	Loss 0.0008 (0.0027)	
training:	Epoch: [85][178/204]	Loss 0.0007 (0.0027)	
training:	Epoch: [85][179/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [85][180/204]	Loss 0.0007 (0.0027)	
training:	Epoch: [85][181/204]	Loss 0.0008 (0.0027)	
training:	Epoch: [85][182/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [85][183/204]	Loss 0.0024 (0.0027)	
training:	Epoch: [85][184/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [85][185/204]	Loss 0.0008 (0.0027)	
training:	Epoch: [85][186/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [85][187/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [85][188/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [85][189/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [85][190/204]	Loss 0.0009 (0.0026)	
training:	Epoch: [85][191/204]	Loss 0.0009 (0.0026)	
training:	Epoch: [85][192/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [85][193/204]	Loss 0.0011 (0.0026)	
training:	Epoch: [85][194/204]	Loss 0.0018 (0.0026)	
training:	Epoch: [85][195/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [85][196/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [85][197/204]	Loss 0.0009 (0.0026)	
training:	Epoch: [85][198/204]	Loss 0.0014 (0.0026)	
training:	Epoch: [85][199/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [85][200/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [85][201/204]	Loss 0.0007 (0.0025)	
training:	Epoch: [85][202/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [85][203/204]	Loss 0.0016 (0.0025)	
training:	Epoch: [85][204/204]	Loss 0.0007 (0.0025)	
Training:	 Loss: 0.0025

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7787 0.7796 0.7973 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3312
Pretraining:	Epoch 86/500
----------
training:	Epoch: [86][1/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [86][2/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [86][3/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [86][4/204]	Loss 0.0017 (0.0010)	
training:	Epoch: [86][5/204]	Loss 0.0015 (0.0011)	
training:	Epoch: [86][6/204]	Loss 0.0008 (0.0011)	
training:	Epoch: [86][7/204]	Loss 0.0027 (0.0013)	
training:	Epoch: [86][8/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [86][9/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [86][10/204]	Loss 0.0008 (0.0011)	
training:	Epoch: [86][11/204]	Loss 0.0007 (0.0011)	
training:	Epoch: [86][12/204]	Loss 0.0017 (0.0011)	
training:	Epoch: [86][13/204]	Loss 0.0009 (0.0011)	
training:	Epoch: [86][14/204]	Loss 0.0011 (0.0011)	
training:	Epoch: [86][15/204]	Loss 0.0007 (0.0011)	
training:	Epoch: [86][16/204]	Loss 0.0007 (0.0011)	
training:	Epoch: [86][17/204]	Loss 0.0011 (0.0011)	
training:	Epoch: [86][18/204]	Loss 0.0007 (0.0011)	
training:	Epoch: [86][19/204]	Loss 0.0007 (0.0010)	
training:	Epoch: [86][20/204]	Loss 0.0008 (0.0010)	
training:	Epoch: [86][21/204]	Loss 0.0008 (0.0010)	
training:	Epoch: [86][22/204]	Loss 0.0012 (0.0010)	
training:	Epoch: [86][23/204]	Loss 0.0009 (0.0010)	
training:	Epoch: [86][24/204]	Loss 0.0160 (0.0016)	
training:	Epoch: [86][25/204]	Loss 0.0020 (0.0017)	
training:	Epoch: [86][26/204]	Loss 0.0027 (0.0017)	
training:	Epoch: [86][27/204]	Loss 0.0014 (0.0017)	
training:	Epoch: [86][28/204]	Loss 0.0009 (0.0017)	
training:	Epoch: [86][29/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [86][30/204]	Loss 0.0014 (0.0016)	
training:	Epoch: [86][31/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [86][32/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [86][33/204]	Loss 0.0012 (0.0016)	
training:	Epoch: [86][34/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [86][35/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [86][36/204]	Loss 0.0015 (0.0015)	
training:	Epoch: [86][37/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [86][38/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [86][39/204]	Loss 0.0023 (0.0015)	
training:	Epoch: [86][40/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [86][41/204]	Loss 0.0007 (0.0015)	
training:	Epoch: [86][42/204]	Loss 0.0007 (0.0015)	
training:	Epoch: [86][43/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [86][44/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [86][45/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [86][46/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [86][47/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [86][48/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [86][49/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [86][50/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [86][51/204]	Loss 0.0052 (0.0014)	
training:	Epoch: [86][52/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [86][53/204]	Loss 0.0010 (0.0014)	
training:	Epoch: [86][54/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [86][55/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [86][56/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [86][57/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [86][58/204]	Loss 0.0040 (0.0014)	
training:	Epoch: [86][59/204]	Loss 0.0014 (0.0014)	
training:	Epoch: [86][60/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [86][61/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [86][62/204]	Loss 0.2129 (0.0048)	
training:	Epoch: [86][63/204]	Loss 0.0043 (0.0048)	
training:	Epoch: [86][64/204]	Loss 0.0007 (0.0047)	
training:	Epoch: [86][65/204]	Loss 0.0007 (0.0047)	
training:	Epoch: [86][66/204]	Loss 0.0008 (0.0046)	
training:	Epoch: [86][67/204]	Loss 0.0021 (0.0046)	
training:	Epoch: [86][68/204]	Loss 0.0011 (0.0045)	
training:	Epoch: [86][69/204]	Loss 0.0007 (0.0045)	
training:	Epoch: [86][70/204]	Loss 0.0009 (0.0044)	
training:	Epoch: [86][71/204]	Loss 0.0009 (0.0044)	
training:	Epoch: [86][72/204]	Loss 0.0014 (0.0043)	
training:	Epoch: [86][73/204]	Loss 0.0014 (0.0043)	
training:	Epoch: [86][74/204]	Loss 0.0010 (0.0042)	
training:	Epoch: [86][75/204]	Loss 0.0007 (0.0042)	
training:	Epoch: [86][76/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [86][77/204]	Loss 0.0055 (0.0042)	
training:	Epoch: [86][78/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [86][79/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [86][80/204]	Loss 0.0007 (0.0040)	
training:	Epoch: [86][81/204]	Loss 0.0007 (0.0040)	
training:	Epoch: [86][82/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [86][83/204]	Loss 0.0007 (0.0039)	
training:	Epoch: [86][84/204]	Loss 0.0007 (0.0039)	
training:	Epoch: [86][85/204]	Loss 0.0007 (0.0038)	
training:	Epoch: [86][86/204]	Loss 0.0006 (0.0038)	
training:	Epoch: [86][87/204]	Loss 0.0013 (0.0038)	
training:	Epoch: [86][88/204]	Loss 0.0007 (0.0037)	
training:	Epoch: [86][89/204]	Loss 0.0007 (0.0037)	
training:	Epoch: [86][90/204]	Loss 0.0007 (0.0037)	
training:	Epoch: [86][91/204]	Loss 0.0007 (0.0036)	
training:	Epoch: [86][92/204]	Loss 0.0008 (0.0036)	
training:	Epoch: [86][93/204]	Loss 0.0028 (0.0036)	
training:	Epoch: [86][94/204]	Loss 0.0009 (0.0036)	
training:	Epoch: [86][95/204]	Loss 0.0008 (0.0035)	
training:	Epoch: [86][96/204]	Loss 0.0018 (0.0035)	
training:	Epoch: [86][97/204]	Loss 0.0009 (0.0035)	
training:	Epoch: [86][98/204]	Loss 0.0009 (0.0035)	
training:	Epoch: [86][99/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [86][100/204]	Loss 0.0013 (0.0034)	
training:	Epoch: [86][101/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [86][102/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [86][103/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [86][104/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [86][105/204]	Loss 0.0008 (0.0033)	
training:	Epoch: [86][106/204]	Loss 0.0008 (0.0033)	
training:	Epoch: [86][107/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [86][108/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [86][109/204]	Loss 0.0044 (0.0032)	
training:	Epoch: [86][110/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [86][111/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [86][112/204]	Loss 0.0010 (0.0032)	
training:	Epoch: [86][113/204]	Loss 0.0014 (0.0031)	
training:	Epoch: [86][114/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [86][115/204]	Loss 0.0009 (0.0031)	
training:	Epoch: [86][116/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [86][117/204]	Loss 0.0011 (0.0031)	
training:	Epoch: [86][118/204]	Loss 0.0012 (0.0031)	
training:	Epoch: [86][119/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][120/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][121/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][122/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][123/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [86][124/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [86][125/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [86][126/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [86][127/204]	Loss 0.0026 (0.0029)	
training:	Epoch: [86][128/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [86][129/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [86][130/204]	Loss 0.0046 (0.0029)	
training:	Epoch: [86][131/204]	Loss 0.0019 (0.0029)	
training:	Epoch: [86][132/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [86][133/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [86][134/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [86][135/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [86][136/204]	Loss 0.0018 (0.0028)	
training:	Epoch: [86][137/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [86][138/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [86][139/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [86][140/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [86][141/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [86][142/204]	Loss 0.0210 (0.0029)	
training:	Epoch: [86][143/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [86][144/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [86][145/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [86][146/204]	Loss 0.0038 (0.0028)	
training:	Epoch: [86][147/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [86][148/204]	Loss 0.0096 (0.0029)	
training:	Epoch: [86][149/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [86][150/204]	Loss 0.0015 (0.0028)	
training:	Epoch: [86][151/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [86][152/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [86][153/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [86][154/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [86][155/204]	Loss 0.0400 (0.0030)	
training:	Epoch: [86][156/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [86][157/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [86][158/204]	Loss 0.0077 (0.0030)	
training:	Epoch: [86][159/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [86][160/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [86][161/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [86][162/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [86][163/204]	Loss 0.0014 (0.0030)	
training:	Epoch: [86][164/204]	Loss 0.0033 (0.0030)	
training:	Epoch: [86][165/204]	Loss 0.0014 (0.0030)	
training:	Epoch: [86][166/204]	Loss 0.0319 (0.0031)	
training:	Epoch: [86][167/204]	Loss 0.0024 (0.0031)	
training:	Epoch: [86][168/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [86][169/204]	Loss 0.0009 (0.0031)	
training:	Epoch: [86][170/204]	Loss 0.0011 (0.0031)	
training:	Epoch: [86][171/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [86][172/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [86][173/204]	Loss 0.0012 (0.0031)	
training:	Epoch: [86][174/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [86][175/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][176/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [86][177/204]	Loss 0.0012 (0.0030)	
training:	Epoch: [86][178/204]	Loss 0.0018 (0.0030)	
training:	Epoch: [86][179/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][180/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [86][181/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][182/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [86][183/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [86][184/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [86][185/204]	Loss 0.0154 (0.0030)	
training:	Epoch: [86][186/204]	Loss 0.0012 (0.0030)	
training:	Epoch: [86][187/204]	Loss 0.0014 (0.0030)	
training:	Epoch: [86][188/204]	Loss 0.0014 (0.0030)	
training:	Epoch: [86][189/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [86][190/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [86][191/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [86][192/204]	Loss 0.0326 (0.0031)	
training:	Epoch: [86][193/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [86][194/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [86][195/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [86][196/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][197/204]	Loss 0.0011 (0.0030)	
training:	Epoch: [86][198/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [86][199/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][200/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [86][201/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [86][202/204]	Loss 0.0013 (0.0030)	
training:	Epoch: [86][203/204]	Loss 0.0013 (0.0030)	
training:	Epoch: [86][204/204]	Loss 0.0031 (0.0030)	
Training:	 Loss: 0.0030

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7846 0.7833 0.7564 0.8128
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3256
Pretraining:	Epoch 87/500
----------
training:	Epoch: [87][1/204]	Loss 0.0022 (0.0022)	
training:	Epoch: [87][2/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [87][3/204]	Loss 0.0689 (0.0240)	
training:	Epoch: [87][4/204]	Loss 0.0008 (0.0182)	
training:	Epoch: [87][5/204]	Loss 0.0007 (0.0147)	
training:	Epoch: [87][6/204]	Loss 0.0007 (0.0124)	
training:	Epoch: [87][7/204]	Loss 0.0018 (0.0109)	
training:	Epoch: [87][8/204]	Loss 0.0008 (0.0096)	
training:	Epoch: [87][9/204]	Loss 0.0009 (0.0086)	
training:	Epoch: [87][10/204]	Loss 0.0008 (0.0079)	
training:	Epoch: [87][11/204]	Loss 0.0039 (0.0075)	
training:	Epoch: [87][12/204]	Loss 0.0011 (0.0070)	
training:	Epoch: [87][13/204]	Loss 0.0015 (0.0065)	
training:	Epoch: [87][14/204]	Loss 0.0008 (0.0061)	
training:	Epoch: [87][15/204]	Loss 0.0008 (0.0058)	
training:	Epoch: [87][16/204]	Loss 0.0096 (0.0060)	
training:	Epoch: [87][17/204]	Loss 0.0006 (0.0057)	
training:	Epoch: [87][18/204]	Loss 0.0006 (0.0054)	
training:	Epoch: [87][19/204]	Loss 0.0017 (0.0052)	
training:	Epoch: [87][20/204]	Loss 0.0512 (0.0075)	
training:	Epoch: [87][21/204]	Loss 0.0055 (0.0074)	
training:	Epoch: [87][22/204]	Loss 0.0019 (0.0072)	
training:	Epoch: [87][23/204]	Loss 0.0008 (0.0069)	
training:	Epoch: [87][24/204]	Loss 0.0007 (0.0066)	
training:	Epoch: [87][25/204]	Loss 0.0006 (0.0064)	
training:	Epoch: [87][26/204]	Loss 0.0006 (0.0062)	
training:	Epoch: [87][27/204]	Loss 0.0505 (0.0078)	
training:	Epoch: [87][28/204]	Loss 0.0010 (0.0076)	
training:	Epoch: [87][29/204]	Loss 0.0007 (0.0073)	
training:	Epoch: [87][30/204]	Loss 0.0009 (0.0071)	
training:	Epoch: [87][31/204]	Loss 0.0008 (0.0069)	
training:	Epoch: [87][32/204]	Loss 0.0008 (0.0067)	
training:	Epoch: [87][33/204]	Loss 0.0007 (0.0065)	
training:	Epoch: [87][34/204]	Loss 0.0023 (0.0064)	
training:	Epoch: [87][35/204]	Loss 0.0008 (0.0063)	
training:	Epoch: [87][36/204]	Loss 0.0009 (0.0061)	
training:	Epoch: [87][37/204]	Loss 0.0007 (0.0060)	
training:	Epoch: [87][38/204]	Loss 0.0021 (0.0059)	
training:	Epoch: [87][39/204]	Loss 0.0008 (0.0057)	
training:	Epoch: [87][40/204]	Loss 0.0006 (0.0056)	
training:	Epoch: [87][41/204]	Loss 0.0007 (0.0055)	
training:	Epoch: [87][42/204]	Loss 0.2143 (0.0105)	
training:	Epoch: [87][43/204]	Loss 0.0010 (0.0102)	
training:	Epoch: [87][44/204]	Loss 0.0006 (0.0100)	
training:	Epoch: [87][45/204]	Loss 0.0007 (0.0098)	
training:	Epoch: [87][46/204]	Loss 0.0014 (0.0096)	
training:	Epoch: [87][47/204]	Loss 0.0009 (0.0094)	
training:	Epoch: [87][48/204]	Loss 0.0010 (0.0093)	
training:	Epoch: [87][49/204]	Loss 0.0006 (0.0091)	
training:	Epoch: [87][50/204]	Loss 0.0012 (0.0089)	
training:	Epoch: [87][51/204]	Loss 0.0019 (0.0088)	
training:	Epoch: [87][52/204]	Loss 0.0007 (0.0086)	
training:	Epoch: [87][53/204]	Loss 0.0010 (0.0085)	
training:	Epoch: [87][54/204]	Loss 0.0036 (0.0084)	
training:	Epoch: [87][55/204]	Loss 0.0043 (0.0083)	
training:	Epoch: [87][56/204]	Loss 0.0093 (0.0083)	
training:	Epoch: [87][57/204]	Loss 0.0011 (0.0082)	
training:	Epoch: [87][58/204]	Loss 0.0012 (0.0081)	
training:	Epoch: [87][59/204]	Loss 0.0007 (0.0080)	
training:	Epoch: [87][60/204]	Loss 0.0007 (0.0078)	
training:	Epoch: [87][61/204]	Loss 0.0013 (0.0077)	
training:	Epoch: [87][62/204]	Loss 0.0007 (0.0076)	
training:	Epoch: [87][63/204]	Loss 0.0008 (0.0075)	
training:	Epoch: [87][64/204]	Loss 0.0800 (0.0087)	
training:	Epoch: [87][65/204]	Loss 0.0195 (0.0088)	
training:	Epoch: [87][66/204]	Loss 0.0792 (0.0099)	
training:	Epoch: [87][67/204]	Loss 0.0010 (0.0097)	
training:	Epoch: [87][68/204]	Loss 0.0007 (0.0096)	
training:	Epoch: [87][69/204]	Loss 0.0011 (0.0095)	
training:	Epoch: [87][70/204]	Loss 0.0016 (0.0094)	
training:	Epoch: [87][71/204]	Loss 0.0007 (0.0093)	
training:	Epoch: [87][72/204]	Loss 0.0007 (0.0091)	
training:	Epoch: [87][73/204]	Loss 0.0011 (0.0090)	
training:	Epoch: [87][74/204]	Loss 0.0071 (0.0090)	
training:	Epoch: [87][75/204]	Loss 0.0007 (0.0089)	
training:	Epoch: [87][76/204]	Loss 0.0008 (0.0088)	
training:	Epoch: [87][77/204]	Loss 0.0007 (0.0087)	
training:	Epoch: [87][78/204]	Loss 0.0008 (0.0086)	
training:	Epoch: [87][79/204]	Loss 0.0009 (0.0085)	
training:	Epoch: [87][80/204]	Loss 0.0006 (0.0084)	
training:	Epoch: [87][81/204]	Loss 0.0010 (0.0083)	
training:	Epoch: [87][82/204]	Loss 0.0011 (0.0082)	
training:	Epoch: [87][83/204]	Loss 0.0012 (0.0081)	
training:	Epoch: [87][84/204]	Loss 0.0008 (0.0080)	
training:	Epoch: [87][85/204]	Loss 0.0008 (0.0079)	
training:	Epoch: [87][86/204]	Loss 0.0007 (0.0079)	
training:	Epoch: [87][87/204]	Loss 0.0006 (0.0078)	
training:	Epoch: [87][88/204]	Loss 0.0006 (0.0077)	
training:	Epoch: [87][89/204]	Loss 0.0360 (0.0080)	
training:	Epoch: [87][90/204]	Loss 0.0336 (0.0083)	
training:	Epoch: [87][91/204]	Loss 0.0086 (0.0083)	
training:	Epoch: [87][92/204]	Loss 0.0147 (0.0084)	
training:	Epoch: [87][93/204]	Loss 0.0011 (0.0083)	
training:	Epoch: [87][94/204]	Loss 0.0011 (0.0082)	
training:	Epoch: [87][95/204]	Loss 0.0012 (0.0081)	
training:	Epoch: [87][96/204]	Loss 0.0010 (0.0081)	
training:	Epoch: [87][97/204]	Loss 0.0006 (0.0080)	
training:	Epoch: [87][98/204]	Loss 0.0012 (0.0079)	
training:	Epoch: [87][99/204]	Loss 0.0014 (0.0079)	
training:	Epoch: [87][100/204]	Loss 0.0007 (0.0078)	
training:	Epoch: [87][101/204]	Loss 0.0010 (0.0077)	
training:	Epoch: [87][102/204]	Loss 0.0007 (0.0077)	
training:	Epoch: [87][103/204]	Loss 0.0089 (0.0077)	
training:	Epoch: [87][104/204]	Loss 0.0007 (0.0076)	
training:	Epoch: [87][105/204]	Loss 0.0013 (0.0075)	
training:	Epoch: [87][106/204]	Loss 0.0007 (0.0075)	
training:	Epoch: [87][107/204]	Loss 0.0009 (0.0074)	
training:	Epoch: [87][108/204]	Loss 0.0016 (0.0074)	
training:	Epoch: [87][109/204]	Loss 0.0007 (0.0073)	
training:	Epoch: [87][110/204]	Loss 0.0016 (0.0072)	
training:	Epoch: [87][111/204]	Loss 0.0009 (0.0072)	
training:	Epoch: [87][112/204]	Loss 0.0007 (0.0071)	
training:	Epoch: [87][113/204]	Loss 0.0006 (0.0071)	
training:	Epoch: [87][114/204]	Loss 0.0010 (0.0070)	
training:	Epoch: [87][115/204]	Loss 0.0031 (0.0070)	
training:	Epoch: [87][116/204]	Loss 0.0007 (0.0069)	
training:	Epoch: [87][117/204]	Loss 0.0918 (0.0077)	
training:	Epoch: [87][118/204]	Loss 0.0008 (0.0076)	
training:	Epoch: [87][119/204]	Loss 0.0008 (0.0075)	
training:	Epoch: [87][120/204]	Loss 0.0009 (0.0075)	
training:	Epoch: [87][121/204]	Loss 0.0014 (0.0074)	
training:	Epoch: [87][122/204]	Loss 0.0011 (0.0074)	
training:	Epoch: [87][123/204]	Loss 0.0008 (0.0073)	
training:	Epoch: [87][124/204]	Loss 0.0008 (0.0073)	
training:	Epoch: [87][125/204]	Loss 0.0205 (0.0074)	
training:	Epoch: [87][126/204]	Loss 0.0008 (0.0073)	
training:	Epoch: [87][127/204]	Loss 0.0010 (0.0073)	
training:	Epoch: [87][128/204]	Loss 0.0442 (0.0076)	
training:	Epoch: [87][129/204]	Loss 0.0054 (0.0076)	
training:	Epoch: [87][130/204]	Loss 0.0012 (0.0075)	
training:	Epoch: [87][131/204]	Loss 0.0010 (0.0075)	
training:	Epoch: [87][132/204]	Loss 0.0006 (0.0074)	
training:	Epoch: [87][133/204]	Loss 0.0008 (0.0074)	
training:	Epoch: [87][134/204]	Loss 0.0009 (0.0073)	
training:	Epoch: [87][135/204]	Loss 0.0007 (0.0073)	
training:	Epoch: [87][136/204]	Loss 0.0026 (0.0072)	
training:	Epoch: [87][137/204]	Loss 0.0028 (0.0072)	
training:	Epoch: [87][138/204]	Loss 0.0009 (0.0071)	
training:	Epoch: [87][139/204]	Loss 0.0008 (0.0071)	
training:	Epoch: [87][140/204]	Loss 0.0006 (0.0071)	
training:	Epoch: [87][141/204]	Loss 0.0007 (0.0070)	
training:	Epoch: [87][142/204]	Loss 0.0016 (0.0070)	
training:	Epoch: [87][143/204]	Loss 0.0006 (0.0069)	
training:	Epoch: [87][144/204]	Loss 0.0009 (0.0069)	
training:	Epoch: [87][145/204]	Loss 0.0007 (0.0068)	
training:	Epoch: [87][146/204]	Loss 0.0008 (0.0068)	
training:	Epoch: [87][147/204]	Loss 0.0009 (0.0068)	
training:	Epoch: [87][148/204]	Loss 0.0007 (0.0067)	
training:	Epoch: [87][149/204]	Loss 0.0750 (0.0072)	
training:	Epoch: [87][150/204]	Loss 0.0007 (0.0071)	
training:	Epoch: [87][151/204]	Loss 0.0007 (0.0071)	
training:	Epoch: [87][152/204]	Loss 0.0007 (0.0070)	
training:	Epoch: [87][153/204]	Loss 0.0009 (0.0070)	
training:	Epoch: [87][154/204]	Loss 0.0011 (0.0070)	
training:	Epoch: [87][155/204]	Loss 0.0011 (0.0069)	
training:	Epoch: [87][156/204]	Loss 0.0007 (0.0069)	
training:	Epoch: [87][157/204]	Loss 0.0022 (0.0069)	
training:	Epoch: [87][158/204]	Loss 0.0007 (0.0068)	
training:	Epoch: [87][159/204]	Loss 0.0007 (0.0068)	
training:	Epoch: [87][160/204]	Loss 0.0009 (0.0067)	
training:	Epoch: [87][161/204]	Loss 0.0007 (0.0067)	
training:	Epoch: [87][162/204]	Loss 0.0104 (0.0067)	
training:	Epoch: [87][163/204]	Loss 0.0071 (0.0067)	
training:	Epoch: [87][164/204]	Loss 0.0007 (0.0067)	
training:	Epoch: [87][165/204]	Loss 0.0007 (0.0067)	
training:	Epoch: [87][166/204]	Loss 0.0009 (0.0066)	
training:	Epoch: [87][167/204]	Loss 0.0026 (0.0066)	
training:	Epoch: [87][168/204]	Loss 0.0070 (0.0066)	
training:	Epoch: [87][169/204]	Loss 0.0010 (0.0066)	
training:	Epoch: [87][170/204]	Loss 0.0013 (0.0065)	
training:	Epoch: [87][171/204]	Loss 0.0069 (0.0065)	
training:	Epoch: [87][172/204]	Loss 0.0010 (0.0065)	
training:	Epoch: [87][173/204]	Loss 0.0017 (0.0065)	
training:	Epoch: [87][174/204]	Loss 0.0109 (0.0065)	
training:	Epoch: [87][175/204]	Loss 0.0040 (0.0065)	
training:	Epoch: [87][176/204]	Loss 0.0007 (0.0065)	
training:	Epoch: [87][177/204]	Loss 0.0006 (0.0064)	
training:	Epoch: [87][178/204]	Loss 0.0008 (0.0064)	
training:	Epoch: [87][179/204]	Loss 0.0008 (0.0064)	
training:	Epoch: [87][180/204]	Loss 0.0007 (0.0063)	
training:	Epoch: [87][181/204]	Loss 0.0008 (0.0063)	
training:	Epoch: [87][182/204]	Loss 0.0018 (0.0063)	
training:	Epoch: [87][183/204]	Loss 0.0031 (0.0063)	
training:	Epoch: [87][184/204]	Loss 0.0006 (0.0062)	
training:	Epoch: [87][185/204]	Loss 0.0007 (0.0062)	
training:	Epoch: [87][186/204]	Loss 0.0007 (0.0062)	
training:	Epoch: [87][187/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [87][188/204]	Loss 0.0287 (0.0063)	
training:	Epoch: [87][189/204]	Loss 0.0019 (0.0062)	
training:	Epoch: [87][190/204]	Loss 0.0038 (0.0062)	
training:	Epoch: [87][191/204]	Loss 0.0020 (0.0062)	
training:	Epoch: [87][192/204]	Loss 0.0008 (0.0062)	
training:	Epoch: [87][193/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [87][194/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [87][195/204]	Loss 0.1553 (0.0069)	
training:	Epoch: [87][196/204]	Loss 0.0006 (0.0069)	
training:	Epoch: [87][197/204]	Loss 0.0011 (0.0068)	
training:	Epoch: [87][198/204]	Loss 0.0724 (0.0072)	
training:	Epoch: [87][199/204]	Loss 0.0030 (0.0071)	
training:	Epoch: [87][200/204]	Loss 0.0008 (0.0071)	
training:	Epoch: [87][201/204]	Loss 0.0009 (0.0071)	
training:	Epoch: [87][202/204]	Loss 0.0012 (0.0070)	
training:	Epoch: [87][203/204]	Loss 0.0007 (0.0070)	
training:	Epoch: [87][204/204]	Loss 0.0013 (0.0070)	
Training:	 Loss: 0.0070

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7828 0.7822 0.7707 0.7948
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.2870
Pretraining:	Epoch 88/500
----------
training:	Epoch: [88][1/204]	Loss 0.0145 (0.0145)	
training:	Epoch: [88][2/204]	Loss 0.0008 (0.0076)	
training:	Epoch: [88][3/204]	Loss 0.0009 (0.0054)	
training:	Epoch: [88][4/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [88][5/204]	Loss 0.0011 (0.0036)	
training:	Epoch: [88][6/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [88][7/204]	Loss 0.0015 (0.0029)	
training:	Epoch: [88][8/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [88][9/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [88][10/204]	Loss 0.0116 (0.0033)	
training:	Epoch: [88][11/204]	Loss 0.0090 (0.0039)	
training:	Epoch: [88][12/204]	Loss 0.0009 (0.0036)	
training:	Epoch: [88][13/204]	Loss 0.0022 (0.0035)	
training:	Epoch: [88][14/204]	Loss 0.0010 (0.0033)	
training:	Epoch: [88][15/204]	Loss 0.0022 (0.0033)	
training:	Epoch: [88][16/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [88][17/204]	Loss 0.0325 (0.0048)	
training:	Epoch: [88][18/204]	Loss 0.0012 (0.0046)	
training:	Epoch: [88][19/204]	Loss 0.0013 (0.0044)	
training:	Epoch: [88][20/204]	Loss 0.0008 (0.0043)	
training:	Epoch: [88][21/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [88][22/204]	Loss 0.0011 (0.0040)	
training:	Epoch: [88][23/204]	Loss 0.0009 (0.0038)	
training:	Epoch: [88][24/204]	Loss 0.0017 (0.0037)	
training:	Epoch: [88][25/204]	Loss 0.0023 (0.0037)	
training:	Epoch: [88][26/204]	Loss 0.0011 (0.0036)	
training:	Epoch: [88][27/204]	Loss 0.0040 (0.0036)	
training:	Epoch: [88][28/204]	Loss 0.0010 (0.0035)	
training:	Epoch: [88][29/204]	Loss 0.0012 (0.0034)	
training:	Epoch: [88][30/204]	Loss 0.0035 (0.0034)	
training:	Epoch: [88][31/204]	Loss 0.0986 (0.0065)	
training:	Epoch: [88][32/204]	Loss 0.0214 (0.0070)	
training:	Epoch: [88][33/204]	Loss 0.0008 (0.0068)	
training:	Epoch: [88][34/204]	Loss 0.0006 (0.0066)	
training:	Epoch: [88][35/204]	Loss 0.0008 (0.0064)	
training:	Epoch: [88][36/204]	Loss 0.0006 (0.0063)	
training:	Epoch: [88][37/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [88][38/204]	Loss 0.0033 (0.0060)	
training:	Epoch: [88][39/204]	Loss 0.0015 (0.0059)	
training:	Epoch: [88][40/204]	Loss 0.0012 (0.0058)	
training:	Epoch: [88][41/204]	Loss 0.0071 (0.0058)	
training:	Epoch: [88][42/204]	Loss 0.0008 (0.0057)	
training:	Epoch: [88][43/204]	Loss 0.0029 (0.0057)	
training:	Epoch: [88][44/204]	Loss 0.0929 (0.0076)	
training:	Epoch: [88][45/204]	Loss 0.0022 (0.0075)	
training:	Epoch: [88][46/204]	Loss 0.0016 (0.0074)	
training:	Epoch: [88][47/204]	Loss 0.0008 (0.0072)	
training:	Epoch: [88][48/204]	Loss 0.0010 (0.0071)	
training:	Epoch: [88][49/204]	Loss 0.0008 (0.0070)	
training:	Epoch: [88][50/204]	Loss 0.0031 (0.0069)	
training:	Epoch: [88][51/204]	Loss 0.0006 (0.0068)	
training:	Epoch: [88][52/204]	Loss 0.0015 (0.0067)	
training:	Epoch: [88][53/204]	Loss 0.0016 (0.0066)	
training:	Epoch: [88][54/204]	Loss 0.0013 (0.0065)	
training:	Epoch: [88][55/204]	Loss 0.0102 (0.0066)	
training:	Epoch: [88][56/204]	Loss 0.0006 (0.0065)	
training:	Epoch: [88][57/204]	Loss 0.0013 (0.0064)	
training:	Epoch: [88][58/204]	Loss 0.0399 (0.0069)	
training:	Epoch: [88][59/204]	Loss 0.0007 (0.0068)	
training:	Epoch: [88][60/204]	Loss 0.0007 (0.0067)	
training:	Epoch: [88][61/204]	Loss 0.0009 (0.0066)	
training:	Epoch: [88][62/204]	Loss 0.0009 (0.0065)	
training:	Epoch: [88][63/204]	Loss 0.0012 (0.0065)	
training:	Epoch: [88][64/204]	Loss 0.0009 (0.0064)	
training:	Epoch: [88][65/204]	Loss 0.0016 (0.0063)	
training:	Epoch: [88][66/204]	Loss 0.0014 (0.0062)	
training:	Epoch: [88][67/204]	Loss 0.0236 (0.0065)	
training:	Epoch: [88][68/204]	Loss 0.0045 (0.0065)	
training:	Epoch: [88][69/204]	Loss 0.0019 (0.0064)	
training:	Epoch: [88][70/204]	Loss 0.0007 (0.0063)	
training:	Epoch: [88][71/204]	Loss 0.0097 (0.0064)	
training:	Epoch: [88][72/204]	Loss 0.0010 (0.0063)	
training:	Epoch: [88][73/204]	Loss 0.0013 (0.0062)	
training:	Epoch: [88][74/204]	Loss 0.0009 (0.0061)	
training:	Epoch: [88][75/204]	Loss 0.0007 (0.0061)	
training:	Epoch: [88][76/204]	Loss 0.0009 (0.0060)	
training:	Epoch: [88][77/204]	Loss 0.0371 (0.0064)	
training:	Epoch: [88][78/204]	Loss 0.0029 (0.0064)	
training:	Epoch: [88][79/204]	Loss 0.0014 (0.0063)	
training:	Epoch: [88][80/204]	Loss 0.0010 (0.0062)	
training:	Epoch: [88][81/204]	Loss 0.0083 (0.0063)	
training:	Epoch: [88][82/204]	Loss 0.0008 (0.0062)	
training:	Epoch: [88][83/204]	Loss 0.0016 (0.0061)	
training:	Epoch: [88][84/204]	Loss 0.0007 (0.0061)	
training:	Epoch: [88][85/204]	Loss 0.0007 (0.0060)	
training:	Epoch: [88][86/204]	Loss 0.0009 (0.0059)	
training:	Epoch: [88][87/204]	Loss 0.0031 (0.0059)	
training:	Epoch: [88][88/204]	Loss 0.0012 (0.0059)	
training:	Epoch: [88][89/204]	Loss 0.0013 (0.0058)	
training:	Epoch: [88][90/204]	Loss 0.2193 (0.0082)	
training:	Epoch: [88][91/204]	Loss 0.0009 (0.0081)	
training:	Epoch: [88][92/204]	Loss 0.0007 (0.0080)	
training:	Epoch: [88][93/204]	Loss 0.0008 (0.0079)	
training:	Epoch: [88][94/204]	Loss 0.0009 (0.0079)	
training:	Epoch: [88][95/204]	Loss 0.0007 (0.0078)	
training:	Epoch: [88][96/204]	Loss 0.0008 (0.0077)	
training:	Epoch: [88][97/204]	Loss 0.0012 (0.0077)	
training:	Epoch: [88][98/204]	Loss 0.0056 (0.0076)	
training:	Epoch: [88][99/204]	Loss 0.0008 (0.0076)	
training:	Epoch: [88][100/204]	Loss 0.0014 (0.0075)	
training:	Epoch: [88][101/204]	Loss 0.0007 (0.0074)	
training:	Epoch: [88][102/204]	Loss 0.0006 (0.0074)	
training:	Epoch: [88][103/204]	Loss 0.0008 (0.0073)	
training:	Epoch: [88][104/204]	Loss 0.0011 (0.0072)	
training:	Epoch: [88][105/204]	Loss 0.0013 (0.0072)	
training:	Epoch: [88][106/204]	Loss 0.0012 (0.0071)	
training:	Epoch: [88][107/204]	Loss 0.0008 (0.0071)	
training:	Epoch: [88][108/204]	Loss 0.0008 (0.0070)	
training:	Epoch: [88][109/204]	Loss 0.0008 (0.0070)	
training:	Epoch: [88][110/204]	Loss 0.0016 (0.0069)	
training:	Epoch: [88][111/204]	Loss 0.0030 (0.0069)	
training:	Epoch: [88][112/204]	Loss 0.0008 (0.0068)	
training:	Epoch: [88][113/204]	Loss 0.0007 (0.0068)	
training:	Epoch: [88][114/204]	Loss 0.0013 (0.0067)	
training:	Epoch: [88][115/204]	Loss 0.0008 (0.0067)	
training:	Epoch: [88][116/204]	Loss 0.0016 (0.0066)	
training:	Epoch: [88][117/204]	Loss 0.0007 (0.0066)	
training:	Epoch: [88][118/204]	Loss 0.0011 (0.0065)	
training:	Epoch: [88][119/204]	Loss 0.0051 (0.0065)	
training:	Epoch: [88][120/204]	Loss 0.0010 (0.0065)	
training:	Epoch: [88][121/204]	Loss 0.0011 (0.0064)	
training:	Epoch: [88][122/204]	Loss 0.0005 (0.0064)	
training:	Epoch: [88][123/204]	Loss 0.0083 (0.0064)	
training:	Epoch: [88][124/204]	Loss 0.0008 (0.0063)	
training:	Epoch: [88][125/204]	Loss 0.0008 (0.0063)	
training:	Epoch: [88][126/204]	Loss 0.0680 (0.0068)	
training:	Epoch: [88][127/204]	Loss 0.0037 (0.0068)	
training:	Epoch: [88][128/204]	Loss 0.0012 (0.0067)	
training:	Epoch: [88][129/204]	Loss 0.0008 (0.0067)	
training:	Epoch: [88][130/204]	Loss 0.0007 (0.0066)	
training:	Epoch: [88][131/204]	Loss 0.0016 (0.0066)	
training:	Epoch: [88][132/204]	Loss 0.0027 (0.0066)	
training:	Epoch: [88][133/204]	Loss 0.0011 (0.0065)	
training:	Epoch: [88][134/204]	Loss 0.0016 (0.0065)	
training:	Epoch: [88][135/204]	Loss 0.0016 (0.0064)	
training:	Epoch: [88][136/204]	Loss 0.0010 (0.0064)	
training:	Epoch: [88][137/204]	Loss 0.0016 (0.0064)	
training:	Epoch: [88][138/204]	Loss 0.0035 (0.0063)	
training:	Epoch: [88][139/204]	Loss 0.0011 (0.0063)	
training:	Epoch: [88][140/204]	Loss 0.0008 (0.0063)	
training:	Epoch: [88][141/204]	Loss 0.0150 (0.0063)	
training:	Epoch: [88][142/204]	Loss 0.0029 (0.0063)	
training:	Epoch: [88][143/204]	Loss 0.0010 (0.0063)	
training:	Epoch: [88][144/204]	Loss 0.0013 (0.0062)	
training:	Epoch: [88][145/204]	Loss 0.0038 (0.0062)	
training:	Epoch: [88][146/204]	Loss 0.0009 (0.0062)	
training:	Epoch: [88][147/204]	Loss 0.0007 (0.0061)	
training:	Epoch: [88][148/204]	Loss 0.0008 (0.0061)	
training:	Epoch: [88][149/204]	Loss 0.0015 (0.0061)	
training:	Epoch: [88][150/204]	Loss 0.0669 (0.0065)	
training:	Epoch: [88][151/204]	Loss 0.0008 (0.0064)	
training:	Epoch: [88][152/204]	Loss 0.0006 (0.0064)	
training:	Epoch: [88][153/204]	Loss 0.0008 (0.0064)	
training:	Epoch: [88][154/204]	Loss 0.0008 (0.0063)	
training:	Epoch: [88][155/204]	Loss 0.0007 (0.0063)	
training:	Epoch: [88][156/204]	Loss 0.0007 (0.0063)	
training:	Epoch: [88][157/204]	Loss 0.0008 (0.0062)	
training:	Epoch: [88][158/204]	Loss 0.0008 (0.0062)	
training:	Epoch: [88][159/204]	Loss 0.0009 (0.0062)	
training:	Epoch: [88][160/204]	Loss 0.0009 (0.0061)	
training:	Epoch: [88][161/204]	Loss 0.0031 (0.0061)	
training:	Epoch: [88][162/204]	Loss 0.0008 (0.0061)	
training:	Epoch: [88][163/204]	Loss 0.0036 (0.0061)	
training:	Epoch: [88][164/204]	Loss 0.0011 (0.0060)	
training:	Epoch: [88][165/204]	Loss 0.0012 (0.0060)	
training:	Epoch: [88][166/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [88][167/204]	Loss 0.0008 (0.0059)	
training:	Epoch: [88][168/204]	Loss 0.0007 (0.0059)	
training:	Epoch: [88][169/204]	Loss 0.0006 (0.0059)	
training:	Epoch: [88][170/204]	Loss 0.0007 (0.0058)	
training:	Epoch: [88][171/204]	Loss 0.0011 (0.0058)	
training:	Epoch: [88][172/204]	Loss 0.0012 (0.0058)	
training:	Epoch: [88][173/204]	Loss 0.0007 (0.0058)	
training:	Epoch: [88][174/204]	Loss 0.0018 (0.0057)	
training:	Epoch: [88][175/204]	Loss 0.0009 (0.0057)	
training:	Epoch: [88][176/204]	Loss 0.0011 (0.0057)	
training:	Epoch: [88][177/204]	Loss 0.0008 (0.0057)	
training:	Epoch: [88][178/204]	Loss 0.0290 (0.0058)	
training:	Epoch: [88][179/204]	Loss 0.0008 (0.0058)	
training:	Epoch: [88][180/204]	Loss 0.0018 (0.0057)	
training:	Epoch: [88][181/204]	Loss 0.0006 (0.0057)	
training:	Epoch: [88][182/204]	Loss 0.0017 (0.0057)	
training:	Epoch: [88][183/204]	Loss 0.0134 (0.0057)	
training:	Epoch: [88][184/204]	Loss 0.0008 (0.0057)	
training:	Epoch: [88][185/204]	Loss 0.0011 (0.0057)	
training:	Epoch: [88][186/204]	Loss 0.0008 (0.0057)	
training:	Epoch: [88][187/204]	Loss 0.0043 (0.0056)	
training:	Epoch: [88][188/204]	Loss 0.0007 (0.0056)	
training:	Epoch: [88][189/204]	Loss 0.0006 (0.0056)	
training:	Epoch: [88][190/204]	Loss 0.0065 (0.0056)	
training:	Epoch: [88][191/204]	Loss 0.0007 (0.0056)	
training:	Epoch: [88][192/204]	Loss 0.0007 (0.0055)	
training:	Epoch: [88][193/204]	Loss 0.0007 (0.0055)	
training:	Epoch: [88][194/204]	Loss 0.0010 (0.0055)	
training:	Epoch: [88][195/204]	Loss 0.0010 (0.0055)	
training:	Epoch: [88][196/204]	Loss 0.1143 (0.0060)	
training:	Epoch: [88][197/204]	Loss 0.0008 (0.0060)	
training:	Epoch: [88][198/204]	Loss 0.0008 (0.0060)	
training:	Epoch: [88][199/204]	Loss 0.0007 (0.0060)	
training:	Epoch: [88][200/204]	Loss 0.0011 (0.0059)	
training:	Epoch: [88][201/204]	Loss 0.0006 (0.0059)	
training:	Epoch: [88][202/204]	Loss 0.0009 (0.0059)	
training:	Epoch: [88][203/204]	Loss 0.0009 (0.0059)	
training:	Epoch: [88][204/204]	Loss 0.0008 (0.0058)	
Training:	 Loss: 0.0058

Training:	 ACC: 0.9995 0.9995 0.9997 0.9994
Validation:	 ACC: 0.7795 0.7806 0.8035 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3013
Pretraining:	Epoch 89/500
----------
training:	Epoch: [89][1/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [89][2/204]	Loss 0.0012 (0.0010)	
training:	Epoch: [89][3/204]	Loss 0.2213 (0.0744)	
training:	Epoch: [89][4/204]	Loss 0.0018 (0.0563)	
training:	Epoch: [89][5/204]	Loss 0.0008 (0.0452)	
training:	Epoch: [89][6/204]	Loss 0.0007 (0.0378)	
training:	Epoch: [89][7/204]	Loss 0.0006 (0.0325)	
training:	Epoch: [89][8/204]	Loss 0.0008 (0.0285)	
training:	Epoch: [89][9/204]	Loss 0.1662 (0.0438)	
training:	Epoch: [89][10/204]	Loss 0.0007 (0.0395)	
training:	Epoch: [89][11/204]	Loss 0.0049 (0.0364)	
training:	Epoch: [89][12/204]	Loss 0.0008 (0.0334)	
training:	Epoch: [89][13/204]	Loss 0.0033 (0.0311)	
training:	Epoch: [89][14/204]	Loss 0.0008 (0.0289)	
training:	Epoch: [89][15/204]	Loss 0.0006 (0.0270)	
training:	Epoch: [89][16/204]	Loss 0.0007 (0.0254)	
training:	Epoch: [89][17/204]	Loss 0.0006 (0.0239)	
training:	Epoch: [89][18/204]	Loss 0.0007 (0.0226)	
training:	Epoch: [89][19/204]	Loss 0.0007 (0.0215)	
training:	Epoch: [89][20/204]	Loss 0.0008 (0.0204)	
training:	Epoch: [89][21/204]	Loss 0.0006 (0.0195)	
training:	Epoch: [89][22/204]	Loss 0.0008 (0.0186)	
training:	Epoch: [89][23/204]	Loss 0.0010 (0.0179)	
training:	Epoch: [89][24/204]	Loss 0.0006 (0.0172)	
training:	Epoch: [89][25/204]	Loss 0.0007 (0.0165)	
training:	Epoch: [89][26/204]	Loss 0.0007 (0.0159)	
training:	Epoch: [89][27/204]	Loss 0.0006 (0.0153)	
training:	Epoch: [89][28/204]	Loss 0.0006 (0.0148)	
training:	Epoch: [89][29/204]	Loss 0.0006 (0.0143)	
training:	Epoch: [89][30/204]	Loss 0.0006 (0.0139)	
training:	Epoch: [89][31/204]	Loss 0.0011 (0.0134)	
training:	Epoch: [89][32/204]	Loss 0.0009 (0.0131)	
training:	Epoch: [89][33/204]	Loss 0.0006 (0.0127)	
training:	Epoch: [89][34/204]	Loss 0.0017 (0.0124)	
training:	Epoch: [89][35/204]	Loss 0.0065 (0.0122)	
training:	Epoch: [89][36/204]	Loss 0.0014 (0.0119)	
training:	Epoch: [89][37/204]	Loss 0.0007 (0.0116)	
training:	Epoch: [89][38/204]	Loss 0.0027 (0.0113)	
training:	Epoch: [89][39/204]	Loss 0.0026 (0.0111)	
training:	Epoch: [89][40/204]	Loss 0.0013 (0.0109)	
training:	Epoch: [89][41/204]	Loss 0.0011 (0.0106)	
training:	Epoch: [89][42/204]	Loss 0.0047 (0.0105)	
training:	Epoch: [89][43/204]	Loss 0.0007 (0.0103)	
training:	Epoch: [89][44/204]	Loss 0.0008 (0.0101)	
training:	Epoch: [89][45/204]	Loss 0.0010 (0.0099)	
training:	Epoch: [89][46/204]	Loss 0.0009 (0.0097)	
training:	Epoch: [89][47/204]	Loss 0.0006 (0.0095)	
training:	Epoch: [89][48/204]	Loss 0.0010 (0.0093)	
training:	Epoch: [89][49/204]	Loss 0.0006 (0.0091)	
training:	Epoch: [89][50/204]	Loss 0.0007 (0.0089)	
training:	Epoch: [89][51/204]	Loss 0.0009 (0.0088)	
training:	Epoch: [89][52/204]	Loss 0.0008 (0.0086)	
training:	Epoch: [89][53/204]	Loss 0.0006 (0.0085)	
training:	Epoch: [89][54/204]	Loss 0.0006 (0.0083)	
training:	Epoch: [89][55/204]	Loss 0.0007 (0.0082)	
training:	Epoch: [89][56/204]	Loss 0.0006 (0.0081)	
training:	Epoch: [89][57/204]	Loss 0.0009 (0.0079)	
training:	Epoch: [89][58/204]	Loss 0.0006 (0.0078)	
training:	Epoch: [89][59/204]	Loss 0.0009 (0.0077)	
training:	Epoch: [89][60/204]	Loss 0.0022 (0.0076)	
training:	Epoch: [89][61/204]	Loss 0.0007 (0.0075)	
training:	Epoch: [89][62/204]	Loss 0.0015 (0.0074)	
training:	Epoch: [89][63/204]	Loss 0.0023 (0.0073)	
training:	Epoch: [89][64/204]	Loss 0.0008 (0.0072)	
training:	Epoch: [89][65/204]	Loss 0.0006 (0.0071)	
training:	Epoch: [89][66/204]	Loss 0.0009 (0.0070)	
training:	Epoch: [89][67/204]	Loss 0.0007 (0.0069)	
training:	Epoch: [89][68/204]	Loss 0.0059 (0.0069)	
training:	Epoch: [89][69/204]	Loss 0.0007 (0.0068)	
training:	Epoch: [89][70/204]	Loss 0.0012 (0.0067)	
training:	Epoch: [89][71/204]	Loss 0.0007 (0.0067)	
training:	Epoch: [89][72/204]	Loss 0.0008 (0.0066)	
training:	Epoch: [89][73/204]	Loss 0.0018 (0.0065)	
training:	Epoch: [89][74/204]	Loss 0.0007 (0.0064)	
training:	Epoch: [89][75/204]	Loss 0.0007 (0.0063)	
training:	Epoch: [89][76/204]	Loss 0.0021 (0.0063)	
training:	Epoch: [89][77/204]	Loss 0.0006 (0.0062)	
training:	Epoch: [89][78/204]	Loss 0.0036 (0.0062)	
training:	Epoch: [89][79/204]	Loss 0.0007 (0.0061)	
training:	Epoch: [89][80/204]	Loss 0.0009 (0.0061)	
training:	Epoch: [89][81/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [89][82/204]	Loss 0.0013 (0.0059)	
training:	Epoch: [89][83/204]	Loss 0.0006 (0.0059)	
training:	Epoch: [89][84/204]	Loss 0.0008 (0.0058)	
training:	Epoch: [89][85/204]	Loss 0.0010 (0.0057)	
training:	Epoch: [89][86/204]	Loss 0.0009 (0.0057)	
training:	Epoch: [89][87/204]	Loss 0.0015 (0.0056)	
training:	Epoch: [89][88/204]	Loss 0.0007 (0.0056)	
training:	Epoch: [89][89/204]	Loss 0.0014 (0.0055)	
training:	Epoch: [89][90/204]	Loss 0.0006 (0.0055)	
training:	Epoch: [89][91/204]	Loss 0.0006 (0.0054)	
training:	Epoch: [89][92/204]	Loss 0.0008 (0.0054)	
training:	Epoch: [89][93/204]	Loss 0.0009 (0.0053)	
training:	Epoch: [89][94/204]	Loss 0.0008 (0.0053)	
training:	Epoch: [89][95/204]	Loss 0.0007 (0.0052)	
training:	Epoch: [89][96/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [89][97/204]	Loss 0.0007 (0.0051)	
training:	Epoch: [89][98/204]	Loss 0.0006 (0.0051)	
training:	Epoch: [89][99/204]	Loss 0.0020 (0.0051)	
training:	Epoch: [89][100/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [89][101/204]	Loss 0.0009 (0.0050)	
training:	Epoch: [89][102/204]	Loss 0.0010 (0.0049)	
training:	Epoch: [89][103/204]	Loss 0.0010 (0.0049)	
training:	Epoch: [89][104/204]	Loss 0.0013 (0.0049)	
training:	Epoch: [89][105/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [89][106/204]	Loss 0.0008 (0.0048)	
training:	Epoch: [89][107/204]	Loss 0.0006 (0.0047)	
training:	Epoch: [89][108/204]	Loss 0.0007 (0.0047)	
training:	Epoch: [89][109/204]	Loss 0.0011 (0.0047)	
training:	Epoch: [89][110/204]	Loss 0.0009 (0.0046)	
training:	Epoch: [89][111/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [89][112/204]	Loss 0.0007 (0.0046)	
training:	Epoch: [89][113/204]	Loss 0.0010 (0.0045)	
training:	Epoch: [89][114/204]	Loss 0.0007 (0.0045)	
training:	Epoch: [89][115/204]	Loss 0.0103 (0.0046)	
training:	Epoch: [89][116/204]	Loss 0.0008 (0.0045)	
training:	Epoch: [89][117/204]	Loss 0.0030 (0.0045)	
training:	Epoch: [89][118/204]	Loss 0.0011 (0.0045)	
training:	Epoch: [89][119/204]	Loss 0.0008 (0.0044)	
training:	Epoch: [89][120/204]	Loss 0.0013 (0.0044)	
training:	Epoch: [89][121/204]	Loss 0.0021 (0.0044)	
training:	Epoch: [89][122/204]	Loss 0.0007 (0.0044)	
training:	Epoch: [89][123/204]	Loss 0.0014 (0.0044)	
training:	Epoch: [89][124/204]	Loss 0.0007 (0.0043)	
training:	Epoch: [89][125/204]	Loss 0.0014 (0.0043)	
training:	Epoch: [89][126/204]	Loss 0.0007 (0.0043)	
training:	Epoch: [89][127/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [89][128/204]	Loss 0.0009 (0.0042)	
training:	Epoch: [89][129/204]	Loss 0.0010 (0.0042)	
training:	Epoch: [89][130/204]	Loss 0.0031 (0.0042)	
training:	Epoch: [89][131/204]	Loss 0.0007 (0.0042)	
training:	Epoch: [89][132/204]	Loss 0.0049 (0.0042)	
training:	Epoch: [89][133/204]	Loss 0.0030 (0.0042)	
training:	Epoch: [89][134/204]	Loss 0.0011 (0.0041)	
training:	Epoch: [89][135/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [89][136/204]	Loss 0.0008 (0.0041)	
training:	Epoch: [89][137/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [89][138/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [89][139/204]	Loss 0.0009 (0.0040)	
training:	Epoch: [89][140/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [89][141/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [89][142/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [89][143/204]	Loss 0.0011 (0.0039)	
training:	Epoch: [89][144/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [89][145/204]	Loss 0.0008 (0.0039)	
training:	Epoch: [89][146/204]	Loss 0.0012 (0.0039)	
training:	Epoch: [89][147/204]	Loss 0.0006 (0.0038)	
training:	Epoch: [89][148/204]	Loss 0.0008 (0.0038)	
training:	Epoch: [89][149/204]	Loss 0.0006 (0.0038)	
training:	Epoch: [89][150/204]	Loss 0.0120 (0.0038)	
training:	Epoch: [89][151/204]	Loss 0.0006 (0.0038)	
training:	Epoch: [89][152/204]	Loss 0.0011 (0.0038)	
training:	Epoch: [89][153/204]	Loss 0.0009 (0.0038)	
training:	Epoch: [89][154/204]	Loss 0.0007 (0.0038)	
training:	Epoch: [89][155/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [89][156/204]	Loss 0.0007 (0.0037)	
training:	Epoch: [89][157/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [89][158/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [89][159/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [89][160/204]	Loss 0.0009 (0.0037)	
training:	Epoch: [89][161/204]	Loss 0.0116 (0.0037)	
training:	Epoch: [89][162/204]	Loss 0.0007 (0.0037)	
training:	Epoch: [89][163/204]	Loss 0.0014 (0.0037)	
training:	Epoch: [89][164/204]	Loss 0.0009 (0.0037)	
training:	Epoch: [89][165/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [89][166/204]	Loss 0.0007 (0.0036)	
training:	Epoch: [89][167/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [89][168/204]	Loss 0.0007 (0.0036)	
training:	Epoch: [89][169/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [89][170/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [89][171/204]	Loss 0.0012 (0.0035)	
training:	Epoch: [89][172/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [89][173/204]	Loss 0.0085 (0.0035)	
training:	Epoch: [89][174/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [89][175/204]	Loss 0.0008 (0.0035)	
training:	Epoch: [89][176/204]	Loss 0.0008 (0.0035)	
training:	Epoch: [89][177/204]	Loss 0.0018 (0.0035)	
training:	Epoch: [89][178/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [89][179/204]	Loss 0.0009 (0.0035)	
training:	Epoch: [89][180/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [89][181/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [89][182/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [89][183/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [89][184/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [89][185/204]	Loss 0.0014 (0.0034)	
training:	Epoch: [89][186/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [89][187/204]	Loss 0.0013 (0.0033)	
training:	Epoch: [89][188/204]	Loss 0.0020 (0.0033)	
training:	Epoch: [89][189/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [89][190/204]	Loss 0.0008 (0.0033)	
training:	Epoch: [89][191/204]	Loss 0.0010 (0.0033)	
training:	Epoch: [89][192/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [89][193/204]	Loss 0.0012 (0.0033)	
training:	Epoch: [89][194/204]	Loss 0.0010 (0.0033)	
training:	Epoch: [89][195/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [89][196/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [89][197/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [89][198/204]	Loss 0.0026 (0.0032)	
training:	Epoch: [89][199/204]	Loss 0.0016 (0.0032)	
training:	Epoch: [89][200/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [89][201/204]	Loss 0.0009 (0.0032)	
training:	Epoch: [89][202/204]	Loss 0.0009 (0.0032)	
training:	Epoch: [89][203/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [89][204/204]	Loss 0.0007 (0.0032)	
Training:	 Loss: 0.0031

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7745 0.7764 0.8158 0.7332
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3325
Pretraining:	Epoch 90/500
----------
training:	Epoch: [90][1/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [90][2/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [90][3/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [90][4/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [90][5/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [90][6/204]	Loss 0.0201 (0.0039)	
training:	Epoch: [90][7/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [90][8/204]	Loss 0.0009 (0.0031)	
training:	Epoch: [90][9/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [90][10/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [90][11/204]	Loss 0.0011 (0.0025)	
training:	Epoch: [90][12/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [90][13/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [90][14/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [90][15/204]	Loss 0.0012 (0.0021)	
training:	Epoch: [90][16/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [90][17/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [90][18/204]	Loss 0.0012 (0.0019)	
training:	Epoch: [90][19/204]	Loss 0.0010 (0.0018)	
training:	Epoch: [90][20/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [90][21/204]	Loss 0.0007 (0.0017)	
training:	Epoch: [90][22/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [90][23/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][24/204]	Loss 0.0021 (0.0017)	
training:	Epoch: [90][25/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [90][26/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [90][27/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [90][28/204]	Loss 0.0007 (0.0015)	
training:	Epoch: [90][29/204]	Loss 0.0007 (0.0015)	
training:	Epoch: [90][30/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [90][31/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [90][32/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [90][33/204]	Loss 0.0015 (0.0014)	
training:	Epoch: [90][34/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [90][35/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [90][36/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [90][37/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [90][38/204]	Loss 0.0446 (0.0025)	
training:	Epoch: [90][39/204]	Loss 0.0016 (0.0025)	
training:	Epoch: [90][40/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [90][41/204]	Loss 0.0009 (0.0024)	
training:	Epoch: [90][42/204]	Loss 0.0010 (0.0024)	
training:	Epoch: [90][43/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [90][44/204]	Loss 0.0014 (0.0023)	
training:	Epoch: [90][45/204]	Loss 0.0014 (0.0023)	
training:	Epoch: [90][46/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [90][47/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [90][48/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [90][49/204]	Loss 0.0013 (0.0022)	
training:	Epoch: [90][50/204]	Loss 0.0011 (0.0021)	
training:	Epoch: [90][51/204]	Loss 0.0040 (0.0022)	
training:	Epoch: [90][52/204]	Loss 0.0009 (0.0021)	
training:	Epoch: [90][53/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [90][54/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [90][55/204]	Loss 0.0014 (0.0021)	
training:	Epoch: [90][56/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [90][57/204]	Loss 0.0011 (0.0020)	
training:	Epoch: [90][58/204]	Loss 0.0009 (0.0020)	
training:	Epoch: [90][59/204]	Loss 0.0007 (0.0020)	
training:	Epoch: [90][60/204]	Loss 0.0008 (0.0020)	
training:	Epoch: [90][61/204]	Loss 0.0184 (0.0022)	
training:	Epoch: [90][62/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [90][63/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [90][64/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [90][65/204]	Loss 0.0015 (0.0022)	
training:	Epoch: [90][66/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [90][67/204]	Loss 0.0009 (0.0021)	
training:	Epoch: [90][68/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [90][69/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [90][70/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [90][71/204]	Loss 0.0014 (0.0021)	
training:	Epoch: [90][72/204]	Loss 0.0012 (0.0020)	
training:	Epoch: [90][73/204]	Loss 0.0008 (0.0020)	
training:	Epoch: [90][74/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [90][75/204]	Loss 0.0009 (0.0020)	
training:	Epoch: [90][76/204]	Loss 0.0007 (0.0020)	
training:	Epoch: [90][77/204]	Loss 0.0008 (0.0020)	
training:	Epoch: [90][78/204]	Loss 0.0008 (0.0019)	
training:	Epoch: [90][79/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [90][80/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [90][81/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [90][82/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [90][83/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [90][84/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [90][85/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [90][86/204]	Loss 0.0007 (0.0018)	
training:	Epoch: [90][87/204]	Loss 0.0007 (0.0018)	
training:	Epoch: [90][88/204]	Loss 0.0007 (0.0018)	
training:	Epoch: [90][89/204]	Loss 0.0007 (0.0018)	
training:	Epoch: [90][90/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [90][91/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [90][92/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [90][93/204]	Loss 0.0009 (0.0017)	
training:	Epoch: [90][94/204]	Loss 0.0007 (0.0017)	
training:	Epoch: [90][95/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [90][96/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [90][97/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [90][98/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [90][99/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [90][100/204]	Loss 0.0009 (0.0017)	
training:	Epoch: [90][101/204]	Loss 0.0018 (0.0017)	
training:	Epoch: [90][102/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [90][103/204]	Loss 0.0013 (0.0017)	
training:	Epoch: [90][104/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][105/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [90][106/204]	Loss 0.0012 (0.0016)	
training:	Epoch: [90][107/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][108/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][109/204]	Loss 0.0011 (0.0016)	
training:	Epoch: [90][110/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [90][111/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][112/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][113/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][114/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [90][115/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [90][116/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][117/204]	Loss 0.0006 (0.0015)	
training:	Epoch: [90][118/204]	Loss 0.0007 (0.0015)	
training:	Epoch: [90][119/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [90][120/204]	Loss 0.0084 (0.0016)	
training:	Epoch: [90][121/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][122/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [90][123/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [90][124/204]	Loss 0.0065 (0.0016)	
training:	Epoch: [90][125/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [90][126/204]	Loss 0.2229 (0.0034)	
training:	Epoch: [90][127/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [90][128/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [90][129/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [90][130/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [90][131/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [90][132/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [90][133/204]	Loss 0.0014 (0.0032)	
training:	Epoch: [90][134/204]	Loss 0.0018 (0.0032)	
training:	Epoch: [90][135/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [90][136/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [90][137/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [90][138/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [90][139/204]	Loss 0.0013 (0.0031)	
training:	Epoch: [90][140/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [90][141/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [90][142/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [90][143/204]	Loss 0.0012 (0.0030)	
training:	Epoch: [90][144/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [90][145/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [90][146/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [90][147/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [90][148/204]	Loss 0.0015 (0.0030)	
training:	Epoch: [90][149/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [90][150/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [90][151/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [90][152/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [90][153/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [90][154/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [90][155/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [90][156/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [90][157/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [90][158/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [90][159/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [90][160/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [90][161/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [90][162/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [90][163/204]	Loss 0.0009 (0.0028)	
training:	Epoch: [90][164/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [90][165/204]	Loss 0.0008 (0.0027)	
training:	Epoch: [90][166/204]	Loss 0.0007 (0.0027)	
training:	Epoch: [90][167/204]	Loss 0.0008 (0.0027)	
training:	Epoch: [90][168/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [90][169/204]	Loss 0.0007 (0.0027)	
training:	Epoch: [90][170/204]	Loss 0.0007 (0.0027)	
training:	Epoch: [90][171/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [90][172/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [90][173/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [90][174/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [90][175/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [90][176/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [90][177/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [90][178/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [90][179/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [90][180/204]	Loss 0.0013 (0.0026)	
training:	Epoch: [90][181/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [90][182/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [90][183/204]	Loss 0.0085 (0.0026)	
training:	Epoch: [90][184/204]	Loss 0.0015 (0.0026)	
training:	Epoch: [90][185/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [90][186/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [90][187/204]	Loss 0.0007 (0.0025)	
training:	Epoch: [90][188/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [90][189/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [90][190/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [90][191/204]	Loss 0.0007 (0.0025)	
training:	Epoch: [90][192/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [90][193/204]	Loss 0.0009 (0.0025)	
training:	Epoch: [90][194/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [90][195/204]	Loss 0.0020 (0.0025)	
training:	Epoch: [90][196/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [90][197/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [90][198/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [90][199/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [90][200/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [90][201/204]	Loss 0.0050 (0.0024)	
training:	Epoch: [90][202/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [90][203/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [90][204/204]	Loss 0.0007 (0.0024)	
Training:	 Loss: 0.0024

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7761 0.7764 0.7820 0.7702
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3516
Pretraining:	Epoch 91/500
----------
training:	Epoch: [91][1/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [91][2/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [91][3/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [91][4/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [91][5/204]	Loss 0.0015 (0.0008)	
training:	Epoch: [91][6/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [91][7/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][8/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][9/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][10/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [91][11/204]	Loss 0.0015 (0.0008)	
training:	Epoch: [91][12/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][13/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][14/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [91][15/204]	Loss 0.0011 (0.0008)	
training:	Epoch: [91][16/204]	Loss 0.0012 (0.0008)	
training:	Epoch: [91][17/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][18/204]	Loss 0.0035 (0.0010)	
training:	Epoch: [91][19/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [91][20/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [91][21/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [91][22/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [91][23/204]	Loss 0.0019 (0.0010)	
training:	Epoch: [91][24/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [91][25/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [91][26/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [91][27/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [91][28/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [91][29/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [91][30/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [91][31/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [91][32/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [91][33/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [91][34/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [91][35/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][36/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [91][37/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][38/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][39/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][40/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [91][41/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][42/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][43/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [91][44/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [91][45/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [91][46/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][47/204]	Loss 0.0011 (0.0008)	
training:	Epoch: [91][48/204]	Loss 0.0035 (0.0009)	
training:	Epoch: [91][49/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [91][50/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [91][51/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [91][52/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][53/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [91][54/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [91][55/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [91][56/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][57/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [91][58/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][59/204]	Loss 0.0020 (0.0008)	
training:	Epoch: [91][60/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][61/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][62/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [91][63/204]	Loss 0.2191 (0.0043)	
training:	Epoch: [91][64/204]	Loss 0.0009 (0.0042)	
training:	Epoch: [91][65/204]	Loss 0.0007 (0.0042)	
training:	Epoch: [91][66/204]	Loss 0.0015 (0.0041)	
training:	Epoch: [91][67/204]	Loss 0.0110 (0.0042)	
training:	Epoch: [91][68/204]	Loss 0.0036 (0.0042)	
training:	Epoch: [91][69/204]	Loss 0.0005 (0.0042)	
training:	Epoch: [91][70/204]	Loss 0.0006 (0.0041)	
training:	Epoch: [91][71/204]	Loss 0.0006 (0.0041)	
training:	Epoch: [91][72/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [91][73/204]	Loss 0.0008 (0.0040)	
training:	Epoch: [91][74/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [91][75/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [91][76/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [91][77/204]	Loss 0.0006 (0.0038)	
training:	Epoch: [91][78/204]	Loss 0.0007 (0.0038)	
training:	Epoch: [91][79/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [91][80/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [91][81/204]	Loss 0.0007 (0.0037)	
training:	Epoch: [91][82/204]	Loss 0.0013 (0.0036)	
training:	Epoch: [91][83/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [91][84/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [91][85/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [91][86/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [91][87/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [91][88/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [91][89/204]	Loss 0.0251 (0.0037)	
training:	Epoch: [91][90/204]	Loss 0.0008 (0.0036)	
training:	Epoch: [91][91/204]	Loss 0.0009 (0.0036)	
training:	Epoch: [91][92/204]	Loss 0.0013 (0.0036)	
training:	Epoch: [91][93/204]	Loss 0.0011 (0.0035)	
training:	Epoch: [91][94/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [91][95/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [91][96/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [91][97/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [91][98/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [91][99/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [91][100/204]	Loss 0.0012 (0.0034)	
training:	Epoch: [91][101/204]	Loss 0.0014 (0.0033)	
training:	Epoch: [91][102/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [91][103/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [91][104/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [91][105/204]	Loss 0.0342 (0.0036)	
training:	Epoch: [91][106/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [91][107/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [91][108/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [91][109/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [91][110/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [91][111/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [91][112/204]	Loss 0.0011 (0.0034)	
training:	Epoch: [91][113/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [91][114/204]	Loss 0.0012 (0.0033)	
training:	Epoch: [91][115/204]	Loss 0.0254 (0.0035)	
training:	Epoch: [91][116/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [91][117/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [91][118/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [91][119/204]	Loss 0.0012 (0.0034)	
training:	Epoch: [91][120/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [91][121/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [91][122/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [91][123/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [91][124/204]	Loss 0.0103 (0.0034)	
training:	Epoch: [91][125/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [91][126/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [91][127/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [91][128/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [91][129/204]	Loss 0.0011 (0.0033)	
training:	Epoch: [91][130/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [91][131/204]	Loss 0.0011 (0.0033)	
training:	Epoch: [91][132/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [91][133/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [91][134/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [91][135/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [91][136/204]	Loss 0.0016 (0.0032)	
training:	Epoch: [91][137/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [91][138/204]	Loss 0.0010 (0.0031)	
training:	Epoch: [91][139/204]	Loss 0.0009 (0.0031)	
training:	Epoch: [91][140/204]	Loss 0.0039 (0.0031)	
training:	Epoch: [91][141/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [91][142/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [91][143/204]	Loss 0.0031 (0.0031)	
training:	Epoch: [91][144/204]	Loss 0.0010 (0.0031)	
training:	Epoch: [91][145/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [91][146/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [91][147/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [91][148/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [91][149/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [91][150/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [91][151/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [91][152/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [91][153/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [91][154/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [91][155/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [91][156/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [91][157/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [91][158/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [91][159/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [91][160/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [91][161/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [91][162/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [91][163/204]	Loss 0.0822 (0.0033)	
training:	Epoch: [91][164/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [91][165/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [91][166/204]	Loss 0.0010 (0.0033)	
training:	Epoch: [91][167/204]	Loss 0.0009 (0.0032)	
training:	Epoch: [91][168/204]	Loss 0.0017 (0.0032)	
training:	Epoch: [91][169/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [91][170/204]	Loss 0.0009 (0.0032)	
training:	Epoch: [91][171/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [91][172/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [91][173/204]	Loss 0.0018 (0.0032)	
training:	Epoch: [91][174/204]	Loss 0.0033 (0.0032)	
training:	Epoch: [91][175/204]	Loss 0.0032 (0.0032)	
training:	Epoch: [91][176/204]	Loss 0.0023 (0.0032)	
training:	Epoch: [91][177/204]	Loss 0.0011 (0.0031)	
training:	Epoch: [91][178/204]	Loss 0.0010 (0.0031)	
training:	Epoch: [91][179/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [91][180/204]	Loss 0.0151 (0.0032)	
training:	Epoch: [91][181/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [91][182/204]	Loss 0.0043 (0.0032)	
training:	Epoch: [91][183/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [91][184/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [91][185/204]	Loss 0.0061 (0.0032)	
training:	Epoch: [91][186/204]	Loss 0.0012 (0.0032)	
training:	Epoch: [91][187/204]	Loss 0.0019 (0.0032)	
training:	Epoch: [91][188/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [91][189/204]	Loss 0.0009 (0.0031)	
training:	Epoch: [91][190/204]	Loss 0.0009 (0.0031)	
training:	Epoch: [91][191/204]	Loss 0.0012 (0.0031)	
training:	Epoch: [91][192/204]	Loss 0.0012 (0.0031)	
training:	Epoch: [91][193/204]	Loss 0.0081 (0.0031)	
training:	Epoch: [91][194/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [91][195/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [91][196/204]	Loss 0.0018 (0.0031)	
training:	Epoch: [91][197/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [91][198/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [91][199/204]	Loss 0.0516 (0.0033)	
training:	Epoch: [91][200/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [91][201/204]	Loss 0.0011 (0.0033)	
training:	Epoch: [91][202/204]	Loss 0.0010 (0.0033)	
training:	Epoch: [91][203/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [91][204/204]	Loss 0.0005 (0.0032)	
Training:	 Loss: 0.0032

Training:	 ACC: 0.9997 0.9997 0.9997 0.9997
Validation:	 ACC: 0.7692 0.7705 0.7973 0.7410
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3997
Pretraining:	Epoch 92/500
----------
training:	Epoch: [92][1/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [92][2/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [92][3/204]	Loss 0.1711 (0.0575)	
training:	Epoch: [92][4/204]	Loss 0.0006 (0.0432)	
training:	Epoch: [92][5/204]	Loss 0.0006 (0.0347)	
training:	Epoch: [92][6/204]	Loss 0.0007 (0.0290)	
training:	Epoch: [92][7/204]	Loss 0.0008 (0.0250)	
training:	Epoch: [92][8/204]	Loss 0.0006 (0.0219)	
training:	Epoch: [92][9/204]	Loss 0.0007 (0.0196)	
training:	Epoch: [92][10/204]	Loss 0.0005 (0.0177)	
training:	Epoch: [92][11/204]	Loss 0.0007 (0.0161)	
training:	Epoch: [92][12/204]	Loss 0.0006 (0.0148)	
training:	Epoch: [92][13/204]	Loss 0.0006 (0.0137)	
training:	Epoch: [92][14/204]	Loss 0.0015 (0.0129)	
training:	Epoch: [92][15/204]	Loss 0.0014 (0.0121)	
training:	Epoch: [92][16/204]	Loss 0.0007 (0.0114)	
training:	Epoch: [92][17/204]	Loss 0.0006 (0.0108)	
training:	Epoch: [92][18/204]	Loss 0.0005 (0.0102)	
training:	Epoch: [92][19/204]	Loss 0.0020 (0.0098)	
training:	Epoch: [92][20/204]	Loss 0.0008 (0.0093)	
training:	Epoch: [92][21/204]	Loss 0.0005 (0.0089)	
training:	Epoch: [92][22/204]	Loss 0.0007 (0.0085)	
training:	Epoch: [92][23/204]	Loss 0.0006 (0.0082)	
training:	Epoch: [92][24/204]	Loss 0.0006 (0.0079)	
training:	Epoch: [92][25/204]	Loss 0.0005 (0.0076)	
training:	Epoch: [92][26/204]	Loss 0.0007 (0.0073)	
training:	Epoch: [92][27/204]	Loss 0.0006 (0.0071)	
training:	Epoch: [92][28/204]	Loss 0.0007 (0.0068)	
training:	Epoch: [92][29/204]	Loss 0.0006 (0.0066)	
training:	Epoch: [92][30/204]	Loss 0.0006 (0.0064)	
training:	Epoch: [92][31/204]	Loss 0.0006 (0.0062)	
training:	Epoch: [92][32/204]	Loss 0.0007 (0.0061)	
training:	Epoch: [92][33/204]	Loss 0.0006 (0.0059)	
training:	Epoch: [92][34/204]	Loss 0.0008 (0.0057)	
training:	Epoch: [92][35/204]	Loss 0.0006 (0.0056)	
training:	Epoch: [92][36/204]	Loss 0.0008 (0.0055)	
training:	Epoch: [92][37/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [92][38/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [92][39/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [92][40/204]	Loss 0.0007 (0.0050)	
training:	Epoch: [92][41/204]	Loss 0.0012 (0.0049)	
training:	Epoch: [92][42/204]	Loss 0.0007 (0.0048)	
training:	Epoch: [92][43/204]	Loss 0.0007 (0.0047)	
training:	Epoch: [92][44/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [92][45/204]	Loss 0.0007 (0.0045)	
training:	Epoch: [92][46/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [92][47/204]	Loss 0.0025 (0.0044)	
training:	Epoch: [92][48/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [92][49/204]	Loss 0.0005 (0.0042)	
training:	Epoch: [92][50/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [92][51/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [92][52/204]	Loss 0.0008 (0.0040)	
training:	Epoch: [92][53/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [92][54/204]	Loss 0.0008 (0.0039)	
training:	Epoch: [92][55/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [92][56/204]	Loss 0.0008 (0.0038)	
training:	Epoch: [92][57/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [92][58/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [92][59/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [92][60/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [92][61/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [92][62/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [92][63/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [92][64/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [92][65/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [92][66/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [92][67/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [92][68/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [92][69/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [92][70/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [92][71/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [92][72/204]	Loss 0.0011 (0.0031)	
training:	Epoch: [92][73/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [92][74/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [92][75/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [92][76/204]	Loss 0.0581 (0.0037)	
training:	Epoch: [92][77/204]	Loss 0.0005 (0.0037)	
training:	Epoch: [92][78/204]	Loss 0.2243 (0.0065)	
training:	Epoch: [92][79/204]	Loss 0.0005 (0.0064)	
training:	Epoch: [92][80/204]	Loss 0.0011 (0.0063)	
training:	Epoch: [92][81/204]	Loss 0.0011 (0.0063)	
training:	Epoch: [92][82/204]	Loss 0.0006 (0.0062)	
training:	Epoch: [92][83/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [92][84/204]	Loss 0.0096 (0.0062)	
training:	Epoch: [92][85/204]	Loss 0.0028 (0.0061)	
training:	Epoch: [92][86/204]	Loss 0.0009 (0.0061)	
training:	Epoch: [92][87/204]	Loss 0.0005 (0.0060)	
training:	Epoch: [92][88/204]	Loss 0.0016 (0.0060)	
training:	Epoch: [92][89/204]	Loss 0.0007 (0.0059)	
training:	Epoch: [92][90/204]	Loss 0.0039 (0.0059)	
training:	Epoch: [92][91/204]	Loss 0.0005 (0.0058)	
training:	Epoch: [92][92/204]	Loss 0.0025 (0.0058)	
training:	Epoch: [92][93/204]	Loss 0.0007 (0.0057)	
training:	Epoch: [92][94/204]	Loss 0.0006 (0.0057)	
training:	Epoch: [92][95/204]	Loss 0.0005 (0.0056)	
training:	Epoch: [92][96/204]	Loss 0.0006 (0.0056)	
training:	Epoch: [92][97/204]	Loss 0.0008 (0.0055)	
training:	Epoch: [92][98/204]	Loss 0.0037 (0.0055)	
training:	Epoch: [92][99/204]	Loss 0.0006 (0.0055)	
training:	Epoch: [92][100/204]	Loss 0.0015 (0.0054)	
training:	Epoch: [92][101/204]	Loss 0.0014 (0.0054)	
training:	Epoch: [92][102/204]	Loss 0.0006 (0.0053)	
training:	Epoch: [92][103/204]	Loss 0.0007 (0.0053)	
training:	Epoch: [92][104/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [92][105/204]	Loss 0.0006 (0.0052)	
training:	Epoch: [92][106/204]	Loss 0.0016 (0.0052)	
training:	Epoch: [92][107/204]	Loss 0.0017 (0.0051)	
training:	Epoch: [92][108/204]	Loss 0.0007 (0.0051)	
training:	Epoch: [92][109/204]	Loss 0.0010 (0.0051)	
training:	Epoch: [92][110/204]	Loss 0.0007 (0.0050)	
training:	Epoch: [92][111/204]	Loss 0.0028 (0.0050)	
training:	Epoch: [92][112/204]	Loss 0.0006 (0.0050)	
training:	Epoch: [92][113/204]	Loss 0.0073 (0.0050)	
training:	Epoch: [92][114/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [92][115/204]	Loss 0.0006 (0.0049)	
training:	Epoch: [92][116/204]	Loss 0.0006 (0.0049)	
training:	Epoch: [92][117/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [92][118/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [92][119/204]	Loss 0.0008 (0.0048)	
training:	Epoch: [92][120/204]	Loss 0.0006 (0.0047)	
training:	Epoch: [92][121/204]	Loss 0.0025 (0.0047)	
training:	Epoch: [92][122/204]	Loss 0.0006 (0.0047)	
training:	Epoch: [92][123/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [92][124/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [92][125/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [92][126/204]	Loss 0.0007 (0.0045)	
training:	Epoch: [92][127/204]	Loss 0.0008 (0.0045)	
training:	Epoch: [92][128/204]	Loss 0.0009 (0.0045)	
training:	Epoch: [92][129/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [92][130/204]	Loss 0.0007 (0.0044)	
training:	Epoch: [92][131/204]	Loss 0.0012 (0.0044)	
training:	Epoch: [92][132/204]	Loss 0.0018 (0.0044)	
training:	Epoch: [92][133/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [92][134/204]	Loss 0.0008 (0.0043)	
training:	Epoch: [92][135/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [92][136/204]	Loss 0.1145 (0.0051)	
training:	Epoch: [92][137/204]	Loss 0.0008 (0.0051)	
training:	Epoch: [92][138/204]	Loss 0.0010 (0.0050)	
training:	Epoch: [92][139/204]	Loss 0.0010 (0.0050)	
training:	Epoch: [92][140/204]	Loss 0.0006 (0.0050)	
training:	Epoch: [92][141/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [92][142/204]	Loss 0.0008 (0.0049)	
training:	Epoch: [92][143/204]	Loss 0.0006 (0.0049)	
training:	Epoch: [92][144/204]	Loss 0.0006 (0.0049)	
training:	Epoch: [92][145/204]	Loss 0.0007 (0.0048)	
training:	Epoch: [92][146/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [92][147/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [92][148/204]	Loss 0.0011 (0.0047)	
training:	Epoch: [92][149/204]	Loss 0.0011 (0.0047)	
training:	Epoch: [92][150/204]	Loss 0.0013 (0.0047)	
training:	Epoch: [92][151/204]	Loss 0.0005 (0.0047)	
training:	Epoch: [92][152/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [92][153/204]	Loss 0.0012 (0.0046)	
training:	Epoch: [92][154/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [92][155/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [92][156/204]	Loss 0.0250 (0.0047)	
training:	Epoch: [92][157/204]	Loss 0.0005 (0.0047)	
training:	Epoch: [92][158/204]	Loss 0.0010 (0.0047)	
training:	Epoch: [92][159/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [92][160/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [92][161/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [92][162/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [92][163/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [92][164/204]	Loss 0.0006 (0.0045)	
training:	Epoch: [92][165/204]	Loss 0.0020 (0.0045)	
training:	Epoch: [92][166/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [92][167/204]	Loss 0.0007 (0.0044)	
training:	Epoch: [92][168/204]	Loss 0.0008 (0.0044)	
training:	Epoch: [92][169/204]	Loss 0.0005 (0.0044)	
training:	Epoch: [92][170/204]	Loss 0.0012 (0.0044)	
training:	Epoch: [92][171/204]	Loss 0.0018 (0.0044)	
training:	Epoch: [92][172/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [92][173/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [92][174/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [92][175/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [92][176/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [92][177/204]	Loss 0.0014 (0.0042)	
training:	Epoch: [92][178/204]	Loss 0.0006 (0.0042)	
training:	Epoch: [92][179/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [92][180/204]	Loss 0.0065 (0.0042)	
training:	Epoch: [92][181/204]	Loss 0.0005 (0.0042)	
training:	Epoch: [92][182/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [92][183/204]	Loss 0.0006 (0.0042)	
training:	Epoch: [92][184/204]	Loss 0.0018 (0.0041)	
training:	Epoch: [92][185/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [92][186/204]	Loss 0.0046 (0.0041)	
training:	Epoch: [92][187/204]	Loss 0.0011 (0.0041)	
training:	Epoch: [92][188/204]	Loss 0.0063 (0.0041)	
training:	Epoch: [92][189/204]	Loss 0.0006 (0.0041)	
training:	Epoch: [92][190/204]	Loss 0.0011 (0.0041)	
training:	Epoch: [92][191/204]	Loss 0.0006 (0.0041)	
training:	Epoch: [92][192/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [92][193/204]	Loss 0.0007 (0.0040)	
training:	Epoch: [92][194/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [92][195/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [92][196/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [92][197/204]	Loss 0.0010 (0.0040)	
training:	Epoch: [92][198/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [92][199/204]	Loss 0.0010 (0.0039)	
training:	Epoch: [92][200/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [92][201/204]	Loss 0.0013 (0.0039)	
training:	Epoch: [92][202/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [92][203/204]	Loss 0.0020 (0.0039)	
training:	Epoch: [92][204/204]	Loss 0.0005 (0.0039)	
Training:	 Loss: 0.0039

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7788 0.7796 0.7963 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3436
Pretraining:	Epoch 93/500
----------
training:	Epoch: [93][1/204]	Loss 0.0010 (0.0010)	
training:	Epoch: [93][2/204]	Loss 0.0009 (0.0009)	
training:	Epoch: [93][3/204]	Loss 0.0010 (0.0009)	
training:	Epoch: [93][4/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [93][5/204]	Loss 0.0009 (0.0009)	
training:	Epoch: [93][6/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [93][7/204]	Loss 0.0029 (0.0011)	
training:	Epoch: [93][8/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [93][9/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [93][10/204]	Loss 0.0008 (0.0010)	
training:	Epoch: [93][11/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [93][12/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [93][13/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [93][14/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [93][15/204]	Loss 0.0016 (0.0009)	
training:	Epoch: [93][16/204]	Loss 0.0010 (0.0009)	
training:	Epoch: [93][17/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [93][18/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [93][19/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [93][20/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [93][21/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [93][22/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][23/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][24/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][25/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][26/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][27/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][28/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][29/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][30/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][31/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][32/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][33/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][34/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][35/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][36/204]	Loss 0.0019 (0.0008)	
training:	Epoch: [93][37/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][38/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][39/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][40/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][41/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [93][42/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][43/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][44/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][45/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][46/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][47/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][48/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][49/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [93][50/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [93][51/204]	Loss 0.0066 (0.0009)	
training:	Epoch: [93][52/204]	Loss 0.0012 (0.0009)	
training:	Epoch: [93][53/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [93][54/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [93][55/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [93][56/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][57/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][58/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][59/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][60/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][61/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][62/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][63/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][64/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][65/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][66/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][67/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][68/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][69/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][70/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][71/204]	Loss 0.0013 (0.0008)	
training:	Epoch: [93][72/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][73/204]	Loss 0.0014 (0.0008)	
training:	Epoch: [93][74/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][75/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][76/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][77/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [93][78/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][79/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][80/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][81/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][82/204]	Loss 0.0011 (0.0008)	
training:	Epoch: [93][83/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][84/204]	Loss 0.0035 (0.0008)	
training:	Epoch: [93][85/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][86/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][87/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][88/204]	Loss 0.0014 (0.0008)	
training:	Epoch: [93][89/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][90/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][91/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][92/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][93/204]	Loss 0.0062 (0.0009)	
training:	Epoch: [93][94/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [93][95/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [93][96/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [93][97/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [93][98/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [93][99/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [93][100/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][101/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][102/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][103/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][104/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][105/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][106/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][107/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][108/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][109/204]	Loss 0.0013 (0.0008)	
training:	Epoch: [93][110/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][111/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][112/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][113/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [93][114/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][115/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][116/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][117/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][118/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][119/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][120/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][121/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][122/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][123/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][124/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][125/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][126/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][127/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [93][128/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][129/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][130/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][131/204]	Loss 0.0013 (0.0008)	
training:	Epoch: [93][132/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][133/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][134/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [93][135/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][136/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][137/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][138/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [93][139/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][140/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][141/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][142/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][143/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][144/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][145/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][146/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][147/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][148/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][149/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][150/204]	Loss 0.0049 (0.0008)	
training:	Epoch: [93][151/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][152/204]	Loss 0.0015 (0.0008)	
training:	Epoch: [93][153/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][154/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][155/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][156/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][157/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][158/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][159/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][160/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][161/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][162/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][163/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][164/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][165/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][166/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][167/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][168/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][169/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][170/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][171/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][172/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][173/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][174/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][175/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][176/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][177/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][178/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][179/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [93][180/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][181/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][182/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][183/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][184/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [93][185/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][186/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][187/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][188/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][189/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [93][190/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][191/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][192/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][193/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][194/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [93][195/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][196/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [93][197/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][198/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [93][199/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [93][200/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][201/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [93][202/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [93][203/204]	Loss 0.2263 (0.0019)	
training:	Epoch: [93][204/204]	Loss 0.0008 (0.0019)	
Training:	 Loss: 0.0019

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7805 0.7817 0.8066 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3633
Pretraining:	Epoch 94/500
----------
training:	Epoch: [94][1/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [94][2/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [94][3/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [94][4/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [94][5/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [94][6/204]	Loss 0.0012 (0.0007)	
training:	Epoch: [94][7/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [94][8/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][9/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [94][10/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][11/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][12/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [94][13/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][14/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][15/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [94][16/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [94][17/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][18/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][19/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][20/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][21/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][22/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [94][23/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [94][24/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [94][25/204]	Loss 0.0012 (0.0006)	
training:	Epoch: [94][26/204]	Loss 0.0026 (0.0007)	
training:	Epoch: [94][27/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [94][28/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [94][29/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [94][30/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [94][31/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [94][32/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [94][33/204]	Loss 0.0018 (0.0007)	
training:	Epoch: [94][34/204]	Loss 0.0011 (0.0007)	
training:	Epoch: [94][35/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [94][36/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [94][37/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [94][38/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [94][39/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [94][40/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [94][41/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [94][42/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [94][43/204]	Loss 0.0346 (0.0015)	
training:	Epoch: [94][44/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [94][45/204]	Loss 0.0007 (0.0015)	
training:	Epoch: [94][46/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [94][47/204]	Loss 0.0025 (0.0015)	
training:	Epoch: [94][48/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [94][49/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [94][50/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [94][51/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [94][52/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [94][53/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [94][54/204]	Loss 0.0006 (0.0013)	
training:	Epoch: [94][55/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [94][56/204]	Loss 0.0010 (0.0013)	
training:	Epoch: [94][57/204]	Loss 0.0012 (0.0013)	
training:	Epoch: [94][58/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [94][59/204]	Loss 0.0006 (0.0013)	
training:	Epoch: [94][60/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [94][61/204]	Loss 0.0006 (0.0013)	
training:	Epoch: [94][62/204]	Loss 0.0015 (0.0013)	
training:	Epoch: [94][63/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [94][64/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][65/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [94][66/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [94][67/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [94][68/204]	Loss 0.0012 (0.0012)	
training:	Epoch: [94][69/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][70/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][71/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [94][72/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][73/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [94][74/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][75/204]	Loss 0.0030 (0.0012)	
training:	Epoch: [94][76/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][77/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][78/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [94][79/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][80/204]	Loss 0.0034 (0.0012)	
training:	Epoch: [94][81/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [94][82/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [94][83/204]	Loss 0.0037 (0.0012)	
training:	Epoch: [94][84/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [94][85/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][86/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [94][87/204]	Loss 0.0023 (0.0012)	
training:	Epoch: [94][88/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [94][89/204]	Loss 0.0027 (0.0012)	
training:	Epoch: [94][90/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][91/204]	Loss 0.0013 (0.0012)	
training:	Epoch: [94][92/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][93/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [94][94/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][95/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][96/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][97/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [94][98/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [94][99/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [94][100/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][101/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][102/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][103/204]	Loss 0.0007 (0.0011)	
training:	Epoch: [94][104/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [94][105/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][106/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][107/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [94][108/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][109/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][110/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][111/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [94][112/204]	Loss 0.0020 (0.0011)	
training:	Epoch: [94][113/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][114/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][115/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][116/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][117/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [94][118/204]	Loss 0.0073 (0.0011)	
training:	Epoch: [94][119/204]	Loss 0.0008 (0.0011)	
training:	Epoch: [94][120/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][121/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [94][122/204]	Loss 0.0008 (0.0011)	
training:	Epoch: [94][123/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][124/204]	Loss 0.0016 (0.0011)	
training:	Epoch: [94][125/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][126/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [94][127/204]	Loss 0.0009 (0.0011)	
training:	Epoch: [94][128/204]	Loss 0.2247 (0.0028)	
training:	Epoch: [94][129/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [94][130/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [94][131/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [94][132/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [94][133/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [94][134/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [94][135/204]	Loss 0.0016 (0.0027)	
training:	Epoch: [94][136/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [94][137/204]	Loss 0.0041 (0.0027)	
training:	Epoch: [94][138/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [94][139/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [94][140/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [94][141/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [94][142/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [94][143/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [94][144/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [94][145/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [94][146/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [94][147/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [94][148/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [94][149/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [94][150/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [94][151/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [94][152/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [94][153/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [94][154/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [94][155/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [94][156/204]	Loss 0.0007 (0.0025)	
training:	Epoch: [94][157/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [94][158/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [94][159/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [94][160/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [94][161/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [94][162/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [94][163/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [94][164/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [94][165/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [94][166/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [94][167/204]	Loss 0.0018 (0.0023)	
training:	Epoch: [94][168/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [94][169/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [94][170/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [94][171/204]	Loss 0.0010 (0.0023)	
training:	Epoch: [94][172/204]	Loss 0.0011 (0.0023)	
training:	Epoch: [94][173/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [94][174/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [94][175/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [94][176/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [94][177/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [94][178/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [94][179/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [94][180/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [94][181/204]	Loss 0.0011 (0.0022)	
training:	Epoch: [94][182/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [94][183/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [94][184/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [94][185/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [94][186/204]	Loss 0.0008 (0.0022)	
training:	Epoch: [94][187/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [94][188/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [94][189/204]	Loss 0.0012 (0.0022)	
training:	Epoch: [94][190/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [94][191/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [94][192/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [94][193/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [94][194/204]	Loss 0.0009 (0.0021)	
training:	Epoch: [94][195/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [94][196/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [94][197/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [94][198/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [94][199/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [94][200/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [94][201/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [94][202/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [94][203/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [94][204/204]	Loss 0.0020 (0.0020)	
Training:	 Loss: 0.0020

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7790 0.7801 0.8035 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3795
Pretraining:	Epoch 95/500
----------
training:	Epoch: [95][1/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][2/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][3/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][4/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][5/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [95][6/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [95][7/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [95][8/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [95][9/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][10/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [95][11/204]	Loss 0.0010 (0.0007)	
training:	Epoch: [95][12/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][13/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][14/204]	Loss 0.0010 (0.0007)	
training:	Epoch: [95][15/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [95][16/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][17/204]	Loss 0.0008 (0.0007)	
training:	Epoch: [95][18/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [95][19/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][20/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][21/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][22/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][23/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [95][24/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][25/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][26/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [95][27/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][28/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][29/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][30/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][31/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][32/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [95][33/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][34/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][35/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][36/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][37/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][38/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][39/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][40/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][41/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][42/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][43/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][44/204]	Loss 0.0040 (0.0007)	
training:	Epoch: [95][45/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][46/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][47/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][48/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][49/204]	Loss 0.0010 (0.0007)	
training:	Epoch: [95][50/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][51/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [95][52/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [95][53/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [95][54/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [95][55/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [95][56/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [95][57/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][58/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][59/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [95][60/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][61/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][62/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [95][63/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [95][64/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][65/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [95][66/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [95][67/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][68/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][69/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][70/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][71/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][72/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [95][73/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [95][74/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][75/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][76/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][77/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][78/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][79/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][80/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][81/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [95][82/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][83/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [95][84/204]	Loss 0.0013 (0.0006)	
training:	Epoch: [95][85/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][86/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][87/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [95][88/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [95][89/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][90/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][91/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][92/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [95][93/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [95][94/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [95][95/204]	Loss 0.2222 (0.0030)	
training:	Epoch: [95][96/204]	Loss 0.0017 (0.0030)	
training:	Epoch: [95][97/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [95][98/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [95][99/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [95][100/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [95][101/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [95][102/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [95][103/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [95][104/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [95][105/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [95][106/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [95][107/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [95][108/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [95][109/204]	Loss 0.0017 (0.0027)	
training:	Epoch: [95][110/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [95][111/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [95][112/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [95][113/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [95][114/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [95][115/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [95][116/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [95][117/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [95][118/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [95][119/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [95][120/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [95][121/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [95][122/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [95][123/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [95][124/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [95][125/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [95][126/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [95][127/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [95][128/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [95][129/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [95][130/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [95][131/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [95][132/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [95][133/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [95][134/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [95][135/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [95][136/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [95][137/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [95][138/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [95][139/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [95][140/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [95][141/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [95][142/204]	Loss 0.0012 (0.0022)	
training:	Epoch: [95][143/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [95][144/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [95][145/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [95][146/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [95][147/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [95][148/204]	Loss 0.0009 (0.0021)	
training:	Epoch: [95][149/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [95][150/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [95][151/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [95][152/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [95][153/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [95][154/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [95][155/204]	Loss 0.0017 (0.0021)	
training:	Epoch: [95][156/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [95][157/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [95][158/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [95][159/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [95][160/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [95][161/204]	Loss 0.0007 (0.0020)	
training:	Epoch: [95][162/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [95][163/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [95][164/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [95][165/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [95][166/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [95][167/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [95][168/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [95][169/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [95][170/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [95][171/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [95][172/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [95][173/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [95][174/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [95][175/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [95][176/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [95][177/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [95][178/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [95][179/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [95][180/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [95][181/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [95][182/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [95][183/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [95][184/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [95][185/204]	Loss 0.0024 (0.0018)	
training:	Epoch: [95][186/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [95][187/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [95][188/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [95][189/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [95][190/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [95][191/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [95][192/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [95][193/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [95][194/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [95][195/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [95][196/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [95][197/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [95][198/204]	Loss 0.0011 (0.0017)	
training:	Epoch: [95][199/204]	Loss 0.0033 (0.0018)	
training:	Epoch: [95][200/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [95][201/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [95][202/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [95][203/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [95][204/204]	Loss 0.0006 (0.0017)	
Training:	 Loss: 0.0017

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7809 0.7817 0.7994 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3932
Pretraining:	Epoch 96/500
----------
training:	Epoch: [96][1/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [96][2/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [96][3/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [96][4/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [96][5/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [96][6/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [96][7/204]	Loss 0.0035 (0.0009)	
training:	Epoch: [96][8/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [96][9/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [96][10/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [96][11/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [96][12/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [96][13/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][14/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][15/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][16/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][17/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [96][18/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][19/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][20/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][21/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][22/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][23/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [96][24/204]	Loss 0.0035 (0.0008)	
training:	Epoch: [96][25/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [96][26/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [96][27/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [96][28/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [96][29/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [96][30/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [96][31/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [96][32/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][33/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][34/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [96][35/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][36/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][37/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [96][38/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][39/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][40/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [96][41/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][42/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][43/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][44/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][45/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][46/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][47/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][48/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][49/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][50/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [96][51/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][52/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][53/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][54/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [96][55/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][56/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][57/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][58/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][59/204]	Loss 0.0012 (0.0007)	
training:	Epoch: [96][60/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][61/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][62/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][63/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][64/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][65/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][66/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [96][67/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][68/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][69/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][70/204]	Loss 0.0008 (0.0007)	
training:	Epoch: [96][71/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][72/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [96][73/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [96][74/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][75/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [96][76/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [96][77/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][78/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][79/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [96][80/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [96][81/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][82/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [96][83/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][84/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][85/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][86/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [96][87/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][88/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][89/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][90/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [96][91/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][92/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][93/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][94/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [96][95/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [96][96/204]	Loss 0.2201 (0.0029)	
training:	Epoch: [96][97/204]	Loss 0.0012 (0.0029)	
training:	Epoch: [96][98/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [96][99/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [96][100/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [96][101/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [96][102/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [96][103/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [96][104/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [96][105/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [96][106/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [96][107/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [96][108/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [96][109/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [96][110/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [96][111/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [96][112/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [96][113/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [96][114/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [96][115/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [96][116/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [96][117/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [96][118/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [96][119/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [96][120/204]	Loss 0.0009 (0.0025)	
training:	Epoch: [96][121/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [96][122/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [96][123/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [96][124/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [96][125/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [96][126/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [96][127/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [96][128/204]	Loss 0.0010 (0.0023)	
training:	Epoch: [96][129/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [96][130/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [96][131/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [96][132/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [96][133/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [96][134/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [96][135/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [96][136/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [96][137/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [96][138/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [96][139/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [96][140/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [96][141/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [96][142/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [96][143/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [96][144/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [96][145/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [96][146/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [96][147/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [96][148/204]	Loss 0.0469 (0.0024)	
training:	Epoch: [96][149/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [96][150/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [96][151/204]	Loss 0.0479 (0.0027)	
training:	Epoch: [96][152/204]	Loss 0.0008 (0.0027)	
training:	Epoch: [96][153/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [96][154/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [96][155/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [96][156/204]	Loss 0.0011 (0.0026)	
training:	Epoch: [96][157/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [96][158/204]	Loss 0.0010 (0.0026)	
training:	Epoch: [96][159/204]	Loss 0.0057 (0.0026)	
training:	Epoch: [96][160/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [96][161/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [96][162/204]	Loss 0.0084 (0.0026)	
training:	Epoch: [96][163/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [96][164/204]	Loss 0.0009 (0.0026)	
training:	Epoch: [96][165/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [96][166/204]	Loss 0.0013 (0.0026)	
training:	Epoch: [96][167/204]	Loss 0.0027 (0.0026)	
training:	Epoch: [96][168/204]	Loss 0.1032 (0.0032)	
training:	Epoch: [96][169/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [96][170/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [96][171/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [96][172/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [96][173/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [96][174/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [96][175/204]	Loss 0.0470 (0.0033)	
training:	Epoch: [96][176/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [96][177/204]	Loss 0.0046 (0.0033)	
training:	Epoch: [96][178/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [96][179/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [96][180/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [96][181/204]	Loss 0.0009 (0.0033)	
training:	Epoch: [96][182/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [96][183/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [96][184/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [96][185/204]	Loss 0.0031 (0.0032)	
training:	Epoch: [96][186/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [96][187/204]	Loss 0.0080 (0.0032)	
training:	Epoch: [96][188/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [96][189/204]	Loss 0.0144 (0.0033)	
training:	Epoch: [96][190/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [96][191/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [96][192/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [96][193/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [96][194/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [96][195/204]	Loss 0.0014 (0.0032)	
training:	Epoch: [96][196/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [96][197/204]	Loss 0.0022 (0.0032)	
training:	Epoch: [96][198/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [96][199/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [96][200/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [96][201/204]	Loss 0.0018 (0.0031)	
training:	Epoch: [96][202/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [96][203/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [96][204/204]	Loss 0.0005 (0.0031)	
Training:	 Loss: 0.0031

Training:	 ACC: 0.9997 0.9997 0.9997 0.9997
Validation:	 ACC: 0.7689 0.7705 0.8025 0.7354
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4294
Pretraining:	Epoch 97/500
----------
training:	Epoch: [97][1/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [97][2/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [97][3/204]	Loss 0.0019 (0.0011)	
training:	Epoch: [97][4/204]	Loss 0.0031 (0.0016)	
training:	Epoch: [97][5/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [97][6/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [97][7/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [97][8/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [97][9/204]	Loss 0.0406 (0.0055)	
training:	Epoch: [97][10/204]	Loss 0.0008 (0.0050)	
training:	Epoch: [97][11/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [97][12/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [97][13/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [97][14/204]	Loss 0.0005 (0.0037)	
training:	Epoch: [97][15/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [97][16/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [97][17/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [97][18/204]	Loss 0.0052 (0.0033)	
training:	Epoch: [97][19/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [97][20/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [97][21/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [97][22/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [97][23/204]	Loss 0.0012 (0.0027)	
training:	Epoch: [97][24/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [97][25/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [97][26/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [97][27/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [97][28/204]	Loss 0.0011 (0.0023)	
training:	Epoch: [97][29/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [97][30/204]	Loss 0.0014 (0.0023)	
training:	Epoch: [97][31/204]	Loss 0.1037 (0.0055)	
training:	Epoch: [97][32/204]	Loss 0.0017 (0.0054)	
training:	Epoch: [97][33/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [97][34/204]	Loss 0.0007 (0.0051)	
training:	Epoch: [97][35/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [97][36/204]	Loss 0.0007 (0.0049)	
training:	Epoch: [97][37/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [97][38/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [97][39/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [97][40/204]	Loss 0.0024 (0.0045)	
training:	Epoch: [97][41/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [97][42/204]	Loss 0.0008 (0.0043)	
training:	Epoch: [97][43/204]	Loss 0.0018 (0.0042)	
training:	Epoch: [97][44/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [97][45/204]	Loss 0.2719 (0.0101)	
training:	Epoch: [97][46/204]	Loss 0.0013 (0.0099)	
training:	Epoch: [97][47/204]	Loss 0.0005 (0.0097)	
training:	Epoch: [97][48/204]	Loss 0.0005 (0.0095)	
training:	Epoch: [97][49/204]	Loss 0.0008 (0.0093)	
training:	Epoch: [97][50/204]	Loss 0.0005 (0.0092)	
training:	Epoch: [97][51/204]	Loss 0.0049 (0.0091)	
training:	Epoch: [97][52/204]	Loss 0.1107 (0.0110)	
training:	Epoch: [97][53/204]	Loss 0.0009 (0.0109)	
training:	Epoch: [97][54/204]	Loss 0.1587 (0.0136)	
training:	Epoch: [97][55/204]	Loss 0.0005 (0.0134)	
training:	Epoch: [97][56/204]	Loss 0.0006 (0.0131)	
training:	Epoch: [97][57/204]	Loss 0.0017 (0.0129)	
training:	Epoch: [97][58/204]	Loss 0.0007 (0.0127)	
training:	Epoch: [97][59/204]	Loss 0.0093 (0.0127)	
training:	Epoch: [97][60/204]	Loss 0.0022 (0.0125)	
training:	Epoch: [97][61/204]	Loss 0.0008 (0.0123)	
training:	Epoch: [97][62/204]	Loss 0.0006 (0.0121)	
training:	Epoch: [97][63/204]	Loss 0.0007 (0.0119)	
training:	Epoch: [97][64/204]	Loss 0.0010 (0.0117)	
training:	Epoch: [97][65/204]	Loss 0.0005 (0.0116)	
training:	Epoch: [97][66/204]	Loss 0.0007 (0.0114)	
training:	Epoch: [97][67/204]	Loss 0.0005 (0.0112)	
training:	Epoch: [97][68/204]	Loss 0.0004 (0.0111)	
training:	Epoch: [97][69/204]	Loss 0.0009 (0.0109)	
training:	Epoch: [97][70/204]	Loss 0.0006 (0.0108)	
training:	Epoch: [97][71/204]	Loss 0.0007 (0.0107)	
training:	Epoch: [97][72/204]	Loss 0.0007 (0.0105)	
training:	Epoch: [97][73/204]	Loss 0.0007 (0.0104)	
training:	Epoch: [97][74/204]	Loss 0.0047 (0.0103)	
training:	Epoch: [97][75/204]	Loss 0.0006 (0.0102)	
training:	Epoch: [97][76/204]	Loss 0.0037 (0.0101)	
training:	Epoch: [97][77/204]	Loss 0.0005 (0.0100)	
training:	Epoch: [97][78/204]	Loss 0.0018 (0.0099)	
training:	Epoch: [97][79/204]	Loss 0.0005 (0.0097)	
training:	Epoch: [97][80/204]	Loss 0.0005 (0.0096)	
training:	Epoch: [97][81/204]	Loss 0.0124 (0.0097)	
training:	Epoch: [97][82/204]	Loss 0.0006 (0.0095)	
training:	Epoch: [97][83/204]	Loss 0.0012 (0.0094)	
training:	Epoch: [97][84/204]	Loss 0.0005 (0.0093)	
training:	Epoch: [97][85/204]	Loss 0.0007 (0.0092)	
training:	Epoch: [97][86/204]	Loss 0.0010 (0.0091)	
training:	Epoch: [97][87/204]	Loss 0.0017 (0.0091)	
training:	Epoch: [97][88/204]	Loss 0.0004 (0.0090)	
training:	Epoch: [97][89/204]	Loss 0.0005 (0.0089)	
training:	Epoch: [97][90/204]	Loss 0.0005 (0.0088)	
training:	Epoch: [97][91/204]	Loss 0.0005 (0.0087)	
training:	Epoch: [97][92/204]	Loss 0.0006 (0.0086)	
training:	Epoch: [97][93/204]	Loss 0.0005 (0.0085)	
training:	Epoch: [97][94/204]	Loss 0.0006 (0.0084)	
training:	Epoch: [97][95/204]	Loss 0.0020 (0.0084)	
training:	Epoch: [97][96/204]	Loss 0.0007 (0.0083)	
training:	Epoch: [97][97/204]	Loss 0.0006 (0.0082)	
training:	Epoch: [97][98/204]	Loss 0.0006 (0.0081)	
training:	Epoch: [97][99/204]	Loss 0.0007 (0.0080)	
training:	Epoch: [97][100/204]	Loss 0.0006 (0.0080)	
training:	Epoch: [97][101/204]	Loss 0.0006 (0.0079)	
training:	Epoch: [97][102/204]	Loss 0.0007 (0.0078)	
training:	Epoch: [97][103/204]	Loss 0.0009 (0.0078)	
training:	Epoch: [97][104/204]	Loss 0.0042 (0.0077)	
training:	Epoch: [97][105/204]	Loss 0.0005 (0.0077)	
training:	Epoch: [97][106/204]	Loss 0.0010 (0.0076)	
training:	Epoch: [97][107/204]	Loss 0.0006 (0.0075)	
training:	Epoch: [97][108/204]	Loss 0.0018 (0.0075)	
training:	Epoch: [97][109/204]	Loss 0.0007 (0.0074)	
training:	Epoch: [97][110/204]	Loss 0.0007 (0.0074)	
training:	Epoch: [97][111/204]	Loss 0.0015 (0.0073)	
training:	Epoch: [97][112/204]	Loss 0.0006 (0.0072)	
training:	Epoch: [97][113/204]	Loss 0.0007 (0.0072)	
training:	Epoch: [97][114/204]	Loss 0.0006 (0.0071)	
training:	Epoch: [97][115/204]	Loss 0.0005 (0.0071)	
training:	Epoch: [97][116/204]	Loss 0.0012 (0.0070)	
training:	Epoch: [97][117/204]	Loss 0.0005 (0.0070)	
training:	Epoch: [97][118/204]	Loss 0.0008 (0.0069)	
training:	Epoch: [97][119/204]	Loss 0.0008 (0.0069)	
training:	Epoch: [97][120/204]	Loss 0.0006 (0.0068)	
training:	Epoch: [97][121/204]	Loss 0.0005 (0.0067)	
training:	Epoch: [97][122/204]	Loss 0.0006 (0.0067)	
training:	Epoch: [97][123/204]	Loss 0.0014 (0.0067)	
training:	Epoch: [97][124/204]	Loss 0.0007 (0.0066)	
training:	Epoch: [97][125/204]	Loss 0.0004 (0.0066)	
training:	Epoch: [97][126/204]	Loss 0.0013 (0.0065)	
training:	Epoch: [97][127/204]	Loss 0.0005 (0.0065)	
training:	Epoch: [97][128/204]	Loss 0.0005 (0.0064)	
training:	Epoch: [97][129/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [97][130/204]	Loss 0.0011 (0.0063)	
training:	Epoch: [97][131/204]	Loss 0.0043 (0.0063)	
training:	Epoch: [97][132/204]	Loss 0.0020 (0.0063)	
training:	Epoch: [97][133/204]	Loss 0.0005 (0.0062)	
training:	Epoch: [97][134/204]	Loss 0.0013 (0.0062)	
training:	Epoch: [97][135/204]	Loss 0.0056 (0.0062)	
training:	Epoch: [97][136/204]	Loss 0.0005 (0.0062)	
training:	Epoch: [97][137/204]	Loss 0.0008 (0.0061)	
training:	Epoch: [97][138/204]	Loss 0.0008 (0.0061)	
training:	Epoch: [97][139/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [97][140/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [97][141/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [97][142/204]	Loss 0.0005 (0.0059)	
training:	Epoch: [97][143/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [97][144/204]	Loss 0.0005 (0.0059)	
training:	Epoch: [97][145/204]	Loss 0.0012 (0.0058)	
training:	Epoch: [97][146/204]	Loss 0.0005 (0.0058)	
training:	Epoch: [97][147/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [97][148/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [97][149/204]	Loss 0.0009 (0.0057)	
training:	Epoch: [97][150/204]	Loss 0.0007 (0.0056)	
training:	Epoch: [97][151/204]	Loss 0.0005 (0.0056)	
training:	Epoch: [97][152/204]	Loss 0.0005 (0.0056)	
training:	Epoch: [97][153/204]	Loss 0.0014 (0.0056)	
training:	Epoch: [97][154/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [97][155/204]	Loss 0.0008 (0.0055)	
training:	Epoch: [97][156/204]	Loss 0.0010 (0.0055)	
training:	Epoch: [97][157/204]	Loss 0.0005 (0.0054)	
training:	Epoch: [97][158/204]	Loss 0.0006 (0.0054)	
training:	Epoch: [97][159/204]	Loss 0.0013 (0.0054)	
training:	Epoch: [97][160/204]	Loss 0.0006 (0.0053)	
training:	Epoch: [97][161/204]	Loss 0.0006 (0.0053)	
training:	Epoch: [97][162/204]	Loss 0.0006 (0.0053)	
training:	Epoch: [97][163/204]	Loss 0.0025 (0.0053)	
training:	Epoch: [97][164/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [97][165/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [97][166/204]	Loss 0.0019 (0.0052)	
training:	Epoch: [97][167/204]	Loss 0.0008 (0.0052)	
training:	Epoch: [97][168/204]	Loss 0.0081 (0.0052)	
training:	Epoch: [97][169/204]	Loss 0.0006 (0.0052)	
training:	Epoch: [97][170/204]	Loss 0.0026 (0.0051)	
training:	Epoch: [97][171/204]	Loss 0.0007 (0.0051)	
training:	Epoch: [97][172/204]	Loss 0.0009 (0.0051)	
training:	Epoch: [97][173/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [97][174/204]	Loss 0.0008 (0.0050)	
training:	Epoch: [97][175/204]	Loss 0.0034 (0.0050)	
training:	Epoch: [97][176/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [97][177/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [97][178/204]	Loss 0.0006 (0.0050)	
training:	Epoch: [97][179/204]	Loss 0.0211 (0.0050)	
training:	Epoch: [97][180/204]	Loss 0.2281 (0.0063)	
training:	Epoch: [97][181/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [97][182/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [97][183/204]	Loss 0.0218 (0.0063)	
training:	Epoch: [97][184/204]	Loss 0.0004 (0.0063)	
training:	Epoch: [97][185/204]	Loss 0.0005 (0.0062)	
training:	Epoch: [97][186/204]	Loss 0.0007 (0.0062)	
training:	Epoch: [97][187/204]	Loss 0.0005 (0.0062)	
training:	Epoch: [97][188/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [97][189/204]	Loss 0.0005 (0.0061)	
training:	Epoch: [97][190/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [97][191/204]	Loss 0.1180 (0.0067)	
training:	Epoch: [97][192/204]	Loss 0.0005 (0.0066)	
training:	Epoch: [97][193/204]	Loss 0.0006 (0.0066)	
training:	Epoch: [97][194/204]	Loss 0.0005 (0.0066)	
training:	Epoch: [97][195/204]	Loss 0.0007 (0.0065)	
training:	Epoch: [97][196/204]	Loss 0.0008 (0.0065)	
training:	Epoch: [97][197/204]	Loss 0.0005 (0.0065)	
training:	Epoch: [97][198/204]	Loss 0.0008 (0.0065)	
training:	Epoch: [97][199/204]	Loss 0.0012 (0.0064)	
training:	Epoch: [97][200/204]	Loss 0.0009 (0.0064)	
training:	Epoch: [97][201/204]	Loss 0.0005 (0.0064)	
training:	Epoch: [97][202/204]	Loss 0.0011 (0.0064)	
training:	Epoch: [97][203/204]	Loss 0.0005 (0.0063)	
training:	Epoch: [97][204/204]	Loss 0.0012 (0.0063)	
Training:	 Loss: 0.0063

Training:	 ACC: 0.9994 0.9994 0.9997 0.9990
Validation:	 ACC: 0.7721 0.7747 0.8301 0.7141
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4114
Pretraining:	Epoch 98/500
----------
training:	Epoch: [98][1/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [98][2/204]	Loss 0.0008 (0.0007)	
training:	Epoch: [98][3/204]	Loss 0.0369 (0.0128)	
training:	Epoch: [98][4/204]	Loss 0.0011 (0.0099)	
training:	Epoch: [98][5/204]	Loss 0.0006 (0.0080)	
training:	Epoch: [98][6/204]	Loss 0.0006 (0.0068)	
training:	Epoch: [98][7/204]	Loss 0.0012 (0.0060)	
training:	Epoch: [98][8/204]	Loss 0.0006 (0.0053)	
training:	Epoch: [98][9/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [98][10/204]	Loss 0.0017 (0.0045)	
training:	Epoch: [98][11/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [98][12/204]	Loss 0.0006 (0.0038)	
training:	Epoch: [98][13/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [98][14/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [98][15/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [98][16/204]	Loss 0.0016 (0.0031)	
training:	Epoch: [98][17/204]	Loss 0.0304 (0.0047)	
training:	Epoch: [98][18/204]	Loss 0.0006 (0.0045)	
training:	Epoch: [98][19/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [98][20/204]	Loss 0.0007 (0.0041)	
training:	Epoch: [98][21/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [98][22/204]	Loss 0.0011 (0.0038)	
training:	Epoch: [98][23/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [98][24/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [98][25/204]	Loss 0.0010 (0.0034)	
training:	Epoch: [98][26/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [98][27/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [98][28/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [98][29/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [98][30/204]	Loss 0.0024 (0.0030)	
training:	Epoch: [98][31/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [98][32/204]	Loss 0.0025 (0.0029)	
training:	Epoch: [98][33/204]	Loss 0.0019 (0.0029)	
training:	Epoch: [98][34/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [98][35/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [98][36/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [98][37/204]	Loss 0.0010 (0.0027)	
training:	Epoch: [98][38/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [98][39/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [98][40/204]	Loss 0.0044 (0.0026)	
training:	Epoch: [98][41/204]	Loss 0.0103 (0.0028)	
training:	Epoch: [98][42/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [98][43/204]	Loss 0.0007 (0.0027)	
training:	Epoch: [98][44/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [98][45/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [98][46/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [98][47/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [98][48/204]	Loss 0.0032 (0.0025)	
training:	Epoch: [98][49/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [98][50/204]	Loss 0.0013 (0.0025)	
training:	Epoch: [98][51/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [98][52/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [98][53/204]	Loss 0.0037 (0.0024)	
training:	Epoch: [98][54/204]	Loss 0.0718 (0.0037)	
training:	Epoch: [98][55/204]	Loss 0.0009 (0.0037)	
training:	Epoch: [98][56/204]	Loss 0.0008 (0.0036)	
training:	Epoch: [98][57/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [98][58/204]	Loss 0.0025 (0.0035)	
training:	Epoch: [98][59/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [98][60/204]	Loss 0.0016 (0.0034)	
training:	Epoch: [98][61/204]	Loss 0.0014 (0.0034)	
training:	Epoch: [98][62/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [98][63/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [98][64/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [98][65/204]	Loss 0.0010 (0.0032)	
training:	Epoch: [98][66/204]	Loss 0.0688 (0.0042)	
training:	Epoch: [98][67/204]	Loss 0.0006 (0.0042)	
training:	Epoch: [98][68/204]	Loss 0.0037 (0.0042)	
training:	Epoch: [98][69/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [98][70/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [98][71/204]	Loss 0.0012 (0.0040)	
training:	Epoch: [98][72/204]	Loss 0.0007 (0.0040)	
training:	Epoch: [98][73/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [98][74/204]	Loss 0.0010 (0.0039)	
training:	Epoch: [98][75/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [98][76/204]	Loss 0.0026 (0.0038)	
training:	Epoch: [98][77/204]	Loss 0.0151 (0.0040)	
training:	Epoch: [98][78/204]	Loss 0.0021 (0.0040)	
training:	Epoch: [98][79/204]	Loss 0.0015 (0.0039)	
training:	Epoch: [98][80/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [98][81/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [98][82/204]	Loss 0.1087 (0.0051)	
training:	Epoch: [98][83/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [98][84/204]	Loss 0.0010 (0.0050)	
training:	Epoch: [98][85/204]	Loss 0.0006 (0.0050)	
training:	Epoch: [98][86/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [98][87/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [98][88/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [98][89/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [98][90/204]	Loss 0.0005 (0.0047)	
training:	Epoch: [98][91/204]	Loss 0.0012 (0.0047)	
training:	Epoch: [98][92/204]	Loss 0.0018 (0.0046)	
training:	Epoch: [98][93/204]	Loss 0.0008 (0.0046)	
training:	Epoch: [98][94/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [98][95/204]	Loss 0.0010 (0.0045)	
training:	Epoch: [98][96/204]	Loss 0.0010 (0.0045)	
training:	Epoch: [98][97/204]	Loss 0.0009 (0.0044)	
training:	Epoch: [98][98/204]	Loss 0.0052 (0.0045)	
training:	Epoch: [98][99/204]	Loss 0.0489 (0.0049)	
training:	Epoch: [98][100/204]	Loss 0.0006 (0.0049)	
training:	Epoch: [98][101/204]	Loss 0.0005 (0.0048)	
training:	Epoch: [98][102/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [98][103/204]	Loss 0.0016 (0.0047)	
training:	Epoch: [98][104/204]	Loss 0.0013 (0.0047)	
training:	Epoch: [98][105/204]	Loss 0.0005 (0.0047)	
training:	Epoch: [98][106/204]	Loss 0.0015 (0.0046)	
training:	Epoch: [98][107/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [98][108/204]	Loss 0.0031 (0.0046)	
training:	Epoch: [98][109/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [98][110/204]	Loss 0.0165 (0.0047)	
training:	Epoch: [98][111/204]	Loss 0.0012 (0.0046)	
training:	Epoch: [98][112/204]	Loss 0.0008 (0.0046)	
training:	Epoch: [98][113/204]	Loss 0.0029 (0.0046)	
training:	Epoch: [98][114/204]	Loss 0.0010 (0.0046)	
training:	Epoch: [98][115/204]	Loss 0.0006 (0.0045)	
training:	Epoch: [98][116/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [98][117/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [98][118/204]	Loss 0.0005 (0.0044)	
training:	Epoch: [98][119/204]	Loss 0.0013 (0.0044)	
training:	Epoch: [98][120/204]	Loss 0.0029 (0.0044)	
training:	Epoch: [98][121/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [98][122/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [98][123/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [98][124/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [98][125/204]	Loss 0.0005 (0.0042)	
training:	Epoch: [98][126/204]	Loss 0.0005 (0.0042)	
training:	Epoch: [98][127/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [98][128/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [98][129/204]	Loss 0.2243 (0.0058)	
training:	Epoch: [98][130/204]	Loss 0.0063 (0.0058)	
training:	Epoch: [98][131/204]	Loss 0.0006 (0.0058)	
training:	Epoch: [98][132/204]	Loss 0.0008 (0.0058)	
training:	Epoch: [98][133/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [98][134/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [98][135/204]	Loss 0.0006 (0.0057)	
training:	Epoch: [98][136/204]	Loss 0.0954 (0.0063)	
training:	Epoch: [98][137/204]	Loss 0.0009 (0.0063)	
training:	Epoch: [98][138/204]	Loss 0.0005 (0.0062)	
training:	Epoch: [98][139/204]	Loss 0.0017 (0.0062)	
training:	Epoch: [98][140/204]	Loss 0.0008 (0.0062)	
training:	Epoch: [98][141/204]	Loss 0.0009 (0.0061)	
training:	Epoch: [98][142/204]	Loss 0.0010 (0.0061)	
training:	Epoch: [98][143/204]	Loss 0.0177 (0.0062)	
training:	Epoch: [98][144/204]	Loss 0.0005 (0.0061)	
training:	Epoch: [98][145/204]	Loss 0.0086 (0.0061)	
training:	Epoch: [98][146/204]	Loss 0.0682 (0.0066)	
training:	Epoch: [98][147/204]	Loss 0.0004 (0.0065)	
training:	Epoch: [98][148/204]	Loss 0.0005 (0.0065)	
training:	Epoch: [98][149/204]	Loss 0.0008 (0.0065)	
training:	Epoch: [98][150/204]	Loss 0.0008 (0.0064)	
training:	Epoch: [98][151/204]	Loss 0.0007 (0.0064)	
training:	Epoch: [98][152/204]	Loss 0.0006 (0.0063)	
training:	Epoch: [98][153/204]	Loss 0.0049 (0.0063)	
training:	Epoch: [98][154/204]	Loss 0.0012 (0.0063)	
training:	Epoch: [98][155/204]	Loss 0.0009 (0.0063)	
training:	Epoch: [98][156/204]	Loss 0.0006 (0.0062)	
training:	Epoch: [98][157/204]	Loss 0.0014 (0.0062)	
training:	Epoch: [98][158/204]	Loss 0.0005 (0.0062)	
training:	Epoch: [98][159/204]	Loss 0.0007 (0.0061)	
training:	Epoch: [98][160/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [98][161/204]	Loss 0.0005 (0.0061)	
training:	Epoch: [98][162/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [98][163/204]	Loss 0.0007 (0.0060)	
training:	Epoch: [98][164/204]	Loss 0.0030 (0.0060)	
training:	Epoch: [98][165/204]	Loss 0.0009 (0.0059)	
training:	Epoch: [98][166/204]	Loss 0.0016 (0.0059)	
training:	Epoch: [98][167/204]	Loss 0.0006 (0.0059)	
training:	Epoch: [98][168/204]	Loss 0.0008 (0.0059)	
training:	Epoch: [98][169/204]	Loss 0.0010 (0.0058)	
training:	Epoch: [98][170/204]	Loss 0.0005 (0.0058)	
training:	Epoch: [98][171/204]	Loss 0.0005 (0.0058)	
training:	Epoch: [98][172/204]	Loss 0.0007 (0.0057)	
training:	Epoch: [98][173/204]	Loss 0.0011 (0.0057)	
training:	Epoch: [98][174/204]	Loss 0.1063 (0.0063)	
training:	Epoch: [98][175/204]	Loss 0.0007 (0.0062)	
training:	Epoch: [98][176/204]	Loss 0.0014 (0.0062)	
training:	Epoch: [98][177/204]	Loss 0.0012 (0.0062)	
training:	Epoch: [98][178/204]	Loss 0.0009 (0.0062)	
training:	Epoch: [98][179/204]	Loss 0.0025 (0.0061)	
training:	Epoch: [98][180/204]	Loss 0.0031 (0.0061)	
training:	Epoch: [98][181/204]	Loss 0.0027 (0.0061)	
training:	Epoch: [98][182/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [98][183/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [98][184/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [98][185/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [98][186/204]	Loss 0.0042 (0.0060)	
training:	Epoch: [98][187/204]	Loss 0.0005 (0.0059)	
training:	Epoch: [98][188/204]	Loss 0.0006 (0.0059)	
training:	Epoch: [98][189/204]	Loss 0.0010 (0.0059)	
training:	Epoch: [98][190/204]	Loss 0.0009 (0.0059)	
training:	Epoch: [98][191/204]	Loss 0.0030 (0.0059)	
training:	Epoch: [98][192/204]	Loss 0.0008 (0.0058)	
training:	Epoch: [98][193/204]	Loss 0.0010 (0.0058)	
training:	Epoch: [98][194/204]	Loss 0.0005 (0.0058)	
training:	Epoch: [98][195/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [98][196/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [98][197/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [98][198/204]	Loss 0.0045 (0.0057)	
training:	Epoch: [98][199/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [98][200/204]	Loss 0.0009 (0.0056)	
training:	Epoch: [98][201/204]	Loss 0.0006 (0.0056)	
training:	Epoch: [98][202/204]	Loss 0.0052 (0.0056)	
training:	Epoch: [98][203/204]	Loss 0.0007 (0.0056)	
training:	Epoch: [98][204/204]	Loss 0.0007 (0.0056)	
Training:	 Loss: 0.0056

Training:	 ACC: 0.9997 0.9997 0.9997 0.9997
Validation:	 ACC: 0.7809 0.7828 0.8219 0.7399
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3657
Pretraining:	Epoch 99/500
----------
training:	Epoch: [99][1/204]	Loss 0.0011 (0.0011)	
training:	Epoch: [99][2/204]	Loss 0.2264 (0.1137)	
training:	Epoch: [99][3/204]	Loss 0.0035 (0.0770)	
training:	Epoch: [99][4/204]	Loss 0.0005 (0.0578)	
training:	Epoch: [99][5/204]	Loss 0.0005 (0.0464)	
training:	Epoch: [99][6/204]	Loss 0.0005 (0.0387)	
training:	Epoch: [99][7/204]	Loss 0.0005 (0.0333)	
training:	Epoch: [99][8/204]	Loss 0.0008 (0.0292)	
training:	Epoch: [99][9/204]	Loss 0.0006 (0.0260)	
training:	Epoch: [99][10/204]	Loss 0.0006 (0.0235)	
training:	Epoch: [99][11/204]	Loss 0.0006 (0.0214)	
training:	Epoch: [99][12/204]	Loss 0.0005 (0.0197)	
training:	Epoch: [99][13/204]	Loss 0.0008 (0.0182)	
training:	Epoch: [99][14/204]	Loss 0.0006 (0.0170)	
training:	Epoch: [99][15/204]	Loss 0.0017 (0.0159)	
training:	Epoch: [99][16/204]	Loss 0.1608 (0.0250)	
training:	Epoch: [99][17/204]	Loss 0.0007 (0.0236)	
training:	Epoch: [99][18/204]	Loss 0.0005 (0.0223)	
training:	Epoch: [99][19/204]	Loss 0.0005 (0.0211)	
training:	Epoch: [99][20/204]	Loss 0.0005 (0.0201)	
training:	Epoch: [99][21/204]	Loss 0.0144 (0.0198)	
training:	Epoch: [99][22/204]	Loss 0.0014 (0.0190)	
training:	Epoch: [99][23/204]	Loss 0.0010 (0.0182)	
training:	Epoch: [99][24/204]	Loss 0.0013 (0.0175)	
training:	Epoch: [99][25/204]	Loss 0.0005 (0.0168)	
training:	Epoch: [99][26/204]	Loss 0.0005 (0.0162)	
training:	Epoch: [99][27/204]	Loss 0.0006 (0.0156)	
training:	Epoch: [99][28/204]	Loss 0.0015 (0.0151)	
training:	Epoch: [99][29/204]	Loss 0.0011 (0.0146)	
training:	Epoch: [99][30/204]	Loss 0.0008 (0.0142)	
training:	Epoch: [99][31/204]	Loss 0.0005 (0.0137)	
training:	Epoch: [99][32/204]	Loss 0.0009 (0.0133)	
training:	Epoch: [99][33/204]	Loss 0.0005 (0.0129)	
training:	Epoch: [99][34/204]	Loss 0.0009 (0.0126)	
training:	Epoch: [99][35/204]	Loss 0.0006 (0.0122)	
training:	Epoch: [99][36/204]	Loss 0.0712 (0.0139)	
training:	Epoch: [99][37/204]	Loss 0.0005 (0.0135)	
training:	Epoch: [99][38/204]	Loss 0.0005 (0.0132)	
training:	Epoch: [99][39/204]	Loss 0.0005 (0.0129)	
training:	Epoch: [99][40/204]	Loss 0.0006 (0.0125)	
training:	Epoch: [99][41/204]	Loss 0.0005 (0.0123)	
training:	Epoch: [99][42/204]	Loss 0.0015 (0.0120)	
training:	Epoch: [99][43/204]	Loss 0.0005 (0.0117)	
training:	Epoch: [99][44/204]	Loss 0.0005 (0.0115)	
training:	Epoch: [99][45/204]	Loss 0.0024 (0.0113)	
training:	Epoch: [99][46/204]	Loss 0.0023 (0.0111)	
training:	Epoch: [99][47/204]	Loss 0.0005 (0.0109)	
training:	Epoch: [99][48/204]	Loss 0.0007 (0.0106)	
training:	Epoch: [99][49/204]	Loss 0.0007 (0.0104)	
training:	Epoch: [99][50/204]	Loss 0.0005 (0.0102)	
training:	Epoch: [99][51/204]	Loss 0.0041 (0.0101)	
training:	Epoch: [99][52/204]	Loss 0.0005 (0.0099)	
training:	Epoch: [99][53/204]	Loss 0.0005 (0.0098)	
training:	Epoch: [99][54/204]	Loss 0.0004 (0.0096)	
training:	Epoch: [99][55/204]	Loss 0.0178 (0.0097)	
training:	Epoch: [99][56/204]	Loss 0.0008 (0.0096)	
training:	Epoch: [99][57/204]	Loss 0.0004 (0.0094)	
training:	Epoch: [99][58/204]	Loss 0.0005 (0.0093)	
training:	Epoch: [99][59/204]	Loss 0.0005 (0.0091)	
training:	Epoch: [99][60/204]	Loss 0.0006 (0.0090)	
training:	Epoch: [99][61/204]	Loss 0.0005 (0.0088)	
training:	Epoch: [99][62/204]	Loss 0.0014 (0.0087)	
training:	Epoch: [99][63/204]	Loss 0.0005 (0.0086)	
training:	Epoch: [99][64/204]	Loss 0.0013 (0.0085)	
training:	Epoch: [99][65/204]	Loss 0.0005 (0.0083)	
training:	Epoch: [99][66/204]	Loss 0.0005 (0.0082)	
training:	Epoch: [99][67/204]	Loss 0.0021 (0.0081)	
training:	Epoch: [99][68/204]	Loss 0.0008 (0.0080)	
training:	Epoch: [99][69/204]	Loss 0.0024 (0.0079)	
training:	Epoch: [99][70/204]	Loss 0.0007 (0.0078)	
training:	Epoch: [99][71/204]	Loss 0.0008 (0.0077)	
training:	Epoch: [99][72/204]	Loss 0.0007 (0.0076)	
training:	Epoch: [99][73/204]	Loss 0.0005 (0.0075)	
training:	Epoch: [99][74/204]	Loss 0.0015 (0.0075)	
training:	Epoch: [99][75/204]	Loss 0.0026 (0.0074)	
training:	Epoch: [99][76/204]	Loss 0.0007 (0.0073)	
training:	Epoch: [99][77/204]	Loss 0.0005 (0.0072)	
training:	Epoch: [99][78/204]	Loss 0.0005 (0.0071)	
training:	Epoch: [99][79/204]	Loss 0.0007 (0.0071)	
training:	Epoch: [99][80/204]	Loss 0.0006 (0.0070)	
training:	Epoch: [99][81/204]	Loss 0.0005 (0.0069)	
training:	Epoch: [99][82/204]	Loss 0.0006 (0.0068)	
training:	Epoch: [99][83/204]	Loss 0.0019 (0.0068)	
training:	Epoch: [99][84/204]	Loss 0.0013 (0.0067)	
training:	Epoch: [99][85/204]	Loss 0.0007 (0.0066)	
training:	Epoch: [99][86/204]	Loss 0.0005 (0.0066)	
training:	Epoch: [99][87/204]	Loss 0.0005 (0.0065)	
training:	Epoch: [99][88/204]	Loss 0.0005 (0.0064)	
training:	Epoch: [99][89/204]	Loss 0.0006 (0.0063)	
training:	Epoch: [99][90/204]	Loss 0.0005 (0.0063)	
training:	Epoch: [99][91/204]	Loss 0.0006 (0.0062)	
training:	Epoch: [99][92/204]	Loss 0.0007 (0.0062)	
training:	Epoch: [99][93/204]	Loss 0.0005 (0.0061)	
training:	Epoch: [99][94/204]	Loss 0.0007 (0.0060)	
training:	Epoch: [99][95/204]	Loss 0.0008 (0.0060)	
training:	Epoch: [99][96/204]	Loss 0.0005 (0.0059)	
training:	Epoch: [99][97/204]	Loss 0.0030 (0.0059)	
training:	Epoch: [99][98/204]	Loss 0.0005 (0.0058)	
training:	Epoch: [99][99/204]	Loss 0.0008 (0.0058)	
training:	Epoch: [99][100/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [99][101/204]	Loss 0.0011 (0.0057)	
training:	Epoch: [99][102/204]	Loss 0.0016 (0.0057)	
training:	Epoch: [99][103/204]	Loss 0.0007 (0.0056)	
training:	Epoch: [99][104/204]	Loss 0.0006 (0.0056)	
training:	Epoch: [99][105/204]	Loss 0.0059 (0.0056)	
training:	Epoch: [99][106/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [99][107/204]	Loss 0.0006 (0.0055)	
training:	Epoch: [99][108/204]	Loss 0.0005 (0.0054)	
training:	Epoch: [99][109/204]	Loss 0.0005 (0.0054)	
training:	Epoch: [99][110/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [99][111/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [99][112/204]	Loss 0.0058 (0.0053)	
training:	Epoch: [99][113/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [99][114/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [99][115/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [99][116/204]	Loss 0.0006 (0.0051)	
training:	Epoch: [99][117/204]	Loss 0.0036 (0.0051)	
training:	Epoch: [99][118/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [99][119/204]	Loss 0.0312 (0.0053)	
training:	Epoch: [99][120/204]	Loss 0.0078 (0.0053)	
training:	Epoch: [99][121/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [99][122/204]	Loss 0.0007 (0.0052)	
training:	Epoch: [99][123/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [99][124/204]	Loss 0.0006 (0.0052)	
training:	Epoch: [99][125/204]	Loss 0.0009 (0.0051)	
training:	Epoch: [99][126/204]	Loss 0.0006 (0.0051)	
training:	Epoch: [99][127/204]	Loss 0.0006 (0.0051)	
training:	Epoch: [99][128/204]	Loss 0.0009 (0.0050)	
training:	Epoch: [99][129/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [99][130/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [99][131/204]	Loss 0.0481 (0.0053)	
training:	Epoch: [99][132/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [99][133/204]	Loss 0.0007 (0.0052)	
training:	Epoch: [99][134/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [99][135/204]	Loss 0.0015 (0.0052)	
training:	Epoch: [99][136/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [99][137/204]	Loss 0.0007 (0.0051)	
training:	Epoch: [99][138/204]	Loss 0.0605 (0.0055)	
training:	Epoch: [99][139/204]	Loss 0.0014 (0.0055)	
training:	Epoch: [99][140/204]	Loss 0.0032 (0.0054)	
training:	Epoch: [99][141/204]	Loss 0.0012 (0.0054)	
training:	Epoch: [99][142/204]	Loss 0.0008 (0.0054)	
training:	Epoch: [99][143/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [99][144/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [99][145/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [99][146/204]	Loss 0.0006 (0.0052)	
training:	Epoch: [99][147/204]	Loss 0.0041 (0.0052)	
training:	Epoch: [99][148/204]	Loss 0.0006 (0.0052)	
training:	Epoch: [99][149/204]	Loss 0.0551 (0.0055)	
training:	Epoch: [99][150/204]	Loss 0.0011 (0.0055)	
training:	Epoch: [99][151/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [99][152/204]	Loss 0.0017 (0.0055)	
training:	Epoch: [99][153/204]	Loss 0.0007 (0.0054)	
training:	Epoch: [99][154/204]	Loss 0.0005 (0.0054)	
training:	Epoch: [99][155/204]	Loss 0.0008 (0.0054)	
training:	Epoch: [99][156/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [99][157/204]	Loss 0.0018 (0.0053)	
training:	Epoch: [99][158/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [99][159/204]	Loss 0.0009 (0.0053)	
training:	Epoch: [99][160/204]	Loss 0.0134 (0.0053)	
training:	Epoch: [99][161/204]	Loss 0.0374 (0.0055)	
training:	Epoch: [99][162/204]	Loss 0.0006 (0.0055)	
training:	Epoch: [99][163/204]	Loss 0.0005 (0.0054)	
training:	Epoch: [99][164/204]	Loss 0.0005 (0.0054)	
training:	Epoch: [99][165/204]	Loss 0.0010 (0.0054)	
training:	Epoch: [99][166/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [99][167/204]	Loss 0.0038 (0.0053)	
training:	Epoch: [99][168/204]	Loss 0.0017 (0.0053)	
training:	Epoch: [99][169/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [99][170/204]	Loss 0.0006 (0.0053)	
training:	Epoch: [99][171/204]	Loss 0.0009 (0.0052)	
training:	Epoch: [99][172/204]	Loss 0.0013 (0.0052)	
training:	Epoch: [99][173/204]	Loss 0.0009 (0.0052)	
training:	Epoch: [99][174/204]	Loss 0.0006 (0.0052)	
training:	Epoch: [99][175/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [99][176/204]	Loss 0.0093 (0.0052)	
training:	Epoch: [99][177/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [99][178/204]	Loss 0.0007 (0.0051)	
training:	Epoch: [99][179/204]	Loss 0.0007 (0.0051)	
training:	Epoch: [99][180/204]	Loss 0.0008 (0.0051)	
training:	Epoch: [99][181/204]	Loss 0.0009 (0.0050)	
training:	Epoch: [99][182/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [99][183/204]	Loss 0.0007 (0.0050)	
training:	Epoch: [99][184/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [99][185/204]	Loss 0.0006 (0.0049)	
training:	Epoch: [99][186/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [99][187/204]	Loss 0.0006 (0.0049)	
training:	Epoch: [99][188/204]	Loss 0.0022 (0.0049)	
training:	Epoch: [99][189/204]	Loss 0.0008 (0.0049)	
training:	Epoch: [99][190/204]	Loss 0.0010 (0.0048)	
training:	Epoch: [99][191/204]	Loss 0.0005 (0.0048)	
training:	Epoch: [99][192/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [99][193/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [99][194/204]	Loss 0.0009 (0.0048)	
training:	Epoch: [99][195/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [99][196/204]	Loss 0.0008 (0.0047)	
training:	Epoch: [99][197/204]	Loss 0.0008 (0.0047)	
training:	Epoch: [99][198/204]	Loss 0.0010 (0.0047)	
training:	Epoch: [99][199/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [99][200/204]	Loss 0.0010 (0.0046)	
training:	Epoch: [99][201/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [99][202/204]	Loss 0.0013 (0.0046)	
training:	Epoch: [99][203/204]	Loss 0.0072 (0.0046)	
training:	Epoch: [99][204/204]	Loss 0.0008 (0.0046)	
Training:	 Loss: 0.0046

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7757 0.7758 0.7779 0.7735
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3788
Pretraining:	Epoch 100/500
----------
training:	Epoch: [100][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [100][2/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [100][3/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [100][4/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [100][5/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [100][6/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [100][7/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][8/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][9/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][10/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][11/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][12/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][13/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [100][14/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [100][15/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [100][16/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [100][17/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [100][18/204]	Loss 0.0014 (0.0006)	
training:	Epoch: [100][19/204]	Loss 0.0015 (0.0006)	
training:	Epoch: [100][20/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [100][21/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][22/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][23/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][24/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][25/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][26/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][27/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][28/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [100][29/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [100][30/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][31/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][32/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [100][33/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][34/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][35/204]	Loss 0.0013 (0.0006)	
training:	Epoch: [100][36/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][37/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][38/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][39/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][40/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][41/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][42/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][43/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][44/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][45/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [100][46/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [100][47/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][48/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][49/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][50/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][51/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][52/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][53/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][54/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [100][55/204]	Loss 0.0012 (0.0006)	
training:	Epoch: [100][56/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][57/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][58/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][59/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][60/204]	Loss 0.0014 (0.0006)	
training:	Epoch: [100][61/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][62/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][63/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][64/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][65/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [100][66/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [100][67/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][68/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][69/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][70/204]	Loss 0.0012 (0.0006)	
training:	Epoch: [100][71/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][72/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][73/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][74/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [100][75/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [100][76/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][77/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][78/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][79/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [100][80/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [100][81/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][82/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][83/204]	Loss 0.0013 (0.0006)	
training:	Epoch: [100][84/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [100][85/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][86/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][87/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][88/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][89/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][90/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][91/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [100][92/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [100][93/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [100][94/204]	Loss 0.0019 (0.0006)	
training:	Epoch: [100][95/204]	Loss 0.2273 (0.0030)	
training:	Epoch: [100][96/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [100][97/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [100][98/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [100][99/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [100][100/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [100][101/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [100][102/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [100][103/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [100][104/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [100][105/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [100][106/204]	Loss 0.0040 (0.0028)	
training:	Epoch: [100][107/204]	Loss 0.0015 (0.0028)	
training:	Epoch: [100][108/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [100][109/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [100][110/204]	Loss 0.0062 (0.0028)	
training:	Epoch: [100][111/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [100][112/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [100][113/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [100][114/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [100][115/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [100][116/204]	Loss 0.0013 (0.0027)	
training:	Epoch: [100][117/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [100][118/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [100][119/204]	Loss 0.0028 (0.0026)	
training:	Epoch: [100][120/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [100][121/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [100][122/204]	Loss 0.0010 (0.0026)	
training:	Epoch: [100][123/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [100][124/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [100][125/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [100][126/204]	Loss 0.0009 (0.0025)	
training:	Epoch: [100][127/204]	Loss 0.0009 (0.0025)	
training:	Epoch: [100][128/204]	Loss 0.0031 (0.0025)	
training:	Epoch: [100][129/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [100][130/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [100][131/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [100][132/204]	Loss 0.0018 (0.0025)	
training:	Epoch: [100][133/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [100][134/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [100][135/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [100][136/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [100][137/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [100][138/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [100][139/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [100][140/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [100][141/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [100][142/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [100][143/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [100][144/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [100][145/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [100][146/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [100][147/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [100][148/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [100][149/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [100][150/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [100][151/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [100][152/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [100][153/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [100][154/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [100][155/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [100][156/204]	Loss 0.0014 (0.0022)	
training:	Epoch: [100][157/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [100][158/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [100][159/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [100][160/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [100][161/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [100][162/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [100][163/204]	Loss 0.0076 (0.0021)	
training:	Epoch: [100][164/204]	Loss 0.0055 (0.0022)	
training:	Epoch: [100][165/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [100][166/204]	Loss 0.0012 (0.0021)	
training:	Epoch: [100][167/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [100][168/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [100][169/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [100][170/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [100][171/204]	Loss 0.0412 (0.0023)	
training:	Epoch: [100][172/204]	Loss 0.0030 (0.0023)	
training:	Epoch: [100][173/204]	Loss 0.0036 (0.0023)	
training:	Epoch: [100][174/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [100][175/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [100][176/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [100][177/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [100][178/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [100][179/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [100][180/204]	Loss 0.0019 (0.0023)	
training:	Epoch: [100][181/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [100][182/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [100][183/204]	Loss 0.0048 (0.0023)	
training:	Epoch: [100][184/204]	Loss 0.0016 (0.0023)	
training:	Epoch: [100][185/204]	Loss 0.0120 (0.0023)	
training:	Epoch: [100][186/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [100][187/204]	Loss 0.0013 (0.0023)	
training:	Epoch: [100][188/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [100][189/204]	Loss 0.0017 (0.0023)	
training:	Epoch: [100][190/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [100][191/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [100][192/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [100][193/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [100][194/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [100][195/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [100][196/204]	Loss 0.0013 (0.0022)	
training:	Epoch: [100][197/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [100][198/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [100][199/204]	Loss 0.0014 (0.0022)	
training:	Epoch: [100][200/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [100][201/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [100][202/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [100][203/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [100][204/204]	Loss 0.0019 (0.0022)	
Training:	 Loss: 0.0022

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7695 0.7710 0.8025 0.7365
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4739
Pretraining:	Epoch 101/500
----------
training:	Epoch: [101][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [101][2/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [101][3/204]	Loss 0.0016 (0.0008)	
training:	Epoch: [101][4/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [101][5/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [101][6/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [101][7/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [101][8/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [101][9/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [101][10/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [101][11/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [101][12/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [101][13/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [101][14/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [101][15/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [101][16/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [101][17/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [101][18/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [101][19/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [101][20/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [101][21/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [101][22/204]	Loss 0.0179 (0.0014)	
training:	Epoch: [101][23/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [101][24/204]	Loss 0.0008 (0.0013)	
training:	Epoch: [101][25/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [101][26/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [101][27/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [101][28/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [101][29/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [101][30/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [101][31/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [101][32/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [101][33/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [101][34/204]	Loss 0.0015 (0.0011)	
training:	Epoch: [101][35/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [101][36/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [101][37/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [101][38/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [101][39/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [101][40/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [101][41/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [101][42/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [101][43/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [101][44/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [101][45/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [101][46/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][47/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][48/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [101][49/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [101][50/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [101][51/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [101][52/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][53/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][54/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [101][55/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [101][56/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][57/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [101][58/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [101][59/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][60/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][61/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][62/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [101][63/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [101][64/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][65/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [101][66/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [101][67/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [101][68/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][69/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [101][70/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [101][71/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [101][72/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][73/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][74/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][75/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [101][76/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [101][77/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][78/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][79/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [101][80/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][81/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [101][82/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [101][83/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [101][84/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [101][85/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [101][86/204]	Loss 0.0162 (0.0009)	
training:	Epoch: [101][87/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][88/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][89/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][90/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [101][91/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][92/204]	Loss 0.0014 (0.0009)	
training:	Epoch: [101][93/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][94/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][95/204]	Loss 0.0015 (0.0009)	
training:	Epoch: [101][96/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][97/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [101][98/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [101][99/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [101][100/204]	Loss 0.2257 (0.0032)	
training:	Epoch: [101][101/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][102/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][103/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][104/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][105/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [101][106/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][107/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][108/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][109/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [101][110/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [101][111/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [101][112/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [101][113/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [101][114/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [101][115/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [101][116/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [101][117/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [101][118/204]	Loss 0.0165 (0.0029)	
training:	Epoch: [101][119/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [101][120/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [101][121/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [101][122/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [101][123/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [101][124/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [101][125/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [101][126/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [101][127/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [101][128/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [101][129/204]	Loss 0.0590 (0.0031)	
training:	Epoch: [101][130/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][131/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][132/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][133/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][134/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][135/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][136/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [101][137/204]	Loss 0.0011 (0.0030)	
training:	Epoch: [101][138/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][139/204]	Loss 0.0037 (0.0030)	
training:	Epoch: [101][140/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [101][141/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [101][142/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [101][143/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [101][144/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [101][145/204]	Loss 0.0138 (0.0030)	
training:	Epoch: [101][146/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][147/204]	Loss 0.0020 (0.0030)	
training:	Epoch: [101][148/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [101][149/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [101][150/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [101][151/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [101][152/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [101][153/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [101][154/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [101][155/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [101][156/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [101][157/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [101][158/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [101][159/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [101][160/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [101][161/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [101][162/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [101][163/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [101][164/204]	Loss 0.0007 (0.0027)	
training:	Epoch: [101][165/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [101][166/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [101][167/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [101][168/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [101][169/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [101][170/204]	Loss 0.0049 (0.0026)	
training:	Epoch: [101][171/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [101][172/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [101][173/204]	Loss 0.0811 (0.0031)	
training:	Epoch: [101][174/204]	Loss 0.0010 (0.0031)	
training:	Epoch: [101][175/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][176/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][177/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][178/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [101][179/204]	Loss 0.0011 (0.0030)	
training:	Epoch: [101][180/204]	Loss 0.0585 (0.0033)	
training:	Epoch: [101][181/204]	Loss 0.0042 (0.0033)	
training:	Epoch: [101][182/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [101][183/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [101][184/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [101][185/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [101][186/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [101][187/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [101][188/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [101][189/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [101][190/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [101][191/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [101][192/204]	Loss 0.0017 (0.0032)	
training:	Epoch: [101][193/204]	Loss 0.0012 (0.0032)	
training:	Epoch: [101][194/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [101][195/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [101][196/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [101][197/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][198/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][199/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [101][200/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [101][201/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [101][202/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [101][203/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [101][204/204]	Loss 0.0007 (0.0030)	
Training:	 Loss: 0.0030

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7732 0.7742 0.7963 0.7500
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3951
Pretraining:	Epoch 102/500
----------
training:	Epoch: [102][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [102][2/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [102][3/204]	Loss 0.0012 (0.0007)	
training:	Epoch: [102][4/204]	Loss 0.0013 (0.0009)	
training:	Epoch: [102][5/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [102][6/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [102][7/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [102][8/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [102][9/204]	Loss 0.0014 (0.0008)	
training:	Epoch: [102][10/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [102][11/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [102][12/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [102][13/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [102][14/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [102][15/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [102][16/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [102][17/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [102][18/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [102][19/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [102][20/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [102][21/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [102][22/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [102][23/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [102][24/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [102][25/204]	Loss 0.0025 (0.0007)	
training:	Epoch: [102][26/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [102][27/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [102][28/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [102][29/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [102][30/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [102][31/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [102][32/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [102][33/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [102][34/204]	Loss 0.0008 (0.0007)	
training:	Epoch: [102][35/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [102][36/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [102][37/204]	Loss 0.2194 (0.0066)	
training:	Epoch: [102][38/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [102][39/204]	Loss 0.0015 (0.0063)	
training:	Epoch: [102][40/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [102][41/204]	Loss 0.0277 (0.0067)	
training:	Epoch: [102][42/204]	Loss 0.0007 (0.0065)	
training:	Epoch: [102][43/204]	Loss 0.0005 (0.0064)	
training:	Epoch: [102][44/204]	Loss 0.0035 (0.0063)	
training:	Epoch: [102][45/204]	Loss 0.0005 (0.0062)	
training:	Epoch: [102][46/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [102][47/204]	Loss 0.0005 (0.0060)	
training:	Epoch: [102][48/204]	Loss 0.0040 (0.0059)	
training:	Epoch: [102][49/204]	Loss 0.0046 (0.0059)	
training:	Epoch: [102][50/204]	Loss 0.0006 (0.0058)	
training:	Epoch: [102][51/204]	Loss 0.0037 (0.0057)	
training:	Epoch: [102][52/204]	Loss 0.0006 (0.0056)	
training:	Epoch: [102][53/204]	Loss 0.0006 (0.0055)	
training:	Epoch: [102][54/204]	Loss 0.0006 (0.0054)	
training:	Epoch: [102][55/204]	Loss 0.0066 (0.0055)	
training:	Epoch: [102][56/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [102][57/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [102][58/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [102][59/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [102][60/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [102][61/204]	Loss 0.0008 (0.0050)	
training:	Epoch: [102][62/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [102][63/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [102][64/204]	Loss 0.0010 (0.0048)	
training:	Epoch: [102][65/204]	Loss 0.0011 (0.0047)	
training:	Epoch: [102][66/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [102][67/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [102][68/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [102][69/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [102][70/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [102][71/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [102][72/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [102][73/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [102][74/204]	Loss 0.0005 (0.0042)	
training:	Epoch: [102][75/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [102][76/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [102][77/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [102][78/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [102][79/204]	Loss 0.0008 (0.0040)	
training:	Epoch: [102][80/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [102][81/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [102][82/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [102][83/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [102][84/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [102][85/204]	Loss 0.0010 (0.0037)	
training:	Epoch: [102][86/204]	Loss 0.0005 (0.0037)	
training:	Epoch: [102][87/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [102][88/204]	Loss 0.0007 (0.0036)	
training:	Epoch: [102][89/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [102][90/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [102][91/204]	Loss 0.0018 (0.0035)	
training:	Epoch: [102][92/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [102][93/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [102][94/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [102][95/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [102][96/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [102][97/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [102][98/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [102][99/204]	Loss 0.0008 (0.0033)	
training:	Epoch: [102][100/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [102][101/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [102][102/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [102][103/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [102][104/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [102][105/204]	Loss 0.0012 (0.0031)	
training:	Epoch: [102][106/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [102][107/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [102][108/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [102][109/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [102][110/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [102][111/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [102][112/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [102][113/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [102][114/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [102][115/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [102][116/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [102][117/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [102][118/204]	Loss 0.0009 (0.0029)	
training:	Epoch: [102][119/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [102][120/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [102][121/204]	Loss 0.0014 (0.0028)	
training:	Epoch: [102][122/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [102][123/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [102][124/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [102][125/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [102][126/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [102][127/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [102][128/204]	Loss 0.0009 (0.0027)	
training:	Epoch: [102][129/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [102][130/204]	Loss 0.0115 (0.0027)	
training:	Epoch: [102][131/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [102][132/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [102][133/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [102][134/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [102][135/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [102][136/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [102][137/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [102][138/204]	Loss 0.0010 (0.0026)	
training:	Epoch: [102][139/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [102][140/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [102][141/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [102][142/204]	Loss 0.0046 (0.0026)	
training:	Epoch: [102][143/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [102][144/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [102][145/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [102][146/204]	Loss 0.0013 (0.0025)	
training:	Epoch: [102][147/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [102][148/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [102][149/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [102][150/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [102][151/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [102][152/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [102][153/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [102][154/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [102][155/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [102][156/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [102][157/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [102][158/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [102][159/204]	Loss 0.0018 (0.0024)	
training:	Epoch: [102][160/204]	Loss 0.0014 (0.0024)	
training:	Epoch: [102][161/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [102][162/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [102][163/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [102][164/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [102][165/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [102][166/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [102][167/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [102][168/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [102][169/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [102][170/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [102][171/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [102][172/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [102][173/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [102][174/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [102][175/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [102][176/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [102][177/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [102][178/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [102][179/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [102][180/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [102][181/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [102][182/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [102][183/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [102][184/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [102][185/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [102][186/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [102][187/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [102][188/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [102][189/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [102][190/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [102][191/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [102][192/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [102][193/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [102][194/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [102][195/204]	Loss 0.0024 (0.0020)	
training:	Epoch: [102][196/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [102][197/204]	Loss 0.0011 (0.0020)	
training:	Epoch: [102][198/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [102][199/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [102][200/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [102][201/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [102][202/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [102][203/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [102][204/204]	Loss 0.0004 (0.0020)	
Training:	 Loss: 0.0020

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7766 0.7774 0.7953 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4445
Pretraining:	Epoch 103/500
----------
training:	Epoch: [103][1/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][2/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][3/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [103][4/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [103][5/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [103][6/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [103][7/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][8/204]	Loss 0.0021 (0.0007)	
training:	Epoch: [103][9/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [103][10/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [103][11/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [103][12/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [103][13/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [103][14/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [103][15/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [103][16/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [103][17/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [103][18/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [103][19/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [103][20/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [103][21/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [103][22/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [103][23/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [103][24/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][25/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][26/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][27/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][28/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][29/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][30/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][31/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][32/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][33/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][34/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][35/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][36/204]	Loss 0.0016 (0.0005)	
training:	Epoch: [103][37/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [103][38/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][39/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][40/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][41/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][42/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][43/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][44/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][45/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][46/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [103][47/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][48/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [103][49/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][50/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][51/204]	Loss 0.0011 (0.0005)	
training:	Epoch: [103][52/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [103][53/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][54/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][55/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [103][56/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][57/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][58/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [103][59/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][60/204]	Loss 0.0010 (0.0005)	
training:	Epoch: [103][61/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][62/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][63/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][64/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][65/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][66/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [103][67/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][68/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][69/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [103][70/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][71/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [103][72/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][73/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [103][74/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][75/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][76/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][77/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][78/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][79/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][80/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [103][81/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][82/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [103][83/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][84/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][85/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][86/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][87/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][88/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][89/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][90/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][91/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [103][92/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][93/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][94/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][95/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][96/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [103][97/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][98/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [103][99/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][100/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][101/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][102/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [103][103/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [103][104/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [103][105/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][106/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][107/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][108/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][109/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][110/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [103][111/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][112/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][113/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][114/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][115/204]	Loss 0.0010 (0.0005)	
training:	Epoch: [103][116/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][117/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][118/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][119/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][120/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][121/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][122/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][123/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [103][124/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][125/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][126/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][127/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][128/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][129/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [103][130/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][131/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [103][132/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [103][133/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][134/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][135/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][136/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][137/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][138/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][139/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][140/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [103][141/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][142/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][143/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][144/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [103][145/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][146/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][147/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][148/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [103][149/204]	Loss 0.2240 (0.0020)	
training:	Epoch: [103][150/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [103][151/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [103][152/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [103][153/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [103][154/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [103][155/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [103][156/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [103][157/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [103][158/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [103][159/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [103][160/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [103][161/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [103][162/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [103][163/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [103][164/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [103][165/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [103][166/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [103][167/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [103][168/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [103][169/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [103][170/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [103][171/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [103][172/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [103][173/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [103][174/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [103][175/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [103][176/204]	Loss 0.0016 (0.0018)	
training:	Epoch: [103][177/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [103][178/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [103][179/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [103][180/204]	Loss 0.0007 (0.0017)	
training:	Epoch: [103][181/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][182/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][183/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [103][184/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [103][185/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][186/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][187/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][188/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [103][189/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][190/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][191/204]	Loss 0.0011 (0.0017)	
training:	Epoch: [103][192/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [103][193/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][194/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][195/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [103][196/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [103][197/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [103][198/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [103][199/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [103][200/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [103][201/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [103][202/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [103][203/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [103][204/204]	Loss 0.0004 (0.0016)	
Training:	 Loss: 0.0016

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7754 0.7764 0.7953 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4580
Pretraining:	Epoch 104/500
----------
training:	Epoch: [104][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [104][2/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [104][3/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [104][4/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [104][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [104][6/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [104][7/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [104][8/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [104][9/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [104][10/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [104][11/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [104][12/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [104][13/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [104][14/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][15/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][16/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [104][17/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][18/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [104][19/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [104][20/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][21/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [104][22/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][23/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [104][24/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][25/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][26/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [104][27/204]	Loss 0.0055 (0.0007)	
training:	Epoch: [104][28/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][29/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][30/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [104][31/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [104][32/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][33/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][34/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][35/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][36/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][37/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][38/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][39/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][40/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][41/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][42/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][43/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][44/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [104][45/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][46/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][47/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][48/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [104][49/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][50/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [104][51/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][52/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [104][53/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [104][54/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][55/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [104][56/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [104][57/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][58/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][59/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][60/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][61/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][62/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][63/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][64/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [104][65/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][66/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][67/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][68/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][69/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [104][70/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][71/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][72/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][73/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][74/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][75/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [104][76/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][77/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [104][78/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [104][79/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][80/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][81/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][82/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][83/204]	Loss 0.0012 (0.0006)	
training:	Epoch: [104][84/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][85/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [104][86/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [104][87/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][88/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [104][89/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][90/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [104][91/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][92/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][93/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][94/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][95/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [104][96/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [104][97/204]	Loss 0.0248 (0.0008)	
training:	Epoch: [104][98/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][99/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][100/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][101/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][102/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][103/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][104/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [104][105/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [104][106/204]	Loss 0.0011 (0.0008)	
training:	Epoch: [104][107/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [104][108/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [104][109/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [104][110/204]	Loss 0.0094 (0.0008)	
training:	Epoch: [104][111/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [104][112/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][113/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [104][114/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [104][115/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [104][116/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][117/204]	Loss 0.0024 (0.0008)	
training:	Epoch: [104][118/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][119/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [104][120/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][121/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [104][122/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [104][123/204]	Loss 0.0016 (0.0008)	
training:	Epoch: [104][124/204]	Loss 0.2222 (0.0026)	
training:	Epoch: [104][125/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [104][126/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [104][127/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [104][128/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [104][129/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [104][130/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [104][131/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [104][132/204]	Loss 0.0008 (0.0025)	
training:	Epoch: [104][133/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [104][134/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [104][135/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [104][136/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [104][137/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [104][138/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [104][139/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [104][140/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [104][141/204]	Loss 0.0008 (0.0024)	
training:	Epoch: [104][142/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [104][143/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [104][144/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [104][145/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [104][146/204]	Loss 0.0008 (0.0023)	
training:	Epoch: [104][147/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [104][148/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [104][149/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [104][150/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [104][151/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [104][152/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [104][153/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [104][154/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [104][155/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [104][156/204]	Loss 0.0025 (0.0022)	
training:	Epoch: [104][157/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [104][158/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [104][159/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [104][160/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [104][161/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [104][162/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [104][163/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [104][164/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [104][165/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [104][166/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [104][167/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [104][168/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [104][169/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [104][170/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [104][171/204]	Loss 0.0008 (0.0020)	
training:	Epoch: [104][172/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [104][173/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [104][174/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [104][175/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [104][176/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [104][177/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [104][178/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [104][179/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [104][180/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [104][181/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [104][182/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][183/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][184/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][185/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][186/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [104][187/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [104][188/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][189/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][190/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][191/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [104][192/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][193/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][194/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [104][195/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [104][196/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [104][197/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [104][198/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [104][199/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [104][200/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [104][201/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [104][202/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [104][203/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [104][204/204]	Loss 0.0004 (0.0018)	
Training:	 Loss: 0.0018

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7745 0.7758 0.8035 0.7455
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4765
Pretraining:	Epoch 105/500
----------
training:	Epoch: [105][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [105][2/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [105][3/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [105][4/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [105][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [105][6/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [105][7/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [105][8/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [105][9/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [105][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [105][11/204]	Loss 0.2207 (0.0204)	
training:	Epoch: [105][12/204]	Loss 0.0004 (0.0188)	
training:	Epoch: [105][13/204]	Loss 0.0004 (0.0174)	
training:	Epoch: [105][14/204]	Loss 0.0004 (0.0162)	
training:	Epoch: [105][15/204]	Loss 0.0004 (0.0151)	
training:	Epoch: [105][16/204]	Loss 0.0005 (0.0142)	
training:	Epoch: [105][17/204]	Loss 0.0004 (0.0134)	
training:	Epoch: [105][18/204]	Loss 0.0004 (0.0127)	
training:	Epoch: [105][19/204]	Loss 0.0007 (0.0120)	
training:	Epoch: [105][20/204]	Loss 0.0004 (0.0114)	
training:	Epoch: [105][21/204]	Loss 0.0004 (0.0109)	
training:	Epoch: [105][22/204]	Loss 0.0004 (0.0104)	
training:	Epoch: [105][23/204]	Loss 0.0005 (0.0100)	
training:	Epoch: [105][24/204]	Loss 0.0005 (0.0096)	
training:	Epoch: [105][25/204]	Loss 0.0006 (0.0093)	
training:	Epoch: [105][26/204]	Loss 0.0012 (0.0089)	
training:	Epoch: [105][27/204]	Loss 0.0004 (0.0086)	
training:	Epoch: [105][28/204]	Loss 0.0004 (0.0083)	
training:	Epoch: [105][29/204]	Loss 0.0003 (0.0081)	
training:	Epoch: [105][30/204]	Loss 0.0004 (0.0078)	
training:	Epoch: [105][31/204]	Loss 0.0006 (0.0076)	
training:	Epoch: [105][32/204]	Loss 0.0007 (0.0074)	
training:	Epoch: [105][33/204]	Loss 0.0004 (0.0071)	
training:	Epoch: [105][34/204]	Loss 0.0005 (0.0069)	
training:	Epoch: [105][35/204]	Loss 0.0004 (0.0068)	
training:	Epoch: [105][36/204]	Loss 0.0004 (0.0066)	
training:	Epoch: [105][37/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [105][38/204]	Loss 0.0005 (0.0063)	
training:	Epoch: [105][39/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [105][40/204]	Loss 0.0007 (0.0060)	
training:	Epoch: [105][41/204]	Loss 0.0004 (0.0058)	
training:	Epoch: [105][42/204]	Loss 0.0004 (0.0057)	
training:	Epoch: [105][43/204]	Loss 0.0005 (0.0056)	
training:	Epoch: [105][44/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [105][45/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [105][46/204]	Loss 0.0006 (0.0053)	
training:	Epoch: [105][47/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [105][48/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [105][49/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [105][50/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [105][51/204]	Loss 0.0005 (0.0048)	
training:	Epoch: [105][52/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [105][53/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [105][54/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [105][55/204]	Loss 0.0013 (0.0045)	
training:	Epoch: [105][56/204]	Loss 0.0003 (0.0044)	
training:	Epoch: [105][57/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [105][58/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [105][59/204]	Loss 0.0005 (0.0042)	
training:	Epoch: [105][60/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [105][61/204]	Loss 0.0006 (0.0041)	
training:	Epoch: [105][62/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [105][63/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [105][64/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [105][65/204]	Loss 0.0007 (0.0039)	
training:	Epoch: [105][66/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [105][67/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [105][68/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [105][69/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [105][70/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [105][71/204]	Loss 0.0007 (0.0036)	
training:	Epoch: [105][72/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [105][73/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [105][74/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [105][75/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [105][76/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [105][77/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [105][78/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [105][79/204]	Loss 0.0051 (0.0033)	
training:	Epoch: [105][80/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [105][81/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [105][82/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [105][83/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [105][84/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [105][85/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [105][86/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [105][87/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [105][88/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [105][89/204]	Loss 0.0028 (0.0030)	
training:	Epoch: [105][90/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [105][91/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [105][92/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [105][93/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [105][94/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [105][95/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [105][96/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [105][97/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [105][98/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [105][99/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [105][100/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [105][101/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [105][102/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [105][103/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [105][104/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [105][105/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [105][106/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [105][107/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [105][108/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [105][109/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [105][110/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [105][111/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [105][112/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [105][113/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [105][114/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [105][115/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [105][116/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [105][117/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [105][118/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [105][119/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [105][120/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [105][121/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [105][122/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [105][123/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [105][124/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [105][125/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [105][126/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [105][127/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [105][128/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [105][129/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [105][130/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [105][131/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [105][132/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [105][133/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [105][134/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [105][135/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [105][136/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [105][137/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [105][138/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [105][139/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [105][140/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [105][141/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [105][142/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [105][143/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [105][144/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [105][145/204]	Loss 0.0008 (0.0020)	
training:	Epoch: [105][146/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [105][147/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [105][148/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [105][149/204]	Loss 0.0017 (0.0020)	
training:	Epoch: [105][150/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [105][151/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [105][152/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [105][153/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [105][154/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [105][155/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [105][156/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [105][157/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [105][158/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [105][159/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [105][160/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [105][161/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [105][162/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [105][163/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [105][164/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [105][165/204]	Loss 0.0007 (0.0018)	
training:	Epoch: [105][166/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [105][167/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [105][168/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [105][169/204]	Loss 0.0014 (0.0018)	
training:	Epoch: [105][170/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [105][171/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [105][172/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [105][173/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [105][174/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [105][175/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [105][176/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [105][177/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [105][178/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][179/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][180/204]	Loss 0.0009 (0.0017)	
training:	Epoch: [105][181/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [105][182/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][183/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][184/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [105][185/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [105][186/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][187/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][188/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][189/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][190/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [105][191/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [105][192/204]	Loss 0.0065 (0.0017)	
training:	Epoch: [105][193/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [105][194/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][195/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [105][196/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][197/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [105][198/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [105][199/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [105][200/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [105][201/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [105][202/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [105][203/204]	Loss 0.0010 (0.0016)	
training:	Epoch: [105][204/204]	Loss 0.0003 (0.0016)	
Training:	 Loss: 0.0016

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7752 0.7758 0.7892 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4809
Pretraining:	Epoch 106/500
----------
training:	Epoch: [106][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][2/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][3/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][4/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [106][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][6/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][7/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][8/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [106][9/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][11/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [106][12/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][13/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][14/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [106][15/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][16/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [106][17/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [106][18/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [106][19/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][20/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][21/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [106][22/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [106][23/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][24/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [106][25/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [106][26/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [106][27/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][28/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [106][29/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][30/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][31/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][32/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [106][33/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][34/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][35/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][36/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][37/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [106][38/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][39/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [106][40/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [106][41/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][42/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][43/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][44/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][45/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [106][46/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][47/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][48/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][49/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [106][50/204]	Loss 0.0018 (0.0005)	
training:	Epoch: [106][51/204]	Loss 0.0020 (0.0005)	
training:	Epoch: [106][52/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][53/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][54/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][55/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][56/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][57/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][58/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][59/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [106][60/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][61/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][62/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][63/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [106][64/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][65/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][66/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][67/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][68/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][69/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [106][70/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][71/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][72/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][73/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][74/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][75/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][76/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][77/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [106][78/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][79/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][80/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][81/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][82/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][83/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][84/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [106][85/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][86/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [106][87/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][88/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][89/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [106][90/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][91/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][92/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][93/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][94/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][95/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][96/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][97/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][98/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][99/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][100/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][101/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][102/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][103/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][104/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][105/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][106/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][107/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][108/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][109/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][110/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][111/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][112/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][113/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][114/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][115/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][116/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][117/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][118/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][119/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][120/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][121/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][122/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][123/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][124/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][125/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][126/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][127/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][128/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][129/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][130/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [106][131/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [106][132/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [106][133/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][134/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [106][135/204]	Loss 0.2252 (0.0021)	
training:	Epoch: [106][136/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [106][137/204]	Loss 0.0010 (0.0021)	
training:	Epoch: [106][138/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [106][139/204]	Loss 0.0009 (0.0021)	
training:	Epoch: [106][140/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [106][141/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [106][142/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [106][143/204]	Loss 0.0008 (0.0020)	
training:	Epoch: [106][144/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [106][145/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [106][146/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [106][147/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [106][148/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [106][149/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [106][150/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [106][151/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [106][152/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [106][153/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [106][154/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [106][155/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [106][156/204]	Loss 0.0008 (0.0019)	
training:	Epoch: [106][157/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [106][158/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [106][159/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [106][160/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [106][161/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [106][162/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [106][163/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [106][164/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [106][165/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [106][166/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [106][167/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [106][168/204]	Loss 0.0011 (0.0018)	
training:	Epoch: [106][169/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [106][170/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [106][171/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [106][172/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [106][173/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [106][174/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [106][175/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [106][176/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [106][177/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [106][178/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [106][179/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [106][180/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [106][181/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [106][182/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [106][183/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [106][184/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [106][185/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [106][186/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [106][187/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [106][188/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [106][189/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [106][190/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [106][191/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [106][192/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [106][193/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [106][194/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [106][195/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [106][196/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [106][197/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [106][198/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [106][199/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [106][200/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [106][201/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [106][202/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [106][203/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [106][204/204]	Loss 0.0003 (0.0016)	
Training:	 Loss: 0.0016

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7744 0.7753 0.7943 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4956
Pretraining:	Epoch 107/500
----------
training:	Epoch: [107][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [107][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [107][3/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][4/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][6/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][7/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][8/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][9/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][11/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][12/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][13/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][14/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][15/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][16/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][17/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][18/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][19/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][20/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][21/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][22/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][23/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][24/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][25/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][26/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][27/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][28/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][29/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][30/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][31/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][32/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][33/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][34/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][35/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][36/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][37/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][38/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][39/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][40/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][41/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][42/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][43/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][44/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][45/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][46/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][47/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][48/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][49/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][50/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][51/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][52/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][53/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][54/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][55/204]	Loss 0.0017 (0.0004)	
training:	Epoch: [107][56/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][57/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][58/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][59/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][60/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][61/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][62/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][63/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][64/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][65/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][66/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][67/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][68/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][69/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][70/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][71/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][72/204]	Loss 0.0017 (0.0004)	
training:	Epoch: [107][73/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][74/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][75/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][76/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][77/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [107][78/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][79/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][80/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][81/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][82/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][83/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][84/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][85/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][86/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][87/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][88/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][89/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][90/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][91/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][92/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][93/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [107][94/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][95/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][96/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][97/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][98/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][99/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][100/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [107][101/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][102/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][103/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][104/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][105/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][106/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [107][107/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][108/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][109/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][110/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][111/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][112/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][113/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][114/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [107][115/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][116/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][117/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [107][118/204]	Loss 0.0047 (0.0005)	
training:	Epoch: [107][119/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [107][120/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [107][121/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][122/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][123/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][124/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [107][125/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][126/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [107][127/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][128/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][129/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][130/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][131/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][132/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][133/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][134/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][135/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][136/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][137/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][138/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [107][139/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [107][140/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [107][141/204]	Loss 0.2191 (0.0020)	
training:	Epoch: [107][142/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [107][143/204]	Loss 0.0036 (0.0020)	
training:	Epoch: [107][144/204]	Loss 0.0012 (0.0020)	
training:	Epoch: [107][145/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [107][146/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [107][147/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [107][148/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [107][149/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [107][150/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [107][151/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [107][152/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [107][153/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [107][154/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [107][155/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [107][156/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [107][157/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [107][158/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [107][159/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [107][160/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [107][161/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [107][162/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [107][163/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [107][164/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [107][165/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [107][166/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [107][167/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [107][168/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [107][169/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [107][170/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [107][171/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [107][172/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [107][173/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [107][174/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [107][175/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [107][176/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [107][177/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [107][178/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [107][179/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [107][180/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [107][181/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [107][182/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [107][183/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [107][184/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [107][185/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [107][186/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [107][187/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [107][188/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [107][189/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [107][190/204]	Loss 0.0049 (0.0016)	
training:	Epoch: [107][191/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [107][192/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [107][193/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [107][194/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [107][195/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [107][196/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [107][197/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [107][198/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [107][199/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [107][200/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [107][201/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [107][202/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [107][203/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [107][204/204]	Loss 0.0004 (0.0015)	
Training:	 Loss: 0.0015

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7749 0.7753 0.7840 0.7657
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5024
Pretraining:	Epoch 108/500
----------
training:	Epoch: [108][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [108][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [108][3/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][4/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][6/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][7/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][8/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][9/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][11/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][12/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][13/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][14/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][15/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [108][16/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][17/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][18/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][19/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][20/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][21/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][22/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [108][23/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [108][24/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [108][25/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [108][26/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [108][27/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [108][28/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [108][29/204]	Loss 0.2184 (0.0079)	
training:	Epoch: [108][30/204]	Loss 0.0007 (0.0077)	
training:	Epoch: [108][31/204]	Loss 0.0010 (0.0075)	
training:	Epoch: [108][32/204]	Loss 0.0004 (0.0072)	
training:	Epoch: [108][33/204]	Loss 0.0006 (0.0070)	
training:	Epoch: [108][34/204]	Loss 0.0004 (0.0068)	
training:	Epoch: [108][35/204]	Loss 0.0004 (0.0067)	
training:	Epoch: [108][36/204]	Loss 0.0004 (0.0065)	
training:	Epoch: [108][37/204]	Loss 0.0004 (0.0063)	
training:	Epoch: [108][38/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [108][39/204]	Loss 0.0003 (0.0060)	
training:	Epoch: [108][40/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [108][41/204]	Loss 0.0087 (0.0059)	
training:	Epoch: [108][42/204]	Loss 0.0003 (0.0058)	
training:	Epoch: [108][43/204]	Loss 0.0003 (0.0057)	
training:	Epoch: [108][44/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [108][45/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [108][46/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [108][47/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [108][48/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [108][49/204]	Loss 0.0003 (0.0050)	
training:	Epoch: [108][50/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [108][51/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [108][52/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [108][53/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [108][54/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [108][55/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [108][56/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [108][57/204]	Loss 0.0005 (0.0044)	
training:	Epoch: [108][58/204]	Loss 0.0003 (0.0043)	
training:	Epoch: [108][59/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [108][60/204]	Loss 0.0109 (0.0044)	
training:	Epoch: [108][61/204]	Loss 0.0007 (0.0043)	
training:	Epoch: [108][62/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [108][63/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [108][64/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [108][65/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [108][66/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [108][67/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [108][68/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [108][69/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [108][70/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [108][71/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [108][72/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [108][73/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [108][74/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [108][75/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [108][76/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [108][77/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [108][78/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [108][79/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [108][80/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [108][81/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [108][82/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [108][83/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [108][84/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [108][85/204]	Loss 0.0011 (0.0032)	
training:	Epoch: [108][86/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [108][87/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [108][88/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [108][89/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [108][90/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [108][91/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [108][92/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [108][93/204]	Loss 0.0107 (0.0031)	
training:	Epoch: [108][94/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [108][95/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [108][96/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [108][97/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [108][98/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [108][99/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [108][100/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [108][101/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [108][102/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [108][103/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [108][104/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [108][105/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [108][106/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [108][107/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [108][108/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [108][109/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [108][110/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [108][111/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [108][112/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [108][113/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [108][114/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [108][115/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [108][116/204]	Loss 0.0009 (0.0026)	
training:	Epoch: [108][117/204]	Loss 0.0015 (0.0026)	
training:	Epoch: [108][118/204]	Loss 0.0015 (0.0025)	
training:	Epoch: [108][119/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [108][120/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [108][121/204]	Loss 0.0013 (0.0025)	
training:	Epoch: [108][122/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [108][123/204]	Loss 0.0011 (0.0025)	
training:	Epoch: [108][124/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [108][125/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [108][126/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [108][127/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [108][128/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [108][129/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [108][130/204]	Loss 0.0018 (0.0024)	
training:	Epoch: [108][131/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [108][132/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [108][133/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [108][134/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [108][135/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [108][136/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [108][137/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [108][138/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [108][139/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [108][140/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [108][141/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [108][142/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [108][143/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [108][144/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [108][145/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [108][146/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [108][147/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [108][148/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [108][149/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [108][150/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [108][151/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [108][152/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [108][153/204]	Loss 0.0013 (0.0021)	
training:	Epoch: [108][154/204]	Loss 0.0070 (0.0021)	
training:	Epoch: [108][155/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [108][156/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [108][157/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [108][158/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [108][159/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [108][160/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [108][161/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [108][162/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [108][163/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [108][164/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [108][165/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [108][166/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [108][167/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [108][168/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [108][169/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [108][170/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [108][171/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [108][172/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [108][173/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [108][174/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [108][175/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [108][176/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [108][177/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [108][178/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [108][179/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [108][180/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [108][181/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [108][182/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [108][183/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [108][184/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [108][185/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [108][186/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [108][187/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [108][188/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [108][189/204]	Loss 0.0021 (0.0018)	
training:	Epoch: [108][190/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [108][191/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [108][192/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [108][193/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [108][194/204]	Loss 0.0010 (0.0018)	
training:	Epoch: [108][195/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [108][196/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [108][197/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [108][198/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [108][199/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [108][200/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [108][201/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [108][202/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [108][203/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [108][204/204]	Loss 0.0004 (0.0017)	
Training:	 Loss: 0.0017

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7769 0.7780 0.7994 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5284
Pretraining:	Epoch 109/500
----------
training:	Epoch: [109][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [109][2/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [109][3/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [109][4/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [109][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [109][6/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [109][7/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [109][8/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [109][9/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [109][10/204]	Loss 0.0033 (0.0007)	
training:	Epoch: [109][11/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [109][12/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [109][13/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [109][14/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [109][15/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [109][16/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [109][17/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [109][18/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [109][19/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [109][20/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [109][21/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [109][22/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [109][23/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [109][24/204]	Loss 0.2156 (0.0095)	
training:	Epoch: [109][25/204]	Loss 0.0004 (0.0091)	
training:	Epoch: [109][26/204]	Loss 0.0004 (0.0088)	
training:	Epoch: [109][27/204]	Loss 0.0004 (0.0085)	
training:	Epoch: [109][28/204]	Loss 0.0004 (0.0082)	
training:	Epoch: [109][29/204]	Loss 0.0004 (0.0079)	
training:	Epoch: [109][30/204]	Loss 0.0004 (0.0077)	
training:	Epoch: [109][31/204]	Loss 0.0004 (0.0074)	
training:	Epoch: [109][32/204]	Loss 0.0007 (0.0072)	
training:	Epoch: [109][33/204]	Loss 0.0004 (0.0070)	
training:	Epoch: [109][34/204]	Loss 0.0004 (0.0068)	
training:	Epoch: [109][35/204]	Loss 0.0012 (0.0067)	
training:	Epoch: [109][36/204]	Loss 0.0004 (0.0065)	
training:	Epoch: [109][37/204]	Loss 0.0004 (0.0063)	
training:	Epoch: [109][38/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [109][39/204]	Loss 0.0005 (0.0060)	
training:	Epoch: [109][40/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [109][41/204]	Loss 0.0003 (0.0057)	
training:	Epoch: [109][42/204]	Loss 0.0005 (0.0056)	
training:	Epoch: [109][43/204]	Loss 0.0004 (0.0055)	
training:	Epoch: [109][44/204]	Loss 0.0005 (0.0054)	
training:	Epoch: [109][45/204]	Loss 0.0003 (0.0053)	
training:	Epoch: [109][46/204]	Loss 0.0006 (0.0052)	
training:	Epoch: [109][47/204]	Loss 0.0003 (0.0051)	
training:	Epoch: [109][48/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [109][49/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [109][50/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [109][51/204]	Loss 0.0003 (0.0047)	
training:	Epoch: [109][52/204]	Loss 0.0017 (0.0046)	
training:	Epoch: [109][53/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [109][54/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [109][55/204]	Loss 0.0003 (0.0044)	
training:	Epoch: [109][56/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [109][57/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [109][58/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [109][59/204]	Loss 0.0007 (0.0042)	
training:	Epoch: [109][60/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [109][61/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [109][62/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [109][63/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [109][64/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [109][65/204]	Loss 0.0007 (0.0038)	
training:	Epoch: [109][66/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [109][67/204]	Loss 0.0005 (0.0037)	
training:	Epoch: [109][68/204]	Loss 0.0005 (0.0037)	
training:	Epoch: [109][69/204]	Loss 0.0378 (0.0042)	
training:	Epoch: [109][70/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [109][71/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [109][72/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [109][73/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [109][74/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [109][75/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [109][76/204]	Loss 0.2065 (0.0065)	
training:	Epoch: [109][77/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [109][78/204]	Loss 0.0182 (0.0066)	
training:	Epoch: [109][79/204]	Loss 0.0004 (0.0065)	
training:	Epoch: [109][80/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [109][81/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [109][82/204]	Loss 0.0004 (0.0063)	
training:	Epoch: [109][83/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [109][84/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [109][85/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [109][86/204]	Loss 0.0149 (0.0062)	
training:	Epoch: [109][87/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [109][88/204]	Loss 0.0010 (0.0061)	
training:	Epoch: [109][89/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [109][90/204]	Loss 0.0003 (0.0059)	
training:	Epoch: [109][91/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [109][92/204]	Loss 0.0006 (0.0058)	
training:	Epoch: [109][93/204]	Loss 0.0004 (0.0058)	
training:	Epoch: [109][94/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [109][95/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [109][96/204]	Loss 0.0005 (0.0056)	
training:	Epoch: [109][97/204]	Loss 0.0004 (0.0055)	
training:	Epoch: [109][98/204]	Loss 0.0003 (0.0055)	
training:	Epoch: [109][99/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [109][100/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [109][101/204]	Loss 0.0003 (0.0053)	
training:	Epoch: [109][102/204]	Loss 0.0003 (0.0053)	
training:	Epoch: [109][103/204]	Loss 0.0003 (0.0052)	
training:	Epoch: [109][104/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [109][105/204]	Loss 0.0003 (0.0051)	
training:	Epoch: [109][106/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [109][107/204]	Loss 0.0023 (0.0051)	
training:	Epoch: [109][108/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [109][109/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [109][110/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [109][111/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [109][112/204]	Loss 0.0490 (0.0053)	
training:	Epoch: [109][113/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [109][114/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [109][115/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [109][116/204]	Loss 0.0006 (0.0051)	
training:	Epoch: [109][117/204]	Loss 0.0006 (0.0051)	
training:	Epoch: [109][118/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [109][119/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [109][120/204]	Loss 0.0013 (0.0050)	
training:	Epoch: [109][121/204]	Loss 0.0152 (0.0051)	
training:	Epoch: [109][122/204]	Loss 0.0006 (0.0050)	
training:	Epoch: [109][123/204]	Loss 0.0016 (0.0050)	
training:	Epoch: [109][124/204]	Loss 0.0013 (0.0050)	
training:	Epoch: [109][125/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [109][126/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [109][127/204]	Loss 0.0109 (0.0050)	
training:	Epoch: [109][128/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [109][129/204]	Loss 0.0008 (0.0049)	
training:	Epoch: [109][130/204]	Loss 0.0047 (0.0049)	
training:	Epoch: [109][131/204]	Loss 0.0011 (0.0049)	
training:	Epoch: [109][132/204]	Loss 0.0048 (0.0049)	
training:	Epoch: [109][133/204]	Loss 0.0019 (0.0048)	
training:	Epoch: [109][134/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [109][135/204]	Loss 0.0010 (0.0048)	
training:	Epoch: [109][136/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [109][137/204]	Loss 0.0019 (0.0047)	
training:	Epoch: [109][138/204]	Loss 0.0003 (0.0047)	
training:	Epoch: [109][139/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [109][140/204]	Loss 0.0061 (0.0047)	
training:	Epoch: [109][141/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [109][142/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [109][143/204]	Loss 0.0024 (0.0046)	
training:	Epoch: [109][144/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [109][145/204]	Loss 0.0007 (0.0045)	
training:	Epoch: [109][146/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [109][147/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [109][148/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [109][149/204]	Loss 0.0005 (0.0044)	
training:	Epoch: [109][150/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [109][151/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [109][152/204]	Loss 0.0104 (0.0044)	
training:	Epoch: [109][153/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [109][154/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [109][155/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [109][156/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [109][157/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [109][158/204]	Loss 0.0176 (0.0044)	
training:	Epoch: [109][159/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [109][160/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [109][161/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [109][162/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [109][163/204]	Loss 0.1288 (0.0050)	
training:	Epoch: [109][164/204]	Loss 0.0012 (0.0050)	
training:	Epoch: [109][165/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [109][166/204]	Loss 0.0010 (0.0050)	
training:	Epoch: [109][167/204]	Loss 0.0003 (0.0049)	
training:	Epoch: [109][168/204]	Loss 0.0060 (0.0049)	
training:	Epoch: [109][169/204]	Loss 0.0003 (0.0049)	
training:	Epoch: [109][170/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [109][171/204]	Loss 0.0011 (0.0049)	
training:	Epoch: [109][172/204]	Loss 0.0023 (0.0049)	
training:	Epoch: [109][173/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [109][174/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [109][175/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [109][176/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [109][177/204]	Loss 0.0006 (0.0047)	
training:	Epoch: [109][178/204]	Loss 0.0003 (0.0047)	
training:	Epoch: [109][179/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [109][180/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [109][181/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [109][182/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [109][183/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [109][184/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [109][185/204]	Loss 0.0012 (0.0045)	
training:	Epoch: [109][186/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [109][187/204]	Loss 0.0005 (0.0045)	
training:	Epoch: [109][188/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [109][189/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [109][190/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [109][191/204]	Loss 0.0033 (0.0044)	
training:	Epoch: [109][192/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [109][193/204]	Loss 0.0005 (0.0044)	
training:	Epoch: [109][194/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [109][195/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [109][196/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [109][197/204]	Loss 0.0011 (0.0043)	
training:	Epoch: [109][198/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [109][199/204]	Loss 0.0333 (0.0044)	
training:	Epoch: [109][200/204]	Loss 0.0003 (0.0044)	
training:	Epoch: [109][201/204]	Loss 0.0005 (0.0044)	
training:	Epoch: [109][202/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [109][203/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [109][204/204]	Loss 0.0005 (0.0043)	
Training:	 Loss: 0.0043

Training:	 ACC: 0.9953 0.9951 0.9909 0.9997
Validation:	 ACC: 0.7792 0.7774 0.7410 0.8173
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4614
Pretraining:	Epoch 110/500
----------
training:	Epoch: [110][1/204]	Loss 0.0024 (0.0024)	
training:	Epoch: [110][2/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [110][3/204]	Loss 0.0075 (0.0035)	
training:	Epoch: [110][4/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [110][5/204]	Loss 0.0039 (0.0029)	
training:	Epoch: [110][6/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [110][7/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [110][8/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [110][9/204]	Loss 0.0409 (0.0063)	
training:	Epoch: [110][10/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [110][11/204]	Loss 0.0265 (0.0076)	
training:	Epoch: [110][12/204]	Loss 0.0005 (0.0070)	
training:	Epoch: [110][13/204]	Loss 0.0004 (0.0065)	
training:	Epoch: [110][14/204]	Loss 0.0018 (0.0062)	
training:	Epoch: [110][15/204]	Loss 0.0007 (0.0058)	
training:	Epoch: [110][16/204]	Loss 0.0010 (0.0055)	
training:	Epoch: [110][17/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [110][18/204]	Loss 0.2800 (0.0205)	
training:	Epoch: [110][19/204]	Loss 0.0005 (0.0194)	
training:	Epoch: [110][20/204]	Loss 0.0004 (0.0185)	
training:	Epoch: [110][21/204]	Loss 0.0010 (0.0176)	
training:	Epoch: [110][22/204]	Loss 0.0365 (0.0185)	
training:	Epoch: [110][23/204]	Loss 0.0005 (0.0177)	
training:	Epoch: [110][24/204]	Loss 0.0054 (0.0172)	
training:	Epoch: [110][25/204]	Loss 0.0005 (0.0165)	
training:	Epoch: [110][26/204]	Loss 0.0007 (0.0159)	
training:	Epoch: [110][27/204]	Loss 0.1219 (0.0199)	
training:	Epoch: [110][28/204]	Loss 0.0004 (0.0192)	
training:	Epoch: [110][29/204]	Loss 0.0381 (0.0198)	
training:	Epoch: [110][30/204]	Loss 0.0005 (0.0192)	
training:	Epoch: [110][31/204]	Loss 0.0005 (0.0186)	
training:	Epoch: [110][32/204]	Loss 0.0003 (0.0180)	
training:	Epoch: [110][33/204]	Loss 0.0004 (0.0175)	
training:	Epoch: [110][34/204]	Loss 0.0004 (0.0170)	
training:	Epoch: [110][35/204]	Loss 0.0012 (0.0165)	
training:	Epoch: [110][36/204]	Loss 0.0246 (0.0167)	
training:	Epoch: [110][37/204]	Loss 0.0424 (0.0174)	
training:	Epoch: [110][38/204]	Loss 0.0006 (0.0170)	
training:	Epoch: [110][39/204]	Loss 0.0007 (0.0166)	
training:	Epoch: [110][40/204]	Loss 0.0004 (0.0162)	
training:	Epoch: [110][41/204]	Loss 0.0004 (0.0158)	
training:	Epoch: [110][42/204]	Loss 0.0008 (0.0154)	
training:	Epoch: [110][43/204]	Loss 0.0004 (0.0151)	
training:	Epoch: [110][44/204]	Loss 0.0005 (0.0147)	
training:	Epoch: [110][45/204]	Loss 0.0004 (0.0144)	
training:	Epoch: [110][46/204]	Loss 0.0004 (0.0141)	
training:	Epoch: [110][47/204]	Loss 0.0014 (0.0138)	
training:	Epoch: [110][48/204]	Loss 0.0018 (0.0136)	
training:	Epoch: [110][49/204]	Loss 0.0003 (0.0133)	
training:	Epoch: [110][50/204]	Loss 0.1046 (0.0152)	
training:	Epoch: [110][51/204]	Loss 0.0056 (0.0150)	
training:	Epoch: [110][52/204]	Loss 0.0006 (0.0147)	
training:	Epoch: [110][53/204]	Loss 0.0019 (0.0144)	
training:	Epoch: [110][54/204]	Loss 0.0005 (0.0142)	
training:	Epoch: [110][55/204]	Loss 0.0008 (0.0139)	
training:	Epoch: [110][56/204]	Loss 0.0005 (0.0137)	
training:	Epoch: [110][57/204]	Loss 0.0005 (0.0135)	
training:	Epoch: [110][58/204]	Loss 0.0037 (0.0133)	
training:	Epoch: [110][59/204]	Loss 0.0007 (0.0131)	
training:	Epoch: [110][60/204]	Loss 0.2598 (0.0172)	
training:	Epoch: [110][61/204]	Loss 0.0015 (0.0169)	
training:	Epoch: [110][62/204]	Loss 0.0015 (0.0167)	
training:	Epoch: [110][63/204]	Loss 0.0003 (0.0164)	
training:	Epoch: [110][64/204]	Loss 0.0004 (0.0162)	
training:	Epoch: [110][65/204]	Loss 0.0004 (0.0159)	
training:	Epoch: [110][66/204]	Loss 0.0003 (0.0157)	
training:	Epoch: [110][67/204]	Loss 0.0221 (0.0158)	
training:	Epoch: [110][68/204]	Loss 0.0005 (0.0156)	
training:	Epoch: [110][69/204]	Loss 0.0005 (0.0154)	
training:	Epoch: [110][70/204]	Loss 0.0005 (0.0151)	
training:	Epoch: [110][71/204]	Loss 0.0004 (0.0149)	
training:	Epoch: [110][72/204]	Loss 0.0006 (0.0147)	
training:	Epoch: [110][73/204]	Loss 0.0004 (0.0145)	
training:	Epoch: [110][74/204]	Loss 0.0138 (0.0145)	
training:	Epoch: [110][75/204]	Loss 0.0092 (0.0145)	
training:	Epoch: [110][76/204]	Loss 0.0008 (0.0143)	
training:	Epoch: [110][77/204]	Loss 0.0005 (0.0141)	
training:	Epoch: [110][78/204]	Loss 0.0007 (0.0139)	
training:	Epoch: [110][79/204]	Loss 0.0004 (0.0138)	
training:	Epoch: [110][80/204]	Loss 0.0007 (0.0136)	
training:	Epoch: [110][81/204]	Loss 0.0007 (0.0134)	
training:	Epoch: [110][82/204]	Loss 0.0004 (0.0133)	
training:	Epoch: [110][83/204]	Loss 0.0006 (0.0131)	
training:	Epoch: [110][84/204]	Loss 0.0004 (0.0130)	
training:	Epoch: [110][85/204]	Loss 0.0175 (0.0130)	
training:	Epoch: [110][86/204]	Loss 0.0025 (0.0129)	
training:	Epoch: [110][87/204]	Loss 0.0016 (0.0128)	
training:	Epoch: [110][88/204]	Loss 0.0006 (0.0126)	
training:	Epoch: [110][89/204]	Loss 0.0004 (0.0125)	
training:	Epoch: [110][90/204]	Loss 0.0020 (0.0124)	
training:	Epoch: [110][91/204]	Loss 0.0006 (0.0123)	
training:	Epoch: [110][92/204]	Loss 0.0004 (0.0121)	
training:	Epoch: [110][93/204]	Loss 0.0527 (0.0126)	
training:	Epoch: [110][94/204]	Loss 0.0005 (0.0124)	
training:	Epoch: [110][95/204]	Loss 0.0006 (0.0123)	
training:	Epoch: [110][96/204]	Loss 0.0009 (0.0122)	
training:	Epoch: [110][97/204]	Loss 0.0005 (0.0121)	
training:	Epoch: [110][98/204]	Loss 0.0305 (0.0123)	
training:	Epoch: [110][99/204]	Loss 0.0019 (0.0122)	
training:	Epoch: [110][100/204]	Loss 0.0005 (0.0120)	
training:	Epoch: [110][101/204]	Loss 0.0004 (0.0119)	
training:	Epoch: [110][102/204]	Loss 0.0003 (0.0118)	
training:	Epoch: [110][103/204]	Loss 0.0017 (0.0117)	
training:	Epoch: [110][104/204]	Loss 0.0004 (0.0116)	
training:	Epoch: [110][105/204]	Loss 0.0015 (0.0115)	
training:	Epoch: [110][106/204]	Loss 0.0008 (0.0114)	
training:	Epoch: [110][107/204]	Loss 0.0153 (0.0114)	
training:	Epoch: [110][108/204]	Loss 0.0004 (0.0113)	
training:	Epoch: [110][109/204]	Loss 0.0004 (0.0112)	
training:	Epoch: [110][110/204]	Loss 0.0004 (0.0111)	
training:	Epoch: [110][111/204]	Loss 0.0022 (0.0111)	
training:	Epoch: [110][112/204]	Loss 0.0011 (0.0110)	
training:	Epoch: [110][113/204]	Loss 0.0004 (0.0109)	
training:	Epoch: [110][114/204]	Loss 0.0006 (0.0108)	
training:	Epoch: [110][115/204]	Loss 0.0004 (0.0107)	
training:	Epoch: [110][116/204]	Loss 0.0005 (0.0106)	
training:	Epoch: [110][117/204]	Loss 0.0025 (0.0105)	
training:	Epoch: [110][118/204]	Loss 0.0012 (0.0105)	
training:	Epoch: [110][119/204]	Loss 0.0004 (0.0104)	
training:	Epoch: [110][120/204]	Loss 0.0008 (0.0103)	
training:	Epoch: [110][121/204]	Loss 0.0007 (0.0102)	
training:	Epoch: [110][122/204]	Loss 0.0046 (0.0102)	
training:	Epoch: [110][123/204]	Loss 0.0004 (0.0101)	
training:	Epoch: [110][124/204]	Loss 0.0005 (0.0100)	
training:	Epoch: [110][125/204]	Loss 0.0010 (0.0099)	
training:	Epoch: [110][126/204]	Loss 0.0006 (0.0099)	
training:	Epoch: [110][127/204]	Loss 0.0038 (0.0098)	
training:	Epoch: [110][128/204]	Loss 0.0007 (0.0097)	
training:	Epoch: [110][129/204]	Loss 0.0005 (0.0097)	
training:	Epoch: [110][130/204]	Loss 0.0116 (0.0097)	
training:	Epoch: [110][131/204]	Loss 0.0012 (0.0096)	
training:	Epoch: [110][132/204]	Loss 0.0005 (0.0096)	
training:	Epoch: [110][133/204]	Loss 0.0122 (0.0096)	
training:	Epoch: [110][134/204]	Loss 0.0107 (0.0096)	
training:	Epoch: [110][135/204]	Loss 0.0004 (0.0095)	
training:	Epoch: [110][136/204]	Loss 0.0004 (0.0094)	
training:	Epoch: [110][137/204]	Loss 0.0008 (0.0094)	
training:	Epoch: [110][138/204]	Loss 0.0006 (0.0093)	
training:	Epoch: [110][139/204]	Loss 0.2148 (0.0108)	
training:	Epoch: [110][140/204]	Loss 0.0005 (0.0107)	
training:	Epoch: [110][141/204]	Loss 0.0004 (0.0107)	
training:	Epoch: [110][142/204]	Loss 0.0048 (0.0106)	
training:	Epoch: [110][143/204]	Loss 0.0004 (0.0105)	
training:	Epoch: [110][144/204]	Loss 0.0007 (0.0105)	
training:	Epoch: [110][145/204]	Loss 0.0301 (0.0106)	
training:	Epoch: [110][146/204]	Loss 0.0006 (0.0105)	
training:	Epoch: [110][147/204]	Loss 0.0004 (0.0105)	
training:	Epoch: [110][148/204]	Loss 0.0005 (0.0104)	
training:	Epoch: [110][149/204]	Loss 0.0004 (0.0103)	
training:	Epoch: [110][150/204]	Loss 0.0008 (0.0103)	
training:	Epoch: [110][151/204]	Loss 0.0005 (0.0102)	
training:	Epoch: [110][152/204]	Loss 0.0007 (0.0101)	
training:	Epoch: [110][153/204]	Loss 0.0004 (0.0101)	
training:	Epoch: [110][154/204]	Loss 0.1154 (0.0108)	
training:	Epoch: [110][155/204]	Loss 0.0004 (0.0107)	
training:	Epoch: [110][156/204]	Loss 0.0007 (0.0106)	
training:	Epoch: [110][157/204]	Loss 0.0006 (0.0106)	
training:	Epoch: [110][158/204]	Loss 0.0004 (0.0105)	
training:	Epoch: [110][159/204]	Loss 0.0018 (0.0105)	
training:	Epoch: [110][160/204]	Loss 0.0078 (0.0104)	
training:	Epoch: [110][161/204]	Loss 0.0004 (0.0104)	
training:	Epoch: [110][162/204]	Loss 0.0124 (0.0104)	
training:	Epoch: [110][163/204]	Loss 0.0004 (0.0103)	
training:	Epoch: [110][164/204]	Loss 0.0009 (0.0103)	
training:	Epoch: [110][165/204]	Loss 0.0004 (0.0102)	
training:	Epoch: [110][166/204]	Loss 0.0012 (0.0102)	
training:	Epoch: [110][167/204]	Loss 0.0004 (0.0101)	
training:	Epoch: [110][168/204]	Loss 0.0003 (0.0100)	
training:	Epoch: [110][169/204]	Loss 0.0005 (0.0100)	
training:	Epoch: [110][170/204]	Loss 0.0005 (0.0099)	
training:	Epoch: [110][171/204]	Loss 0.0150 (0.0100)	
training:	Epoch: [110][172/204]	Loss 0.0004 (0.0099)	
training:	Epoch: [110][173/204]	Loss 0.0003 (0.0098)	
training:	Epoch: [110][174/204]	Loss 0.0004 (0.0098)	
training:	Epoch: [110][175/204]	Loss 0.0004 (0.0097)	
training:	Epoch: [110][176/204]	Loss 0.0009 (0.0097)	
training:	Epoch: [110][177/204]	Loss 0.0003 (0.0096)	
training:	Epoch: [110][178/204]	Loss 0.0015 (0.0096)	
training:	Epoch: [110][179/204]	Loss 0.0009 (0.0095)	
training:	Epoch: [110][180/204]	Loss 0.0011 (0.0095)	
training:	Epoch: [110][181/204]	Loss 0.0003 (0.0094)	
training:	Epoch: [110][182/204]	Loss 0.0004 (0.0094)	
training:	Epoch: [110][183/204]	Loss 0.0193 (0.0094)	
training:	Epoch: [110][184/204]	Loss 0.0004 (0.0094)	
training:	Epoch: [110][185/204]	Loss 0.0010 (0.0093)	
training:	Epoch: [110][186/204]	Loss 0.0006 (0.0093)	
training:	Epoch: [110][187/204]	Loss 0.0091 (0.0093)	
training:	Epoch: [110][188/204]	Loss 0.0004 (0.0093)	
training:	Epoch: [110][189/204]	Loss 0.0004 (0.0092)	
training:	Epoch: [110][190/204]	Loss 0.0004 (0.0092)	
training:	Epoch: [110][191/204]	Loss 0.0004 (0.0091)	
training:	Epoch: [110][192/204]	Loss 0.0118 (0.0091)	
training:	Epoch: [110][193/204]	Loss 0.0004 (0.0091)	
training:	Epoch: [110][194/204]	Loss 0.0003 (0.0090)	
training:	Epoch: [110][195/204]	Loss 0.0004 (0.0090)	
training:	Epoch: [110][196/204]	Loss 0.0553 (0.0092)	
training:	Epoch: [110][197/204]	Loss 0.0008 (0.0092)	
training:	Epoch: [110][198/204]	Loss 0.0149 (0.0092)	
training:	Epoch: [110][199/204]	Loss 0.0842 (0.0096)	
training:	Epoch: [110][200/204]	Loss 0.0004 (0.0095)	
training:	Epoch: [110][201/204]	Loss 0.0007 (0.0095)	
training:	Epoch: [110][202/204]	Loss 0.0005 (0.0095)	
training:	Epoch: [110][203/204]	Loss 0.0004 (0.0094)	
training:	Epoch: [110][204/204]	Loss 0.0006 (0.0094)	
Training:	 Loss: 0.0094

Training:	 ACC: 0.9997 0.9997 0.9997 0.9997
Validation:	 ACC: 0.7799 0.7817 0.8188 0.7410
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3646
Pretraining:	Epoch 111/500
----------
training:	Epoch: [111][1/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [111][2/204]	Loss 0.0029 (0.0018)	
training:	Epoch: [111][3/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [111][4/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [111][5/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [111][6/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [111][7/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [111][8/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [111][9/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [111][10/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [111][11/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [111][12/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [111][13/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [111][14/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [111][15/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [111][16/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [111][17/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [111][18/204]	Loss 0.0024 (0.0007)	
training:	Epoch: [111][19/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [111][20/204]	Loss 0.0008 (0.0007)	
training:	Epoch: [111][21/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [111][22/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [111][23/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [111][24/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [111][25/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [111][26/204]	Loss 0.0008 (0.0007)	
training:	Epoch: [111][27/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [111][28/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [111][29/204]	Loss 0.1039 (0.0042)	
training:	Epoch: [111][30/204]	Loss 0.0024 (0.0042)	
training:	Epoch: [111][31/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [111][32/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [111][33/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [111][34/204]	Loss 0.0023 (0.0038)	
training:	Epoch: [111][35/204]	Loss 0.0013 (0.0037)	
training:	Epoch: [111][36/204]	Loss 0.0003 (0.0036)	
training:	Epoch: [111][37/204]	Loss 0.0009 (0.0035)	
training:	Epoch: [111][38/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [111][39/204]	Loss 0.0066 (0.0035)	
training:	Epoch: [111][40/204]	Loss 0.0008 (0.0035)	
training:	Epoch: [111][41/204]	Loss 0.0038 (0.0035)	
training:	Epoch: [111][42/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [111][43/204]	Loss 0.0471 (0.0044)	
training:	Epoch: [111][44/204]	Loss 0.0046 (0.0044)	
training:	Epoch: [111][45/204]	Loss 0.0049 (0.0044)	
training:	Epoch: [111][46/204]	Loss 0.0560 (0.0056)	
training:	Epoch: [111][47/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [111][48/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [111][49/204]	Loss 0.0044 (0.0053)	
training:	Epoch: [111][50/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [111][51/204]	Loss 0.0014 (0.0052)	
training:	Epoch: [111][52/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [111][53/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [111][54/204]	Loss 0.0042 (0.0050)	
training:	Epoch: [111][55/204]	Loss 0.0138 (0.0051)	
training:	Epoch: [111][56/204]	Loss 0.0442 (0.0058)	
training:	Epoch: [111][57/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [111][58/204]	Loss 0.0010 (0.0056)	
training:	Epoch: [111][59/204]	Loss 0.0010 (0.0056)	
training:	Epoch: [111][60/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [111][61/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [111][62/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [111][63/204]	Loss 0.0006 (0.0052)	
training:	Epoch: [111][64/204]	Loss 0.0008 (0.0052)	
training:	Epoch: [111][65/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [111][66/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [111][67/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [111][68/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [111][69/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [111][70/204]	Loss 0.0035 (0.0048)	
training:	Epoch: [111][71/204]	Loss 0.0466 (0.0054)	
training:	Epoch: [111][72/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [111][73/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [111][74/204]	Loss 0.0003 (0.0052)	
training:	Epoch: [111][75/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [111][76/204]	Loss 0.0202 (0.0053)	
training:	Epoch: [111][77/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [111][78/204]	Loss 0.0012 (0.0052)	
training:	Epoch: [111][79/204]	Loss 0.0005 (0.0052)	
training:	Epoch: [111][80/204]	Loss 0.0003 (0.0051)	
training:	Epoch: [111][81/204]	Loss 0.0072 (0.0051)	
training:	Epoch: [111][82/204]	Loss 0.0037 (0.0051)	
training:	Epoch: [111][83/204]	Loss 0.0005 (0.0051)	
training:	Epoch: [111][84/204]	Loss 0.0006 (0.0050)	
training:	Epoch: [111][85/204]	Loss 0.0006 (0.0049)	
training:	Epoch: [111][86/204]	Loss 0.0006 (0.0049)	
training:	Epoch: [111][87/204]	Loss 0.0023 (0.0049)	
training:	Epoch: [111][88/204]	Loss 0.0018 (0.0048)	
training:	Epoch: [111][89/204]	Loss 0.0005 (0.0048)	
training:	Epoch: [111][90/204]	Loss 0.0026 (0.0048)	
training:	Epoch: [111][91/204]	Loss 0.0392 (0.0051)	
training:	Epoch: [111][92/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [111][93/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [111][94/204]	Loss 0.0003 (0.0050)	
training:	Epoch: [111][95/204]	Loss 0.0703 (0.0057)	
training:	Epoch: [111][96/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [111][97/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [111][98/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [111][99/204]	Loss 0.0025 (0.0055)	
training:	Epoch: [111][100/204]	Loss 0.0012 (0.0054)	
training:	Epoch: [111][101/204]	Loss 0.0018 (0.0054)	
training:	Epoch: [111][102/204]	Loss 0.0005 (0.0054)	
training:	Epoch: [111][103/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [111][104/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [111][105/204]	Loss 0.0010 (0.0052)	
training:	Epoch: [111][106/204]	Loss 0.0007 (0.0052)	
training:	Epoch: [111][107/204]	Loss 0.0011 (0.0051)	
training:	Epoch: [111][108/204]	Loss 0.0006 (0.0051)	
training:	Epoch: [111][109/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [111][110/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [111][111/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [111][112/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [111][113/204]	Loss 0.1211 (0.0060)	
training:	Epoch: [111][114/204]	Loss 0.0010 (0.0059)	
training:	Epoch: [111][115/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [111][116/204]	Loss 0.0005 (0.0058)	
training:	Epoch: [111][117/204]	Loss 0.0004 (0.0058)	
training:	Epoch: [111][118/204]	Loss 0.0004 (0.0057)	
training:	Epoch: [111][119/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [111][120/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [111][121/204]	Loss 0.0007 (0.0056)	
training:	Epoch: [111][122/204]	Loss 0.0005 (0.0056)	
training:	Epoch: [111][123/204]	Loss 0.0003 (0.0055)	
training:	Epoch: [111][124/204]	Loss 0.0003 (0.0055)	
training:	Epoch: [111][125/204]	Loss 0.0010 (0.0054)	
training:	Epoch: [111][126/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [111][127/204]	Loss 0.2193 (0.0071)	
training:	Epoch: [111][128/204]	Loss 0.0006 (0.0070)	
training:	Epoch: [111][129/204]	Loss 0.0004 (0.0070)	
training:	Epoch: [111][130/204]	Loss 0.0086 (0.0070)	
training:	Epoch: [111][131/204]	Loss 0.0005 (0.0069)	
training:	Epoch: [111][132/204]	Loss 0.0005 (0.0069)	
training:	Epoch: [111][133/204]	Loss 0.0004 (0.0068)	
training:	Epoch: [111][134/204]	Loss 0.0004 (0.0068)	
training:	Epoch: [111][135/204]	Loss 0.0004 (0.0067)	
training:	Epoch: [111][136/204]	Loss 0.0004 (0.0067)	
training:	Epoch: [111][137/204]	Loss 0.0009 (0.0067)	
training:	Epoch: [111][138/204]	Loss 0.0004 (0.0066)	
training:	Epoch: [111][139/204]	Loss 0.0003 (0.0066)	
training:	Epoch: [111][140/204]	Loss 0.0005 (0.0065)	
training:	Epoch: [111][141/204]	Loss 0.0004 (0.0065)	
training:	Epoch: [111][142/204]	Loss 0.0007 (0.0064)	
training:	Epoch: [111][143/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [111][144/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [111][145/204]	Loss 0.0004 (0.0063)	
training:	Epoch: [111][146/204]	Loss 0.0005 (0.0063)	
training:	Epoch: [111][147/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [111][148/204]	Loss 0.0095 (0.0063)	
training:	Epoch: [111][149/204]	Loss 0.0005 (0.0062)	
training:	Epoch: [111][150/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [111][151/204]	Loss 0.0046 (0.0062)	
training:	Epoch: [111][152/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [111][153/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [111][154/204]	Loss 0.0008 (0.0061)	
training:	Epoch: [111][155/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [111][156/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [111][157/204]	Loss 0.0030 (0.0060)	
training:	Epoch: [111][158/204]	Loss 0.0003 (0.0059)	
training:	Epoch: [111][159/204]	Loss 0.0005 (0.0059)	
training:	Epoch: [111][160/204]	Loss 0.0003 (0.0059)	
training:	Epoch: [111][161/204]	Loss 0.0004 (0.0058)	
training:	Epoch: [111][162/204]	Loss 0.0003 (0.0058)	
training:	Epoch: [111][163/204]	Loss 0.0004 (0.0058)	
training:	Epoch: [111][164/204]	Loss 0.0003 (0.0057)	
training:	Epoch: [111][165/204]	Loss 0.0003 (0.0057)	
training:	Epoch: [111][166/204]	Loss 0.0007 (0.0057)	
training:	Epoch: [111][167/204]	Loss 0.0052 (0.0057)	
training:	Epoch: [111][168/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [111][169/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [111][170/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [111][171/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [111][172/204]	Loss 0.0020 (0.0055)	
training:	Epoch: [111][173/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [111][174/204]	Loss 0.0008 (0.0055)	
training:	Epoch: [111][175/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [111][176/204]	Loss 0.0003 (0.0054)	
training:	Epoch: [111][177/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [111][178/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [111][179/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [111][180/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [111][181/204]	Loss 0.0006 (0.0053)	
training:	Epoch: [111][182/204]	Loss 0.0008 (0.0052)	
training:	Epoch: [111][183/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [111][184/204]	Loss 0.0018 (0.0052)	
training:	Epoch: [111][185/204]	Loss 0.0006 (0.0052)	
training:	Epoch: [111][186/204]	Loss 0.0047 (0.0052)	
training:	Epoch: [111][187/204]	Loss 0.0032 (0.0052)	
training:	Epoch: [111][188/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [111][189/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [111][190/204]	Loss 0.0009 (0.0051)	
training:	Epoch: [111][191/204]	Loss 0.0013 (0.0051)	
training:	Epoch: [111][192/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [111][193/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [111][194/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [111][195/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [111][196/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [111][197/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [111][198/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [111][199/204]	Loss 0.0011 (0.0049)	
training:	Epoch: [111][200/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [111][201/204]	Loss 0.0009 (0.0048)	
training:	Epoch: [111][202/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [111][203/204]	Loss 0.0017 (0.0048)	
training:	Epoch: [111][204/204]	Loss 0.0005 (0.0048)	
Training:	 Loss: 0.0048

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7736 0.7742 0.7861 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4191
Pretraining:	Epoch 112/500
----------
training:	Epoch: [112][1/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [112][2/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [112][3/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][4/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][5/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][6/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][7/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [112][8/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [112][9/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [112][10/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][11/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][12/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [112][13/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [112][14/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][15/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [112][16/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][17/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][18/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [112][19/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][20/204]	Loss 0.0022 (0.0006)	
training:	Epoch: [112][21/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [112][22/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][23/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][24/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [112][25/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [112][26/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][27/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][28/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [112][29/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][30/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][31/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [112][32/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][33/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [112][34/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][35/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [112][36/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][37/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [112][38/204]	Loss 0.0063 (0.0007)	
training:	Epoch: [112][39/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][40/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][41/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][42/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [112][43/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [112][44/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][45/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][46/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [112][47/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][48/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][49/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [112][50/204]	Loss 0.0871 (0.0023)	
training:	Epoch: [112][51/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [112][52/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [112][53/204]	Loss 0.0154 (0.0025)	
training:	Epoch: [112][54/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [112][55/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [112][56/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [112][57/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [112][58/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [112][59/204]	Loss 0.0040 (0.0024)	
training:	Epoch: [112][60/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [112][61/204]	Loss 0.0025 (0.0023)	
training:	Epoch: [112][62/204]	Loss 0.0035 (0.0024)	
training:	Epoch: [112][63/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [112][64/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [112][65/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [112][66/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [112][67/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [112][68/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [112][69/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [112][70/204]	Loss 0.0009 (0.0021)	
training:	Epoch: [112][71/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [112][72/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [112][73/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [112][74/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [112][75/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [112][76/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [112][77/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [112][78/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [112][79/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [112][80/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [112][81/204]	Loss 0.2198 (0.0046)	
training:	Epoch: [112][82/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [112][83/204]	Loss 0.0058 (0.0046)	
training:	Epoch: [112][84/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [112][85/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [112][86/204]	Loss 0.0005 (0.0044)	
training:	Epoch: [112][87/204]	Loss 0.0010 (0.0044)	
training:	Epoch: [112][88/204]	Loss 0.0009 (0.0044)	
training:	Epoch: [112][89/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [112][90/204]	Loss 0.0029 (0.0043)	
training:	Epoch: [112][91/204]	Loss 0.0032 (0.0043)	
training:	Epoch: [112][92/204]	Loss 0.0018 (0.0043)	
training:	Epoch: [112][93/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [112][94/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [112][95/204]	Loss 0.0006 (0.0041)	
training:	Epoch: [112][96/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [112][97/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [112][98/204]	Loss 0.0008 (0.0040)	
training:	Epoch: [112][99/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [112][100/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [112][101/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [112][102/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [112][103/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [112][104/204]	Loss 0.0007 (0.0038)	
training:	Epoch: [112][105/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [112][106/204]	Loss 0.0007 (0.0038)	
training:	Epoch: [112][107/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [112][108/204]	Loss 0.0011 (0.0037)	
training:	Epoch: [112][109/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [112][110/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [112][111/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [112][112/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [112][113/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [112][114/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [112][115/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [112][116/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [112][117/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [112][118/204]	Loss 0.0007 (0.0034)	
training:	Epoch: [112][119/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [112][120/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [112][121/204]	Loss 0.0024 (0.0034)	
training:	Epoch: [112][122/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [112][123/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [112][124/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [112][125/204]	Loss 0.0017 (0.0033)	
training:	Epoch: [112][126/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [112][127/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [112][128/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [112][129/204]	Loss 0.0037 (0.0032)	
training:	Epoch: [112][130/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [112][131/204]	Loss 0.0154 (0.0033)	
training:	Epoch: [112][132/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [112][133/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [112][134/204]	Loss 0.0007 (0.0032)	
training:	Epoch: [112][135/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [112][136/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [112][137/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [112][138/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [112][139/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [112][140/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [112][141/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [112][142/204]	Loss 0.0010 (0.0031)	
training:	Epoch: [112][143/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [112][144/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [112][145/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [112][146/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [112][147/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [112][148/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [112][149/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [112][150/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [112][151/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [112][152/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [112][153/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [112][154/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [112][155/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [112][156/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [112][157/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [112][158/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [112][159/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [112][160/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [112][161/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [112][162/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [112][163/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [112][164/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [112][165/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [112][166/204]	Loss 0.0012 (0.0027)	
training:	Epoch: [112][167/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [112][168/204]	Loss 0.0011 (0.0027)	
training:	Epoch: [112][169/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [112][170/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [112][171/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [112][172/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [112][173/204]	Loss 0.0020 (0.0026)	
training:	Epoch: [112][174/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [112][175/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [112][176/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [112][177/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [112][178/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [112][179/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [112][180/204]	Loss 0.0325 (0.0027)	
training:	Epoch: [112][181/204]	Loss 0.0007 (0.0027)	
training:	Epoch: [112][182/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [112][183/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [112][184/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [112][185/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [112][186/204]	Loss 0.1646 (0.0035)	
training:	Epoch: [112][187/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [112][188/204]	Loss 0.0017 (0.0035)	
training:	Epoch: [112][189/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [112][190/204]	Loss 0.0298 (0.0036)	
training:	Epoch: [112][191/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [112][192/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [112][193/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [112][194/204]	Loss 0.0014 (0.0036)	
training:	Epoch: [112][195/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [112][196/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [112][197/204]	Loss 0.0008 (0.0035)	
training:	Epoch: [112][198/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [112][199/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [112][200/204]	Loss 0.0008 (0.0035)	
training:	Epoch: [112][201/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [112][202/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [112][203/204]	Loss 0.0008 (0.0034)	
training:	Epoch: [112][204/204]	Loss 0.0003 (0.0034)	
Training:	 Loss: 0.0034

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7762 0.7780 0.8147 0.7377
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4341
Pretraining:	Epoch 113/500
----------
training:	Epoch: [113][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [113][2/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [113][3/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [113][4/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [113][5/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [113][6/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [113][7/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [113][8/204]	Loss 0.0010 (0.0005)	
training:	Epoch: [113][9/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [113][10/204]	Loss 0.0013 (0.0006)	
training:	Epoch: [113][11/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [113][12/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [113][13/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [113][14/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [113][15/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [113][16/204]	Loss 0.0033 (0.0007)	
training:	Epoch: [113][17/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [113][18/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [113][19/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [113][20/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [113][21/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [113][22/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [113][23/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [113][24/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][25/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][26/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][27/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][28/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][29/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][30/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [113][31/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][32/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][33/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [113][34/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][35/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][36/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][37/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [113][38/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][39/204]	Loss 0.0030 (0.0006)	
training:	Epoch: [113][40/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][41/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][42/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][43/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [113][44/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][45/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][46/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][47/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][48/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [113][49/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][50/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][51/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][52/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][53/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][54/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][55/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][56/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][57/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [113][58/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [113][59/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][60/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][61/204]	Loss 0.0012 (0.0006)	
training:	Epoch: [113][62/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [113][63/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][64/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][65/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [113][66/204]	Loss 0.0049 (0.0007)	
training:	Epoch: [113][67/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [113][68/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [113][69/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [113][70/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [113][71/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [113][72/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][73/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][74/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][75/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][76/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][77/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][78/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][79/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][80/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][81/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][82/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][83/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][84/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][85/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][86/204]	Loss 0.0037 (0.0006)	
training:	Epoch: [113][87/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][88/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][89/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][90/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][91/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][92/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][93/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][94/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][95/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][96/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [113][97/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][98/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [113][99/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][100/204]	Loss 0.0034 (0.0006)	
training:	Epoch: [113][101/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [113][102/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][103/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][104/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][105/204]	Loss 0.0019 (0.0006)	
training:	Epoch: [113][106/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [113][107/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [113][108/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [113][109/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [113][110/204]	Loss 0.1640 (0.0021)	
training:	Epoch: [113][111/204]	Loss 0.2202 (0.0041)	
training:	Epoch: [113][112/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [113][113/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [113][114/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [113][115/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [113][116/204]	Loss 0.0121 (0.0040)	
training:	Epoch: [113][117/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [113][118/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [113][119/204]	Loss 0.0119 (0.0040)	
training:	Epoch: [113][120/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [113][121/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [113][122/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [113][123/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [113][124/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [113][125/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [113][126/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [113][127/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [113][128/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [113][129/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [113][130/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [113][131/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [113][132/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [113][133/204]	Loss 0.0008 (0.0037)	
training:	Epoch: [113][134/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [113][135/204]	Loss 0.0003 (0.0036)	
training:	Epoch: [113][136/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [113][137/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [113][138/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [113][139/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [113][140/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [113][141/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [113][142/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [113][143/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [113][144/204]	Loss 0.0027 (0.0034)	
training:	Epoch: [113][145/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [113][146/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [113][147/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [113][148/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [113][149/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [113][150/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [113][151/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [113][152/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [113][153/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [113][154/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [113][155/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [113][156/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [113][157/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [113][158/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [113][159/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [113][160/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [113][161/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [113][162/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [113][163/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [113][164/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [113][165/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [113][166/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [113][167/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [113][168/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [113][169/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [113][170/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [113][171/204]	Loss 0.0038 (0.0030)	
training:	Epoch: [113][172/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [113][173/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [113][174/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [113][175/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [113][176/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [113][177/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [113][178/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [113][179/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [113][180/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [113][181/204]	Loss 0.0034 (0.0029)	
training:	Epoch: [113][182/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [113][183/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [113][184/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [113][185/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [113][186/204]	Loss 0.0017 (0.0028)	
training:	Epoch: [113][187/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [113][188/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [113][189/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [113][190/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [113][191/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [113][192/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [113][193/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [113][194/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [113][195/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [113][196/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [113][197/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [113][198/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [113][199/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [113][200/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [113][201/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [113][202/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [113][203/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [113][204/204]	Loss 0.0003 (0.0026)	
Training:	 Loss: 0.0026

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7754 0.7769 0.8076 0.7433
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4366
Pretraining:	Epoch 114/500
----------
training:	Epoch: [114][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][2/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][3/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [114][4/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][6/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [114][7/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [114][8/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][9/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [114][10/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [114][11/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][12/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [114][13/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][14/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [114][15/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [114][16/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [114][17/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][18/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [114][19/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [114][20/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][21/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][22/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [114][23/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [114][24/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [114][25/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][26/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][27/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][28/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][29/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [114][30/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [114][31/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][32/204]	Loss 0.0011 (0.0004)	
training:	Epoch: [114][33/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [114][34/204]	Loss 0.0017 (0.0005)	
training:	Epoch: [114][35/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [114][36/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][37/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [114][38/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [114][39/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [114][40/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [114][41/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [114][42/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][43/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][44/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [114][45/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][46/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][47/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [114][48/204]	Loss 0.0022 (0.0005)	
training:	Epoch: [114][49/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][50/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [114][51/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [114][52/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][53/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][54/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][55/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [114][56/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][57/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][58/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [114][59/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [114][60/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][61/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][62/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [114][63/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [114][64/204]	Loss 0.0342 (0.0010)	
training:	Epoch: [114][65/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [114][66/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [114][67/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [114][68/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [114][69/204]	Loss 0.0010 (0.0010)	
training:	Epoch: [114][70/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [114][71/204]	Loss 0.0060 (0.0010)	
training:	Epoch: [114][72/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [114][73/204]	Loss 0.0015 (0.0010)	
training:	Epoch: [114][74/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [114][75/204]	Loss 0.0007 (0.0010)	
training:	Epoch: [114][76/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [114][77/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [114][78/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [114][79/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [114][80/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [114][81/204]	Loss 0.0009 (0.0010)	
training:	Epoch: [114][82/204]	Loss 0.0007 (0.0010)	
training:	Epoch: [114][83/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [114][84/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [114][85/204]	Loss 0.0012 (0.0010)	
training:	Epoch: [114][86/204]	Loss 0.0011 (0.0010)	
training:	Epoch: [114][87/204]	Loss 0.0103 (0.0011)	
training:	Epoch: [114][88/204]	Loss 0.0195 (0.0013)	
training:	Epoch: [114][89/204]	Loss 0.0006 (0.0013)	
training:	Epoch: [114][90/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [114][91/204]	Loss 0.0007 (0.0013)	
training:	Epoch: [114][92/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [114][93/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [114][94/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [114][95/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [114][96/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [114][97/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [114][98/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [114][99/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [114][100/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [114][101/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [114][102/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [114][103/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [114][104/204]	Loss 0.0022 (0.0012)	
training:	Epoch: [114][105/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [114][106/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [114][107/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [114][108/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [114][109/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [114][110/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [114][111/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [114][112/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [114][113/204]	Loss 0.2131 (0.0030)	
training:	Epoch: [114][114/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [114][115/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [114][116/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [114][117/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [114][118/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [114][119/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [114][120/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [114][121/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [114][122/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [114][123/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [114][124/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [114][125/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [114][126/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [114][127/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [114][128/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [114][129/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [114][130/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [114][131/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [114][132/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [114][133/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [114][134/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [114][135/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [114][136/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [114][137/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [114][138/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][139/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][140/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [114][141/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][142/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][143/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [114][144/204]	Loss 0.0024 (0.0025)	
training:	Epoch: [114][145/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [114][146/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [114][147/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [114][148/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [114][149/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [114][150/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [114][151/204]	Loss 0.0332 (0.0026)	
training:	Epoch: [114][152/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [114][153/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [114][154/204]	Loss 0.0009 (0.0026)	
training:	Epoch: [114][155/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][156/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][157/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [114][158/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][159/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][160/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [114][161/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [114][162/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [114][163/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [114][164/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [114][165/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [114][166/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [114][167/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [114][168/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [114][169/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [114][170/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [114][171/204]	Loss 0.0263 (0.0025)	
training:	Epoch: [114][172/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [114][173/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][174/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [114][175/204]	Loss 0.0295 (0.0026)	
training:	Epoch: [114][176/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [114][177/204]	Loss 0.0098 (0.0026)	
training:	Epoch: [114][178/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [114][179/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [114][180/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [114][181/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [114][182/204]	Loss 0.0017 (0.0026)	
training:	Epoch: [114][183/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [114][184/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [114][185/204]	Loss 0.0007 (0.0026)	
training:	Epoch: [114][186/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [114][187/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][188/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [114][189/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][190/204]	Loss 0.0007 (0.0025)	
training:	Epoch: [114][191/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [114][192/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][193/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [114][194/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][195/204]	Loss 0.0103 (0.0025)	
training:	Epoch: [114][196/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [114][197/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [114][198/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [114][199/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [114][200/204]	Loss 0.0012 (0.0024)	
training:	Epoch: [114][201/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [114][202/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [114][203/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [114][204/204]	Loss 0.0005 (0.0024)	
Training:	 Loss: 0.0024

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7774 0.7785 0.8004 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4361
Pretraining:	Epoch 115/500
----------
training:	Epoch: [115][1/204]	Loss 0.0014 (0.0014)	
training:	Epoch: [115][2/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][3/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [115][4/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [115][5/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [115][6/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [115][7/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [115][8/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [115][9/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [115][10/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [115][11/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [115][12/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [115][13/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [115][14/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [115][15/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [115][16/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [115][17/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [115][18/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [115][19/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [115][20/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [115][21/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [115][22/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [115][23/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [115][24/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [115][25/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [115][26/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [115][27/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [115][28/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [115][29/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [115][30/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [115][31/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [115][32/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [115][33/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [115][34/204]	Loss 0.0013 (0.0006)	
training:	Epoch: [115][35/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [115][36/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [115][37/204]	Loss 0.0102 (0.0008)	
training:	Epoch: [115][38/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [115][39/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [115][40/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [115][41/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [115][42/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [115][43/204]	Loss 0.0013 (0.0008)	
training:	Epoch: [115][44/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [115][45/204]	Loss 0.0015 (0.0008)	
training:	Epoch: [115][46/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [115][47/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [115][48/204]	Loss 0.0054 (0.0009)	
training:	Epoch: [115][49/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][50/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [115][51/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [115][52/204]	Loss 0.0017 (0.0009)	
training:	Epoch: [115][53/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [115][54/204]	Loss 0.0242 (0.0013)	
training:	Epoch: [115][55/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [115][56/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [115][57/204]	Loss 0.0011 (0.0013)	
training:	Epoch: [115][58/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [115][59/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][60/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [115][61/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][62/204]	Loss 0.0016 (0.0012)	
training:	Epoch: [115][63/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][64/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [115][65/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][66/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [115][67/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [115][68/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [115][69/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [115][70/204]	Loss 0.0188 (0.0014)	
training:	Epoch: [115][71/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [115][72/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [115][73/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [115][74/204]	Loss 0.0006 (0.0013)	
training:	Epoch: [115][75/204]	Loss 0.0012 (0.0013)	
training:	Epoch: [115][76/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [115][77/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [115][78/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [115][79/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [115][80/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [115][81/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [115][82/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [115][83/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][84/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][85/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [115][86/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [115][87/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][88/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [115][89/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][90/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][91/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][92/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][93/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [115][94/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [115][95/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [115][96/204]	Loss 0.0012 (0.0011)	
training:	Epoch: [115][97/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [115][98/204]	Loss 0.0020 (0.0011)	
training:	Epoch: [115][99/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [115][100/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [115][101/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [115][102/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [115][103/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [115][104/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [115][105/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [115][106/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [115][107/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [115][108/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [115][109/204]	Loss 0.0011 (0.0011)	
training:	Epoch: [115][110/204]	Loss 0.0007 (0.0011)	
training:	Epoch: [115][111/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [115][112/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [115][113/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][114/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [115][115/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [115][116/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][117/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [115][118/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][119/204]	Loss 0.0010 (0.0010)	
training:	Epoch: [115][120/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][121/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][122/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][123/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][124/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [115][125/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [115][126/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [115][127/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [115][128/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][129/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][130/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][131/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [115][132/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][133/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [115][134/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][135/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [115][136/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [115][137/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [115][138/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [115][139/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [115][140/204]	Loss 0.0015 (0.0009)	
training:	Epoch: [115][141/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [115][142/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][143/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][144/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [115][145/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][146/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [115][147/204]	Loss 0.0012 (0.0009)	
training:	Epoch: [115][148/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][149/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][150/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [115][151/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][152/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [115][153/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][154/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][155/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [115][156/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][157/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [115][158/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [115][159/204]	Loss 0.0009 (0.0009)	
training:	Epoch: [115][160/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [115][161/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [115][162/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [115][163/204]	Loss 0.0155 (0.0010)	
training:	Epoch: [115][164/204]	Loss 0.0008 (0.0010)	
training:	Epoch: [115][165/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [115][166/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [115][167/204]	Loss 0.0017 (0.0010)	
training:	Epoch: [115][168/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [115][169/204]	Loss 0.2192 (0.0022)	
training:	Epoch: [115][170/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [115][171/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [115][172/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [115][173/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [115][174/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [115][175/204]	Loss 0.0008 (0.0022)	
training:	Epoch: [115][176/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [115][177/204]	Loss 0.0009 (0.0022)	
training:	Epoch: [115][178/204]	Loss 0.2308 (0.0035)	
training:	Epoch: [115][179/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [115][180/204]	Loss 0.0011 (0.0034)	
training:	Epoch: [115][181/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [115][182/204]	Loss 0.0009 (0.0034)	
training:	Epoch: [115][183/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [115][184/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [115][185/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [115][186/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [115][187/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [115][188/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [115][189/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [115][190/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [115][191/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [115][192/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [115][193/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [115][194/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [115][195/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [115][196/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [115][197/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [115][198/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [115][199/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [115][200/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [115][201/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [115][202/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [115][203/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [115][204/204]	Loss 0.0004 (0.0031)	
Training:	 Loss: 0.0031

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7804 0.7806 0.7861 0.7747
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4627
Pretraining:	Epoch 116/500
----------
training:	Epoch: [116][1/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [116][2/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [116][3/204]	Loss 0.0011 (0.0007)	
training:	Epoch: [116][4/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [116][5/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [116][6/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][7/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][8/204]	Loss 0.0051 (0.0012)	
training:	Epoch: [116][9/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [116][10/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [116][11/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [116][12/204]	Loss 0.0084 (0.0016)	
training:	Epoch: [116][13/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [116][14/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [116][15/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [116][16/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [116][17/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [116][18/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [116][19/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [116][20/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [116][21/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [116][22/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [116][23/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [116][24/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [116][25/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [116][26/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [116][27/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [116][28/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [116][29/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [116][30/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [116][31/204]	Loss 0.0008 (0.0009)	
training:	Epoch: [116][32/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [116][33/204]	Loss 0.0037 (0.0010)	
training:	Epoch: [116][34/204]	Loss 0.0009 (0.0010)	
training:	Epoch: [116][35/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [116][36/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [116][37/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [116][38/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [116][39/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [116][40/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [116][41/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [116][42/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [116][43/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [116][44/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [116][45/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [116][46/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [116][47/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [116][48/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [116][49/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [116][50/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [116][51/204]	Loss 0.0017 (0.0008)	
training:	Epoch: [116][52/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [116][53/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [116][54/204]	Loss 0.0011 (0.0008)	
training:	Epoch: [116][55/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [116][56/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [116][57/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [116][58/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [116][59/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [116][60/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][61/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [116][62/204]	Loss 0.0023 (0.0008)	
training:	Epoch: [116][63/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [116][64/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [116][65/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [116][66/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [116][67/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [116][68/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][69/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [116][70/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][71/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][72/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [116][73/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [116][74/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [116][75/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][76/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][77/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][78/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [116][79/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][80/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [116][81/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][82/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][83/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [116][84/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][85/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [116][86/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][87/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][88/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [116][89/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][90/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][91/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][92/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [116][93/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][94/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][95/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][96/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][97/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][98/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][99/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][100/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][101/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [116][102/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][103/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [116][104/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][105/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [116][106/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [116][107/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][108/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][109/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][110/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][111/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][112/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][113/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][114/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][115/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][116/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][117/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][118/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][119/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][120/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][121/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][122/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][123/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][124/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][125/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][126/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][127/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][128/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][129/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][130/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][131/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][132/204]	Loss 0.0023 (0.0006)	
training:	Epoch: [116][133/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][134/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][135/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][136/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][137/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][138/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][139/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][140/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][141/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][142/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][143/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][144/204]	Loss 0.0015 (0.0006)	
training:	Epoch: [116][145/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [116][146/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][147/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][148/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][149/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [116][150/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][151/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][152/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][153/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][154/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][155/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][156/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][157/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][158/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [116][159/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][160/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][161/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][162/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][163/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][164/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][165/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [116][166/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][167/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][168/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][169/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][170/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][171/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][172/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][173/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][174/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][175/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][176/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][177/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][178/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [116][179/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [116][180/204]	Loss 0.0031 (0.0006)	
training:	Epoch: [116][181/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][182/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][183/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][184/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][185/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][186/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][187/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][188/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [116][189/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [116][190/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][191/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [116][192/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [116][193/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [116][194/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [116][195/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [116][196/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [116][197/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [116][198/204]	Loss 0.2141 (0.0016)	
training:	Epoch: [116][199/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [116][200/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [116][201/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [116][202/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [116][203/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [116][204/204]	Loss 0.0003 (0.0016)	
Training:	 Loss: 0.0016

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7777 0.7790 0.8066 0.7489
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4858
Pretraining:	Epoch 117/500
----------
training:	Epoch: [117][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [117][3/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [117][4/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [117][5/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [117][6/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [117][7/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][8/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][9/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][11/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][12/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][13/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][14/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][15/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][16/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][17/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [117][18/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][19/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][20/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][21/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][22/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][23/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][24/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][25/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][26/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][27/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][28/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][29/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][30/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][31/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][32/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][33/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][34/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][35/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][36/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][37/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][38/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][39/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][40/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][41/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][42/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][43/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][44/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][45/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][46/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][47/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][48/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][49/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][50/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][51/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][52/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][53/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [117][54/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][55/204]	Loss 0.0037 (0.0004)	
training:	Epoch: [117][56/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][57/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][58/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][59/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][60/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][61/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][62/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][63/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][64/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][65/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][66/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][67/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][68/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][69/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][70/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][71/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][72/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][73/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][74/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [117][75/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][76/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][77/204]	Loss 0.0020 (0.0004)	
training:	Epoch: [117][78/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][79/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][80/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][81/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [117][82/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][83/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [117][84/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][85/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][86/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][87/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][88/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][89/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][90/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][91/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][92/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][93/204]	Loss 0.0018 (0.0005)	
training:	Epoch: [117][94/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][95/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][96/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [117][97/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][98/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][99/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][100/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][101/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][102/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [117][103/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][104/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][105/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][106/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][107/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][108/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][109/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][110/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][111/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][112/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][113/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][114/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][115/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][116/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][117/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][118/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][119/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][120/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][121/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][122/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][123/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][124/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][125/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][126/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][127/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][128/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][129/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][130/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][131/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][132/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][133/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [117][134/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][135/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][136/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][137/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [117][138/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][139/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][140/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][141/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][142/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][143/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][144/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][145/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][146/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][147/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][148/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][149/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][150/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][151/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][152/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][153/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][154/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][155/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][156/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][157/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][158/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][159/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][160/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][161/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][162/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][163/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][164/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [117][165/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [117][166/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][167/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][168/204]	Loss 0.0067 (0.0005)	
training:	Epoch: [117][169/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][170/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][171/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][172/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [117][173/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][174/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][175/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][176/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][177/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][178/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][179/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][180/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][181/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][182/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [117][183/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][184/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][185/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][186/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][187/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][188/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [117][189/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][190/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [117][191/204]	Loss 0.0010 (0.0005)	
training:	Epoch: [117][192/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][193/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [117][194/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][195/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [117][196/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][197/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [117][198/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [117][199/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [117][200/204]	Loss 0.2127 (0.0015)	
training:	Epoch: [117][201/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [117][202/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [117][203/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [117][204/204]	Loss 0.0005 (0.0015)	
Training:	 Loss: 0.0015

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7752 0.7774 0.8240 0.7265
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5159
Pretraining:	Epoch 118/500
----------
training:	Epoch: [118][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [118][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [118][3/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [118][4/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [118][5/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [118][6/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [118][7/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [118][8/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [118][9/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [118][10/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [118][11/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [118][12/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [118][13/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [118][14/204]	Loss 0.0130 (0.0012)	
training:	Epoch: [118][15/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [118][16/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [118][17/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [118][18/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [118][19/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [118][20/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [118][21/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [118][22/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [118][23/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [118][24/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [118][25/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [118][26/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [118][27/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [118][28/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [118][29/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [118][30/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [118][31/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [118][32/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [118][33/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [118][34/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [118][35/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [118][36/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [118][37/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [118][38/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [118][39/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [118][40/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [118][41/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [118][42/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [118][43/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [118][44/204]	Loss 0.0255 (0.0012)	
training:	Epoch: [118][45/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [118][46/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [118][47/204]	Loss 0.0139 (0.0014)	
training:	Epoch: [118][48/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [118][49/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [118][50/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [118][51/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [118][52/204]	Loss 0.0011 (0.0014)	
training:	Epoch: [118][53/204]	Loss 0.0573 (0.0024)	
training:	Epoch: [118][54/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [118][55/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [118][56/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [118][57/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [118][58/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [118][59/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [118][60/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [118][61/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [118][62/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [118][63/204]	Loss 0.0023 (0.0021)	
training:	Epoch: [118][64/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [118][65/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [118][66/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [118][67/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [118][68/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [118][69/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [118][70/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [118][71/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [118][72/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [118][73/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [118][74/204]	Loss 0.0022 (0.0019)	
training:	Epoch: [118][75/204]	Loss 0.0060 (0.0019)	
training:	Epoch: [118][76/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [118][77/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [118][78/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [118][79/204]	Loss 0.0011 (0.0019)	
training:	Epoch: [118][80/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [118][81/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [118][82/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [118][83/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [118][84/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [118][85/204]	Loss 0.0176 (0.0020)	
training:	Epoch: [118][86/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [118][87/204]	Loss 0.0008 (0.0019)	
training:	Epoch: [118][88/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [118][89/204]	Loss 0.0046 (0.0020)	
training:	Epoch: [118][90/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [118][91/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [118][92/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [118][93/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [118][94/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [118][95/204]	Loss 0.0016 (0.0019)	
training:	Epoch: [118][96/204]	Loss 0.0094 (0.0019)	
training:	Epoch: [118][97/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [118][98/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [118][99/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [118][100/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [118][101/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [118][102/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [118][103/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [118][104/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [118][105/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [118][106/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [118][107/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [118][108/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [118][109/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [118][110/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [118][111/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [118][112/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [118][113/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [118][114/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [118][115/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [118][116/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [118][117/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [118][118/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [118][119/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [118][120/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [118][121/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [118][122/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [118][123/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [118][124/204]	Loss 0.0011 (0.0016)	
training:	Epoch: [118][125/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [118][126/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [118][127/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [118][128/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [118][129/204]	Loss 0.0069 (0.0016)	
training:	Epoch: [118][130/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [118][131/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [118][132/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [118][133/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [118][134/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [118][135/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [118][136/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [118][137/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [118][138/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [118][139/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [118][140/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [118][141/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [118][142/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [118][143/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [118][144/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [118][145/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [118][146/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [118][147/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [118][148/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [118][149/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [118][150/204]	Loss 0.2098 (0.0028)	
training:	Epoch: [118][151/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [118][152/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [118][153/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [118][154/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [118][155/204]	Loss 0.0006 (0.0028)	
training:	Epoch: [118][156/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [118][157/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [118][158/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [118][159/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [118][160/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [118][161/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [118][162/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [118][163/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [118][164/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [118][165/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [118][166/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [118][167/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [118][168/204]	Loss 0.0011 (0.0026)	
training:	Epoch: [118][169/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [118][170/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [118][171/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [118][172/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [118][173/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [118][174/204]	Loss 0.0018 (0.0025)	
training:	Epoch: [118][175/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [118][176/204]	Loss 0.0057 (0.0025)	
training:	Epoch: [118][177/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [118][178/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [118][179/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [118][180/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [118][181/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [118][182/204]	Loss 0.0010 (0.0024)	
training:	Epoch: [118][183/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [118][184/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [118][185/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [118][186/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [118][187/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [118][188/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [118][189/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [118][190/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [118][191/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [118][192/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [118][193/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [118][194/204]	Loss 0.0020 (0.0023)	
training:	Epoch: [118][195/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [118][196/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [118][197/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [118][198/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [118][199/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [118][200/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [118][201/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [118][202/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [118][203/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [118][204/204]	Loss 0.0003 (0.0022)	
Training:	 Loss: 0.0022

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7825 0.7833 0.8004 0.7646
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4854
Pretraining:	Epoch 119/500
----------
training:	Epoch: [119][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [119][2/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [119][3/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [119][4/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [119][5/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [119][6/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [119][7/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [119][8/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [119][9/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [119][10/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [119][11/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [119][12/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [119][13/204]	Loss 0.0032 (0.0006)	
training:	Epoch: [119][14/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [119][15/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [119][16/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [119][17/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [119][18/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [119][19/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [119][20/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [119][21/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [119][22/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [119][23/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [119][24/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [119][25/204]	Loss 0.0168 (0.0012)	
training:	Epoch: [119][26/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [119][27/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [119][28/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [119][29/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [119][30/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [119][31/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [119][32/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [119][33/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [119][34/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [119][35/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [119][36/204]	Loss 0.0026 (0.0010)	
training:	Epoch: [119][37/204]	Loss 0.0224 (0.0016)	
training:	Epoch: [119][38/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [119][39/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [119][40/204]	Loss 0.0032 (0.0016)	
training:	Epoch: [119][41/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [119][42/204]	Loss 0.0007 (0.0015)	
training:	Epoch: [119][43/204]	Loss 0.2008 (0.0062)	
training:	Epoch: [119][44/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [119][45/204]	Loss 0.0003 (0.0059)	
training:	Epoch: [119][46/204]	Loss 0.0004 (0.0058)	
training:	Epoch: [119][47/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [119][48/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [119][49/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [119][50/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [119][51/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [119][52/204]	Loss 0.0003 (0.0052)	
training:	Epoch: [119][53/204]	Loss 0.0006 (0.0051)	
training:	Epoch: [119][54/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [119][55/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [119][56/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [119][57/204]	Loss 0.0005 (0.0047)	
training:	Epoch: [119][58/204]	Loss 0.0003 (0.0047)	
training:	Epoch: [119][59/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [119][60/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [119][61/204]	Loss 0.0011 (0.0045)	
training:	Epoch: [119][62/204]	Loss 0.0009 (0.0044)	
training:	Epoch: [119][63/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [119][64/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [119][65/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [119][66/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [119][67/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [119][68/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [119][69/204]	Loss 0.0012 (0.0040)	
training:	Epoch: [119][70/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [119][71/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [119][72/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [119][73/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [119][74/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [119][75/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [119][76/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [119][77/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [119][78/204]	Loss 0.0005 (0.0036)	
training:	Epoch: [119][79/204]	Loss 0.0003 (0.0036)	
training:	Epoch: [119][80/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [119][81/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [119][82/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [119][83/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [119][84/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [119][85/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [119][86/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [119][87/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [119][88/204]	Loss 0.0005 (0.0032)	
training:	Epoch: [119][89/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [119][90/204]	Loss 0.0010 (0.0032)	
training:	Epoch: [119][91/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [119][92/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [119][93/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [119][94/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [119][95/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [119][96/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [119][97/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [119][98/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [119][99/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [119][100/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [119][101/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [119][102/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [119][103/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [119][104/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [119][105/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [119][106/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [119][107/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [119][108/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [119][109/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [119][110/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [119][111/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [119][112/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [119][113/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [119][114/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [119][115/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [119][116/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [119][117/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [119][118/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [119][119/204]	Loss 0.0007 (0.0025)	
training:	Epoch: [119][120/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [119][121/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [119][122/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [119][123/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [119][124/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [119][125/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [119][126/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [119][127/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [119][128/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [119][129/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [119][130/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [119][131/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [119][132/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [119][133/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [119][134/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [119][135/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [119][136/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [119][137/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [119][138/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [119][139/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [119][140/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [119][141/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [119][142/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [119][143/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [119][144/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [119][145/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [119][146/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [119][147/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [119][148/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [119][149/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [119][150/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [119][151/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [119][152/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [119][153/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [119][154/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [119][155/204]	Loss 0.0029 (0.0020)	
training:	Epoch: [119][156/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [119][157/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [119][158/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [119][159/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [119][160/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [119][161/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [119][162/204]	Loss 0.0025 (0.0020)	
training:	Epoch: [119][163/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [119][164/204]	Loss 0.0021 (0.0020)	
training:	Epoch: [119][165/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [119][166/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [119][167/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [119][168/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [119][169/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [119][170/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [119][171/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [119][172/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [119][173/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [119][174/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [119][175/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [119][176/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [119][177/204]	Loss 0.0030 (0.0019)	
training:	Epoch: [119][178/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [119][179/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [119][180/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [119][181/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [119][182/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [119][183/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [119][184/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [119][185/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [119][186/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [119][187/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [119][188/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [119][189/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [119][190/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [119][191/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [119][192/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [119][193/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [119][194/204]	Loss 0.0008 (0.0017)	
training:	Epoch: [119][195/204]	Loss 0.0007 (0.0017)	
training:	Epoch: [119][196/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [119][197/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [119][198/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [119][199/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [119][200/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [119][201/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [119][202/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [119][203/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [119][204/204]	Loss 0.0004 (0.0017)	
Training:	 Loss: 0.0017

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7758 0.7764 0.7871 0.7646
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5356
Pretraining:	Epoch 120/500
----------
training:	Epoch: [120][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [120][2/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [120][3/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [120][4/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [120][5/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [120][6/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [120][7/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [120][8/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [120][9/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [120][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [120][11/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [120][12/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [120][13/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [120][14/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [120][15/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [120][16/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [120][17/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [120][18/204]	Loss 0.2064 (0.0118)	
training:	Epoch: [120][19/204]	Loss 0.0003 (0.0112)	
training:	Epoch: [120][20/204]	Loss 0.0030 (0.0108)	
training:	Epoch: [120][21/204]	Loss 0.0003 (0.0103)	
training:	Epoch: [120][22/204]	Loss 0.0003 (0.0099)	
training:	Epoch: [120][23/204]	Loss 0.0003 (0.0094)	
training:	Epoch: [120][24/204]	Loss 0.0004 (0.0091)	
training:	Epoch: [120][25/204]	Loss 0.0005 (0.0087)	
training:	Epoch: [120][26/204]	Loss 0.0003 (0.0084)	
training:	Epoch: [120][27/204]	Loss 0.0005 (0.0081)	
training:	Epoch: [120][28/204]	Loss 0.0004 (0.0078)	
training:	Epoch: [120][29/204]	Loss 0.0003 (0.0076)	
training:	Epoch: [120][30/204]	Loss 0.0003 (0.0073)	
training:	Epoch: [120][31/204]	Loss 0.0004 (0.0071)	
training:	Epoch: [120][32/204]	Loss 0.0004 (0.0069)	
training:	Epoch: [120][33/204]	Loss 0.0004 (0.0067)	
training:	Epoch: [120][34/204]	Loss 0.0003 (0.0065)	
training:	Epoch: [120][35/204]	Loss 0.0004 (0.0063)	
training:	Epoch: [120][36/204]	Loss 0.0003 (0.0062)	
training:	Epoch: [120][37/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [120][38/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [120][39/204]	Loss 0.0003 (0.0057)	
training:	Epoch: [120][40/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [120][41/204]	Loss 0.0003 (0.0055)	
training:	Epoch: [120][42/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [120][43/204]	Loss 0.0003 (0.0052)	
training:	Epoch: [120][44/204]	Loss 0.0003 (0.0051)	
training:	Epoch: [120][45/204]	Loss 0.0009 (0.0050)	
training:	Epoch: [120][46/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [120][47/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [120][48/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [120][49/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [120][50/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [120][51/204]	Loss 0.0006 (0.0045)	
training:	Epoch: [120][52/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [120][53/204]	Loss 0.0003 (0.0043)	
training:	Epoch: [120][54/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [120][55/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [120][56/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [120][57/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [120][58/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [120][59/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [120][60/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [120][61/204]	Loss 0.0012 (0.0038)	
training:	Epoch: [120][62/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [120][63/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [120][64/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [120][65/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [120][66/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [120][67/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [120][68/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [120][69/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [120][70/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [120][71/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [120][72/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [120][73/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [120][74/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [120][75/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [120][76/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [120][77/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [120][78/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [120][79/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [120][80/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [120][81/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [120][82/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [120][83/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [120][84/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [120][85/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [120][86/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [120][87/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [120][88/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [120][89/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [120][90/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [120][91/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [120][92/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [120][93/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [120][94/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [120][95/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [120][96/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [120][97/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [120][98/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [120][99/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [120][100/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [120][101/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [120][102/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [120][103/204]	Loss 0.0007 (0.0024)	
training:	Epoch: [120][104/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [120][105/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [120][106/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [120][107/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [120][108/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [120][109/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [120][110/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [120][111/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [120][112/204]	Loss 0.0106 (0.0023)	
training:	Epoch: [120][113/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [120][114/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [120][115/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [120][116/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [120][117/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [120][118/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [120][119/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [120][120/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [120][121/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [120][122/204]	Loss 0.0009 (0.0022)	
training:	Epoch: [120][123/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [120][124/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [120][125/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [120][126/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [120][127/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [120][128/204]	Loss 0.0073 (0.0022)	
training:	Epoch: [120][129/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [120][130/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [120][131/204]	Loss 0.0033 (0.0021)	
training:	Epoch: [120][132/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [120][133/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [120][134/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [120][135/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [120][136/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [120][137/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [120][138/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [120][139/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [120][140/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [120][141/204]	Loss 0.0009 (0.0020)	
training:	Epoch: [120][142/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [120][143/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [120][144/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [120][145/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [120][146/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [120][147/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [120][148/204]	Loss 0.0839 (0.0025)	
training:	Epoch: [120][149/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [120][150/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [120][151/204]	Loss 0.0007 (0.0025)	
training:	Epoch: [120][152/204]	Loss 0.0010 (0.0025)	
training:	Epoch: [120][153/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [120][154/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [120][155/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [120][156/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [120][157/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [120][158/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [120][159/204]	Loss 0.0692 (0.0028)	
training:	Epoch: [120][160/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [120][161/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [120][162/204]	Loss 0.0015 (0.0028)	
training:	Epoch: [120][163/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [120][164/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [120][165/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [120][166/204]	Loss 0.0769 (0.0032)	
training:	Epoch: [120][167/204]	Loss 0.0016 (0.0032)	
training:	Epoch: [120][168/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [120][169/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [120][170/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [120][171/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [120][172/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [120][173/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [120][174/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [120][175/204]	Loss 0.0060 (0.0031)	
training:	Epoch: [120][176/204]	Loss 0.0022 (0.0031)	
training:	Epoch: [120][177/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [120][178/204]	Loss 0.1173 (0.0037)	
training:	Epoch: [120][179/204]	Loss 0.2035 (0.0048)	
training:	Epoch: [120][180/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [120][181/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [120][182/204]	Loss 0.1392 (0.0055)	
training:	Epoch: [120][183/204]	Loss 0.0019 (0.0055)	
training:	Epoch: [120][184/204]	Loss 0.0010 (0.0055)	
training:	Epoch: [120][185/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [120][186/204]	Loss 0.0005 (0.0054)	
training:	Epoch: [120][187/204]	Loss 0.0008 (0.0054)	
training:	Epoch: [120][188/204]	Loss 0.0003 (0.0053)	
training:	Epoch: [120][189/204]	Loss 0.0015 (0.0053)	
training:	Epoch: [120][190/204]	Loss 0.0097 (0.0054)	
training:	Epoch: [120][191/204]	Loss 0.0034 (0.0053)	
training:	Epoch: [120][192/204]	Loss 0.0066 (0.0053)	
training:	Epoch: [120][193/204]	Loss 0.1589 (0.0061)	
training:	Epoch: [120][194/204]	Loss 0.0257 (0.0062)	
training:	Epoch: [120][195/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [120][196/204]	Loss 0.0003 (0.0062)	
training:	Epoch: [120][197/204]	Loss 0.0014 (0.0062)	
training:	Epoch: [120][198/204]	Loss 0.0003 (0.0061)	
training:	Epoch: [120][199/204]	Loss 0.0460 (0.0063)	
training:	Epoch: [120][200/204]	Loss 0.0003 (0.0063)	
training:	Epoch: [120][201/204]	Loss 0.0003 (0.0063)	
training:	Epoch: [120][202/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [120][203/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [120][204/204]	Loss 0.0094 (0.0062)	
Training:	 Loss: 0.0062

Training:	 ACC: 0.9936 0.9939 0.9997 0.9876
Validation:	 ACC: 0.7708 0.7753 0.8700 0.6715
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5375
Pretraining:	Epoch 121/500
----------
training:	Epoch: [121][1/204]	Loss 0.0025 (0.0025)	
training:	Epoch: [121][2/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [121][3/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [121][4/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [121][5/204]	Loss 0.0773 (0.0163)	
training:	Epoch: [121][6/204]	Loss 0.0027 (0.0140)	
training:	Epoch: [121][7/204]	Loss 0.0805 (0.0235)	
training:	Epoch: [121][8/204]	Loss 0.0121 (0.0221)	
training:	Epoch: [121][9/204]	Loss 0.0009 (0.0197)	
training:	Epoch: [121][10/204]	Loss 0.0176 (0.0195)	
training:	Epoch: [121][11/204]	Loss 0.2047 (0.0363)	
training:	Epoch: [121][12/204]	Loss 0.0003 (0.0333)	
training:	Epoch: [121][13/204]	Loss 0.0531 (0.0349)	
training:	Epoch: [121][14/204]	Loss 0.0069 (0.0329)	
training:	Epoch: [121][15/204]	Loss 0.0007 (0.0307)	
training:	Epoch: [121][16/204]	Loss 0.1431 (0.0377)	
training:	Epoch: [121][17/204]	Loss 0.0053 (0.0358)	
training:	Epoch: [121][18/204]	Loss 0.0004 (0.0339)	
training:	Epoch: [121][19/204]	Loss 0.0005 (0.0321)	
training:	Epoch: [121][20/204]	Loss 0.0107 (0.0310)	
training:	Epoch: [121][21/204]	Loss 0.0004 (0.0296)	
training:	Epoch: [121][22/204]	Loss 0.0008 (0.0283)	
training:	Epoch: [121][23/204]	Loss 0.0004 (0.0271)	
training:	Epoch: [121][24/204]	Loss 0.0006 (0.0260)	
training:	Epoch: [121][25/204]	Loss 0.0014 (0.0250)	
training:	Epoch: [121][26/204]	Loss 0.0008 (0.0240)	
training:	Epoch: [121][27/204]	Loss 0.0005 (0.0232)	
training:	Epoch: [121][28/204]	Loss 0.0005 (0.0224)	
training:	Epoch: [121][29/204]	Loss 0.0005 (0.0216)	
training:	Epoch: [121][30/204]	Loss 0.0006 (0.0209)	
training:	Epoch: [121][31/204]	Loss 0.0007 (0.0203)	
training:	Epoch: [121][32/204]	Loss 0.0011 (0.0197)	
training:	Epoch: [121][33/204]	Loss 0.0005 (0.0191)	
training:	Epoch: [121][34/204]	Loss 0.0008 (0.0185)	
training:	Epoch: [121][35/204]	Loss 0.0003 (0.0180)	
training:	Epoch: [121][36/204]	Loss 0.0077 (0.0177)	
training:	Epoch: [121][37/204]	Loss 0.0282 (0.0180)	
training:	Epoch: [121][38/204]	Loss 0.0006 (0.0176)	
training:	Epoch: [121][39/204]	Loss 0.0011 (0.0171)	
training:	Epoch: [121][40/204]	Loss 0.0006 (0.0167)	
training:	Epoch: [121][41/204]	Loss 0.0005 (0.0163)	
training:	Epoch: [121][42/204]	Loss 0.0021 (0.0160)	
training:	Epoch: [121][43/204]	Loss 0.0006 (0.0156)	
training:	Epoch: [121][44/204]	Loss 0.0004 (0.0153)	
training:	Epoch: [121][45/204]	Loss 0.0012 (0.0150)	
training:	Epoch: [121][46/204]	Loss 0.0003 (0.0147)	
training:	Epoch: [121][47/204]	Loss 0.0005 (0.0144)	
training:	Epoch: [121][48/204]	Loss 0.0004 (0.0141)	
training:	Epoch: [121][49/204]	Loss 0.1313 (0.0165)	
training:	Epoch: [121][50/204]	Loss 0.0062 (0.0162)	
training:	Epoch: [121][51/204]	Loss 0.0004 (0.0159)	
training:	Epoch: [121][52/204]	Loss 0.0003 (0.0156)	
training:	Epoch: [121][53/204]	Loss 0.0006 (0.0154)	
training:	Epoch: [121][54/204]	Loss 0.0004 (0.0151)	
training:	Epoch: [121][55/204]	Loss 0.0004 (0.0148)	
training:	Epoch: [121][56/204]	Loss 0.0083 (0.0147)	
training:	Epoch: [121][57/204]	Loss 0.0004 (0.0144)	
training:	Epoch: [121][58/204]	Loss 0.0004 (0.0142)	
training:	Epoch: [121][59/204]	Loss 0.0106 (0.0141)	
training:	Epoch: [121][60/204]	Loss 0.0005 (0.0139)	
training:	Epoch: [121][61/204]	Loss 0.0005 (0.0137)	
training:	Epoch: [121][62/204]	Loss 0.0004 (0.0135)	
training:	Epoch: [121][63/204]	Loss 0.0140 (0.0135)	
training:	Epoch: [121][64/204]	Loss 0.0004 (0.0133)	
training:	Epoch: [121][65/204]	Loss 0.0020 (0.0131)	
training:	Epoch: [121][66/204]	Loss 0.0003 (0.0129)	
training:	Epoch: [121][67/204]	Loss 0.0003 (0.0127)	
training:	Epoch: [121][68/204]	Loss 0.0026 (0.0126)	
training:	Epoch: [121][69/204]	Loss 0.0146 (0.0126)	
training:	Epoch: [121][70/204]	Loss 0.0004 (0.0124)	
training:	Epoch: [121][71/204]	Loss 0.0005 (0.0123)	
training:	Epoch: [121][72/204]	Loss 0.0005 (0.0121)	
training:	Epoch: [121][73/204]	Loss 0.0024 (0.0120)	
training:	Epoch: [121][74/204]	Loss 0.0003 (0.0118)	
training:	Epoch: [121][75/204]	Loss 0.0007 (0.0117)	
training:	Epoch: [121][76/204]	Loss 0.0004 (0.0115)	
training:	Epoch: [121][77/204]	Loss 0.0005 (0.0114)	
training:	Epoch: [121][78/204]	Loss 0.0031 (0.0113)	
training:	Epoch: [121][79/204]	Loss 0.0020 (0.0111)	
training:	Epoch: [121][80/204]	Loss 0.0007 (0.0110)	
training:	Epoch: [121][81/204]	Loss 0.0003 (0.0109)	
training:	Epoch: [121][82/204]	Loss 0.0121 (0.0109)	
training:	Epoch: [121][83/204]	Loss 0.0004 (0.0108)	
training:	Epoch: [121][84/204]	Loss 0.0004 (0.0106)	
training:	Epoch: [121][85/204]	Loss 0.0003 (0.0105)	
training:	Epoch: [121][86/204]	Loss 0.0004 (0.0104)	
training:	Epoch: [121][87/204]	Loss 0.0003 (0.0103)	
training:	Epoch: [121][88/204]	Loss 0.0006 (0.0102)	
training:	Epoch: [121][89/204]	Loss 0.0004 (0.0101)	
training:	Epoch: [121][90/204]	Loss 0.0006 (0.0100)	
training:	Epoch: [121][91/204]	Loss 0.0003 (0.0099)	
training:	Epoch: [121][92/204]	Loss 0.0039 (0.0098)	
training:	Epoch: [121][93/204]	Loss 0.0005 (0.0097)	
training:	Epoch: [121][94/204]	Loss 0.0003 (0.0096)	
training:	Epoch: [121][95/204]	Loss 0.0006 (0.0095)	
training:	Epoch: [121][96/204]	Loss 0.0005 (0.0094)	
training:	Epoch: [121][97/204]	Loss 0.0008 (0.0093)	
training:	Epoch: [121][98/204]	Loss 0.0003 (0.0092)	
training:	Epoch: [121][99/204]	Loss 0.0003 (0.0091)	
training:	Epoch: [121][100/204]	Loss 0.0004 (0.0090)	
training:	Epoch: [121][101/204]	Loss 0.0005 (0.0090)	
training:	Epoch: [121][102/204]	Loss 0.0034 (0.0089)	
training:	Epoch: [121][103/204]	Loss 0.0003 (0.0088)	
training:	Epoch: [121][104/204]	Loss 0.0004 (0.0087)	
training:	Epoch: [121][105/204]	Loss 0.0003 (0.0087)	
training:	Epoch: [121][106/204]	Loss 0.0003 (0.0086)	
training:	Epoch: [121][107/204]	Loss 0.0004 (0.0085)	
training:	Epoch: [121][108/204]	Loss 0.0005 (0.0084)	
training:	Epoch: [121][109/204]	Loss 0.0003 (0.0084)	
training:	Epoch: [121][110/204]	Loss 0.0003 (0.0083)	
training:	Epoch: [121][111/204]	Loss 0.0006 (0.0082)	
training:	Epoch: [121][112/204]	Loss 0.0034 (0.0082)	
training:	Epoch: [121][113/204]	Loss 0.0005 (0.0081)	
training:	Epoch: [121][114/204]	Loss 0.0003 (0.0080)	
training:	Epoch: [121][115/204]	Loss 0.0005 (0.0080)	
training:	Epoch: [121][116/204]	Loss 0.0005 (0.0079)	
training:	Epoch: [121][117/204]	Loss 0.0004 (0.0078)	
training:	Epoch: [121][118/204]	Loss 0.0004 (0.0078)	
training:	Epoch: [121][119/204]	Loss 0.0005 (0.0077)	
training:	Epoch: [121][120/204]	Loss 0.0008 (0.0077)	
training:	Epoch: [121][121/204]	Loss 0.0003 (0.0076)	
training:	Epoch: [121][122/204]	Loss 0.0004 (0.0075)	
training:	Epoch: [121][123/204]	Loss 0.0004 (0.0075)	
training:	Epoch: [121][124/204]	Loss 0.0036 (0.0075)	
training:	Epoch: [121][125/204]	Loss 0.0012 (0.0074)	
training:	Epoch: [121][126/204]	Loss 0.0004 (0.0073)	
training:	Epoch: [121][127/204]	Loss 0.0003 (0.0073)	
training:	Epoch: [121][128/204]	Loss 0.0009 (0.0072)	
training:	Epoch: [121][129/204]	Loss 0.0005 (0.0072)	
training:	Epoch: [121][130/204]	Loss 0.0004 (0.0071)	
training:	Epoch: [121][131/204]	Loss 0.0004 (0.0071)	
training:	Epoch: [121][132/204]	Loss 0.0004 (0.0070)	
training:	Epoch: [121][133/204]	Loss 0.0009 (0.0070)	
training:	Epoch: [121][134/204]	Loss 0.0350 (0.0072)	
training:	Epoch: [121][135/204]	Loss 0.0005 (0.0071)	
training:	Epoch: [121][136/204]	Loss 0.0003 (0.0071)	
training:	Epoch: [121][137/204]	Loss 0.0005 (0.0070)	
training:	Epoch: [121][138/204]	Loss 0.0003 (0.0070)	
training:	Epoch: [121][139/204]	Loss 0.0003 (0.0070)	
training:	Epoch: [121][140/204]	Loss 0.0003 (0.0069)	
training:	Epoch: [121][141/204]	Loss 0.0004 (0.0069)	
training:	Epoch: [121][142/204]	Loss 0.0005 (0.0068)	
training:	Epoch: [121][143/204]	Loss 0.0003 (0.0068)	
training:	Epoch: [121][144/204]	Loss 0.0004 (0.0067)	
training:	Epoch: [121][145/204]	Loss 0.0004 (0.0067)	
training:	Epoch: [121][146/204]	Loss 0.0005 (0.0066)	
training:	Epoch: [121][147/204]	Loss 0.0003 (0.0066)	
training:	Epoch: [121][148/204]	Loss 0.0041 (0.0066)	
training:	Epoch: [121][149/204]	Loss 0.0003 (0.0065)	
training:	Epoch: [121][150/204]	Loss 0.0005 (0.0065)	
training:	Epoch: [121][151/204]	Loss 0.0008 (0.0065)	
training:	Epoch: [121][152/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [121][153/204]	Loss 0.0003 (0.0064)	
training:	Epoch: [121][154/204]	Loss 0.0003 (0.0063)	
training:	Epoch: [121][155/204]	Loss 0.0005 (0.0063)	
training:	Epoch: [121][156/204]	Loss 0.0020 (0.0063)	
training:	Epoch: [121][157/204]	Loss 0.0010 (0.0062)	
training:	Epoch: [121][158/204]	Loss 0.0009 (0.0062)	
training:	Epoch: [121][159/204]	Loss 0.0003 (0.0062)	
training:	Epoch: [121][160/204]	Loss 0.0003 (0.0061)	
training:	Epoch: [121][161/204]	Loss 0.0005 (0.0061)	
training:	Epoch: [121][162/204]	Loss 0.0096 (0.0061)	
training:	Epoch: [121][163/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [121][164/204]	Loss 0.0003 (0.0060)	
training:	Epoch: [121][165/204]	Loss 0.0105 (0.0061)	
training:	Epoch: [121][166/204]	Loss 0.0019 (0.0060)	
training:	Epoch: [121][167/204]	Loss 0.0034 (0.0060)	
training:	Epoch: [121][168/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [121][169/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [121][170/204]	Loss 0.0009 (0.0059)	
training:	Epoch: [121][171/204]	Loss 0.0003 (0.0059)	
training:	Epoch: [121][172/204]	Loss 0.0010 (0.0059)	
training:	Epoch: [121][173/204]	Loss 0.0012 (0.0058)	
training:	Epoch: [121][174/204]	Loss 0.0004 (0.0058)	
training:	Epoch: [121][175/204]	Loss 0.0005 (0.0058)	
training:	Epoch: [121][176/204]	Loss 0.0004 (0.0058)	
training:	Epoch: [121][177/204]	Loss 0.0013 (0.0057)	
training:	Epoch: [121][178/204]	Loss 0.0021 (0.0057)	
training:	Epoch: [121][179/204]	Loss 0.0003 (0.0057)	
training:	Epoch: [121][180/204]	Loss 0.0006 (0.0057)	
training:	Epoch: [121][181/204]	Loss 0.0003 (0.0056)	
training:	Epoch: [121][182/204]	Loss 0.0003 (0.0056)	
training:	Epoch: [121][183/204]	Loss 0.0013 (0.0056)	
training:	Epoch: [121][184/204]	Loss 0.0005 (0.0055)	
training:	Epoch: [121][185/204]	Loss 0.0010 (0.0055)	
training:	Epoch: [121][186/204]	Loss 0.0003 (0.0055)	
training:	Epoch: [121][187/204]	Loss 0.0003 (0.0055)	
training:	Epoch: [121][188/204]	Loss 0.0912 (0.0059)	
training:	Epoch: [121][189/204]	Loss 0.0008 (0.0059)	
training:	Epoch: [121][190/204]	Loss 0.0006 (0.0059)	
training:	Epoch: [121][191/204]	Loss 0.0003 (0.0058)	
training:	Epoch: [121][192/204]	Loss 0.0003 (0.0058)	
training:	Epoch: [121][193/204]	Loss 0.0004 (0.0058)	
training:	Epoch: [121][194/204]	Loss 0.0004 (0.0057)	
training:	Epoch: [121][195/204]	Loss 0.0004 (0.0057)	
training:	Epoch: [121][196/204]	Loss 0.0004 (0.0057)	
training:	Epoch: [121][197/204]	Loss 0.0004 (0.0057)	
training:	Epoch: [121][198/204]	Loss 0.0010 (0.0056)	
training:	Epoch: [121][199/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [121][200/204]	Loss 0.0007 (0.0056)	
training:	Epoch: [121][201/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [121][202/204]	Loss 0.0003 (0.0055)	
training:	Epoch: [121][203/204]	Loss 0.0003 (0.0055)	
training:	Epoch: [121][204/204]	Loss 0.0004 (0.0055)	
Training:	 Loss: 0.0055

Training:	 ACC: 0.9991 0.9991 0.9997 0.9984
Validation:	 ACC: 0.7720 0.7753 0.8434 0.7007
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5154
Pretraining:	Epoch 122/500
----------
training:	Epoch: [122][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [122][2/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [122][3/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [122][4/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [122][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [122][6/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [122][7/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [122][8/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [122][9/204]	Loss 0.0011 (0.0005)	
training:	Epoch: [122][10/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [122][11/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [122][12/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [122][13/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [122][14/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [122][15/204]	Loss 0.0012 (0.0006)	
training:	Epoch: [122][16/204]	Loss 0.0014 (0.0007)	
training:	Epoch: [122][17/204]	Loss 0.0069 (0.0010)	
training:	Epoch: [122][18/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [122][19/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [122][20/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [122][21/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [122][22/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [122][23/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [122][24/204]	Loss 0.0022 (0.0009)	
training:	Epoch: [122][25/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [122][26/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [122][27/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [122][28/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][29/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][30/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][31/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][32/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [122][33/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][34/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][35/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][36/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][37/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][38/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][39/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][40/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][41/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][42/204]	Loss 0.0012 (0.0007)	
training:	Epoch: [122][43/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][44/204]	Loss 0.0008 (0.0007)	
training:	Epoch: [122][45/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][46/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][47/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [122][48/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][49/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][50/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [122][51/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [122][52/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [122][53/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [122][54/204]	Loss 0.0077 (0.0008)	
training:	Epoch: [122][55/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][56/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][57/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][58/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [122][59/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [122][60/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [122][61/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][62/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [122][63/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][64/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][65/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][66/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][67/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][68/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][69/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][70/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][71/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][72/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [122][73/204]	Loss 0.0018 (0.0007)	
training:	Epoch: [122][74/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [122][75/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][76/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][77/204]	Loss 0.0112 (0.0008)	
training:	Epoch: [122][78/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [122][79/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [122][80/204]	Loss 0.0011 (0.0008)	
training:	Epoch: [122][81/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [122][82/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][83/204]	Loss 0.0023 (0.0008)	
training:	Epoch: [122][84/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][85/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][86/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [122][87/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][88/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][89/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][90/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [122][91/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][92/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [122][93/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][94/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [122][95/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [122][96/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][97/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [122][98/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][99/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [122][100/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][101/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][102/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][103/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][104/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][105/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][106/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][107/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][108/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [122][109/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][110/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [122][111/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][112/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][113/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][114/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][115/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [122][116/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][117/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][118/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [122][119/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [122][120/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][121/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][122/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [122][123/204]	Loss 0.0032 (0.0007)	
training:	Epoch: [122][124/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [122][125/204]	Loss 0.0015 (0.0007)	
training:	Epoch: [122][126/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [122][127/204]	Loss 0.0190 (0.0009)	
training:	Epoch: [122][128/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [122][129/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [122][130/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][131/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][132/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][133/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][134/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][135/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][136/204]	Loss 0.0021 (0.0008)	
training:	Epoch: [122][137/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][138/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][139/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [122][140/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][141/204]	Loss 0.0043 (0.0009)	
training:	Epoch: [122][142/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [122][143/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][144/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [122][145/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][146/204]	Loss 0.0013 (0.0008)	
training:	Epoch: [122][147/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][148/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [122][149/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [122][150/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [122][151/204]	Loss 0.1975 (0.0021)	
training:	Epoch: [122][152/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [122][153/204]	Loss 0.0399 (0.0024)	
training:	Epoch: [122][154/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [122][155/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [122][156/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [122][157/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [122][158/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [122][159/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [122][160/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [122][161/204]	Loss 0.0012 (0.0023)	
training:	Epoch: [122][162/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [122][163/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [122][164/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [122][165/204]	Loss 0.0042 (0.0023)	
training:	Epoch: [122][166/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [122][167/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [122][168/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [122][169/204]	Loss 0.0009 (0.0022)	
training:	Epoch: [122][170/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [122][171/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [122][172/204]	Loss 0.0011 (0.0022)	
training:	Epoch: [122][173/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [122][174/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [122][175/204]	Loss 0.0085 (0.0022)	
training:	Epoch: [122][176/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [122][177/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [122][178/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [122][179/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [122][180/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [122][181/204]	Loss 0.0063 (0.0022)	
training:	Epoch: [122][182/204]	Loss 0.0011 (0.0022)	
training:	Epoch: [122][183/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [122][184/204]	Loss 0.0011 (0.0022)	
training:	Epoch: [122][185/204]	Loss 0.0046 (0.0022)	
training:	Epoch: [122][186/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [122][187/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [122][188/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [122][189/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [122][190/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [122][191/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [122][192/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [122][193/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [122][194/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [122][195/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [122][196/204]	Loss 0.0009 (0.0021)	
training:	Epoch: [122][197/204]	Loss 0.0019 (0.0021)	
training:	Epoch: [122][198/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [122][199/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [122][200/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [122][201/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [122][202/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [122][203/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [122][204/204]	Loss 0.0076 (0.0020)	
Training:	 Loss: 0.0020

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7696 0.7699 0.7758 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4905
Pretraining:	Epoch 123/500
----------
training:	Epoch: [123][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [123][2/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][3/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [123][4/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][5/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][6/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [123][7/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][8/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][9/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [123][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][11/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][12/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][13/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][14/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][15/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][16/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][17/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][18/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [123][19/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][20/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][21/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][22/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][23/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [123][24/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][25/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][26/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][27/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [123][28/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [123][29/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][30/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [123][31/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][32/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][33/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][34/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][35/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][36/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][37/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [123][38/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][39/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [123][40/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][41/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [123][42/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][43/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [123][44/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][45/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][46/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][47/204]	Loss 0.0017 (0.0004)	
training:	Epoch: [123][48/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][49/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][50/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][51/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][52/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][53/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][54/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [123][55/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][56/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][57/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][58/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][59/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][60/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [123][61/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][62/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][63/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [123][64/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][65/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [123][66/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][67/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][68/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [123][69/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [123][70/204]	Loss 0.1983 (0.0032)	
training:	Epoch: [123][71/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [123][72/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [123][73/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [123][74/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [123][75/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [123][76/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [123][77/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [123][78/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [123][79/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [123][80/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [123][81/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [123][82/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [123][83/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [123][84/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [123][85/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [123][86/204]	Loss 0.0020 (0.0027)	
training:	Epoch: [123][87/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [123][88/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [123][89/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [123][90/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [123][91/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [123][92/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [123][93/204]	Loss 0.0008 (0.0026)	
training:	Epoch: [123][94/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [123][95/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [123][96/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [123][97/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [123][98/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [123][99/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [123][100/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [123][101/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [123][102/204]	Loss 0.0013 (0.0024)	
training:	Epoch: [123][103/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [123][104/204]	Loss 0.0012 (0.0023)	
training:	Epoch: [123][105/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [123][106/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [123][107/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [123][108/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [123][109/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [123][110/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [123][111/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [123][112/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [123][113/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [123][114/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [123][115/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [123][116/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [123][117/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [123][118/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [123][119/204]	Loss 0.0015 (0.0021)	
training:	Epoch: [123][120/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [123][121/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [123][122/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [123][123/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [123][124/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [123][125/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [123][126/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [123][127/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [123][128/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [123][129/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [123][130/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [123][131/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [123][132/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [123][133/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [123][134/204]	Loss 0.0018 (0.0019)	
training:	Epoch: [123][135/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [123][136/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [123][137/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [123][138/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [123][139/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [123][140/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [123][141/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [123][142/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [123][143/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [123][144/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [123][145/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [123][146/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [123][147/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [123][148/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [123][149/204]	Loss 0.0110 (0.0018)	
training:	Epoch: [123][150/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [123][151/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [123][152/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [123][153/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [123][154/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [123][155/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [123][156/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [123][157/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [123][158/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [123][159/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [123][160/204]	Loss 0.0009 (0.0017)	
training:	Epoch: [123][161/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [123][162/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [123][163/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [123][164/204]	Loss 0.0013 (0.0017)	
training:	Epoch: [123][165/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [123][166/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [123][167/204]	Loss 0.0007 (0.0017)	
training:	Epoch: [123][168/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [123][169/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [123][170/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [123][171/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [123][172/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [123][173/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [123][174/204]	Loss 0.0781 (0.0021)	
training:	Epoch: [123][175/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [123][176/204]	Loss 0.0080 (0.0021)	
training:	Epoch: [123][177/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [123][178/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [123][179/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [123][180/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [123][181/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [123][182/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [123][183/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [123][184/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [123][185/204]	Loss 0.0007 (0.0020)	
training:	Epoch: [123][186/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [123][187/204]	Loss 0.0024 (0.0020)	
training:	Epoch: [123][188/204]	Loss 0.0564 (0.0023)	
training:	Epoch: [123][189/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [123][190/204]	Loss 0.0008 (0.0023)	
training:	Epoch: [123][191/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [123][192/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [123][193/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [123][194/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [123][195/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [123][196/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [123][197/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [123][198/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [123][199/204]	Loss 0.0009 (0.0022)	
training:	Epoch: [123][200/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [123][201/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [123][202/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [123][203/204]	Loss 0.0042 (0.0022)	
training:	Epoch: [123][204/204]	Loss 0.0004 (0.0022)	
Training:	 Loss: 0.0022

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7691 0.7694 0.7758 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4825
Pretraining:	Epoch 124/500
----------
training:	Epoch: [124][1/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [124][2/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [124][3/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [124][4/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [124][5/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [124][6/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [124][7/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [124][8/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [124][9/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [124][10/204]	Loss 0.0012 (0.0005)	
training:	Epoch: [124][11/204]	Loss 0.0835 (0.0081)	
training:	Epoch: [124][12/204]	Loss 0.0004 (0.0074)	
training:	Epoch: [124][13/204]	Loss 0.0153 (0.0080)	
training:	Epoch: [124][14/204]	Loss 0.0003 (0.0075)	
training:	Epoch: [124][15/204]	Loss 0.0006 (0.0070)	
training:	Epoch: [124][16/204]	Loss 0.0003 (0.0066)	
training:	Epoch: [124][17/204]	Loss 0.0003 (0.0062)	
training:	Epoch: [124][18/204]	Loss 0.0003 (0.0059)	
training:	Epoch: [124][19/204]	Loss 0.0003 (0.0056)	
training:	Epoch: [124][20/204]	Loss 0.0003 (0.0053)	
training:	Epoch: [124][21/204]	Loss 0.0781 (0.0088)	
training:	Epoch: [124][22/204]	Loss 0.0003 (0.0084)	
training:	Epoch: [124][23/204]	Loss 0.0003 (0.0081)	
training:	Epoch: [124][24/204]	Loss 0.0004 (0.0078)	
training:	Epoch: [124][25/204]	Loss 0.0003 (0.0075)	
training:	Epoch: [124][26/204]	Loss 0.0004 (0.0072)	
training:	Epoch: [124][27/204]	Loss 0.0003 (0.0069)	
training:	Epoch: [124][28/204]	Loss 0.0242 (0.0075)	
training:	Epoch: [124][29/204]	Loss 0.0003 (0.0073)	
training:	Epoch: [124][30/204]	Loss 0.0003 (0.0071)	
training:	Epoch: [124][31/204]	Loss 0.0631 (0.0089)	
training:	Epoch: [124][32/204]	Loss 0.0004 (0.0086)	
training:	Epoch: [124][33/204]	Loss 0.0006 (0.0084)	
training:	Epoch: [124][34/204]	Loss 0.0004 (0.0081)	
training:	Epoch: [124][35/204]	Loss 0.0037 (0.0080)	
training:	Epoch: [124][36/204]	Loss 0.0005 (0.0078)	
training:	Epoch: [124][37/204]	Loss 0.0004 (0.0076)	
training:	Epoch: [124][38/204]	Loss 0.0004 (0.0074)	
training:	Epoch: [124][39/204]	Loss 0.0011 (0.0072)	
training:	Epoch: [124][40/204]	Loss 0.0229 (0.0076)	
training:	Epoch: [124][41/204]	Loss 0.0005 (0.0075)	
training:	Epoch: [124][42/204]	Loss 0.0004 (0.0073)	
training:	Epoch: [124][43/204]	Loss 0.0003 (0.0071)	
training:	Epoch: [124][44/204]	Loss 0.0068 (0.0071)	
training:	Epoch: [124][45/204]	Loss 0.0003 (0.0070)	
training:	Epoch: [124][46/204]	Loss 0.0003 (0.0068)	
training:	Epoch: [124][47/204]	Loss 0.0003 (0.0067)	
training:	Epoch: [124][48/204]	Loss 0.0002 (0.0065)	
training:	Epoch: [124][49/204]	Loss 0.0012 (0.0064)	
training:	Epoch: [124][50/204]	Loss 0.0003 (0.0063)	
training:	Epoch: [124][51/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [124][52/204]	Loss 0.0008 (0.0061)	
training:	Epoch: [124][53/204]	Loss 0.0009 (0.0060)	
training:	Epoch: [124][54/204]	Loss 0.0621 (0.0070)	
training:	Epoch: [124][55/204]	Loss 0.0004 (0.0069)	
training:	Epoch: [124][56/204]	Loss 0.0004 (0.0068)	
training:	Epoch: [124][57/204]	Loss 0.0005 (0.0067)	
training:	Epoch: [124][58/204]	Loss 0.0003 (0.0066)	
training:	Epoch: [124][59/204]	Loss 0.0006 (0.0065)	
training:	Epoch: [124][60/204]	Loss 0.0003 (0.0064)	
training:	Epoch: [124][61/204]	Loss 0.0004 (0.0063)	
training:	Epoch: [124][62/204]	Loss 0.0019 (0.0062)	
training:	Epoch: [124][63/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [124][64/204]	Loss 0.0003 (0.0060)	
training:	Epoch: [124][65/204]	Loss 0.0003 (0.0059)	
training:	Epoch: [124][66/204]	Loss 0.0003 (0.0059)	
training:	Epoch: [124][67/204]	Loss 0.0024 (0.0058)	
training:	Epoch: [124][68/204]	Loss 0.0005 (0.0057)	
training:	Epoch: [124][69/204]	Loss 0.0003 (0.0056)	
training:	Epoch: [124][70/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [124][71/204]	Loss 0.0006 (0.0055)	
training:	Epoch: [124][72/204]	Loss 0.0009 (0.0054)	
training:	Epoch: [124][73/204]	Loss 0.0003 (0.0054)	
training:	Epoch: [124][74/204]	Loss 0.0007 (0.0053)	
training:	Epoch: [124][75/204]	Loss 0.0012 (0.0052)	
training:	Epoch: [124][76/204]	Loss 0.0007 (0.0052)	
training:	Epoch: [124][77/204]	Loss 0.0025 (0.0052)	
training:	Epoch: [124][78/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [124][79/204]	Loss 0.0009 (0.0050)	
training:	Epoch: [124][80/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [124][81/204]	Loss 0.0003 (0.0049)	
training:	Epoch: [124][82/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [124][83/204]	Loss 0.1928 (0.0071)	
training:	Epoch: [124][84/204]	Loss 0.0530 (0.0077)	
training:	Epoch: [124][85/204]	Loss 0.0005 (0.0076)	
training:	Epoch: [124][86/204]	Loss 0.0003 (0.0075)	
training:	Epoch: [124][87/204]	Loss 0.0003 (0.0074)	
training:	Epoch: [124][88/204]	Loss 0.0003 (0.0073)	
training:	Epoch: [124][89/204]	Loss 0.0004 (0.0073)	
training:	Epoch: [124][90/204]	Loss 0.0005 (0.0072)	
training:	Epoch: [124][91/204]	Loss 0.0003 (0.0071)	
training:	Epoch: [124][92/204]	Loss 0.0003 (0.0070)	
training:	Epoch: [124][93/204]	Loss 0.0003 (0.0070)	
training:	Epoch: [124][94/204]	Loss 0.0010 (0.0069)	
training:	Epoch: [124][95/204]	Loss 0.0002 (0.0068)	
training:	Epoch: [124][96/204]	Loss 0.0007 (0.0068)	
training:	Epoch: [124][97/204]	Loss 0.0003 (0.0067)	
training:	Epoch: [124][98/204]	Loss 0.0004 (0.0066)	
training:	Epoch: [124][99/204]	Loss 0.0004 (0.0066)	
training:	Epoch: [124][100/204]	Loss 0.0053 (0.0066)	
training:	Epoch: [124][101/204]	Loss 0.0003 (0.0065)	
training:	Epoch: [124][102/204]	Loss 0.0051 (0.0065)	
training:	Epoch: [124][103/204]	Loss 0.0024 (0.0065)	
training:	Epoch: [124][104/204]	Loss 0.0008 (0.0064)	
training:	Epoch: [124][105/204]	Loss 0.0007 (0.0063)	
training:	Epoch: [124][106/204]	Loss 0.0010 (0.0063)	
training:	Epoch: [124][107/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [124][108/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [124][109/204]	Loss 0.0031 (0.0062)	
training:	Epoch: [124][110/204]	Loss 0.0113 (0.0062)	
training:	Epoch: [124][111/204]	Loss 0.0003 (0.0061)	
training:	Epoch: [124][112/204]	Loss 0.0003 (0.0061)	
training:	Epoch: [124][113/204]	Loss 0.0003 (0.0060)	
training:	Epoch: [124][114/204]	Loss 0.0146 (0.0061)	
training:	Epoch: [124][115/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [124][116/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [124][117/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [124][118/204]	Loss 0.0013 (0.0059)	
training:	Epoch: [124][119/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [124][120/204]	Loss 0.1505 (0.0071)	
training:	Epoch: [124][121/204]	Loss 0.0008 (0.0070)	
training:	Epoch: [124][122/204]	Loss 0.0004 (0.0070)	
training:	Epoch: [124][123/204]	Loss 0.0022 (0.0069)	
training:	Epoch: [124][124/204]	Loss 0.0004 (0.0069)	
training:	Epoch: [124][125/204]	Loss 0.0004 (0.0068)	
training:	Epoch: [124][126/204]	Loss 0.1223 (0.0078)	
training:	Epoch: [124][127/204]	Loss 0.0004 (0.0077)	
training:	Epoch: [124][128/204]	Loss 0.0010 (0.0076)	
training:	Epoch: [124][129/204]	Loss 0.0018 (0.0076)	
training:	Epoch: [124][130/204]	Loss 0.1850 (0.0090)	
training:	Epoch: [124][131/204]	Loss 0.0005 (0.0089)	
training:	Epoch: [124][132/204]	Loss 0.0005 (0.0088)	
training:	Epoch: [124][133/204]	Loss 0.0004 (0.0088)	
training:	Epoch: [124][134/204]	Loss 0.0291 (0.0089)	
training:	Epoch: [124][135/204]	Loss 0.0004 (0.0089)	
training:	Epoch: [124][136/204]	Loss 0.0005 (0.0088)	
training:	Epoch: [124][137/204]	Loss 0.0005 (0.0087)	
training:	Epoch: [124][138/204]	Loss 0.0003 (0.0087)	
training:	Epoch: [124][139/204]	Loss 0.0006 (0.0086)	
training:	Epoch: [124][140/204]	Loss 0.0006 (0.0086)	
training:	Epoch: [124][141/204]	Loss 0.0003 (0.0085)	
training:	Epoch: [124][142/204]	Loss 0.0003 (0.0084)	
training:	Epoch: [124][143/204]	Loss 0.0004 (0.0084)	
training:	Epoch: [124][144/204]	Loss 0.0003 (0.0083)	
training:	Epoch: [124][145/204]	Loss 0.0292 (0.0085)	
training:	Epoch: [124][146/204]	Loss 0.0713 (0.0089)	
training:	Epoch: [124][147/204]	Loss 0.0007 (0.0089)	
training:	Epoch: [124][148/204]	Loss 0.0004 (0.0088)	
training:	Epoch: [124][149/204]	Loss 0.0003 (0.0087)	
training:	Epoch: [124][150/204]	Loss 0.0004 (0.0087)	
training:	Epoch: [124][151/204]	Loss 0.0046 (0.0087)	
training:	Epoch: [124][152/204]	Loss 0.0003 (0.0086)	
training:	Epoch: [124][153/204]	Loss 0.0005 (0.0085)	
training:	Epoch: [124][154/204]	Loss 0.0004 (0.0085)	
training:	Epoch: [124][155/204]	Loss 0.0024 (0.0085)	
training:	Epoch: [124][156/204]	Loss 0.0003 (0.0084)	
training:	Epoch: [124][157/204]	Loss 0.0005 (0.0084)	
training:	Epoch: [124][158/204]	Loss 0.0468 (0.0086)	
training:	Epoch: [124][159/204]	Loss 0.0004 (0.0085)	
training:	Epoch: [124][160/204]	Loss 0.0003 (0.0085)	
training:	Epoch: [124][161/204]	Loss 0.0455 (0.0087)	
training:	Epoch: [124][162/204]	Loss 0.0003 (0.0087)	
training:	Epoch: [124][163/204]	Loss 0.0008 (0.0086)	
training:	Epoch: [124][164/204]	Loss 0.0004 (0.0086)	
training:	Epoch: [124][165/204]	Loss 0.0004 (0.0085)	
training:	Epoch: [124][166/204]	Loss 0.0003 (0.0085)	
training:	Epoch: [124][167/204]	Loss 0.0003 (0.0084)	
training:	Epoch: [124][168/204]	Loss 0.0004 (0.0084)	
training:	Epoch: [124][169/204]	Loss 0.0007 (0.0083)	
training:	Epoch: [124][170/204]	Loss 0.0007 (0.0083)	
training:	Epoch: [124][171/204]	Loss 0.0080 (0.0083)	
training:	Epoch: [124][172/204]	Loss 0.0316 (0.0084)	
training:	Epoch: [124][173/204]	Loss 0.0069 (0.0084)	
training:	Epoch: [124][174/204]	Loss 0.0004 (0.0084)	
training:	Epoch: [124][175/204]	Loss 0.0005 (0.0083)	
training:	Epoch: [124][176/204]	Loss 0.0006 (0.0083)	
training:	Epoch: [124][177/204]	Loss 0.0135 (0.0083)	
training:	Epoch: [124][178/204]	Loss 0.0004 (0.0083)	
training:	Epoch: [124][179/204]	Loss 0.0005 (0.0082)	
training:	Epoch: [124][180/204]	Loss 0.0003 (0.0082)	
training:	Epoch: [124][181/204]	Loss 0.0005 (0.0081)	
training:	Epoch: [124][182/204]	Loss 0.0004 (0.0081)	
training:	Epoch: [124][183/204]	Loss 0.0003 (0.0080)	
training:	Epoch: [124][184/204]	Loss 0.0004 (0.0080)	
training:	Epoch: [124][185/204]	Loss 0.0004 (0.0080)	
training:	Epoch: [124][186/204]	Loss 0.0004 (0.0079)	
training:	Epoch: [124][187/204]	Loss 0.0004 (0.0079)	
training:	Epoch: [124][188/204]	Loss 0.0005 (0.0078)	
training:	Epoch: [124][189/204]	Loss 0.0003 (0.0078)	
training:	Epoch: [124][190/204]	Loss 0.0031 (0.0078)	
training:	Epoch: [124][191/204]	Loss 0.0004 (0.0077)	
training:	Epoch: [124][192/204]	Loss 0.0003 (0.0077)	
training:	Epoch: [124][193/204]	Loss 0.0003 (0.0077)	
training:	Epoch: [124][194/204]	Loss 0.0033 (0.0076)	
training:	Epoch: [124][195/204]	Loss 0.0004 (0.0076)	
training:	Epoch: [124][196/204]	Loss 0.0003 (0.0076)	
training:	Epoch: [124][197/204]	Loss 0.0004 (0.0075)	
training:	Epoch: [124][198/204]	Loss 0.0004 (0.0075)	
training:	Epoch: [124][199/204]	Loss 0.0150 (0.0075)	
training:	Epoch: [124][200/204]	Loss 0.0004 (0.0075)	
training:	Epoch: [124][201/204]	Loss 0.0013 (0.0075)	
training:	Epoch: [124][202/204]	Loss 0.0020 (0.0074)	
training:	Epoch: [124][203/204]	Loss 0.0004 (0.0074)	
training:	Epoch: [124][204/204]	Loss 0.0092 (0.0074)	
Training:	 Loss: 0.0074

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7741 0.7737 0.7656 0.7825
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4111
Pretraining:	Epoch 125/500
----------
training:	Epoch: [125][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][2/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][3/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][4/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [125][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][6/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][7/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][8/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][9/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][10/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [125][11/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][12/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [125][13/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][14/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [125][15/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][16/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][17/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][18/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][19/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][20/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][21/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [125][22/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][23/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][24/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][25/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [125][26/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][27/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][28/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][29/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][30/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [125][31/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [125][32/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [125][33/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][34/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][35/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][36/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][37/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][38/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [125][39/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][40/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [125][41/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][42/204]	Loss 0.0016 (0.0005)	
training:	Epoch: [125][43/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][44/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [125][45/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][46/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][47/204]	Loss 0.0011 (0.0005)	
training:	Epoch: [125][48/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][49/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][50/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [125][51/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [125][52/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [125][53/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [125][54/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [125][55/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [125][56/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [125][57/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][58/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][59/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][60/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][61/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [125][62/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][63/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [125][64/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][65/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][66/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [125][67/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [125][68/204]	Loss 0.0041 (0.0005)	
training:	Epoch: [125][69/204]	Loss 0.0022 (0.0005)	
training:	Epoch: [125][70/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [125][71/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [125][72/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][73/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [125][74/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][75/204]	Loss 0.0014 (0.0005)	
training:	Epoch: [125][76/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [125][77/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][78/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][79/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [125][80/204]	Loss 0.0019 (0.0005)	
training:	Epoch: [125][81/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [125][82/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][83/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][84/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][85/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [125][86/204]	Loss 0.0160 (0.0007)	
training:	Epoch: [125][87/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [125][88/204]	Loss 0.1888 (0.0028)	
training:	Epoch: [125][89/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [125][90/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [125][91/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [125][92/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [125][93/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [125][94/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [125][95/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [125][96/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [125][97/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [125][98/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [125][99/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [125][100/204]	Loss 0.1177 (0.0037)	
training:	Epoch: [125][101/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [125][102/204]	Loss 0.0005 (0.0037)	
training:	Epoch: [125][103/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [125][104/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [125][105/204]	Loss 0.0012 (0.0036)	
training:	Epoch: [125][106/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [125][107/204]	Loss 0.0014 (0.0035)	
training:	Epoch: [125][108/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [125][109/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [125][110/204]	Loss 0.0020 (0.0035)	
training:	Epoch: [125][111/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [125][112/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [125][113/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [125][114/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [125][115/204]	Loss 0.0161 (0.0035)	
training:	Epoch: [125][116/204]	Loss 0.0015 (0.0034)	
training:	Epoch: [125][117/204]	Loss 0.0006 (0.0034)	
training:	Epoch: [125][118/204]	Loss 0.1698 (0.0048)	
training:	Epoch: [125][119/204]	Loss 0.0314 (0.0051)	
training:	Epoch: [125][120/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [125][121/204]	Loss 0.0003 (0.0050)	
training:	Epoch: [125][122/204]	Loss 0.0003 (0.0049)	
training:	Epoch: [125][123/204]	Loss 0.0003 (0.0049)	
training:	Epoch: [125][124/204]	Loss 0.0005 (0.0049)	
training:	Epoch: [125][125/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [125][126/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [125][127/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [125][128/204]	Loss 0.0007 (0.0047)	
training:	Epoch: [125][129/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [125][130/204]	Loss 0.0006 (0.0047)	
training:	Epoch: [125][131/204]	Loss 0.0007 (0.0046)	
training:	Epoch: [125][132/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [125][133/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [125][134/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [125][135/204]	Loss 0.0582 (0.0049)	
training:	Epoch: [125][136/204]	Loss 0.0008 (0.0049)	
training:	Epoch: [125][137/204]	Loss 0.0055 (0.0049)	
training:	Epoch: [125][138/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [125][139/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [125][140/204]	Loss 0.0017 (0.0048)	
training:	Epoch: [125][141/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [125][142/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [125][143/204]	Loss 0.0142 (0.0048)	
training:	Epoch: [125][144/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [125][145/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [125][146/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [125][147/204]	Loss 0.0003 (0.0047)	
training:	Epoch: [125][148/204]	Loss 0.0008 (0.0047)	
training:	Epoch: [125][149/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [125][150/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [125][151/204]	Loss 0.0009 (0.0046)	
training:	Epoch: [125][152/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [125][153/204]	Loss 0.0007 (0.0045)	
training:	Epoch: [125][154/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [125][155/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [125][156/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [125][157/204]	Loss 0.0012 (0.0044)	
training:	Epoch: [125][158/204]	Loss 0.0006 (0.0044)	
training:	Epoch: [125][159/204]	Loss 0.0070 (0.0044)	
training:	Epoch: [125][160/204]	Loss 0.0003 (0.0044)	
training:	Epoch: [125][161/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [125][162/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [125][163/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [125][164/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [125][165/204]	Loss 0.0070 (0.0043)	
training:	Epoch: [125][166/204]	Loss 0.0010 (0.0043)	
training:	Epoch: [125][167/204]	Loss 0.0056 (0.0043)	
training:	Epoch: [125][168/204]	Loss 0.0003 (0.0043)	
training:	Epoch: [125][169/204]	Loss 0.0929 (0.0048)	
training:	Epoch: [125][170/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [125][171/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [125][172/204]	Loss 0.0006 (0.0047)	
training:	Epoch: [125][173/204]	Loss 0.0006 (0.0047)	
training:	Epoch: [125][174/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [125][175/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [125][176/204]	Loss 0.0233 (0.0048)	
training:	Epoch: [125][177/204]	Loss 0.0024 (0.0048)	
training:	Epoch: [125][178/204]	Loss 0.0003 (0.0047)	
training:	Epoch: [125][179/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [125][180/204]	Loss 0.0007 (0.0047)	
training:	Epoch: [125][181/204]	Loss 0.0003 (0.0047)	
training:	Epoch: [125][182/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [125][183/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [125][184/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [125][185/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [125][186/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [125][187/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [125][188/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [125][189/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [125][190/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [125][191/204]	Loss 0.0016 (0.0044)	
training:	Epoch: [125][192/204]	Loss 0.0003 (0.0044)	
training:	Epoch: [125][193/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [125][194/204]	Loss 0.0010 (0.0044)	
training:	Epoch: [125][195/204]	Loss 0.0005 (0.0044)	
training:	Epoch: [125][196/204]	Loss 0.0003 (0.0043)	
training:	Epoch: [125][197/204]	Loss 0.0015 (0.0043)	
training:	Epoch: [125][198/204]	Loss 0.0003 (0.0043)	
training:	Epoch: [125][199/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [125][200/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [125][201/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [125][202/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [125][203/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [125][204/204]	Loss 0.0003 (0.0042)	
Training:	 Loss: 0.0042

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7752 0.7753 0.7769 0.7735
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.3867
Pretraining:	Epoch 126/500
----------
training:	Epoch: [126][1/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [126][2/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [126][3/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [126][4/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [126][5/204]	Loss 0.0029 (0.0009)	
training:	Epoch: [126][6/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [126][7/204]	Loss 0.1880 (0.0276)	
training:	Epoch: [126][8/204]	Loss 0.0004 (0.0242)	
training:	Epoch: [126][9/204]	Loss 0.0013 (0.0216)	
training:	Epoch: [126][10/204]	Loss 0.0003 (0.0195)	
training:	Epoch: [126][11/204]	Loss 0.0003 (0.0178)	
training:	Epoch: [126][12/204]	Loss 0.0022 (0.0165)	
training:	Epoch: [126][13/204]	Loss 0.0008 (0.0153)	
training:	Epoch: [126][14/204]	Loss 0.0190 (0.0155)	
training:	Epoch: [126][15/204]	Loss 0.0004 (0.0145)	
training:	Epoch: [126][16/204]	Loss 0.0003 (0.0136)	
training:	Epoch: [126][17/204]	Loss 0.0012 (0.0129)	
training:	Epoch: [126][18/204]	Loss 0.0006 (0.0122)	
training:	Epoch: [126][19/204]	Loss 0.0005 (0.0116)	
training:	Epoch: [126][20/204]	Loss 0.0006 (0.0110)	
training:	Epoch: [126][21/204]	Loss 0.0004 (0.0105)	
training:	Epoch: [126][22/204]	Loss 0.0010 (0.0101)	
training:	Epoch: [126][23/204]	Loss 0.0008 (0.0097)	
training:	Epoch: [126][24/204]	Loss 0.0004 (0.0093)	
training:	Epoch: [126][25/204]	Loss 0.0005 (0.0090)	
training:	Epoch: [126][26/204]	Loss 0.0003 (0.0086)	
training:	Epoch: [126][27/204]	Loss 0.0029 (0.0084)	
training:	Epoch: [126][28/204]	Loss 0.0005 (0.0081)	
training:	Epoch: [126][29/204]	Loss 0.0005 (0.0079)	
training:	Epoch: [126][30/204]	Loss 0.0004 (0.0076)	
training:	Epoch: [126][31/204]	Loss 0.0003 (0.0074)	
training:	Epoch: [126][32/204]	Loss 0.0005 (0.0072)	
training:	Epoch: [126][33/204]	Loss 0.0004 (0.0070)	
training:	Epoch: [126][34/204]	Loss 0.0003 (0.0068)	
training:	Epoch: [126][35/204]	Loss 0.0003 (0.0066)	
training:	Epoch: [126][36/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [126][37/204]	Loss 0.0006 (0.0063)	
training:	Epoch: [126][38/204]	Loss 0.0006 (0.0061)	
training:	Epoch: [126][39/204]	Loss 0.0005 (0.0060)	
training:	Epoch: [126][40/204]	Loss 0.0003 (0.0058)	
training:	Epoch: [126][41/204]	Loss 0.0003 (0.0057)	
training:	Epoch: [126][42/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [126][43/204]	Loss 0.0006 (0.0054)	
training:	Epoch: [126][44/204]	Loss 0.0005 (0.0053)	
training:	Epoch: [126][45/204]	Loss 0.0009 (0.0052)	
training:	Epoch: [126][46/204]	Loss 0.0008 (0.0051)	
training:	Epoch: [126][47/204]	Loss 0.0002 (0.0050)	
training:	Epoch: [126][48/204]	Loss 0.0004 (0.0049)	
training:	Epoch: [126][49/204]	Loss 0.0006 (0.0048)	
training:	Epoch: [126][50/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [126][51/204]	Loss 0.0007 (0.0047)	
training:	Epoch: [126][52/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [126][53/204]	Loss 0.0007 (0.0045)	
training:	Epoch: [126][54/204]	Loss 0.0009 (0.0045)	
training:	Epoch: [126][55/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [126][56/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [126][57/204]	Loss 0.0005 (0.0042)	
training:	Epoch: [126][58/204]	Loss 0.0007 (0.0042)	
training:	Epoch: [126][59/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [126][60/204]	Loss 0.0010 (0.0041)	
training:	Epoch: [126][61/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [126][62/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [126][63/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [126][64/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [126][65/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [126][66/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [126][67/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [126][68/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [126][69/204]	Loss 0.0003 (0.0036)	
training:	Epoch: [126][70/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [126][71/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [126][72/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [126][73/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [126][74/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [126][75/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [126][76/204]	Loss 0.0007 (0.0033)	
training:	Epoch: [126][77/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [126][78/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [126][79/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [126][80/204]	Loss 0.0006 (0.0032)	
training:	Epoch: [126][81/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [126][82/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [126][83/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [126][84/204]	Loss 0.0010 (0.0030)	
training:	Epoch: [126][85/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [126][86/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [126][87/204]	Loss 0.0015 (0.0030)	
training:	Epoch: [126][88/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [126][89/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [126][90/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [126][91/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [126][92/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [126][93/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [126][94/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [126][95/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [126][96/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [126][97/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [126][98/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [126][99/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [126][100/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [126][101/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [126][102/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [126][103/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [126][104/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [126][105/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [126][106/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [126][107/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [126][108/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [126][109/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [126][110/204]	Loss 0.0015 (0.0024)	
training:	Epoch: [126][111/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [126][112/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [126][113/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [126][114/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [126][115/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [126][116/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [126][117/204]	Loss 0.0012 (0.0023)	
training:	Epoch: [126][118/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [126][119/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [126][120/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [126][121/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [126][122/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [126][123/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [126][124/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [126][125/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [126][126/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [126][127/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [126][128/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [126][129/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [126][130/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [126][131/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [126][132/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [126][133/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [126][134/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [126][135/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [126][136/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [126][137/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [126][138/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [126][139/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [126][140/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [126][141/204]	Loss 0.2314 (0.0036)	
training:	Epoch: [126][142/204]	Loss 0.0003 (0.0036)	
training:	Epoch: [126][143/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [126][144/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [126][145/204]	Loss 0.0003 (0.0036)	
training:	Epoch: [126][146/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [126][147/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [126][148/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [126][149/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [126][150/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [126][151/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [126][152/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [126][153/204]	Loss 0.0004 (0.0034)	
training:	Epoch: [126][154/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [126][155/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [126][156/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [126][157/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [126][158/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [126][159/204]	Loss 0.0015 (0.0033)	
training:	Epoch: [126][160/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [126][161/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [126][162/204]	Loss 0.0009 (0.0032)	
training:	Epoch: [126][163/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [126][164/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [126][165/204]	Loss 0.0004 (0.0032)	
training:	Epoch: [126][166/204]	Loss 0.0008 (0.0032)	
training:	Epoch: [126][167/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [126][168/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [126][169/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [126][170/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [126][171/204]	Loss 0.0006 (0.0031)	
training:	Epoch: [126][172/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [126][173/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [126][174/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [126][175/204]	Loss 0.0007 (0.0030)	
training:	Epoch: [126][176/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [126][177/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [126][178/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [126][179/204]	Loss 0.0006 (0.0030)	
training:	Epoch: [126][180/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [126][181/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [126][182/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [126][183/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [126][184/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [126][185/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [126][186/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [126][187/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [126][188/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [126][189/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [126][190/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [126][191/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [126][192/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [126][193/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [126][194/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [126][195/204]	Loss 0.0016 (0.0028)	
training:	Epoch: [126][196/204]	Loss 0.0008 (0.0027)	
training:	Epoch: [126][197/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [126][198/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [126][199/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [126][200/204]	Loss 0.0015 (0.0027)	
training:	Epoch: [126][201/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [126][202/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [126][203/204]	Loss 0.0004 (0.0027)	
training:	Epoch: [126][204/204]	Loss 0.0004 (0.0027)	
Training:	 Loss: 0.0027

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7668 0.7683 0.8004 0.7332
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4215
Pretraining:	Epoch 127/500
----------
training:	Epoch: [127][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][2/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][3/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [127][4/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [127][5/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][6/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][7/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][8/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][9/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][11/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][12/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][13/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][14/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][15/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][16/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][17/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][18/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [127][19/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][20/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][21/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][22/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][23/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][24/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][25/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][26/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][27/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][28/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][29/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][30/204]	Loss 0.0012 (0.0004)	
training:	Epoch: [127][31/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][32/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][33/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][34/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][35/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][36/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][37/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][38/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][39/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][40/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][41/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][42/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][43/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][44/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][45/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [127][46/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][47/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][48/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][49/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][50/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][51/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][52/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][53/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][54/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][55/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [127][56/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][57/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][58/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][59/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [127][60/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][61/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][62/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][63/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][64/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][65/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][66/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][67/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][68/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][69/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][70/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][71/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][72/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][73/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][74/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][75/204]	Loss 0.0017 (0.0004)	
training:	Epoch: [127][76/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][77/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][78/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [127][79/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][80/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][81/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][82/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][83/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][84/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][85/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][86/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][87/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][88/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][89/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][90/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][91/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][92/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][93/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][94/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][95/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [127][96/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [127][97/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][98/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][99/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][100/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][101/204]	Loss 0.0040 (0.0005)	
training:	Epoch: [127][102/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [127][103/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][104/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][105/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [127][106/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [127][107/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [127][108/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [127][109/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [127][110/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][111/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [127][112/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [127][113/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [127][114/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [127][115/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][116/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][117/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [127][118/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [127][119/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [127][120/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [127][121/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][122/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [127][123/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [127][124/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][125/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][126/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][127/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][128/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][129/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [127][130/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][131/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][132/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][133/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][134/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][135/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][136/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][137/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][138/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][139/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][140/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][141/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][142/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][143/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][144/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [127][145/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][146/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][147/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][148/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][149/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][150/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][151/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][152/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][153/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][154/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][155/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [127][156/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][157/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][158/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][159/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][160/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][161/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][162/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][163/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][164/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][165/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][166/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][167/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [127][168/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][169/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][170/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][171/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [127][172/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][173/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][174/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][175/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [127][176/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][177/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][178/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][179/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [127][180/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][181/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][182/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [127][183/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [127][184/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [127][185/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [127][186/204]	Loss 0.1906 (0.0015)	
training:	Epoch: [127][187/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [127][188/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [127][189/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [127][190/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [127][191/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [127][192/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [127][193/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [127][194/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [127][195/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [127][196/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [127][197/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [127][198/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [127][199/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [127][200/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [127][201/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [127][202/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [127][203/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [127][204/204]	Loss 0.0003 (0.0014)	
Training:	 Loss: 0.0014

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7693 0.7710 0.8066 0.7321
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4399
Pretraining:	Epoch 128/500
----------
training:	Epoch: [128][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [128][2/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [128][3/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][4/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][5/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][6/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [128][7/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [128][8/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][9/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [128][10/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [128][11/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [128][12/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [128][13/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][14/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][15/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][16/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][17/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][18/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][19/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][20/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [128][21/204]	Loss 0.0014 (0.0005)	
training:	Epoch: [128][22/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][23/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][24/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][25/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][26/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][27/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][28/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][29/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [128][30/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][31/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [128][32/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][33/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][34/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][35/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][36/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][37/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [128][38/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [128][39/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][40/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [128][41/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][42/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][43/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][44/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][45/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][46/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][47/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][48/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [128][49/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][50/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][51/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][52/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][53/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [128][54/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][55/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][56/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [128][57/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][58/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][59/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][60/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [128][61/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [128][62/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][63/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][64/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][65/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][66/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][67/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][68/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][69/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][70/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][71/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][72/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][73/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][74/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][75/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][76/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][77/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][78/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][79/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][80/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][81/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [128][82/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][83/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][84/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][85/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [128][86/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [128][87/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [128][88/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][89/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [128][90/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [128][91/204]	Loss 0.1846 (0.0024)	
training:	Epoch: [128][92/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [128][93/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [128][94/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [128][95/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [128][96/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [128][97/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [128][98/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [128][99/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [128][100/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [128][101/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [128][102/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [128][103/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [128][104/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [128][105/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [128][106/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [128][107/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [128][108/204]	Loss 0.0015 (0.0021)	
training:	Epoch: [128][109/204]	Loss 0.0006 (0.0021)	
training:	Epoch: [128][110/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [128][111/204]	Loss 0.0045 (0.0021)	
training:	Epoch: [128][112/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [128][113/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [128][114/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [128][115/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [128][116/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [128][117/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [128][118/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [128][119/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [128][120/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [128][121/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [128][122/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [128][123/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [128][124/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [128][125/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [128][126/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [128][127/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [128][128/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [128][129/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [128][130/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [128][131/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [128][132/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [128][133/204]	Loss 0.0007 (0.0018)	
training:	Epoch: [128][134/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [128][135/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [128][136/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [128][137/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [128][138/204]	Loss 0.0021 (0.0018)	
training:	Epoch: [128][139/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [128][140/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [128][141/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [128][142/204]	Loss 0.0011 (0.0018)	
training:	Epoch: [128][143/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [128][144/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [128][145/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [128][146/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [128][147/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [128][148/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [128][149/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [128][150/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [128][151/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [128][152/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [128][153/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [128][154/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [128][155/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [128][156/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [128][157/204]	Loss 0.0008 (0.0016)	
training:	Epoch: [128][158/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [128][159/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [128][160/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [128][161/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [128][162/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [128][163/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [128][164/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [128][165/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [128][166/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [128][167/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [128][168/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [128][169/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [128][170/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [128][171/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [128][172/204]	Loss 0.0006 (0.0015)	
training:	Epoch: [128][173/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [128][174/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [128][175/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [128][176/204]	Loss 0.0014 (0.0015)	
training:	Epoch: [128][177/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [128][178/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [128][179/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [128][180/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [128][181/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [128][182/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [128][183/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [128][184/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][185/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][186/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][187/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [128][188/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [128][189/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [128][190/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][191/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][192/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [128][193/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][194/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [128][195/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [128][196/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [128][197/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][198/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][199/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][200/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [128][201/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [128][202/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [128][203/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [128][204/204]	Loss 0.0005 (0.0013)	
Training:	 Loss: 0.0013

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7716 0.7726 0.7932 0.7500
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4572
Pretraining:	Epoch 129/500
----------
training:	Epoch: [129][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [129][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [129][3/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [129][4/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [129][5/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [129][6/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [129][7/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [129][8/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [129][9/204]	Loss 0.0069 (0.0011)	
training:	Epoch: [129][10/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [129][11/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [129][12/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [129][13/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][14/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [129][15/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [129][16/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][17/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][18/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [129][19/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][20/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [129][21/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][22/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [129][23/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][24/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][25/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][26/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [129][27/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [129][28/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [129][29/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [129][30/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [129][31/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [129][32/204]	Loss 0.0224 (0.0013)	
training:	Epoch: [129][33/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [129][34/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [129][35/204]	Loss 0.0055 (0.0014)	
training:	Epoch: [129][36/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [129][37/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [129][38/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [129][39/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [129][40/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [129][41/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [129][42/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [129][43/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [129][44/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [129][45/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [129][46/204]	Loss 0.0007 (0.0011)	
training:	Epoch: [129][47/204]	Loss 0.0011 (0.0011)	
training:	Epoch: [129][48/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [129][49/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [129][50/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [129][51/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [129][52/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [129][53/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [129][54/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [129][55/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [129][56/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [129][57/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [129][58/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [129][59/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [129][60/204]	Loss 0.0017 (0.0010)	
training:	Epoch: [129][61/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [129][62/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [129][63/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [129][64/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [129][65/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [129][66/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][67/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [129][68/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [129][69/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [129][70/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [129][71/204]	Loss 0.0021 (0.0009)	
training:	Epoch: [129][72/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [129][73/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][74/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][75/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [129][76/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][77/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [129][78/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [129][79/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][80/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][81/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][82/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [129][83/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [129][84/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [129][85/204]	Loss 0.0011 (0.0009)	
training:	Epoch: [129][86/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][87/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][88/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][89/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][90/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][91/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [129][92/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [129][93/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [129][94/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][95/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [129][96/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][97/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [129][98/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][99/204]	Loss 0.0045 (0.0008)	
training:	Epoch: [129][100/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][101/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][102/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [129][103/204]	Loss 0.0052 (0.0009)	
training:	Epoch: [129][104/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][105/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][106/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [129][107/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][108/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][109/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][110/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][111/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][112/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][113/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][114/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][115/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][116/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][117/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][118/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][119/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][120/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][121/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][122/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][123/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][124/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][125/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][126/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [129][127/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [129][128/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [129][129/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [129][130/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][131/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [129][132/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [129][133/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [129][134/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [129][135/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][136/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [129][137/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][138/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][139/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][140/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][141/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][142/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][143/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [129][144/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [129][145/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][146/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][147/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][148/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][149/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [129][150/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][151/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][152/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][153/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [129][154/204]	Loss 0.0010 (0.0007)	
training:	Epoch: [129][155/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][156/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][157/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][158/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][159/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [129][160/204]	Loss 0.0023 (0.0007)	
training:	Epoch: [129][161/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][162/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [129][163/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [129][164/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [129][165/204]	Loss 0.1821 (0.0018)	
training:	Epoch: [129][166/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [129][167/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [129][168/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [129][169/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [129][170/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [129][171/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [129][172/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [129][173/204]	Loss 0.0002 (0.0017)	
training:	Epoch: [129][174/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [129][175/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [129][176/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [129][177/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [129][178/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [129][179/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [129][180/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [129][181/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [129][182/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [129][183/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [129][184/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [129][185/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [129][186/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [129][187/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [129][188/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [129][189/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [129][190/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [129][191/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [129][192/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [129][193/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [129][194/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [129][195/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [129][196/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [129][197/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [129][198/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [129][199/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [129][200/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [129][201/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [129][202/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [129][203/204]	Loss 0.0013 (0.0015)	
training:	Epoch: [129][204/204]	Loss 0.0004 (0.0015)	
Training:	 Loss: 0.0015

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7662 0.7673 0.7892 0.7433
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4957
Pretraining:	Epoch 130/500
----------
training:	Epoch: [130][1/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [130][2/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [130][3/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [130][4/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [130][5/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][6/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][7/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][8/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [130][9/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][11/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][12/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][13/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][14/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [130][15/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][16/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][17/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][18/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][19/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [130][20/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][21/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][22/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][23/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][24/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][25/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][26/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [130][27/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [130][28/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][29/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][30/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [130][31/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][32/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][33/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [130][34/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][35/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][36/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][37/204]	Loss 0.0015 (0.0004)	
training:	Epoch: [130][38/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][39/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [130][40/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [130][41/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][42/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][43/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [130][44/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][45/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [130][46/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][47/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [130][48/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][49/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][50/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][51/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][52/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][53/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [130][54/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][55/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][56/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][57/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][58/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [130][59/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][60/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][61/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][62/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][63/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][64/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][65/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][66/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [130][67/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [130][68/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][69/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][70/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][71/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][72/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [130][73/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][74/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][75/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][76/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][77/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][78/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [130][79/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][80/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][81/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][82/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [130][83/204]	Loss 0.1769 (0.0025)	
training:	Epoch: [130][84/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [130][85/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [130][86/204]	Loss 0.0005 (0.0025)	
training:	Epoch: [130][87/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [130][88/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [130][89/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [130][90/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [130][91/204]	Loss 0.0005 (0.0023)	
training:	Epoch: [130][92/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [130][93/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [130][94/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [130][95/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [130][96/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [130][97/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [130][98/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [130][99/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [130][100/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [130][101/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [130][102/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [130][103/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [130][104/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [130][105/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [130][106/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [130][107/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [130][108/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [130][109/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [130][110/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [130][111/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [130][112/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [130][113/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [130][114/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [130][115/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [130][116/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [130][117/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [130][118/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [130][119/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [130][120/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [130][121/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [130][122/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [130][123/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [130][124/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [130][125/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [130][126/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [130][127/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [130][128/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [130][129/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [130][130/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [130][131/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [130][132/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [130][133/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [130][134/204]	Loss 0.0007 (0.0017)	
training:	Epoch: [130][135/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [130][136/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [130][137/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [130][138/204]	Loss 0.0008 (0.0017)	
training:	Epoch: [130][139/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [130][140/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [130][141/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [130][142/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [130][143/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [130][144/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [130][145/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [130][146/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [130][147/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [130][148/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [130][149/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [130][150/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [130][151/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [130][152/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [130][153/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [130][154/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [130][155/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [130][156/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [130][157/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [130][158/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [130][159/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [130][160/204]	Loss 0.0006 (0.0015)	
training:	Epoch: [130][161/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [130][162/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [130][163/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [130][164/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [130][165/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [130][166/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [130][167/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [130][168/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [130][169/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [130][170/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [130][171/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [130][172/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [130][173/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [130][174/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [130][175/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [130][176/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [130][177/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [130][178/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [130][179/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [130][180/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [130][181/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [130][182/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [130][183/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [130][184/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [130][185/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [130][186/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [130][187/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [130][188/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [130][189/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [130][190/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [130][191/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [130][192/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [130][193/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [130][194/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [130][195/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [130][196/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [130][197/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [130][198/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [130][199/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [130][200/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [130][201/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [130][202/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [130][203/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [130][204/204]	Loss 0.0004 (0.0013)	
Training:	 Loss: 0.0013

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7680 0.7694 0.7984 0.7377
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5033
Pretraining:	Epoch 131/500
----------
training:	Epoch: [131][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [131][2/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [131][3/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [131][4/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [131][5/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [131][6/204]	Loss 0.1515 (0.0255)	
training:	Epoch: [131][7/204]	Loss 0.0004 (0.0219)	
training:	Epoch: [131][8/204]	Loss 0.0004 (0.0193)	
training:	Epoch: [131][9/204]	Loss 0.0004 (0.0172)	
training:	Epoch: [131][10/204]	Loss 0.0004 (0.0155)	
training:	Epoch: [131][11/204]	Loss 0.0003 (0.0141)	
training:	Epoch: [131][12/204]	Loss 0.0004 (0.0130)	
training:	Epoch: [131][13/204]	Loss 0.0003 (0.0120)	
training:	Epoch: [131][14/204]	Loss 0.0004 (0.0112)	
training:	Epoch: [131][15/204]	Loss 0.0003 (0.0104)	
training:	Epoch: [131][16/204]	Loss 0.0004 (0.0098)	
training:	Epoch: [131][17/204]	Loss 0.0004 (0.0093)	
training:	Epoch: [131][18/204]	Loss 0.0007 (0.0088)	
training:	Epoch: [131][19/204]	Loss 0.0004 (0.0083)	
training:	Epoch: [131][20/204]	Loss 0.0007 (0.0080)	
training:	Epoch: [131][21/204]	Loss 0.0003 (0.0076)	
training:	Epoch: [131][22/204]	Loss 0.0003 (0.0073)	
training:	Epoch: [131][23/204]	Loss 0.0004 (0.0070)	
training:	Epoch: [131][24/204]	Loss 0.0004 (0.0067)	
training:	Epoch: [131][25/204]	Loss 0.0002 (0.0064)	
training:	Epoch: [131][26/204]	Loss 0.0007 (0.0062)	
training:	Epoch: [131][27/204]	Loss 0.0005 (0.0060)	
training:	Epoch: [131][28/204]	Loss 0.0005 (0.0058)	
training:	Epoch: [131][29/204]	Loss 0.0004 (0.0056)	
training:	Epoch: [131][30/204]	Loss 0.0003 (0.0054)	
training:	Epoch: [131][31/204]	Loss 0.0003 (0.0053)	
training:	Epoch: [131][32/204]	Loss 0.0003 (0.0051)	
training:	Epoch: [131][33/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [131][34/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [131][35/204]	Loss 0.0005 (0.0047)	
training:	Epoch: [131][36/204]	Loss 0.0004 (0.0046)	
training:	Epoch: [131][37/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [131][38/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [131][39/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [131][40/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [131][41/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [131][42/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [131][43/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [131][44/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [131][45/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [131][46/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [131][47/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [131][48/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [131][49/204]	Loss 0.0007 (0.0035)	
training:	Epoch: [131][50/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [131][51/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [131][52/204]	Loss 0.0005 (0.0033)	
training:	Epoch: [131][53/204]	Loss 0.0006 (0.0033)	
training:	Epoch: [131][54/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [131][55/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [131][56/204]	Loss 0.0004 (0.0031)	
training:	Epoch: [131][57/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [131][58/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [131][59/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [131][60/204]	Loss 0.0007 (0.0029)	
training:	Epoch: [131][61/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [131][62/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [131][63/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [131][64/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [131][65/204]	Loss 0.0007 (0.0027)	
training:	Epoch: [131][66/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [131][67/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [131][68/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [131][69/204]	Loss 0.0006 (0.0026)	
training:	Epoch: [131][70/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [131][71/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [131][72/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [131][73/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [131][74/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [131][75/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [131][76/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [131][77/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [131][78/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [131][79/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [131][80/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [131][81/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [131][82/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [131][83/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [131][84/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [131][85/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [131][86/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [131][87/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [131][88/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [131][89/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [131][90/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [131][91/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [131][92/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [131][93/204]	Loss 0.0005 (0.0020)	
training:	Epoch: [131][94/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [131][95/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [131][96/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [131][97/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [131][98/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [131][99/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [131][100/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [131][101/204]	Loss 0.0006 (0.0019)	
training:	Epoch: [131][102/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [131][103/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [131][104/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [131][105/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [131][106/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [131][107/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [131][108/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [131][109/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [131][110/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [131][111/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [131][112/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [131][113/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [131][114/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [131][115/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [131][116/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [131][117/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [131][118/204]	Loss 0.0011 (0.0017)	
training:	Epoch: [131][119/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [131][120/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [131][121/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [131][122/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [131][123/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [131][124/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [131][125/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [131][126/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [131][127/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [131][128/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [131][129/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [131][130/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [131][131/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [131][132/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [131][133/204]	Loss 0.0009 (0.0015)	
training:	Epoch: [131][134/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [131][135/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [131][136/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [131][137/204]	Loss 0.0014 (0.0015)	
training:	Epoch: [131][138/204]	Loss 0.0006 (0.0015)	
training:	Epoch: [131][139/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [131][140/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [131][141/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [131][142/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [131][143/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [131][144/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [131][145/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [131][146/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [131][147/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [131][148/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [131][149/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [131][150/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [131][151/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [131][152/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [131][153/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [131][154/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [131][155/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [131][156/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [131][157/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [131][158/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [131][159/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [131][160/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [131][161/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][162/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [131][163/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][164/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][165/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][166/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [131][167/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][168/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [131][169/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][170/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [131][171/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][172/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [131][173/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][174/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [131][175/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][176/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [131][177/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [131][178/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [131][179/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][180/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [131][181/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][182/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][183/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][184/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][185/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [131][186/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][187/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [131][188/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][189/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][190/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [131][191/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [131][192/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [131][193/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][194/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [131][195/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [131][196/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][197/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][198/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [131][199/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [131][200/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [131][201/204]	Loss 0.0008 (0.0011)	
training:	Epoch: [131][202/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [131][203/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [131][204/204]	Loss 0.0002 (0.0011)	
Training:	 Loss: 0.0011

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7657 0.7673 0.7994 0.7321
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5242
Pretraining:	Epoch 132/500
----------
training:	Epoch: [132][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][2/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][3/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][4/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][5/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [132][6/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [132][7/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][8/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][9/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][10/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][11/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][12/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [132][13/204]	Loss 0.0034 (0.0006)	
training:	Epoch: [132][14/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [132][15/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [132][16/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [132][17/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [132][18/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [132][19/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [132][20/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [132][21/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [132][22/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [132][23/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [132][24/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [132][25/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [132][26/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [132][27/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [132][28/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [132][29/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [132][30/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [132][31/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [132][32/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][33/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][34/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][35/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][36/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][37/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][38/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][39/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][40/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][41/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][42/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [132][43/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][44/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][45/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][46/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][47/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][48/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][49/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][50/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][51/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][52/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][53/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][54/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][55/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][56/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][57/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][58/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][59/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][60/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][61/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][62/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][63/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][64/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][65/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][66/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][67/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][68/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][69/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [132][70/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][71/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][72/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][73/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][74/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][75/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][76/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][77/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][78/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][79/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][80/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][81/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][82/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][83/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][84/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][85/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][86/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][87/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][88/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][89/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][90/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][91/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][92/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][93/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][94/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][95/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][96/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][97/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][98/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [132][99/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][100/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][101/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][102/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][103/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][104/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][105/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][106/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][107/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [132][108/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][109/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][110/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][111/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][112/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [132][113/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [132][114/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [132][115/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][116/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][117/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][118/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][119/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][120/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][121/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [132][122/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][123/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][124/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [132][125/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][126/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][127/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][128/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][129/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][130/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [132][131/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [132][132/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [132][133/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][134/204]	Loss 0.0013 (0.0004)	
training:	Epoch: [132][135/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [132][136/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][137/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [132][138/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][139/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][140/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][141/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][142/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][143/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [132][144/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][145/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [132][146/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][147/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [132][148/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][149/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][150/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [132][151/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][152/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [132][153/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][154/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][155/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][156/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [132][157/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [132][158/204]	Loss 0.1460 (0.0013)	
training:	Epoch: [132][159/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [132][160/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [132][161/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [132][162/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][163/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][164/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][165/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][166/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][167/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][168/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][169/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [132][170/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][171/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][172/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [132][173/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][174/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][175/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [132][176/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [132][177/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [132][178/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [132][179/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][180/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][181/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [132][182/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [132][183/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [132][184/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [132][185/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [132][186/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [132][187/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [132][188/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [132][189/204]	Loss 0.0035 (0.0011)	
training:	Epoch: [132][190/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [132][191/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [132][192/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [132][193/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [132][194/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [132][195/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [132][196/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [132][197/204]	Loss 0.0008 (0.0011)	
training:	Epoch: [132][198/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [132][199/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [132][200/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [132][201/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [132][202/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [132][203/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [132][204/204]	Loss 0.0003 (0.0011)	
Training:	 Loss: 0.0011

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7676 0.7689 0.7943 0.7410
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5239
Pretraining:	Epoch 133/500
----------
training:	Epoch: [133][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][3/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][4/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][5/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][6/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [133][7/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][8/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [133][9/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][10/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][11/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][12/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [133][13/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [133][14/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [133][15/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][16/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][17/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][18/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][19/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][20/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][21/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][22/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][23/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [133][24/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][25/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][26/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][27/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [133][28/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [133][29/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][30/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][31/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][32/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][33/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [133][34/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [133][35/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [133][36/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [133][37/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [133][38/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [133][39/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [133][40/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][41/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][42/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][43/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [133][44/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][45/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][46/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [133][47/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [133][48/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [133][49/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][50/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][51/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][52/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][53/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][54/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][55/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [133][56/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][57/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][58/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][59/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][60/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][61/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][62/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][63/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][64/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][65/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][66/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][67/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][68/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][69/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][70/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][71/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][72/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][73/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][74/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [133][75/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][76/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][77/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][78/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [133][79/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][80/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][81/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][82/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][83/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][84/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][85/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][86/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][87/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][88/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [133][89/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][90/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][91/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][92/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][93/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][94/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][95/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][96/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][97/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][98/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][99/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][100/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [133][101/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][102/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][103/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [133][104/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][105/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [133][106/204]	Loss 0.0825 (0.0011)	
training:	Epoch: [133][107/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][108/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][109/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [133][110/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][111/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][112/204]	Loss 0.0013 (0.0011)	
training:	Epoch: [133][113/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [133][114/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [133][115/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][116/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][117/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [133][118/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [133][119/204]	Loss 0.0014 (0.0010)	
training:	Epoch: [133][120/204]	Loss 0.0186 (0.0012)	
training:	Epoch: [133][121/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][122/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][123/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [133][124/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [133][125/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][126/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][127/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][128/204]	Loss 0.0012 (0.0011)	
training:	Epoch: [133][129/204]	Loss 0.0015 (0.0012)	
training:	Epoch: [133][130/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [133][131/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][132/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [133][133/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [133][134/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [133][135/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][136/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [133][137/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [133][138/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [133][139/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [133][140/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][141/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][142/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][143/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][144/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][145/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [133][146/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [133][147/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [133][148/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [133][149/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [133][150/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [133][151/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [133][152/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [133][153/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [133][154/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [133][155/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [133][156/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [133][157/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [133][158/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [133][159/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [133][160/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [133][161/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [133][162/204]	Loss 0.0373 (0.0012)	
training:	Epoch: [133][163/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [133][164/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [133][165/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][166/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][167/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][168/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][169/204]	Loss 0.0017 (0.0012)	
training:	Epoch: [133][170/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [133][171/204]	Loss 0.0106 (0.0012)	
training:	Epoch: [133][172/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][173/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [133][174/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][175/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [133][176/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][177/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][178/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [133][179/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [133][180/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][181/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][182/204]	Loss 0.0009 (0.0012)	
training:	Epoch: [133][183/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][184/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [133][185/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][186/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [133][187/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][188/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][189/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [133][190/204]	Loss 0.0035 (0.0012)	
training:	Epoch: [133][191/204]	Loss 0.0052 (0.0012)	
training:	Epoch: [133][192/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][193/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [133][194/204]	Loss 0.0019 (0.0012)	
training:	Epoch: [133][195/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][196/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][197/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][198/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [133][199/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [133][200/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][201/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [133][202/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [133][203/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [133][204/204]	Loss 0.0004 (0.0011)	
Training:	 Loss: 0.0011

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7693 0.7710 0.8076 0.7309
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5459
Pretraining:	Epoch 134/500
----------
training:	Epoch: [134][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][2/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [134][3/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [134][4/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [134][5/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [134][6/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [134][7/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][8/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][9/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][10/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][11/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][12/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][13/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][14/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][15/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][16/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][17/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][18/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][19/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][20/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][21/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [134][22/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][23/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [134][24/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][25/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][26/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][27/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][28/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][29/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [134][30/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][31/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][32/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][33/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][34/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][35/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][36/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [134][37/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][38/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][39/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][40/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][41/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][42/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][43/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][44/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][45/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][46/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][47/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][48/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][49/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][50/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][51/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][52/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][53/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][54/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [134][55/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [134][56/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][57/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][58/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][59/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][60/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][61/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][62/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [134][63/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [134][64/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][65/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][66/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][67/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][68/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][69/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][70/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [134][71/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][72/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][73/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][74/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][75/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [134][76/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][77/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][78/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][79/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][80/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][81/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][82/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][83/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][84/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [134][85/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][86/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][87/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][88/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][89/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][90/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][91/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][92/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][93/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][94/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][95/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [134][96/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][97/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][98/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][99/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [134][100/204]	Loss 0.0857 (0.0011)	
training:	Epoch: [134][101/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [134][102/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [134][103/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [134][104/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [134][105/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [134][106/204]	Loss 0.0011 (0.0011)	
training:	Epoch: [134][107/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [134][108/204]	Loss 0.0625 (0.0017)	
training:	Epoch: [134][109/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [134][110/204]	Loss 0.0007 (0.0016)	
training:	Epoch: [134][111/204]	Loss 0.0012 (0.0016)	
training:	Epoch: [134][112/204]	Loss 0.0440 (0.0020)	
training:	Epoch: [134][113/204]	Loss 0.0217 (0.0022)	
training:	Epoch: [134][114/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [134][115/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [134][116/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [134][117/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [134][118/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [134][119/204]	Loss 0.0017 (0.0021)	
training:	Epoch: [134][120/204]	Loss 0.0014 (0.0021)	
training:	Epoch: [134][121/204]	Loss 0.0152 (0.0022)	
training:	Epoch: [134][122/204]	Loss 0.0009 (0.0022)	
training:	Epoch: [134][123/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [134][124/204]	Loss 0.0112 (0.0023)	
training:	Epoch: [134][125/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [134][126/204]	Loss 0.0758 (0.0028)	
training:	Epoch: [134][127/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [134][128/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [134][129/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [134][130/204]	Loss 0.0010 (0.0028)	
training:	Epoch: [134][131/204]	Loss 0.0230 (0.0029)	
training:	Epoch: [134][132/204]	Loss 0.0142 (0.0030)	
training:	Epoch: [134][133/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [134][134/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [134][135/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [134][136/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [134][137/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [134][138/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [134][139/204]	Loss 0.0031 (0.0029)	
training:	Epoch: [134][140/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [134][141/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [134][142/204]	Loss 0.0023 (0.0029)	
training:	Epoch: [134][143/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [134][144/204]	Loss 0.0969 (0.0035)	
training:	Epoch: [134][145/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [134][146/204]	Loss 0.0827 (0.0040)	
training:	Epoch: [134][147/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [134][148/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [134][149/204]	Loss 0.0034 (0.0040)	
training:	Epoch: [134][150/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [134][151/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [134][152/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [134][153/204]	Loss 0.0002 (0.0039)	
training:	Epoch: [134][154/204]	Loss 0.0382 (0.0041)	
training:	Epoch: [134][155/204]	Loss 0.0048 (0.0041)	
training:	Epoch: [134][156/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [134][157/204]	Loss 0.0290 (0.0042)	
training:	Epoch: [134][158/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [134][159/204]	Loss 0.0310 (0.0044)	
training:	Epoch: [134][160/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [134][161/204]	Loss 0.0002 (0.0043)	
training:	Epoch: [134][162/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [134][163/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [134][164/204]	Loss 0.0003 (0.0043)	
training:	Epoch: [134][165/204]	Loss 0.0006 (0.0042)	
training:	Epoch: [134][166/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [134][167/204]	Loss 0.0007 (0.0042)	
training:	Epoch: [134][168/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [134][169/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [134][170/204]	Loss 0.0017 (0.0041)	
training:	Epoch: [134][171/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [134][172/204]	Loss 0.0924 (0.0046)	
training:	Epoch: [134][173/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [134][174/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [134][175/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [134][176/204]	Loss 0.0002 (0.0045)	
training:	Epoch: [134][177/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [134][178/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [134][179/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [134][180/204]	Loss 0.1589 (0.0053)	
training:	Epoch: [134][181/204]	Loss 0.0003 (0.0053)	
training:	Epoch: [134][182/204]	Loss 0.0003 (0.0053)	
training:	Epoch: [134][183/204]	Loss 0.1475 (0.0060)	
training:	Epoch: [134][184/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [134][185/204]	Loss 0.0007 (0.0060)	
training:	Epoch: [134][186/204]	Loss 0.0509 (0.0062)	
training:	Epoch: [134][187/204]	Loss 0.0003 (0.0062)	
training:	Epoch: [134][188/204]	Loss 0.0005 (0.0062)	
training:	Epoch: [134][189/204]	Loss 0.0036 (0.0061)	
training:	Epoch: [134][190/204]	Loss 0.0003 (0.0061)	
training:	Epoch: [134][191/204]	Loss 0.0004 (0.0061)	
training:	Epoch: [134][192/204]	Loss 0.0043 (0.0061)	
training:	Epoch: [134][193/204]	Loss 0.0184 (0.0061)	
training:	Epoch: [134][194/204]	Loss 0.0386 (0.0063)	
training:	Epoch: [134][195/204]	Loss 0.0009 (0.0063)	
training:	Epoch: [134][196/204]	Loss 0.0003 (0.0062)	
training:	Epoch: [134][197/204]	Loss 0.0003 (0.0062)	
training:	Epoch: [134][198/204]	Loss 0.0003 (0.0062)	
training:	Epoch: [134][199/204]	Loss 0.0003 (0.0062)	
training:	Epoch: [134][200/204]	Loss 0.0003 (0.0061)	
training:	Epoch: [134][201/204]	Loss 0.0003 (0.0061)	
training:	Epoch: [134][202/204]	Loss 0.0018 (0.0061)	
training:	Epoch: [134][203/204]	Loss 0.0005 (0.0060)	
training:	Epoch: [134][204/204]	Loss 0.0005 (0.0060)	
Training:	 Loss: 0.0060

Training:	 ACC: 0.9991 0.9991 0.9997 0.9984
Validation:	 ACC: 0.7738 0.7764 0.8301 0.7175
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4325
Pretraining:	Epoch 135/500
----------
training:	Epoch: [135][1/204]	Loss 0.0010 (0.0010)	
training:	Epoch: [135][2/204]	Loss 0.0005 (0.0008)	
training:	Epoch: [135][3/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [135][4/204]	Loss 0.0112 (0.0033)	
training:	Epoch: [135][5/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [135][6/204]	Loss 0.0015 (0.0025)	
training:	Epoch: [135][7/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [135][8/204]	Loss 0.0011 (0.0020)	
training:	Epoch: [135][9/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [135][10/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [135][11/204]	Loss 0.0045 (0.0020)	
training:	Epoch: [135][12/204]	Loss 0.0015 (0.0019)	
training:	Epoch: [135][13/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [135][14/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [135][15/204]	Loss 0.0015 (0.0017)	
training:	Epoch: [135][16/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [135][17/204]	Loss 0.0053 (0.0018)	
training:	Epoch: [135][18/204]	Loss 0.0578 (0.0049)	
training:	Epoch: [135][19/204]	Loss 0.0003 (0.0047)	
training:	Epoch: [135][20/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [135][21/204]	Loss 0.0021 (0.0044)	
training:	Epoch: [135][22/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [135][23/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [135][24/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [135][25/204]	Loss 0.0009 (0.0038)	
training:	Epoch: [135][26/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [135][27/204]	Loss 0.0009 (0.0035)	
training:	Epoch: [135][28/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [135][29/204]	Loss 0.0002 (0.0033)	
training:	Epoch: [135][30/204]	Loss 0.0268 (0.0041)	
training:	Epoch: [135][31/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [135][32/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [135][33/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [135][34/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [135][35/204]	Loss 0.0017 (0.0036)	
training:	Epoch: [135][36/204]	Loss 0.0006 (0.0035)	
training:	Epoch: [135][37/204]	Loss 0.0020 (0.0035)	
training:	Epoch: [135][38/204]	Loss 0.0201 (0.0039)	
training:	Epoch: [135][39/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [135][40/204]	Loss 0.0007 (0.0037)	
training:	Epoch: [135][41/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [135][42/204]	Loss 0.0009 (0.0036)	
training:	Epoch: [135][43/204]	Loss 0.0002 (0.0035)	
training:	Epoch: [135][44/204]	Loss 0.0018 (0.0035)	
training:	Epoch: [135][45/204]	Loss 0.0002 (0.0034)	
training:	Epoch: [135][46/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [135][47/204]	Loss 0.0103 (0.0035)	
training:	Epoch: [135][48/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [135][49/204]	Loss 0.0373 (0.0041)	
training:	Epoch: [135][50/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [135][51/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [135][52/204]	Loss 0.0047 (0.0040)	
training:	Epoch: [135][53/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [135][54/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [135][55/204]	Loss 0.0072 (0.0039)	
training:	Epoch: [135][56/204]	Loss 0.0017 (0.0039)	
training:	Epoch: [135][57/204]	Loss 0.0010 (0.0038)	
training:	Epoch: [135][58/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [135][59/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [135][60/204]	Loss 0.0014 (0.0037)	
training:	Epoch: [135][61/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [135][62/204]	Loss 0.0007 (0.0036)	
training:	Epoch: [135][63/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [135][64/204]	Loss 0.0018 (0.0035)	
training:	Epoch: [135][65/204]	Loss 0.0046 (0.0035)	
training:	Epoch: [135][66/204]	Loss 0.0005 (0.0035)	
training:	Epoch: [135][67/204]	Loss 0.0158 (0.0036)	
training:	Epoch: [135][68/204]	Loss 0.0711 (0.0046)	
training:	Epoch: [135][69/204]	Loss 0.0224 (0.0049)	
training:	Epoch: [135][70/204]	Loss 0.0025 (0.0049)	
training:	Epoch: [135][71/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [135][72/204]	Loss 0.0003 (0.0047)	
training:	Epoch: [135][73/204]	Loss 0.0022 (0.0047)	
training:	Epoch: [135][74/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [135][75/204]	Loss 0.0008 (0.0046)	
training:	Epoch: [135][76/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [135][77/204]	Loss 0.0004 (0.0045)	
training:	Epoch: [135][78/204]	Loss 0.0012 (0.0044)	
training:	Epoch: [135][79/204]	Loss 0.0266 (0.0047)	
training:	Epoch: [135][80/204]	Loss 0.0029 (0.0047)	
training:	Epoch: [135][81/204]	Loss 0.0006 (0.0046)	
training:	Epoch: [135][82/204]	Loss 0.0015 (0.0046)	
training:	Epoch: [135][83/204]	Loss 0.0288 (0.0049)	
training:	Epoch: [135][84/204]	Loss 0.0011 (0.0048)	
training:	Epoch: [135][85/204]	Loss 0.0003 (0.0048)	
training:	Epoch: [135][86/204]	Loss 0.0006 (0.0047)	
training:	Epoch: [135][87/204]	Loss 0.0004 (0.0047)	
training:	Epoch: [135][88/204]	Loss 0.0003 (0.0046)	
training:	Epoch: [135][89/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [135][90/204]	Loss 0.0005 (0.0046)	
training:	Epoch: [135][91/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [135][92/204]	Loss 0.0002 (0.0045)	
training:	Epoch: [135][93/204]	Loss 0.0034 (0.0044)	
training:	Epoch: [135][94/204]	Loss 0.0007 (0.0044)	
training:	Epoch: [135][95/204]	Loss 0.0075 (0.0044)	
training:	Epoch: [135][96/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [135][97/204]	Loss 0.0004 (0.0044)	
training:	Epoch: [135][98/204]	Loss 0.0005 (0.0043)	
training:	Epoch: [135][99/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [135][100/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [135][101/204]	Loss 0.0002 (0.0042)	
training:	Epoch: [135][102/204]	Loss 0.0006 (0.0042)	
training:	Epoch: [135][103/204]	Loss 0.0142 (0.0043)	
training:	Epoch: [135][104/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [135][105/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [135][106/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [135][107/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [135][108/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [135][109/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [135][110/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [135][111/204]	Loss 0.0157 (0.0041)	
training:	Epoch: [135][112/204]	Loss 0.0026 (0.0041)	
training:	Epoch: [135][113/204]	Loss 0.0009 (0.0041)	
training:	Epoch: [135][114/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [135][115/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [135][116/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [135][117/204]	Loss 0.0009 (0.0040)	
training:	Epoch: [135][118/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [135][119/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [135][120/204]	Loss 0.0016 (0.0039)	
training:	Epoch: [135][121/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [135][122/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [135][123/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [135][124/204]	Loss 0.0022 (0.0038)	
training:	Epoch: [135][125/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [135][126/204]	Loss 0.0542 (0.0042)	
training:	Epoch: [135][127/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [135][128/204]	Loss 0.0002 (0.0041)	
training:	Epoch: [135][129/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [135][130/204]	Loss 0.0012 (0.0040)	
training:	Epoch: [135][131/204]	Loss 0.0005 (0.0040)	
training:	Epoch: [135][132/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [135][133/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [135][134/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [135][135/204]	Loss 0.0005 (0.0039)	
training:	Epoch: [135][136/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [135][137/204]	Loss 0.0042 (0.0039)	
training:	Epoch: [135][138/204]	Loss 0.0010 (0.0039)	
training:	Epoch: [135][139/204]	Loss 0.0002 (0.0038)	
training:	Epoch: [135][140/204]	Loss 0.0011 (0.0038)	
training:	Epoch: [135][141/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [135][142/204]	Loss 0.0195 (0.0039)	
training:	Epoch: [135][143/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [135][144/204]	Loss 0.0006 (0.0039)	
training:	Epoch: [135][145/204]	Loss 0.0809 (0.0044)	
training:	Epoch: [135][146/204]	Loss 0.0002 (0.0044)	
training:	Epoch: [135][147/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [135][148/204]	Loss 0.0009 (0.0043)	
training:	Epoch: [135][149/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [135][150/204]	Loss 0.0007 (0.0043)	
training:	Epoch: [135][151/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [135][152/204]	Loss 0.0002 (0.0042)	
training:	Epoch: [135][153/204]	Loss 0.0008 (0.0042)	
training:	Epoch: [135][154/204]	Loss 0.0013 (0.0042)	
training:	Epoch: [135][155/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [135][156/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [135][157/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [135][158/204]	Loss 0.0005 (0.0041)	
training:	Epoch: [135][159/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [135][160/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [135][161/204]	Loss 0.0006 (0.0040)	
training:	Epoch: [135][162/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [135][163/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [135][164/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [135][165/204]	Loss 0.0008 (0.0039)	
training:	Epoch: [135][166/204]	Loss 0.0010 (0.0039)	
training:	Epoch: [135][167/204]	Loss 0.0007 (0.0039)	
training:	Epoch: [135][168/204]	Loss 0.0009 (0.0039)	
training:	Epoch: [135][169/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [135][170/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [135][171/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [135][172/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [135][173/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [135][174/204]	Loss 0.0105 (0.0038)	
training:	Epoch: [135][175/204]	Loss 0.0003 (0.0038)	
training:	Epoch: [135][176/204]	Loss 0.0009 (0.0038)	
training:	Epoch: [135][177/204]	Loss 0.0230 (0.0039)	
training:	Epoch: [135][178/204]	Loss 0.0004 (0.0039)	
training:	Epoch: [135][179/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [135][180/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [135][181/204]	Loss 0.0002 (0.0038)	
training:	Epoch: [135][182/204]	Loss 0.0006 (0.0038)	
training:	Epoch: [135][183/204]	Loss 0.0009 (0.0038)	
training:	Epoch: [135][184/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [135][185/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [135][186/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [135][187/204]	Loss 0.0004 (0.0037)	
training:	Epoch: [135][188/204]	Loss 0.0244 (0.0038)	
training:	Epoch: [135][189/204]	Loss 0.0004 (0.0038)	
training:	Epoch: [135][190/204]	Loss 0.0012 (0.0038)	
training:	Epoch: [135][191/204]	Loss 0.0002 (0.0038)	
training:	Epoch: [135][192/204]	Loss 0.0005 (0.0037)	
training:	Epoch: [135][193/204]	Loss 0.0006 (0.0037)	
training:	Epoch: [135][194/204]	Loss 0.0002 (0.0037)	
training:	Epoch: [135][195/204]	Loss 0.0005 (0.0037)	
training:	Epoch: [135][196/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [135][197/204]	Loss 0.0005 (0.0037)	
training:	Epoch: [135][198/204]	Loss 0.0003 (0.0036)	
training:	Epoch: [135][199/204]	Loss 0.0003 (0.0036)	
training:	Epoch: [135][200/204]	Loss 0.0012 (0.0036)	
training:	Epoch: [135][201/204]	Loss 0.0006 (0.0036)	
training:	Epoch: [135][202/204]	Loss 0.0004 (0.0036)	
training:	Epoch: [135][203/204]	Loss 0.0287 (0.0037)	
training:	Epoch: [135][204/204]	Loss 0.0003 (0.0037)	
Training:	 Loss: 0.0037

Training:	 ACC: 0.9995 0.9995 1.0000 0.9990
Validation:	 ACC: 0.7714 0.7747 0.8454 0.6973
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5413
Pretraining:	Epoch 136/500
----------
training:	Epoch: [136][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [136][2/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [136][3/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][4/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [136][5/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [136][6/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [136][7/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [136][8/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [136][9/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [136][10/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [136][11/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [136][12/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [136][13/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [136][14/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][15/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][16/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [136][17/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [136][18/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [136][19/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][20/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][21/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][22/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [136][23/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][24/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][25/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [136][26/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][27/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [136][28/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [136][29/204]	Loss 0.0016 (0.0005)	
training:	Epoch: [136][30/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][31/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][32/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [136][33/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [136][34/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][35/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [136][36/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [136][37/204]	Loss 0.0074 (0.0006)	
training:	Epoch: [136][38/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [136][39/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [136][40/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [136][41/204]	Loss 0.0134 (0.0009)	
training:	Epoch: [136][42/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][43/204]	Loss 0.0011 (0.0009)	
training:	Epoch: [136][44/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [136][45/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [136][46/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][47/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [136][48/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [136][49/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][50/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [136][51/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][52/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [136][53/204]	Loss 0.0034 (0.0008)	
training:	Epoch: [136][54/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][55/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [136][56/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][57/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [136][58/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][59/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][60/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][61/204]	Loss 0.0170 (0.0010)	
training:	Epoch: [136][62/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [136][63/204]	Loss 0.0048 (0.0011)	
training:	Epoch: [136][64/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [136][65/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [136][66/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [136][67/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [136][68/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [136][69/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [136][70/204]	Loss 0.0010 (0.0010)	
training:	Epoch: [136][71/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [136][72/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [136][73/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [136][74/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [136][75/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [136][76/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [136][77/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [136][78/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][79/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][80/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [136][81/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][82/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][83/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][84/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][85/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][86/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][87/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][88/204]	Loss 0.0030 (0.0009)	
training:	Epoch: [136][89/204]	Loss 0.0096 (0.0010)	
training:	Epoch: [136][90/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [136][91/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [136][92/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [136][93/204]	Loss 0.0008 (0.0010)	
training:	Epoch: [136][94/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [136][95/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [136][96/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [136][97/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][98/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][99/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][100/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [136][101/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][102/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][103/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [136][104/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [136][105/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][106/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][107/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [136][108/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [136][109/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][110/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [136][111/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][112/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [136][113/204]	Loss 0.0017 (0.0009)	
training:	Epoch: [136][114/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [136][115/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [136][116/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [136][117/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [136][118/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][119/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [136][120/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [136][121/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [136][122/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][123/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [136][124/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [136][125/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][126/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [136][127/204]	Loss 0.0086 (0.0009)	
training:	Epoch: [136][128/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [136][129/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [136][130/204]	Loss 0.1308 (0.0019)	
training:	Epoch: [136][131/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [136][132/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [136][133/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [136][134/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [136][135/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [136][136/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [136][137/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [136][138/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [136][139/204]	Loss 0.0008 (0.0018)	
training:	Epoch: [136][140/204]	Loss 0.0043 (0.0018)	
training:	Epoch: [136][141/204]	Loss 0.0040 (0.0018)	
training:	Epoch: [136][142/204]	Loss 0.0149 (0.0019)	
training:	Epoch: [136][143/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [136][144/204]	Loss 0.0005 (0.0019)	
training:	Epoch: [136][145/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [136][146/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [136][147/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [136][148/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [136][149/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [136][150/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [136][151/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [136][152/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [136][153/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [136][154/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [136][155/204]	Loss 0.0031 (0.0018)	
training:	Epoch: [136][156/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [136][157/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [136][158/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [136][159/204]	Loss 0.0002 (0.0017)	
training:	Epoch: [136][160/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [136][161/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [136][162/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [136][163/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [136][164/204]	Loss 0.1291 (0.0025)	
training:	Epoch: [136][165/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [136][166/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [136][167/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [136][168/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [136][169/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [136][170/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [136][171/204]	Loss 0.0006 (0.0024)	
training:	Epoch: [136][172/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [136][173/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [136][174/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [136][175/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [136][176/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [136][177/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [136][178/204]	Loss 0.0006 (0.0023)	
training:	Epoch: [136][179/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [136][180/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [136][181/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [136][182/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [136][183/204]	Loss 0.0012 (0.0023)	
training:	Epoch: [136][184/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [136][185/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [136][186/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [136][187/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [136][188/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [136][189/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [136][190/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [136][191/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [136][192/204]	Loss 0.0009 (0.0022)	
training:	Epoch: [136][193/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [136][194/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [136][195/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [136][196/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [136][197/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [136][198/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [136][199/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [136][200/204]	Loss 0.0012 (0.0021)	
training:	Epoch: [136][201/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [136][202/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [136][203/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [136][204/204]	Loss 0.0002 (0.0021)	
Training:	 Loss: 0.0021

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7665 0.7673 0.7840 0.7489
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5082
Pretraining:	Epoch 137/500
----------
training:	Epoch: [137][1/204]	Loss 0.0082 (0.0082)	
training:	Epoch: [137][2/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [137][3/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [137][4/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [137][5/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [137][6/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [137][7/204]	Loss 0.0011 (0.0015)	
training:	Epoch: [137][8/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [137][9/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [137][10/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [137][11/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [137][12/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [137][13/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [137][14/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [137][15/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [137][16/204]	Loss 0.0017 (0.0009)	
training:	Epoch: [137][17/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [137][18/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [137][19/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [137][20/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [137][21/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [137][22/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][23/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][24/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [137][25/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][26/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][27/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][28/204]	Loss 0.0020 (0.0007)	
training:	Epoch: [137][29/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][30/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][31/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][32/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [137][33/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][34/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][35/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [137][36/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][37/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][38/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][39/204]	Loss 0.0127 (0.0009)	
training:	Epoch: [137][40/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [137][41/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [137][42/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [137][43/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [137][44/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [137][45/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [137][46/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [137][47/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [137][48/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [137][49/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [137][50/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [137][51/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [137][52/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [137][53/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [137][54/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][55/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [137][56/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][57/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][58/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [137][59/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][60/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][61/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][62/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [137][63/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][64/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][65/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][66/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][67/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [137][68/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][69/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [137][70/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][71/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][72/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][73/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][74/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [137][75/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][76/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][77/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][78/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][79/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][80/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][81/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][82/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][83/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][84/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [137][85/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [137][86/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][87/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][88/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][89/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][90/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [137][91/204]	Loss 0.0023 (0.0006)	
training:	Epoch: [137][92/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][93/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][94/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][95/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][96/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][97/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][98/204]	Loss 0.0017 (0.0006)	
training:	Epoch: [137][99/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][100/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][101/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][102/204]	Loss 0.0018 (0.0006)	
training:	Epoch: [137][103/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [137][104/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [137][105/204]	Loss 0.0021 (0.0006)	
training:	Epoch: [137][106/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][107/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][108/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][109/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][110/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][111/204]	Loss 0.0016 (0.0006)	
training:	Epoch: [137][112/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][113/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][114/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][115/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][116/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [137][117/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][118/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][119/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][120/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][121/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][122/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][123/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][124/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][125/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [137][126/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][127/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][128/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [137][129/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][130/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][131/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][132/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][133/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][134/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][135/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][136/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][137/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [137][138/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [137][139/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [137][140/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][141/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][142/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][143/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][144/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][145/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][146/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [137][147/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][148/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][149/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][150/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [137][151/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][152/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][153/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][154/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][155/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][156/204]	Loss 0.0015 (0.0005)	
training:	Epoch: [137][157/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][158/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [137][159/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][160/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][161/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][162/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [137][163/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][164/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][165/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][166/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][167/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][168/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][169/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][170/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][171/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][172/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][173/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [137][174/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [137][175/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][176/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][177/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][178/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][179/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][180/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][181/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][182/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][183/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [137][184/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][185/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [137][186/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][187/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][188/204]	Loss 0.0011 (0.0005)	
training:	Epoch: [137][189/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][190/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][191/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][192/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [137][193/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][194/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][195/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][196/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][197/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][198/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][199/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [137][200/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [137][201/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][202/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [137][203/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [137][204/204]	Loss 0.0002 (0.0005)	
Training:	 Loss: 0.0005

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7669 0.7678 0.7871 0.7466
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5321
Pretraining:	Epoch 138/500
----------
training:	Epoch: [138][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][3/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][4/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][5/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][6/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][7/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][8/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][9/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][10/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][11/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [138][12/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][13/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][14/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][15/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][16/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][17/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][18/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][19/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][20/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][21/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][22/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][23/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][24/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][25/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][26/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][27/204]	Loss 0.0009 (0.0003)	
training:	Epoch: [138][28/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][29/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][30/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [138][31/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][32/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][33/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][34/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][35/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][36/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [138][37/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][38/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][39/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][40/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][41/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][42/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][43/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][44/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][45/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][46/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][47/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][48/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][49/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][50/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][51/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][52/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][53/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][54/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][55/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][56/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][57/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][58/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [138][59/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][60/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [138][61/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][62/204]	Loss 0.0089 (0.0004)	
training:	Epoch: [138][63/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][64/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [138][65/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][66/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][67/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][68/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][69/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][70/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][71/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [138][72/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][73/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][74/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][75/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][76/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [138][77/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][78/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [138][79/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][80/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][81/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][82/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][83/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][84/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][85/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [138][86/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][87/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][88/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [138][89/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][90/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][91/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][92/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][93/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][94/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][95/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][96/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][97/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][98/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [138][99/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][100/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][101/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [138][102/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][103/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][104/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [138][105/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [138][106/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [138][107/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][108/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][109/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][110/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][111/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [138][112/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][113/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][114/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][115/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][116/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [138][117/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][118/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][119/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][120/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][121/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][122/204]	Loss 0.0021 (0.0004)	
training:	Epoch: [138][123/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][124/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][125/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][126/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][127/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][128/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][129/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][130/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][131/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][132/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][133/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][134/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][135/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][136/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][137/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][138/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][139/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][140/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][141/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][142/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][143/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][144/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [138][145/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][146/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][147/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][148/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][149/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][150/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [138][151/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][152/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [138][153/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][154/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][155/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][156/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][157/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [138][158/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][159/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][160/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][161/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][162/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][163/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][164/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][165/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][166/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [138][167/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [138][168/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][169/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][170/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][171/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][172/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][173/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][174/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][175/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][176/204]	Loss 0.0010 (0.0003)	
training:	Epoch: [138][177/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][178/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][179/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][180/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][181/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][182/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][183/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][184/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][185/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][186/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][187/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][188/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [138][189/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [138][190/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][191/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][192/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][193/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][194/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][195/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][196/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][197/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][198/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][199/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [138][200/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][201/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][202/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [138][203/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [138][204/204]	Loss 0.0003 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7674 0.7689 0.8004 0.7343
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5540
Pretraining:	Epoch 139/500
----------
training:	Epoch: [139][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [139][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][3/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][4/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [139][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [139][7/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [139][8/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [139][9/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][10/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][11/204]	Loss 0.0015 (0.0004)	
training:	Epoch: [139][12/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [139][13/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][14/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][15/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][16/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][17/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][18/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][19/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][20/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][21/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][22/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][23/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][24/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][25/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][26/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][27/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][28/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][29/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][30/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][31/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][32/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][33/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][34/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][35/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][36/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][37/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][38/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][39/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][40/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][41/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][42/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][43/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][44/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][45/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][46/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][47/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][48/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][49/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][50/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][51/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][52/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][53/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][54/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][55/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][56/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][57/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][58/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][59/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][60/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][61/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][62/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][63/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][64/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [139][65/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][66/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][67/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][68/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][69/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][70/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][71/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][72/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][73/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][74/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][75/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][76/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][77/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][78/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][79/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][80/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][81/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][82/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][83/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][84/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][85/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [139][86/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [139][87/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][88/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][89/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][90/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][91/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][92/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][93/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][94/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][95/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][96/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][97/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][98/204]	Loss 0.0028 (0.0003)	
training:	Epoch: [139][99/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][100/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][101/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][102/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][103/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][104/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][105/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][106/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][107/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][108/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][109/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][110/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][111/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][112/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][113/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][114/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][115/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][116/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][117/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][118/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][119/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][120/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][121/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][122/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][123/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][124/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][125/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][126/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][127/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][128/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][129/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][130/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][131/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][132/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][133/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][134/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][135/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][136/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][137/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][138/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][139/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][140/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][141/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][142/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [139][143/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][144/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][145/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][146/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [139][147/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][148/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][149/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][150/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [139][151/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][152/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][153/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][154/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][155/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][156/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][157/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][158/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][159/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][160/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][161/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][162/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][163/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][164/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][165/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][166/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [139][167/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][168/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][169/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][170/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][171/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][172/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][173/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][174/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][175/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][176/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][177/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][178/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][179/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][180/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][181/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][182/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][183/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][184/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][185/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][186/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [139][187/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][188/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][189/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][190/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][191/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][192/204]	Loss 0.0048 (0.0003)	
training:	Epoch: [139][193/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][194/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][195/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][196/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][197/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][198/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][199/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [139][200/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][201/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][202/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [139][203/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [139][204/204]	Loss 0.0002 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7699 0.7715 0.8066 0.7332
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5712
Pretraining:	Epoch 140/500
----------
training:	Epoch: [140][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][3/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][7/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][8/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][10/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [140][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][12/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [140][13/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [140][14/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][15/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][16/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][17/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][18/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][19/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][20/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][21/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][22/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][24/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [140][25/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][26/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][28/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][29/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [140][30/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [140][31/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][33/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [140][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][36/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][37/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [140][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][41/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [140][42/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][43/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [140][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][45/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [140][49/204]	Loss 0.0082 (0.0004)	
training:	Epoch: [140][50/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][51/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][52/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][53/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][54/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [140][55/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][56/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][57/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][58/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][59/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [140][60/204]	Loss 0.0014 (0.0004)	
training:	Epoch: [140][61/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][62/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][63/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [140][64/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [140][65/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [140][66/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][67/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][68/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [140][69/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][70/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [140][71/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][72/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [140][73/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [140][74/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][75/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [140][76/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][77/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][78/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [140][79/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][80/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [140][81/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][82/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][83/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][84/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [140][85/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][86/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][87/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][88/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][89/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][90/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][91/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][92/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][93/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [140][94/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][95/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][96/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][97/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][98/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][99/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][100/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][101/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][102/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][103/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][104/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [140][105/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][106/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][107/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][108/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [140][109/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][110/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][111/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][112/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][113/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][114/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][115/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][116/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][117/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][118/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][119/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][120/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][121/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][122/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][123/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][124/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][125/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][126/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][127/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][128/204]	Loss 0.0011 (0.0003)	
training:	Epoch: [140][129/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][130/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [140][131/204]	Loss 0.0009 (0.0003)	
training:	Epoch: [140][132/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][133/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][134/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [140][135/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][136/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [140][137/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][138/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][139/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][140/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][141/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][142/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][143/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][144/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][145/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][146/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][147/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][148/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][149/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][150/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][151/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][152/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][153/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][154/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][155/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][156/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][157/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][158/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][159/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][160/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][161/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][162/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][163/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][164/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][165/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][166/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][167/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][168/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][169/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][170/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][171/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][172/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][173/204]	Loss 0.0009 (0.0003)	
training:	Epoch: [140][174/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][175/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][176/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][177/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][178/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [140][179/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][180/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][181/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][182/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][183/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][184/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][185/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [140][186/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [140][187/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][188/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][189/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][190/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][191/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][192/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][193/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][194/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][195/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][196/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][197/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][198/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][199/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][200/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [140][201/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][202/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][203/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [140][204/204]	Loss 0.0002 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7691 0.7705 0.7984 0.7399
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5777
Pretraining:	Epoch 141/500
----------
training:	Epoch: [141][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][3/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][5/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [141][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][7/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][8/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][9/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][10/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][13/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][14/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][15/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][16/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][17/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][18/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][19/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][20/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][21/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][22/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][24/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][25/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][26/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][28/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][31/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][33/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][36/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][42/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][43/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][45/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][46/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][49/204]	Loss 0.0010 (0.0002)	
training:	Epoch: [141][50/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][51/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][52/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][53/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][54/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][55/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][56/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][58/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][59/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][60/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][61/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][62/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [141][63/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][64/204]	Loss 0.0011 (0.0002)	
training:	Epoch: [141][65/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][66/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][67/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][68/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][69/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][70/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [141][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][72/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][74/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [141][75/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][76/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][77/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][78/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][79/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][80/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][81/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][82/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][83/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][84/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][85/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][86/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][87/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][88/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [141][89/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][90/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][91/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][92/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][93/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][94/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][95/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][96/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][97/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][98/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][99/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][100/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][101/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][102/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][103/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][104/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][105/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][106/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][107/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][108/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][109/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][110/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][111/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][112/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][113/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][114/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][115/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [141][116/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][117/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][118/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][119/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][120/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][121/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][122/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][123/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][124/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][125/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][126/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][127/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][128/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][129/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][130/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][131/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][132/204]	Loss 0.0010 (0.0002)	
training:	Epoch: [141][133/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][134/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][135/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][136/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][137/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][138/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][139/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][140/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][141/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][142/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][143/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][144/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][145/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][146/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][147/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][148/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][149/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][150/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][151/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][152/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][153/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][154/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][155/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][156/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][157/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][158/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][159/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][160/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][161/204]	Loss 0.0020 (0.0002)	
training:	Epoch: [141][162/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][163/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][164/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][165/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][166/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][167/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][168/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][169/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][170/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][171/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][172/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][173/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][174/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][175/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][176/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][177/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [141][178/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][179/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][180/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][181/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][182/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][183/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][184/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][185/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][186/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [141][187/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][188/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][189/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][190/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][191/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][192/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][193/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][194/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][195/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][196/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][197/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [141][198/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][199/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][200/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][201/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][202/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][203/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [141][204/204]	Loss 0.0002 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7685 0.7699 0.8004 0.7365
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5913
Pretraining:	Epoch 142/500
----------
training:	Epoch: [142][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][2/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][3/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][7/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][8/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][10/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][13/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][14/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][15/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][16/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][17/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][18/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [142][19/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][20/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][21/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][22/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][24/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][25/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][26/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][28/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][31/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][33/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][34/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [142][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][42/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][43/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][45/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][47/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][50/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][51/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][52/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][53/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [142][55/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][56/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][58/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][59/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][60/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][61/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [142][62/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][63/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][64/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][65/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][66/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][67/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][68/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [142][69/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][70/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][72/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][74/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][75/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [142][76/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][77/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][78/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][79/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][80/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][81/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][82/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][83/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][84/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][85/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][86/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][87/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][89/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][90/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][91/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][92/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][93/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [142][94/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][95/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][96/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][97/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][98/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [142][99/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][100/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][101/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][102/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][103/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][104/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][105/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [142][107/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][108/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][109/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][110/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][111/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][112/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][113/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][114/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [142][115/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [142][116/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][117/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][118/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][119/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][120/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][121/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][122/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][123/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][124/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][125/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][126/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][127/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][128/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][129/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][130/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][131/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [142][132/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][133/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][134/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][135/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][136/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][137/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][138/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][139/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][140/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][141/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][142/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [142][143/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][144/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][145/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][146/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][147/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][148/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][149/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][150/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][151/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][152/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][153/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [142][154/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][155/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][156/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][157/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][158/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][159/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][160/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][161/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][162/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][163/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][164/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][165/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][166/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][167/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][168/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][169/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [142][171/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][172/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][173/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][174/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][175/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][176/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][177/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][178/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][179/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][180/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][181/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][182/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][183/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][184/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][185/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][186/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][187/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][188/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][189/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][190/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][191/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][192/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][193/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][194/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][195/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][196/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][197/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][198/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][199/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][200/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [142][201/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][202/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][203/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [142][204/204]	Loss 0.0002 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7692 0.7705 0.7973 0.7410
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6006
Pretraining:	Epoch 143/500
----------
training:	Epoch: [143][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][3/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][5/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [143][6/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [143][7/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [143][8/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [143][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][10/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][13/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][14/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][15/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][16/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][17/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][18/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][20/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][21/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][22/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][24/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][25/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][26/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][28/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][31/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][33/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][36/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][43/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][45/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][50/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][51/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][52/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][53/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][54/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][55/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][56/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][58/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][59/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][60/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][61/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][62/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][63/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][64/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][65/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][66/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][67/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][68/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][69/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][70/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][71/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [143][72/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][74/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][75/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [143][76/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][77/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][78/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][79/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][80/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][81/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][82/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][83/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][84/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][85/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][86/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][87/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][89/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][91/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][92/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][93/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][94/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][95/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][96/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][97/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][98/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][99/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][100/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][101/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [143][102/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][103/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][104/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][105/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][106/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][107/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][108/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][109/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][110/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][111/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][112/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][113/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][114/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][115/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][116/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][117/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][118/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][119/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][120/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][121/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][122/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][123/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][124/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][125/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][126/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][127/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][128/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][129/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][130/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][131/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][132/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][133/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][134/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][135/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][136/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][137/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][138/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][139/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][140/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][141/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][142/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][143/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][144/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][145/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][146/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][147/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][148/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][149/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][150/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][151/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][152/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][153/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][154/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][155/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][156/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][157/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][158/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][159/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][160/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][161/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][162/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][163/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][164/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][165/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][166/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][167/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][168/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][169/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [143][171/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][172/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][173/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][174/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][175/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][176/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][177/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][178/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][179/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][180/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][181/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][182/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][183/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][184/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][185/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][186/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][187/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][188/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][189/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][190/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][191/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][192/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][193/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][194/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][195/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][196/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][197/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][198/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][199/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][200/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][201/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][202/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [143][203/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [143][204/204]	Loss 0.0002 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7697 0.7710 0.7973 0.7422
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6087
Pretraining:	Epoch 144/500
----------
training:	Epoch: [144][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][3/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [144][8/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][10/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [144][14/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][15/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][16/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][17/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][18/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][19/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][20/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [144][22/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][24/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][25/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][26/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][28/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [144][31/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [144][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][33/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][36/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][42/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][43/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][45/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [144][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [144][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][50/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][51/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][52/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][53/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][54/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][55/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][56/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][58/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][59/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][60/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][61/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][62/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][63/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][64/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][65/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][66/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][67/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [144][68/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][69/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][70/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][72/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][74/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][75/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [144][76/204]	Loss 0.0228 (0.0005)	
training:	Epoch: [144][77/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][78/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][79/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][80/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][81/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][82/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [144][83/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][84/204]	Loss 0.0081 (0.0006)	
training:	Epoch: [144][85/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][86/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][87/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][88/204]	Loss 0.0013 (0.0006)	
training:	Epoch: [144][89/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][90/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][91/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][92/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][93/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][94/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][95/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][96/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][97/204]	Loss 0.0015 (0.0005)	
training:	Epoch: [144][98/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][99/204]	Loss 0.0011 (0.0005)	
training:	Epoch: [144][100/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [144][101/204]	Loss 0.0047 (0.0006)	
training:	Epoch: [144][102/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [144][103/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][104/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][105/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][106/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][107/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [144][108/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][109/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [144][110/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [144][111/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][112/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][113/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][114/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][115/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][116/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][117/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][118/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][119/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][120/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][121/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][122/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][123/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][124/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][125/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][126/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][127/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][128/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][129/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][130/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][131/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][132/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][133/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [144][134/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][135/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][136/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][137/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][138/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][139/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [144][140/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][141/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][142/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][143/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][144/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][145/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][146/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][147/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][148/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [144][149/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][150/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][151/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][152/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][153/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][154/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [144][155/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [144][156/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][157/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][158/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][159/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [144][160/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][161/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][162/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [144][163/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][164/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][165/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][166/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][167/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][168/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][169/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [144][170/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [144][171/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][172/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][173/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [144][174/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [144][175/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][176/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [144][177/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][178/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][179/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [144][180/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][181/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][182/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][183/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][184/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][185/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][186/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][187/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [144][188/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [144][189/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [144][190/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][191/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][192/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][193/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][194/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][195/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][196/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][197/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][198/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][199/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][200/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][201/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][202/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [144][203/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [144][204/204]	Loss 0.0002 (0.0004)	
Training:	 Loss: 0.0004

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7707 0.7721 0.8014 0.7399
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6139
Pretraining:	Epoch 145/500
----------
training:	Epoch: [145][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][3/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][4/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [145][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][7/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][8/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][9/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][10/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][13/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][15/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][16/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][17/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][19/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][20/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][22/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][24/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][25/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][26/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][28/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][31/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][33/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][36/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][42/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][43/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][45/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][51/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][52/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][53/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][54/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][55/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][58/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][59/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][60/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][61/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][63/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][64/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][65/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][66/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][67/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][68/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][69/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][70/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][72/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][74/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][75/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][76/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][77/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][78/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][79/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][80/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][81/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][83/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [145][84/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][85/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][86/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][87/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][89/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][90/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][91/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][92/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][93/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][94/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][95/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][96/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][97/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][98/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][99/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][100/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][101/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][102/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][103/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][104/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][105/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][106/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][107/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][108/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [145][109/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][110/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][111/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][113/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][114/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][115/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][116/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][117/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][118/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][119/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][120/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][121/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][122/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][123/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][124/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][125/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][126/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][127/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][128/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][129/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][130/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][131/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [145][132/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][133/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][135/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][137/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][138/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][139/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][140/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][141/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][142/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][143/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][144/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][145/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][146/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][147/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][148/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][149/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][150/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][151/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][153/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][154/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][155/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][156/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][158/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][159/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][161/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][162/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][163/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][164/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][165/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][166/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][168/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][170/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][171/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][172/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [145][173/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][174/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][175/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][176/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][177/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][178/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][179/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][180/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][181/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][182/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][183/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][184/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][185/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [145][186/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][187/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][189/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][190/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][191/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][192/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][193/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][194/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][195/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][196/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][197/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][198/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][199/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][200/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][201/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][202/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [145][203/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [145][204/204]	Loss 0.0002 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7726 0.7742 0.8076 0.7377
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6304
Pretraining:	Epoch 146/500
----------
training:	Epoch: [146][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][3/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][8/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][10/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][12/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][13/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][14/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][15/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][16/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][17/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][18/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [146][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][20/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][22/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][25/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][31/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][33/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][36/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][42/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [146][43/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][51/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][52/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][53/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][55/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][56/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][58/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][59/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][60/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][61/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][65/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][66/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][67/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][68/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][69/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][70/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][72/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][74/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][75/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][76/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][77/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][78/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][79/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][80/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][81/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][83/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][84/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][85/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [146][86/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][89/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][90/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][92/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [146][93/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][94/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][95/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][96/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][97/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][98/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][99/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [146][100/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][101/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][102/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][103/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][104/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][105/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][106/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [146][107/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][108/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][109/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][110/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][111/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][112/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][113/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][114/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][115/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][116/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][117/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][118/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][119/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][120/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][121/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][122/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][123/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][124/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][125/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][126/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][127/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][128/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][129/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][130/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][131/204]	Loss 0.0048 (0.0002)	
training:	Epoch: [146][132/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][134/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][135/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][136/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][137/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][138/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][139/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][141/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][142/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][143/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][144/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][145/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][146/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][147/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][148/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][149/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][150/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [146][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][152/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][153/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][154/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][155/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [146][156/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][158/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][160/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][161/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][163/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][164/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][165/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][167/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][168/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][169/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][171/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][172/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][173/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][174/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [146][175/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][176/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][177/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][178/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][179/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][181/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][182/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][183/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][184/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][186/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][187/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][189/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][190/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][191/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][192/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][193/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][194/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [146][195/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][196/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][197/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][198/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][199/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][200/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][201/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [146][202/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [146][203/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [146][204/204]	Loss 0.0003 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7727 0.7742 0.8066 0.7388
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6443
Pretraining:	Epoch 147/500
----------
training:	Epoch: [147][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [147][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][3/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][6/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][7/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][8/204]	Loss 0.0009 (0.0003)	
training:	Epoch: [147][9/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [147][10/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [147][11/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][15/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][16/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][19/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][20/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][22/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [147][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][31/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [147][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][35/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [147][36/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [147][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][42/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][52/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][53/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][58/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][59/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][60/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][61/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][62/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [147][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][65/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][66/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][67/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][68/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][69/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][70/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][72/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][73/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][74/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][75/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][76/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][77/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][78/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][79/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][80/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [147][81/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][84/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][85/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][86/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][89/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][92/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][93/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][94/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][95/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][96/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][97/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][98/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][99/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][100/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][101/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][102/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][103/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][104/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][105/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][107/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][108/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][109/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][110/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][111/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][112/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][113/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][114/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][115/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][116/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][117/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][118/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][119/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][120/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][121/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][122/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][123/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][124/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][125/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][126/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][127/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][128/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][129/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][130/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][131/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][132/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [147][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][135/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][136/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][137/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][139/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][140/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][141/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][142/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][143/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][144/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][145/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][146/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][147/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][148/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][149/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [147][150/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][151/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][153/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][154/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][155/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][156/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][158/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][161/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][163/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][164/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][165/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][168/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][171/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][172/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][173/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][174/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][175/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][176/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [147][177/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][178/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][179/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][181/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][182/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][183/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][184/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][186/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][187/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][189/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][190/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][191/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][192/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][193/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][194/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][195/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][196/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][197/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][198/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][199/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][200/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][201/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [147][202/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [147][203/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [147][204/204]	Loss 0.0001 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7707 0.7721 0.8004 0.7410
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6487
Pretraining:	Epoch 148/500
----------
training:	Epoch: [148][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][3/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][4/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][5/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][7/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][8/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [148][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][11/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][12/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][13/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][15/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][16/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][19/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][50/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][56/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][57/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][58/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][59/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][60/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][61/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][63/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][66/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][67/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][68/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][69/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][70/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][72/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][74/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][75/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][76/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][77/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][78/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][79/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][80/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][81/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][83/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][84/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][85/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][86/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][87/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][89/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][92/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][93/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][94/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][95/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][96/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][97/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][98/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][99/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][100/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][101/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][102/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][103/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][104/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][105/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][107/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][108/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][109/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][110/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][111/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][113/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][114/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][115/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][116/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][118/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][119/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [148][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [148][122/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][123/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [148][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [148][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [148][127/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [148][128/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][129/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][130/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [148][131/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][132/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][135/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][137/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][138/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][139/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][141/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][142/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][143/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][144/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][145/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][146/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][147/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][148/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][149/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][150/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][153/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][154/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][155/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][156/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][158/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][161/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][163/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][164/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][165/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][168/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][169/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][170/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][171/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][172/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][173/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][174/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][175/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][176/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][177/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][178/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][179/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][181/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][182/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [148][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [148][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [148][186/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [148][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [148][188/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][189/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][190/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][191/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][192/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][193/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][194/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][195/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [148][196/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][197/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][198/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][199/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][200/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][201/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][202/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [148][203/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [148][204/204]	Loss 0.0002 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7703 0.7715 0.7973 0.7433
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6598
Pretraining:	Epoch 149/500
----------
training:	Epoch: [149][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][2/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [149][3/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][4/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [149][6/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [149][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][8/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [149][9/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][11/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][12/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][15/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [149][16/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][17/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [149][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [149][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [149][31/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [149][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [149][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [149][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][53/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][61/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][64/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][66/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][68/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][69/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][76/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [149][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][91/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][95/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][108/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][112/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][120/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][122/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][124/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [149][125/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][126/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][131/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][133/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][137/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][139/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][149/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][150/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][153/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][156/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][158/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][163/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][172/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][183/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][188/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [149][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [149][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7710 0.7963 0.7433
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6680
Pretraining:	Epoch 150/500
----------
training:	Epoch: [150][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [150][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [150][3/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [150][4/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [150][5/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [150][6/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [150][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][10/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [150][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][14/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][17/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][19/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][29/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][32/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][37/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][49/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][53/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][56/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][61/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][65/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][72/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][74/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][75/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][80/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][84/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [150][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [150][86/204]	Loss 0.0208 (0.0004)	
training:	Epoch: [150][87/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [150][88/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [150][89/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [150][90/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [150][91/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [150][92/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [150][93/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [150][94/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [150][95/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [150][96/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [150][97/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [150][98/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [150][99/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [150][100/204]	Loss 0.0036 (0.0004)	
training:	Epoch: [150][101/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [150][102/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [150][103/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [150][104/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [150][105/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [150][106/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [150][107/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [150][108/204]	Loss 0.0794 (0.0011)	
training:	Epoch: [150][109/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [150][110/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [150][111/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [150][112/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [150][113/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [150][114/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [150][115/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [150][116/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [150][117/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [150][118/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][119/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [150][120/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][121/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][122/204]	Loss 0.0159 (0.0011)	
training:	Epoch: [150][123/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [150][124/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [150][125/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [150][126/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [150][127/204]	Loss 0.0007 (0.0011)	
training:	Epoch: [150][128/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [150][129/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [150][130/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [150][131/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [150][132/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [150][133/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [150][134/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [150][135/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [150][136/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [150][137/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][138/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][139/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [150][140/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [150][141/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][142/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [150][143/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [150][144/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][145/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [150][146/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][147/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [150][148/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][149/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][150/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][151/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [150][152/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][153/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [150][154/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][155/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][156/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][157/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][158/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][159/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][160/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][161/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][162/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][163/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][164/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][165/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][166/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][167/204]	Loss 0.0007 (0.0009)	
training:	Epoch: [150][168/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][169/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][170/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [150][171/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [150][172/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][173/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][174/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][175/204]	Loss 0.0067 (0.0009)	
training:	Epoch: [150][176/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][177/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][178/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][179/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][180/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][181/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][182/204]	Loss 0.0077 (0.0009)	
training:	Epoch: [150][183/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][184/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][185/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][186/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][187/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][188/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][189/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [150][190/204]	Loss 0.0009 (0.0009)	
training:	Epoch: [150][191/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][192/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][193/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][194/204]	Loss 0.0014 (0.0009)	
training:	Epoch: [150][195/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][196/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][197/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [150][198/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][199/204]	Loss 0.0065 (0.0009)	
training:	Epoch: [150][200/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][201/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][202/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [150][203/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [150][204/204]	Loss 0.0001 (0.0009)	
Training:	 Loss: 0.0009

Training:	 ACC: 0.9997 0.9997 1.0000 0.9994
Validation:	 ACC: 0.7660 0.7667 0.7820 0.7500
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7161
Pretraining:	Epoch 151/500
----------
training:	Epoch: [151][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [151][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [151][3/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [151][4/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [151][5/204]	Loss 0.0508 (0.0104)	
training:	Epoch: [151][6/204]	Loss 0.0020 (0.0090)	
training:	Epoch: [151][7/204]	Loss 0.0004 (0.0078)	
training:	Epoch: [151][8/204]	Loss 0.0001 (0.0068)	
training:	Epoch: [151][9/204]	Loss 0.0001 (0.0061)	
training:	Epoch: [151][10/204]	Loss 0.0002 (0.0055)	
training:	Epoch: [151][11/204]	Loss 0.0040 (0.0053)	
training:	Epoch: [151][12/204]	Loss 0.0001 (0.0049)	
training:	Epoch: [151][13/204]	Loss 0.0086 (0.0052)	
training:	Epoch: [151][14/204]	Loss 0.0113 (0.0056)	
training:	Epoch: [151][15/204]	Loss 0.0001 (0.0053)	
training:	Epoch: [151][16/204]	Loss 0.0001 (0.0049)	
training:	Epoch: [151][17/204]	Loss 0.0001 (0.0047)	
training:	Epoch: [151][18/204]	Loss 0.0001 (0.0044)	
training:	Epoch: [151][19/204]	Loss 0.0001 (0.0042)	
training:	Epoch: [151][20/204]	Loss 0.0001 (0.0040)	
training:	Epoch: [151][21/204]	Loss 0.0001 (0.0038)	
training:	Epoch: [151][22/204]	Loss 0.0001 (0.0036)	
training:	Epoch: [151][23/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [151][24/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [151][25/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [151][26/204]	Loss 0.0014 (0.0031)	
training:	Epoch: [151][27/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [151][28/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [151][29/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [151][30/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [151][31/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [151][32/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [151][33/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [151][34/204]	Loss 0.0651 (0.0043)	
training:	Epoch: [151][35/204]	Loss 0.0002 (0.0042)	
training:	Epoch: [151][36/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [151][37/204]	Loss 0.0001 (0.0040)	
training:	Epoch: [151][38/204]	Loss 0.0009 (0.0039)	
training:	Epoch: [151][39/204]	Loss 0.0001 (0.0038)	
training:	Epoch: [151][40/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [151][41/204]	Loss 0.1365 (0.0070)	
training:	Epoch: [151][42/204]	Loss 0.0002 (0.0068)	
training:	Epoch: [151][43/204]	Loss 0.2154 (0.0117)	
training:	Epoch: [151][44/204]	Loss 0.0003 (0.0114)	
training:	Epoch: [151][45/204]	Loss 0.0006 (0.0112)	
training:	Epoch: [151][46/204]	Loss 0.0006 (0.0109)	
training:	Epoch: [151][47/204]	Loss 0.0001 (0.0107)	
training:	Epoch: [151][48/204]	Loss 0.0033 (0.0106)	
training:	Epoch: [151][49/204]	Loss 0.0220 (0.0108)	
training:	Epoch: [151][50/204]	Loss 0.3335 (0.0172)	
training:	Epoch: [151][51/204]	Loss 0.0848 (0.0186)	
training:	Epoch: [151][52/204]	Loss 0.2055 (0.0222)	
training:	Epoch: [151][53/204]	Loss 0.0002 (0.0217)	
training:	Epoch: [151][54/204]	Loss 0.0001 (0.0213)	
training:	Epoch: [151][55/204]	Loss 0.0002 (0.0210)	
training:	Epoch: [151][56/204]	Loss 0.2661 (0.0253)	
training:	Epoch: [151][57/204]	Loss 0.0144 (0.0252)	
training:	Epoch: [151][58/204]	Loss 0.1459 (0.0272)	
training:	Epoch: [151][59/204]	Loss 0.0009 (0.0268)	
training:	Epoch: [151][60/204]	Loss 0.0050 (0.0264)	
training:	Epoch: [151][61/204]	Loss 0.0446 (0.0267)	
training:	Epoch: [151][62/204]	Loss 0.0020 (0.0263)	
training:	Epoch: [151][63/204]	Loss 0.0033 (0.0260)	
training:	Epoch: [151][64/204]	Loss 0.0002 (0.0256)	
training:	Epoch: [151][65/204]	Loss 0.0041 (0.0252)	
training:	Epoch: [151][66/204]	Loss 0.0028 (0.0249)	
training:	Epoch: [151][67/204]	Loss 0.1881 (0.0273)	
training:	Epoch: [151][68/204]	Loss 0.2709 (0.0309)	
training:	Epoch: [151][69/204]	Loss 0.0003 (0.0305)	
training:	Epoch: [151][70/204]	Loss 0.0009 (0.0300)	
training:	Epoch: [151][71/204]	Loss 0.0153 (0.0298)	
training:	Epoch: [151][72/204]	Loss 0.0167 (0.0296)	
training:	Epoch: [151][73/204]	Loss 0.0028 (0.0293)	
training:	Epoch: [151][74/204]	Loss 0.0003 (0.0289)	
training:	Epoch: [151][75/204]	Loss 0.0005 (0.0285)	
training:	Epoch: [151][76/204]	Loss 0.0005 (0.0281)	
training:	Epoch: [151][77/204]	Loss 0.0013 (0.0278)	
training:	Epoch: [151][78/204]	Loss 0.0164 (0.0276)	
training:	Epoch: [151][79/204]	Loss 0.0002 (0.0273)	
training:	Epoch: [151][80/204]	Loss 0.0002 (0.0270)	
training:	Epoch: [151][81/204]	Loss 0.0004 (0.0266)	
training:	Epoch: [151][82/204]	Loss 0.0008 (0.0263)	
training:	Epoch: [151][83/204]	Loss 0.0005 (0.0260)	
training:	Epoch: [151][84/204]	Loss 0.0002 (0.0257)	
training:	Epoch: [151][85/204]	Loss 0.0695 (0.0262)	
training:	Epoch: [151][86/204]	Loss 0.0001 (0.0259)	
training:	Epoch: [151][87/204]	Loss 0.0002 (0.0256)	
training:	Epoch: [151][88/204]	Loss 0.0006 (0.0253)	
training:	Epoch: [151][89/204]	Loss 0.0007 (0.0250)	
training:	Epoch: [151][90/204]	Loss 0.0002 (0.0248)	
training:	Epoch: [151][91/204]	Loss 0.0002 (0.0245)	
training:	Epoch: [151][92/204]	Loss 0.0002 (0.0242)	
training:	Epoch: [151][93/204]	Loss 0.0929 (0.0250)	
training:	Epoch: [151][94/204]	Loss 0.0002 (0.0247)	
training:	Epoch: [151][95/204]	Loss 0.0003 (0.0245)	
training:	Epoch: [151][96/204]	Loss 0.0003 (0.0242)	
training:	Epoch: [151][97/204]	Loss 0.0008 (0.0240)	
training:	Epoch: [151][98/204]	Loss 0.0056 (0.0238)	
training:	Epoch: [151][99/204]	Loss 0.0150 (0.0237)	
training:	Epoch: [151][100/204]	Loss 0.0005 (0.0235)	
training:	Epoch: [151][101/204]	Loss 0.0002 (0.0232)	
training:	Epoch: [151][102/204]	Loss 0.0115 (0.0231)	
training:	Epoch: [151][103/204]	Loss 0.0014 (0.0229)	
training:	Epoch: [151][104/204]	Loss 0.0010 (0.0227)	
training:	Epoch: [151][105/204]	Loss 0.0881 (0.0233)	
training:	Epoch: [151][106/204]	Loss 0.0005 (0.0231)	
training:	Epoch: [151][107/204]	Loss 0.0003 (0.0229)	
training:	Epoch: [151][108/204]	Loss 0.0022 (0.0227)	
training:	Epoch: [151][109/204]	Loss 0.0002 (0.0225)	
training:	Epoch: [151][110/204]	Loss 0.1799 (0.0239)	
training:	Epoch: [151][111/204]	Loss 0.0004 (0.0237)	
training:	Epoch: [151][112/204]	Loss 0.0154 (0.0236)	
training:	Epoch: [151][113/204]	Loss 0.0004 (0.0234)	
training:	Epoch: [151][114/204]	Loss 0.0005 (0.0232)	
training:	Epoch: [151][115/204]	Loss 0.0024 (0.0230)	
training:	Epoch: [151][116/204]	Loss 0.0124 (0.0230)	
training:	Epoch: [151][117/204]	Loss 0.0004 (0.0228)	
training:	Epoch: [151][118/204]	Loss 0.0003 (0.0226)	
training:	Epoch: [151][119/204]	Loss 0.0807 (0.0231)	
training:	Epoch: [151][120/204]	Loss 0.0030 (0.0229)	
training:	Epoch: [151][121/204]	Loss 0.0337 (0.0230)	
training:	Epoch: [151][122/204]	Loss 0.0060 (0.0228)	
training:	Epoch: [151][123/204]	Loss 0.0070 (0.0227)	
training:	Epoch: [151][124/204]	Loss 0.0004 (0.0225)	
training:	Epoch: [151][125/204]	Loss 0.0137 (0.0225)	
training:	Epoch: [151][126/204]	Loss 0.0020 (0.0223)	
training:	Epoch: [151][127/204]	Loss 0.0005 (0.0221)	
training:	Epoch: [151][128/204]	Loss 0.0012 (0.0220)	
training:	Epoch: [151][129/204]	Loss 0.0003 (0.0218)	
training:	Epoch: [151][130/204]	Loss 0.0002 (0.0216)	
training:	Epoch: [151][131/204]	Loss 0.0005 (0.0215)	
training:	Epoch: [151][132/204]	Loss 0.0085 (0.0214)	
training:	Epoch: [151][133/204]	Loss 0.0012 (0.0212)	
training:	Epoch: [151][134/204]	Loss 0.0006 (0.0211)	
training:	Epoch: [151][135/204]	Loss 0.0263 (0.0211)	
training:	Epoch: [151][136/204]	Loss 0.0031 (0.0210)	
training:	Epoch: [151][137/204]	Loss 0.0005 (0.0208)	
training:	Epoch: [151][138/204]	Loss 0.0006 (0.0207)	
training:	Epoch: [151][139/204]	Loss 0.0016 (0.0205)	
training:	Epoch: [151][140/204]	Loss 0.0011 (0.0204)	
training:	Epoch: [151][141/204]	Loss 0.0008 (0.0203)	
training:	Epoch: [151][142/204]	Loss 0.0034 (0.0201)	
training:	Epoch: [151][143/204]	Loss 0.0106 (0.0201)	
training:	Epoch: [151][144/204]	Loss 0.0010 (0.0199)	
training:	Epoch: [151][145/204]	Loss 0.0140 (0.0199)	
training:	Epoch: [151][146/204]	Loss 0.0006 (0.0198)	
training:	Epoch: [151][147/204]	Loss 0.0002 (0.0196)	
training:	Epoch: [151][148/204]	Loss 0.0679 (0.0200)	
training:	Epoch: [151][149/204]	Loss 0.0002 (0.0198)	
training:	Epoch: [151][150/204]	Loss 0.0009 (0.0197)	
training:	Epoch: [151][151/204]	Loss 0.0055 (0.0196)	
training:	Epoch: [151][152/204]	Loss 0.1216 (0.0203)	
training:	Epoch: [151][153/204]	Loss 0.0042 (0.0202)	
training:	Epoch: [151][154/204]	Loss 0.0010 (0.0201)	
training:	Epoch: [151][155/204]	Loss 0.0003 (0.0199)	
training:	Epoch: [151][156/204]	Loss 0.0007 (0.0198)	
training:	Epoch: [151][157/204]	Loss 0.0003 (0.0197)	
training:	Epoch: [151][158/204]	Loss 0.0003 (0.0196)	
training:	Epoch: [151][159/204]	Loss 0.0002 (0.0194)	
training:	Epoch: [151][160/204]	Loss 0.0002 (0.0193)	
training:	Epoch: [151][161/204]	Loss 0.0026 (0.0192)	
training:	Epoch: [151][162/204]	Loss 0.0035 (0.0191)	
training:	Epoch: [151][163/204]	Loss 0.0023 (0.0190)	
training:	Epoch: [151][164/204]	Loss 0.0002 (0.0189)	
training:	Epoch: [151][165/204]	Loss 0.0006 (0.0188)	
training:	Epoch: [151][166/204]	Loss 0.0003 (0.0187)	
training:	Epoch: [151][167/204]	Loss 0.0002 (0.0186)	
training:	Epoch: [151][168/204]	Loss 0.0003 (0.0185)	
training:	Epoch: [151][169/204]	Loss 0.0149 (0.0184)	
training:	Epoch: [151][170/204]	Loss 0.0009 (0.0183)	
training:	Epoch: [151][171/204]	Loss 0.0003 (0.0182)	
training:	Epoch: [151][172/204]	Loss 0.0002 (0.0181)	
training:	Epoch: [151][173/204]	Loss 0.0029 (0.0180)	
training:	Epoch: [151][174/204]	Loss 0.0006 (0.0179)	
training:	Epoch: [151][175/204]	Loss 0.0003 (0.0178)	
training:	Epoch: [151][176/204]	Loss 0.0003 (0.0177)	
training:	Epoch: [151][177/204]	Loss 0.0012 (0.0176)	
training:	Epoch: [151][178/204]	Loss 0.0007 (0.0175)	
training:	Epoch: [151][179/204]	Loss 0.0006 (0.0174)	
training:	Epoch: [151][180/204]	Loss 0.0006 (0.0174)	
training:	Epoch: [151][181/204]	Loss 0.0004 (0.0173)	
training:	Epoch: [151][182/204]	Loss 0.0005 (0.0172)	
training:	Epoch: [151][183/204]	Loss 0.0002 (0.0171)	
training:	Epoch: [151][184/204]	Loss 0.0003 (0.0170)	
training:	Epoch: [151][185/204]	Loss 0.0009 (0.0169)	
training:	Epoch: [151][186/204]	Loss 0.0301 (0.0170)	
training:	Epoch: [151][187/204]	Loss 0.0003 (0.0169)	
training:	Epoch: [151][188/204]	Loss 0.0002 (0.0168)	
training:	Epoch: [151][189/204]	Loss 0.0004 (0.0167)	
training:	Epoch: [151][190/204]	Loss 0.0003 (0.0166)	
training:	Epoch: [151][191/204]	Loss 0.0007 (0.0165)	
training:	Epoch: [151][192/204]	Loss 0.0007 (0.0164)	
training:	Epoch: [151][193/204]	Loss 0.0004 (0.0164)	
training:	Epoch: [151][194/204]	Loss 0.0002 (0.0163)	
training:	Epoch: [151][195/204]	Loss 0.0003 (0.0162)	
training:	Epoch: [151][196/204]	Loss 0.0008 (0.0161)	
training:	Epoch: [151][197/204]	Loss 0.0003 (0.0160)	
training:	Epoch: [151][198/204]	Loss 0.0006 (0.0160)	
training:	Epoch: [151][199/204]	Loss 0.0003 (0.0159)	
training:	Epoch: [151][200/204]	Loss 0.0017 (0.0158)	
training:	Epoch: [151][201/204]	Loss 0.0012 (0.0157)	
training:	Epoch: [151][202/204]	Loss 0.0003 (0.0157)	
training:	Epoch: [151][203/204]	Loss 0.0014 (0.0156)	
training:	Epoch: [151][204/204]	Loss 0.0008 (0.0155)	
Training:	 Loss: 0.0155

Training:	 ACC: 0.9992 0.9992 1.0000 0.9984
Validation:	 ACC: 0.7711 0.7737 0.8270 0.7152
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4591
Pretraining:	Epoch 152/500
----------
training:	Epoch: [152][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [152][2/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [152][3/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [152][4/204]	Loss 0.0013 (0.0006)	
training:	Epoch: [152][5/204]	Loss 0.0427 (0.0090)	
training:	Epoch: [152][6/204]	Loss 0.0002 (0.0076)	
training:	Epoch: [152][7/204]	Loss 0.0003 (0.0065)	
training:	Epoch: [152][8/204]	Loss 0.0025 (0.0060)	
training:	Epoch: [152][9/204]	Loss 0.0003 (0.0054)	
training:	Epoch: [152][10/204]	Loss 0.0002 (0.0049)	
training:	Epoch: [152][11/204]	Loss 0.0161 (0.0059)	
training:	Epoch: [152][12/204]	Loss 0.0004 (0.0054)	
training:	Epoch: [152][13/204]	Loss 0.0002 (0.0050)	
training:	Epoch: [152][14/204]	Loss 0.0001 (0.0047)	
training:	Epoch: [152][15/204]	Loss 0.0009 (0.0044)	
training:	Epoch: [152][16/204]	Loss 0.0002 (0.0042)	
training:	Epoch: [152][17/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [152][18/204]	Loss 0.0002 (0.0037)	
training:	Epoch: [152][19/204]	Loss 0.0002 (0.0035)	
training:	Epoch: [152][20/204]	Loss 0.0005 (0.0034)	
training:	Epoch: [152][21/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [152][22/204]	Loss 0.0034 (0.0032)	
training:	Epoch: [152][23/204]	Loss 0.0007 (0.0031)	
training:	Epoch: [152][24/204]	Loss 0.0009 (0.0030)	
training:	Epoch: [152][25/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [152][26/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [152][27/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [152][28/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [152][29/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [152][30/204]	Loss 0.0009 (0.0025)	
training:	Epoch: [152][31/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [152][32/204]	Loss 0.0016 (0.0024)	
training:	Epoch: [152][33/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [152][34/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [152][35/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [152][36/204]	Loss 0.0017 (0.0022)	
training:	Epoch: [152][37/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][38/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [152][39/204]	Loss 0.0004 (0.0021)	
training:	Epoch: [152][40/204]	Loss 0.0016 (0.0021)	
training:	Epoch: [152][41/204]	Loss 0.0036 (0.0021)	
training:	Epoch: [152][42/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [152][43/204]	Loss 0.0146 (0.0023)	
training:	Epoch: [152][44/204]	Loss 0.0008 (0.0023)	
training:	Epoch: [152][45/204]	Loss 0.0009 (0.0023)	
training:	Epoch: [152][46/204]	Loss 0.0047 (0.0023)	
training:	Epoch: [152][47/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [152][48/204]	Loss 0.0010 (0.0023)	
training:	Epoch: [152][49/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [152][50/204]	Loss 0.0012 (0.0022)	
training:	Epoch: [152][51/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][52/204]	Loss 0.0005 (0.0021)	
training:	Epoch: [152][53/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [152][54/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [152][55/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [152][56/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [152][57/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [152][58/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [152][59/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [152][60/204]	Loss 0.0044 (0.0020)	
training:	Epoch: [152][61/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [152][62/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [152][63/204]	Loss 0.0008 (0.0019)	
training:	Epoch: [152][64/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [152][65/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [152][66/204]	Loss 0.0007 (0.0018)	
training:	Epoch: [152][67/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [152][68/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [152][69/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [152][70/204]	Loss 0.0002 (0.0017)	
training:	Epoch: [152][71/204]	Loss 0.0002 (0.0017)	
training:	Epoch: [152][72/204]	Loss 0.0063 (0.0018)	
training:	Epoch: [152][73/204]	Loss 0.0002 (0.0017)	
training:	Epoch: [152][74/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [152][75/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [152][76/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [152][77/204]	Loss 0.0197 (0.0019)	
training:	Epoch: [152][78/204]	Loss 0.0019 (0.0019)	
training:	Epoch: [152][79/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [152][80/204]	Loss 0.0007 (0.0019)	
training:	Epoch: [152][81/204]	Loss 0.0023 (0.0019)	
training:	Epoch: [152][82/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [152][83/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [152][84/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [152][85/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [152][86/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [152][87/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [152][88/204]	Loss 0.0006 (0.0018)	
training:	Epoch: [152][89/204]	Loss 0.0082 (0.0018)	
training:	Epoch: [152][90/204]	Loss 0.0670 (0.0026)	
training:	Epoch: [152][91/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [152][92/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [152][93/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [152][94/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [152][95/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [152][96/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [152][97/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [152][98/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [152][99/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [152][100/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [152][101/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [152][102/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [152][103/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [152][104/204]	Loss 0.0014 (0.0023)	
training:	Epoch: [152][105/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [152][106/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [152][107/204]	Loss 0.0011 (0.0022)	
training:	Epoch: [152][108/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][109/204]	Loss 0.0054 (0.0022)	
training:	Epoch: [152][110/204]	Loss 0.0021 (0.0022)	
training:	Epoch: [152][111/204]	Loss 0.0007 (0.0022)	
training:	Epoch: [152][112/204]	Loss 0.0065 (0.0023)	
training:	Epoch: [152][113/204]	Loss 0.0741 (0.0029)	
training:	Epoch: [152][114/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [152][115/204]	Loss 0.0068 (0.0029)	
training:	Epoch: [152][116/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [152][117/204]	Loss 0.0037 (0.0029)	
training:	Epoch: [152][118/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [152][119/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [152][120/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [152][121/204]	Loss 0.0115 (0.0029)	
training:	Epoch: [152][122/204]	Loss 0.0058 (0.0029)	
training:	Epoch: [152][123/204]	Loss 0.0011 (0.0029)	
training:	Epoch: [152][124/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [152][125/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [152][126/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [152][127/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [152][128/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [152][129/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [152][130/204]	Loss 0.0230 (0.0029)	
training:	Epoch: [152][131/204]	Loss 0.0070 (0.0030)	
training:	Epoch: [152][132/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [152][133/204]	Loss 0.0076 (0.0030)	
training:	Epoch: [152][134/204]	Loss 0.0002 (0.0030)	
training:	Epoch: [152][135/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [152][136/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [152][137/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [152][138/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [152][139/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [152][140/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [152][141/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [152][142/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [152][143/204]	Loss 0.0019 (0.0028)	
training:	Epoch: [152][144/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [152][145/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [152][146/204]	Loss 0.0042 (0.0028)	
training:	Epoch: [152][147/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [152][148/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [152][149/204]	Loss 0.0006 (0.0027)	
training:	Epoch: [152][150/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [152][151/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [152][152/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [152][153/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [152][154/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [152][155/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [152][156/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [152][157/204]	Loss 0.0017 (0.0026)	
training:	Epoch: [152][158/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [152][159/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [152][160/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [152][161/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [152][162/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [152][163/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [152][164/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [152][165/204]	Loss 0.0011 (0.0025)	
training:	Epoch: [152][166/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [152][167/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [152][168/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [152][169/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [152][170/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [152][171/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [152][172/204]	Loss 0.0011 (0.0024)	
training:	Epoch: [152][173/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [152][174/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [152][175/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [152][176/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [152][177/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [152][178/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [152][179/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [152][180/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [152][181/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [152][182/204]	Loss 0.0123 (0.0024)	
training:	Epoch: [152][183/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [152][184/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [152][185/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [152][186/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [152][187/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [152][188/204]	Loss 0.0008 (0.0023)	
training:	Epoch: [152][189/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [152][190/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [152][191/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [152][192/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [152][193/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [152][194/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][195/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][196/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][197/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][198/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][199/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][200/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][201/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][202/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [152][203/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [152][204/204]	Loss 0.0183 (0.0022)	
Training:	 Loss: 0.0022

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7759 0.7764 0.7851 0.7668
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.4942
Pretraining:	Epoch 153/500
----------
training:	Epoch: [153][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [153][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [153][3/204]	Loss 0.0025 (0.0010)	
training:	Epoch: [153][4/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [153][5/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [153][6/204]	Loss 0.0035 (0.0012)	
training:	Epoch: [153][7/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][8/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [153][9/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [153][10/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [153][11/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [153][12/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [153][13/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [153][14/204]	Loss 0.0008 (0.0007)	
training:	Epoch: [153][15/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [153][16/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][17/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][18/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [153][19/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [153][20/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][21/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [153][22/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [153][23/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][24/204]	Loss 0.0022 (0.0006)	
training:	Epoch: [153][25/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][26/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [153][27/204]	Loss 0.0031 (0.0007)	
training:	Epoch: [153][28/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [153][29/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [153][30/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][31/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [153][32/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][33/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [153][34/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [153][35/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [153][36/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [153][37/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [153][38/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][39/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [153][40/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][41/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][42/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][43/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][44/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][45/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][46/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [153][47/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [153][48/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][49/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][50/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][51/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][52/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][53/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][54/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][55/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [153][56/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [153][57/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [153][58/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [153][59/204]	Loss 0.0051 (0.0005)	
training:	Epoch: [153][60/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][61/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][62/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][63/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][64/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][65/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][66/204]	Loss 0.0080 (0.0006)	
training:	Epoch: [153][67/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [153][68/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [153][69/204]	Loss 0.0012 (0.0006)	
training:	Epoch: [153][70/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][71/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][72/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][73/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [153][74/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [153][75/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][76/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [153][77/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [153][78/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [153][79/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][80/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][81/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][82/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][83/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][84/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [153][85/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][86/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][87/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][88/204]	Loss 0.0024 (0.0005)	
training:	Epoch: [153][89/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][90/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][91/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][92/204]	Loss 0.0044 (0.0006)	
training:	Epoch: [153][93/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][94/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][95/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [153][96/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [153][97/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][98/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][99/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [153][100/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [153][101/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][102/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][103/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][104/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][105/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][106/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][107/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][108/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [153][109/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [153][110/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][111/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [153][112/204]	Loss 0.0584 (0.0010)	
training:	Epoch: [153][113/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][114/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][115/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [153][116/204]	Loss 0.0009 (0.0010)	
training:	Epoch: [153][117/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][118/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][119/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [153][120/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [153][121/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][122/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [153][123/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [153][124/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][125/204]	Loss 0.0396 (0.0013)	
training:	Epoch: [153][126/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [153][127/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [153][128/204]	Loss 0.0016 (0.0012)	
training:	Epoch: [153][129/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [153][130/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [153][131/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [153][132/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [153][133/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [153][134/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [153][135/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [153][136/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [153][137/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [153][138/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [153][139/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [153][140/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [153][141/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [153][142/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [153][143/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [153][144/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [153][145/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][146/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [153][147/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [153][148/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][149/204]	Loss 0.0014 (0.0011)	
training:	Epoch: [153][150/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [153][151/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][152/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][153/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][154/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][155/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [153][156/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [153][157/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [153][158/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][159/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][160/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][161/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [153][162/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [153][163/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [153][164/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [153][165/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][166/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][167/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][168/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][169/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [153][170/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [153][171/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][172/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][173/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [153][174/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [153][175/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][176/204]	Loss 0.0014 (0.0010)	
training:	Epoch: [153][177/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][178/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [153][179/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [153][180/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [153][181/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [153][182/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [153][183/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [153][184/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [153][185/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [153][186/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [153][187/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [153][188/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [153][189/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [153][190/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [153][191/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [153][192/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [153][193/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [153][194/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [153][195/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [153][196/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [153][197/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [153][198/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [153][199/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [153][200/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [153][201/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [153][202/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [153][203/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [153][204/204]	Loss 0.0002 (0.0009)	
Training:	 Loss: 0.0009

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7734 0.7742 0.7912 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5409
Pretraining:	Epoch 154/500
----------
training:	Epoch: [154][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [154][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [154][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [154][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [154][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][7/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][8/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [154][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][10/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][12/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [154][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][14/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [154][15/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][16/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][20/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][21/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][24/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][25/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [154][26/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][27/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [154][28/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][31/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [154][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][33/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][36/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [154][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][38/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [154][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][42/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [154][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][50/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][51/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][52/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][54/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [154][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][56/204]	Loss 0.0021 (0.0002)	
training:	Epoch: [154][57/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][58/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][59/204]	Loss 0.0009 (0.0003)	
training:	Epoch: [154][60/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][61/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][63/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][64/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][66/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][67/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [154][68/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][69/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][70/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [154][71/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [154][72/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][73/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][74/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [154][75/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [154][76/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [154][77/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [154][78/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [154][79/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [154][80/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][81/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][82/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][83/204]	Loss 0.0119 (0.0004)	
training:	Epoch: [154][84/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][85/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][86/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][87/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][88/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][89/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][90/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][91/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][92/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][93/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [154][94/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][95/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][96/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [154][97/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][98/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][99/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][100/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [154][101/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][102/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [154][103/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][104/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][105/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [154][106/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][107/204]	Loss 0.0020 (0.0004)	
training:	Epoch: [154][108/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [154][109/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][110/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][111/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][112/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][113/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][114/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][115/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][116/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][117/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [154][118/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [154][119/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][120/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][121/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][122/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][123/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][124/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][125/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][126/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [154][127/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [154][128/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][129/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [154][130/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][131/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][132/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][133/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][134/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][135/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][136/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][137/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [154][138/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [154][139/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][140/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][141/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][142/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [154][143/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][144/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [154][145/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][146/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][147/204]	Loss 0.0022 (0.0003)	
training:	Epoch: [154][148/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][149/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][150/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][151/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][152/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [154][153/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [154][154/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][155/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [154][156/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [154][157/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [154][158/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][159/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][160/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [154][161/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [154][162/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][163/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][164/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [154][165/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][166/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][167/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][168/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][169/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][170/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [154][171/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][172/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [154][173/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][174/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][175/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [154][176/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][177/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][178/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][179/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][180/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][181/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][182/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][183/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][184/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][185/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][186/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][187/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][188/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][189/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [154][190/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][191/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [154][192/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][193/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][194/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [154][195/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][196/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][197/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [154][198/204]	Loss 0.0064 (0.0004)	
training:	Epoch: [154][199/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][200/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][201/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][202/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][203/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [154][204/204]	Loss 0.0002 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7746 0.7758 0.8014 0.7478
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5651
Pretraining:	Epoch 155/500
----------
training:	Epoch: [155][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][3/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][5/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][6/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [155][7/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][8/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][9/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][10/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][11/204]	Loss 0.0016 (0.0003)	
training:	Epoch: [155][12/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [155][13/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][14/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][15/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][16/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][17/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][18/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][19/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][20/204]	Loss 0.0014 (0.0003)	
training:	Epoch: [155][21/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [155][22/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][23/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][24/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][25/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [155][26/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][27/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][28/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][29/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][30/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][31/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][32/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][33/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][49/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][50/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][53/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][55/204]	Loss 0.0031 (0.0003)	
training:	Epoch: [155][56/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][57/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][58/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [155][59/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [155][60/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][61/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][62/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][63/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][64/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][65/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][66/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][67/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][68/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][69/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [155][70/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][71/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][72/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][73/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][74/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][75/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][76/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][77/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][78/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][79/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][80/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][81/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][82/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][84/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][85/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][86/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [155][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][89/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][92/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][93/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [155][94/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][95/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [155][96/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][97/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][98/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][99/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][100/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][101/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [155][102/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [155][103/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [155][104/204]	Loss 0.0021 (0.0003)	
training:	Epoch: [155][105/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][106/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [155][107/204]	Loss 0.0013 (0.0003)	
training:	Epoch: [155][108/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [155][109/204]	Loss 0.0301 (0.0005)	
training:	Epoch: [155][110/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][111/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][112/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][113/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][114/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [155][115/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][116/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][117/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][118/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][119/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][120/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [155][121/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][122/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][123/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][124/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][125/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][126/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [155][127/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][128/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][129/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][130/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][131/204]	Loss 0.0051 (0.0005)	
training:	Epoch: [155][132/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][133/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][134/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][135/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [155][136/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][137/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][138/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][139/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][140/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][141/204]	Loss 0.0013 (0.0005)	
training:	Epoch: [155][142/204]	Loss 0.0010 (0.0005)	
training:	Epoch: [155][143/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][144/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [155][145/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][146/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][147/204]	Loss 0.0017 (0.0005)	
training:	Epoch: [155][148/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][149/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][150/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][151/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][152/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][153/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [155][154/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [155][155/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [155][156/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][157/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [155][158/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [155][159/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [155][160/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [155][161/204]	Loss 0.0471 (0.0008)	
training:	Epoch: [155][162/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [155][163/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][164/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [155][165/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][166/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [155][167/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][168/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [155][169/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [155][170/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [155][171/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [155][172/204]	Loss 0.0011 (0.0007)	
training:	Epoch: [155][173/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [155][174/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [155][175/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [155][176/204]	Loss 0.0012 (0.0007)	
training:	Epoch: [155][177/204]	Loss 0.0110 (0.0008)	
training:	Epoch: [155][178/204]	Loss 0.0032 (0.0008)	
training:	Epoch: [155][179/204]	Loss 0.0026 (0.0008)	
training:	Epoch: [155][180/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][181/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [155][182/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][183/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][184/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][185/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][186/204]	Loss 0.0015 (0.0008)	
training:	Epoch: [155][187/204]	Loss 0.0013 (0.0008)	
training:	Epoch: [155][188/204]	Loss 0.0024 (0.0008)	
training:	Epoch: [155][189/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][190/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [155][191/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][192/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][193/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][194/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [155][195/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [155][196/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [155][197/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][198/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [155][199/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][200/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [155][201/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][202/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [155][203/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [155][204/204]	Loss 0.0003 (0.0008)	
Training:	 Loss: 0.0008

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7788 0.7796 0.7953 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5449
Pretraining:	Epoch 156/500
----------
training:	Epoch: [156][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [156][2/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [156][3/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][4/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][5/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [156][7/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [156][8/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][9/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][10/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [156][11/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [156][12/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][13/204]	Loss 0.0023 (0.0004)	
training:	Epoch: [156][14/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][15/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][16/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][17/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][18/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][19/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][20/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][21/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][22/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][23/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][24/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][25/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][26/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [156][27/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][28/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][29/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [156][30/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][31/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][32/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][33/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][34/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][35/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][36/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][37/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [156][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [156][41/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [156][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][43/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [156][44/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [156][45/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [156][46/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][47/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][48/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][49/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][50/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][51/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][52/204]	Loss 0.0010 (0.0003)	
training:	Epoch: [156][53/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][54/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][55/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][56/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][57/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][58/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][59/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][60/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][61/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [156][64/204]	Loss 0.0022 (0.0003)	
training:	Epoch: [156][65/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [156][66/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][67/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][68/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [156][69/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][70/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][71/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][72/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][73/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][74/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][75/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][76/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][77/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][78/204]	Loss 0.0033 (0.0003)	
training:	Epoch: [156][79/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][80/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][81/204]	Loss 0.0096 (0.0004)	
training:	Epoch: [156][82/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [156][83/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][84/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][85/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][86/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][87/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][88/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][89/204]	Loss 0.0020 (0.0004)	
training:	Epoch: [156][90/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][91/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][92/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [156][93/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][94/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][95/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [156][96/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [156][97/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][98/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][99/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][100/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][101/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][102/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][103/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][104/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [156][105/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][106/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][107/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][108/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][109/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][110/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][111/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][112/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][113/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][114/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][115/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][116/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [156][117/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][118/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][119/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [156][120/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][121/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][122/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][123/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][124/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][125/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][126/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][127/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][128/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][129/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [156][130/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][131/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [156][132/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [156][133/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [156][134/204]	Loss 0.0067 (0.0004)	
training:	Epoch: [156][135/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][136/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][137/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][138/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][139/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][140/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][141/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][142/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][143/204]	Loss 0.0046 (0.0004)	
training:	Epoch: [156][144/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][145/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][146/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][147/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [156][148/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [156][149/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [156][150/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [156][151/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [156][152/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [156][153/204]	Loss 0.0178 (0.0005)	
training:	Epoch: [156][154/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][155/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][156/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][157/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][158/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][159/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][160/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][161/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][162/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][163/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][164/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [156][165/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][166/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][167/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][168/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][169/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][170/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][171/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][172/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][173/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][174/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][175/204]	Loss 0.0069 (0.0005)	
training:	Epoch: [156][176/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][177/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][178/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][179/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [156][180/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [156][181/204]	Loss 0.0243 (0.0006)	
training:	Epoch: [156][182/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][183/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][184/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][185/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][186/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][187/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][188/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][189/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][190/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [156][191/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][192/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][193/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][194/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][195/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][196/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][197/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][198/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [156][199/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [156][200/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][201/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][202/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][203/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [156][204/204]	Loss 0.0003 (0.0006)	
Training:	 Loss: 0.0006

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7793 0.7806 0.8096 0.7489
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5713
Pretraining:	Epoch 157/500
----------
training:	Epoch: [157][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [157][2/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [157][3/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [157][4/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [157][5/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [157][6/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [157][7/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [157][8/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [157][9/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][11/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][12/204]	Loss 0.0011 (0.0003)	
training:	Epoch: [157][13/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [157][14/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [157][15/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [157][16/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [157][17/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [157][18/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [157][19/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [157][20/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [157][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][36/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][38/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][41/204]	Loss 0.0010 (0.0002)	
training:	Epoch: [157][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][43/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [157][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][49/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][51/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][52/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][54/204]	Loss 0.0013 (0.0002)	
training:	Epoch: [157][55/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [157][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][57/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][58/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][59/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][60/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [157][61/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][66/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][67/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][68/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][69/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][70/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [157][71/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][72/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][74/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][75/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][76/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][77/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][78/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][79/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [157][80/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][81/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][84/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [157][85/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][86/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][88/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][89/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][92/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][93/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][94/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][95/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [157][96/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][97/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][98/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [157][99/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [157][100/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][101/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [157][102/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][103/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [157][104/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [157][105/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [157][106/204]	Loss 0.0459 (0.0006)	
training:	Epoch: [157][107/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [157][108/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [157][109/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [157][110/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [157][111/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [157][112/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [157][113/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [157][114/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [157][115/204]	Loss 0.0039 (0.0006)	
training:	Epoch: [157][116/204]	Loss 0.0958 (0.0015)	
training:	Epoch: [157][117/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [157][118/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][119/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][120/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][121/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [157][122/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][123/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][124/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][125/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][126/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][127/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][128/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][129/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][130/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [157][131/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][132/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][133/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][134/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [157][135/204]	Loss 0.0340 (0.0015)	
training:	Epoch: [157][136/204]	Loss 0.0036 (0.0015)	
training:	Epoch: [157][137/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [157][138/204]	Loss 0.0010 (0.0015)	
training:	Epoch: [157][139/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [157][140/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [157][141/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [157][142/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [157][143/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [157][144/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [157][145/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [157][146/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [157][147/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [157][148/204]	Loss 0.0008 (0.0014)	
training:	Epoch: [157][149/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][150/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][151/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][152/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][153/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [157][154/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][155/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][156/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][157/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [157][158/204]	Loss 0.0168 (0.0015)	
training:	Epoch: [157][159/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [157][160/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [157][161/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][162/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [157][163/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][164/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][165/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][166/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][167/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][168/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][169/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][170/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][171/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [157][172/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [157][173/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][174/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [157][175/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [157][176/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [157][177/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][178/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][179/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [157][180/204]	Loss 0.0014 (0.0013)	
training:	Epoch: [157][181/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [157][182/204]	Loss 0.0005 (0.0013)	
training:	Epoch: [157][183/204]	Loss 0.0010 (0.0013)	
training:	Epoch: [157][184/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [157][185/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][186/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [157][187/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][188/204]	Loss 0.0015 (0.0013)	
training:	Epoch: [157][189/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][190/204]	Loss 0.0009 (0.0013)	
training:	Epoch: [157][191/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][192/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [157][193/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [157][194/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][195/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [157][196/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [157][197/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [157][198/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [157][199/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [157][200/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [157][201/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [157][202/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [157][203/204]	Loss 0.0010 (0.0012)	
training:	Epoch: [157][204/204]	Loss 0.0001 (0.0012)	
Training:	 Loss: 0.0012

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7755 0.7764 0.7943 0.7567
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5839
Pretraining:	Epoch 158/500
----------
training:	Epoch: [158][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [158][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [158][3/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [158][4/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [158][5/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [158][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [158][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [158][8/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [158][9/204]	Loss 0.0035 (0.0005)	
training:	Epoch: [158][10/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [158][11/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [158][12/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [158][13/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [158][14/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [158][15/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [158][16/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [158][17/204]	Loss 0.0085 (0.0009)	
training:	Epoch: [158][18/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [158][19/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [158][20/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [158][21/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [158][22/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [158][23/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [158][24/204]	Loss 0.0026 (0.0008)	
training:	Epoch: [158][25/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [158][26/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [158][27/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [158][28/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [158][29/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [158][30/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [158][31/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [158][32/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [158][33/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [158][34/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [158][35/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [158][36/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [158][37/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [158][38/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [158][39/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [158][40/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [158][41/204]	Loss 0.0994 (0.0030)	
training:	Epoch: [158][42/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [158][43/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [158][44/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [158][45/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [158][46/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [158][47/204]	Loss 0.0259 (0.0032)	
training:	Epoch: [158][48/204]	Loss 0.0002 (0.0031)	
training:	Epoch: [158][49/204]	Loss 0.0910 (0.0049)	
training:	Epoch: [158][50/204]	Loss 0.0001 (0.0048)	
training:	Epoch: [158][51/204]	Loss 0.0001 (0.0047)	
training:	Epoch: [158][52/204]	Loss 0.0002 (0.0046)	
training:	Epoch: [158][53/204]	Loss 0.0002 (0.0045)	
training:	Epoch: [158][54/204]	Loss 0.0001 (0.0045)	
training:	Epoch: [158][55/204]	Loss 0.0011 (0.0044)	
training:	Epoch: [158][56/204]	Loss 0.0002 (0.0043)	
training:	Epoch: [158][57/204]	Loss 0.0001 (0.0042)	
training:	Epoch: [158][58/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [158][59/204]	Loss 0.0001 (0.0041)	
training:	Epoch: [158][60/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [158][61/204]	Loss 0.0253 (0.0044)	
training:	Epoch: [158][62/204]	Loss 0.0001 (0.0043)	
training:	Epoch: [158][63/204]	Loss 0.0002 (0.0043)	
training:	Epoch: [158][64/204]	Loss 0.0001 (0.0042)	
training:	Epoch: [158][65/204]	Loss 0.0001 (0.0041)	
training:	Epoch: [158][66/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [158][67/204]	Loss 0.0001 (0.0040)	
training:	Epoch: [158][68/204]	Loss 0.0002 (0.0040)	
training:	Epoch: [158][69/204]	Loss 0.0521 (0.0047)	
training:	Epoch: [158][70/204]	Loss 0.0001 (0.0046)	
training:	Epoch: [158][71/204]	Loss 0.0001 (0.0045)	
training:	Epoch: [158][72/204]	Loss 0.0003 (0.0045)	
training:	Epoch: [158][73/204]	Loss 0.0001 (0.0044)	
training:	Epoch: [158][74/204]	Loss 0.0001 (0.0043)	
training:	Epoch: [158][75/204]	Loss 0.0002 (0.0043)	
training:	Epoch: [158][76/204]	Loss 0.0077 (0.0043)	
training:	Epoch: [158][77/204]	Loss 0.0001 (0.0043)	
training:	Epoch: [158][78/204]	Loss 0.0001 (0.0042)	
training:	Epoch: [158][79/204]	Loss 0.0005 (0.0042)	
training:	Epoch: [158][80/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [158][81/204]	Loss 0.0058 (0.0042)	
training:	Epoch: [158][82/204]	Loss 0.0019 (0.0041)	
training:	Epoch: [158][83/204]	Loss 0.0001 (0.0041)	
training:	Epoch: [158][84/204]	Loss 0.0002 (0.0040)	
training:	Epoch: [158][85/204]	Loss 0.0001 (0.0040)	
training:	Epoch: [158][86/204]	Loss 0.2300 (0.0066)	
training:	Epoch: [158][87/204]	Loss 0.0747 (0.0074)	
training:	Epoch: [158][88/204]	Loss 0.0011 (0.0073)	
training:	Epoch: [158][89/204]	Loss 0.0005 (0.0072)	
training:	Epoch: [158][90/204]	Loss 0.0001 (0.0072)	
training:	Epoch: [158][91/204]	Loss 0.0002 (0.0071)	
training:	Epoch: [158][92/204]	Loss 0.0007 (0.0070)	
training:	Epoch: [158][93/204]	Loss 0.0004 (0.0070)	
training:	Epoch: [158][94/204]	Loss 0.0009 (0.0069)	
training:	Epoch: [158][95/204]	Loss 0.0002 (0.0068)	
training:	Epoch: [158][96/204]	Loss 0.0090 (0.0068)	
training:	Epoch: [158][97/204]	Loss 0.0002 (0.0068)	
training:	Epoch: [158][98/204]	Loss 0.0002 (0.0067)	
training:	Epoch: [158][99/204]	Loss 0.0042 (0.0067)	
training:	Epoch: [158][100/204]	Loss 0.0003 (0.0066)	
training:	Epoch: [158][101/204]	Loss 0.0003 (0.0066)	
training:	Epoch: [158][102/204]	Loss 0.0002 (0.0065)	
training:	Epoch: [158][103/204]	Loss 0.0003 (0.0064)	
training:	Epoch: [158][104/204]	Loss 0.0004 (0.0064)	
training:	Epoch: [158][105/204]	Loss 0.0002 (0.0063)	
training:	Epoch: [158][106/204]	Loss 0.0001 (0.0063)	
training:	Epoch: [158][107/204]	Loss 0.0002 (0.0062)	
training:	Epoch: [158][108/204]	Loss 0.0273 (0.0064)	
training:	Epoch: [158][109/204]	Loss 0.0001 (0.0063)	
training:	Epoch: [158][110/204]	Loss 0.0003 (0.0063)	
training:	Epoch: [158][111/204]	Loss 0.0004 (0.0062)	
training:	Epoch: [158][112/204]	Loss 0.0010 (0.0062)	
training:	Epoch: [158][113/204]	Loss 0.0002 (0.0061)	
training:	Epoch: [158][114/204]	Loss 0.0010 (0.0061)	
training:	Epoch: [158][115/204]	Loss 0.0003 (0.0060)	
training:	Epoch: [158][116/204]	Loss 0.0002 (0.0060)	
training:	Epoch: [158][117/204]	Loss 0.0248 (0.0061)	
training:	Epoch: [158][118/204]	Loss 0.0002 (0.0061)	
training:	Epoch: [158][119/204]	Loss 0.0006 (0.0060)	
training:	Epoch: [158][120/204]	Loss 0.0002 (0.0060)	
training:	Epoch: [158][121/204]	Loss 0.0001 (0.0059)	
training:	Epoch: [158][122/204]	Loss 0.0003 (0.0059)	
training:	Epoch: [158][123/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [158][124/204]	Loss 0.0002 (0.0058)	
training:	Epoch: [158][125/204]	Loss 0.0002 (0.0058)	
training:	Epoch: [158][126/204]	Loss 0.0002 (0.0057)	
training:	Epoch: [158][127/204]	Loss 0.0015 (0.0057)	
training:	Epoch: [158][128/204]	Loss 0.0072 (0.0057)	
training:	Epoch: [158][129/204]	Loss 0.0003 (0.0057)	
training:	Epoch: [158][130/204]	Loss 0.0002 (0.0056)	
training:	Epoch: [158][131/204]	Loss 0.0002 (0.0056)	
training:	Epoch: [158][132/204]	Loss 0.0012 (0.0055)	
training:	Epoch: [158][133/204]	Loss 0.0090 (0.0056)	
training:	Epoch: [158][134/204]	Loss 0.0006 (0.0055)	
training:	Epoch: [158][135/204]	Loss 0.0001 (0.0055)	
training:	Epoch: [158][136/204]	Loss 0.0002 (0.0055)	
training:	Epoch: [158][137/204]	Loss 0.0001 (0.0054)	
training:	Epoch: [158][138/204]	Loss 0.1112 (0.0062)	
training:	Epoch: [158][139/204]	Loss 0.0003 (0.0061)	
training:	Epoch: [158][140/204]	Loss 0.0002 (0.0061)	
training:	Epoch: [158][141/204]	Loss 0.0001 (0.0061)	
training:	Epoch: [158][142/204]	Loss 0.0002 (0.0060)	
training:	Epoch: [158][143/204]	Loss 0.0001 (0.0060)	
training:	Epoch: [158][144/204]	Loss 0.0048 (0.0060)	
training:	Epoch: [158][145/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [158][146/204]	Loss 0.0002 (0.0059)	
training:	Epoch: [158][147/204]	Loss 0.0002 (0.0058)	
training:	Epoch: [158][148/204]	Loss 0.0002 (0.0058)	
training:	Epoch: [158][149/204]	Loss 0.0001 (0.0058)	
training:	Epoch: [158][150/204]	Loss 0.0002 (0.0057)	
training:	Epoch: [158][151/204]	Loss 0.0604 (0.0061)	
training:	Epoch: [158][152/204]	Loss 0.0001 (0.0061)	
training:	Epoch: [158][153/204]	Loss 0.0001 (0.0060)	
training:	Epoch: [158][154/204]	Loss 0.0004 (0.0060)	
training:	Epoch: [158][155/204]	Loss 0.0002 (0.0059)	
training:	Epoch: [158][156/204]	Loss 0.0002 (0.0059)	
training:	Epoch: [158][157/204]	Loss 0.0050 (0.0059)	
training:	Epoch: [158][158/204]	Loss 0.0001 (0.0059)	
training:	Epoch: [158][159/204]	Loss 0.0001 (0.0058)	
training:	Epoch: [158][160/204]	Loss 0.0003 (0.0058)	
training:	Epoch: [158][161/204]	Loss 0.0002 (0.0058)	
training:	Epoch: [158][162/204]	Loss 0.0001 (0.0057)	
training:	Epoch: [158][163/204]	Loss 0.0001 (0.0057)	
training:	Epoch: [158][164/204]	Loss 0.0001 (0.0057)	
training:	Epoch: [158][165/204]	Loss 0.0017 (0.0056)	
training:	Epoch: [158][166/204]	Loss 0.0001 (0.0056)	
training:	Epoch: [158][167/204]	Loss 0.0002 (0.0056)	
training:	Epoch: [158][168/204]	Loss 0.0037 (0.0056)	
training:	Epoch: [158][169/204]	Loss 0.0006 (0.0055)	
training:	Epoch: [158][170/204]	Loss 0.0010 (0.0055)	
training:	Epoch: [158][171/204]	Loss 0.0004 (0.0055)	
training:	Epoch: [158][172/204]	Loss 0.0002 (0.0054)	
training:	Epoch: [158][173/204]	Loss 0.0076 (0.0054)	
training:	Epoch: [158][174/204]	Loss 0.0029 (0.0054)	
training:	Epoch: [158][175/204]	Loss 0.0001 (0.0054)	
training:	Epoch: [158][176/204]	Loss 0.0001 (0.0054)	
training:	Epoch: [158][177/204]	Loss 0.0002 (0.0053)	
training:	Epoch: [158][178/204]	Loss 0.0002 (0.0053)	
training:	Epoch: [158][179/204]	Loss 0.0002 (0.0053)	
training:	Epoch: [158][180/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [158][181/204]	Loss 0.0002 (0.0052)	
training:	Epoch: [158][182/204]	Loss 0.0004 (0.0052)	
training:	Epoch: [158][183/204]	Loss 0.0002 (0.0052)	
training:	Epoch: [158][184/204]	Loss 0.0001 (0.0051)	
training:	Epoch: [158][185/204]	Loss 0.0004 (0.0051)	
training:	Epoch: [158][186/204]	Loss 0.0001 (0.0051)	
training:	Epoch: [158][187/204]	Loss 0.0010 (0.0051)	
training:	Epoch: [158][188/204]	Loss 0.0002 (0.0050)	
training:	Epoch: [158][189/204]	Loss 0.0005 (0.0050)	
training:	Epoch: [158][190/204]	Loss 0.0002 (0.0050)	
training:	Epoch: [158][191/204]	Loss 0.0002 (0.0050)	
training:	Epoch: [158][192/204]	Loss 0.0327 (0.0051)	
training:	Epoch: [158][193/204]	Loss 0.0037 (0.0051)	
training:	Epoch: [158][194/204]	Loss 0.0001 (0.0051)	
training:	Epoch: [158][195/204]	Loss 0.0002 (0.0051)	
training:	Epoch: [158][196/204]	Loss 0.0002 (0.0050)	
training:	Epoch: [158][197/204]	Loss 0.0001 (0.0050)	
training:	Epoch: [158][198/204]	Loss 0.0001 (0.0050)	
training:	Epoch: [158][199/204]	Loss 0.0406 (0.0052)	
training:	Epoch: [158][200/204]	Loss 0.0008 (0.0051)	
training:	Epoch: [158][201/204]	Loss 0.0002 (0.0051)	
training:	Epoch: [158][202/204]	Loss 0.0003 (0.0051)	
training:	Epoch: [158][203/204]	Loss 0.0002 (0.0051)	
training:	Epoch: [158][204/204]	Loss 0.0002 (0.0050)	
Training:	 Loss: 0.0050

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7830 0.7844 0.8137 0.7522
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5186
Pretraining:	Epoch 159/500
----------
training:	Epoch: [159][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [159][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [159][3/204]	Loss 0.0009 (0.0004)	
training:	Epoch: [159][4/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [159][5/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [159][6/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [159][7/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [159][8/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [159][9/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [159][10/204]	Loss 0.0020 (0.0005)	
training:	Epoch: [159][11/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [159][12/204]	Loss 0.0105 (0.0013)	
training:	Epoch: [159][13/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [159][14/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][15/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][16/204]	Loss 0.0076 (0.0015)	
training:	Epoch: [159][17/204]	Loss 0.0089 (0.0019)	
training:	Epoch: [159][18/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [159][19/204]	Loss 0.0002 (0.0017)	
training:	Epoch: [159][20/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [159][21/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [159][22/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [159][23/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [159][24/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [159][25/204]	Loss 0.0018 (0.0014)	
training:	Epoch: [159][26/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][27/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [159][28/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [159][29/204]	Loss 0.0023 (0.0013)	
training:	Epoch: [159][30/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [159][31/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [159][32/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [159][33/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [159][34/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [159][35/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][36/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][37/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [159][38/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][39/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [159][40/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [159][41/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [159][42/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [159][43/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [159][44/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [159][45/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [159][46/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [159][47/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [159][48/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [159][49/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [159][50/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [159][51/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [159][52/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [159][53/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [159][54/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [159][55/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [159][56/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [159][57/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [159][58/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [159][59/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [159][60/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [159][61/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [159][62/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [159][63/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [159][64/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [159][65/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [159][66/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [159][67/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [159][68/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [159][69/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [159][70/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [159][71/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [159][72/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][73/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][74/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][75/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][76/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][77/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [159][78/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [159][79/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][80/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][81/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][82/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][83/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][84/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][85/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][86/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][87/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][88/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][89/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][90/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][91/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][92/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [159][93/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [159][94/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [159][95/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [159][96/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [159][97/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [159][98/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [159][99/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [159][100/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [159][101/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [159][102/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [159][103/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [159][104/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [159][105/204]	Loss 0.0120 (0.0006)	
training:	Epoch: [159][106/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][107/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][108/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][109/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][110/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [159][111/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][112/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [159][113/204]	Loss 0.0784 (0.0013)	
training:	Epoch: [159][114/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [159][115/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [159][116/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [159][117/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [159][118/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [159][119/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [159][120/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [159][121/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [159][122/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [159][123/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [159][124/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [159][125/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [159][126/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [159][127/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [159][128/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [159][129/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [159][130/204]	Loss 0.0016 (0.0012)	
training:	Epoch: [159][131/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][132/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][133/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][134/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [159][135/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][136/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][137/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][138/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][139/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][140/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [159][141/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][142/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [159][143/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [159][144/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [159][145/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [159][146/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [159][147/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [159][148/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [159][149/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [159][150/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [159][151/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [159][152/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [159][153/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [159][154/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [159][155/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [159][156/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [159][157/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [159][158/204]	Loss 0.0713 (0.0014)	
training:	Epoch: [159][159/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][160/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][161/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [159][162/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [159][163/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][164/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [159][165/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][166/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][167/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [159][168/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][169/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][170/204]	Loss 0.0176 (0.0014)	
training:	Epoch: [159][171/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][172/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][173/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][174/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][175/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [159][176/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][177/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][178/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][179/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][180/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][181/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][182/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [159][183/204]	Loss 0.0007 (0.0014)	
training:	Epoch: [159][184/204]	Loss 0.0012 (0.0014)	
training:	Epoch: [159][185/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [159][186/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][187/204]	Loss 0.0074 (0.0014)	
training:	Epoch: [159][188/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][189/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [159][190/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [159][191/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][192/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][193/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [159][194/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [159][195/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [159][196/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [159][197/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [159][198/204]	Loss 0.0175 (0.0014)	
training:	Epoch: [159][199/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][200/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [159][201/204]	Loss 0.0043 (0.0014)	
training:	Epoch: [159][202/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][203/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [159][204/204]	Loss 0.0003 (0.0014)	
Training:	 Loss: 0.0014

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7687 0.7683 0.7605 0.7769
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6104
Pretraining:	Epoch 160/500
----------
training:	Epoch: [160][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [160][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [160][3/204]	Loss 0.0047 (0.0017)	
training:	Epoch: [160][4/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [160][5/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [160][6/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [160][7/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [160][8/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [160][9/204]	Loss 0.0008 (0.0008)	
training:	Epoch: [160][10/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][11/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][12/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][13/204]	Loss 0.0012 (0.0007)	
training:	Epoch: [160][14/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][15/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][16/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][17/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [160][18/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [160][19/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [160][20/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [160][21/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [160][22/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [160][23/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [160][24/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [160][25/204]	Loss 0.0187 (0.0012)	
training:	Epoch: [160][26/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [160][27/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [160][28/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [160][29/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][30/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][31/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][32/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][33/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][34/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][35/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][36/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][37/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [160][38/204]	Loss 0.0003 (0.0008)	
training:	Epoch: [160][39/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [160][40/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [160][41/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [160][42/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [160][43/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][44/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [160][45/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][46/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][47/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [160][48/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [160][49/204]	Loss 0.0024 (0.0007)	
training:	Epoch: [160][50/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][51/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [160][52/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [160][53/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][54/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [160][55/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][56/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][57/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][58/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][59/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][60/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [160][61/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][62/204]	Loss 0.0070 (0.0007)	
training:	Epoch: [160][63/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][64/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][65/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][66/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [160][67/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][68/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [160][69/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][70/204]	Loss 0.0019 (0.0007)	
training:	Epoch: [160][71/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][72/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][73/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [160][74/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][75/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][76/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][77/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][78/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][79/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][80/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [160][81/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][82/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][83/204]	Loss 0.0086 (0.0007)	
training:	Epoch: [160][84/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [160][85/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][86/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [160][87/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][88/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][89/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][90/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][91/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [160][92/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][93/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][94/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][95/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][96/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][97/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][98/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][99/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][100/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][101/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [160][102/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][103/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][104/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [160][105/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [160][106/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][107/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [160][108/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][109/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][110/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [160][111/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][112/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][113/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][114/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [160][115/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][116/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][117/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [160][118/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [160][119/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [160][120/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [160][121/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [160][122/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [160][123/204]	Loss 0.0437 (0.0009)	
training:	Epoch: [160][124/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [160][125/204]	Loss 0.0451 (0.0012)	
training:	Epoch: [160][126/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [160][127/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [160][128/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [160][129/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [160][130/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [160][131/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [160][132/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [160][133/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [160][134/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [160][135/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [160][136/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [160][137/204]	Loss 0.0012 (0.0012)	
training:	Epoch: [160][138/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [160][139/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][140/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][141/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [160][142/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][143/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [160][144/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][145/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][146/204]	Loss 0.0021 (0.0011)	
training:	Epoch: [160][147/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][148/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][149/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [160][150/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][151/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][152/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [160][153/204]	Loss 0.0021 (0.0011)	
training:	Epoch: [160][154/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [160][155/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [160][156/204]	Loss 0.0004 (0.0011)	
training:	Epoch: [160][157/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][158/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [160][159/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][160/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][161/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [160][162/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][163/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][164/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][165/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][166/204]	Loss 0.0023 (0.0010)	
training:	Epoch: [160][167/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][168/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][169/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][170/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][171/204]	Loss 0.0006 (0.0010)	
training:	Epoch: [160][172/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][173/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][174/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][175/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][176/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][177/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [160][178/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][179/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][180/204]	Loss 0.0016 (0.0010)	
training:	Epoch: [160][181/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][182/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [160][183/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [160][184/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][185/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][186/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [160][187/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][188/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][189/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [160][190/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][191/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][192/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][193/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [160][194/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][195/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [160][196/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][197/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][198/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [160][199/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [160][200/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][201/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [160][202/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][203/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [160][204/204]	Loss 0.0001 (0.0009)	
Training:	 Loss: 0.0009

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7728 0.7737 0.7922 0.7534
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6171
Pretraining:	Epoch 161/500
----------
training:	Epoch: [161][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][3/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [161][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][6/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][8/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][11/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][15/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][16/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][24/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][25/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][27/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [161][28/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [161][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][30/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [161][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][35/204]	Loss 0.0024 (0.0002)	
training:	Epoch: [161][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][38/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [161][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][42/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [161][43/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][49/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [161][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][51/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [161][52/204]	Loss 0.0035 (0.0003)	
training:	Epoch: [161][53/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][54/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][55/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][56/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][57/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][58/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][59/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][60/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][61/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][62/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][63/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][64/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][65/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][66/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][67/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][68/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][69/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][70/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][71/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][72/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][73/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][74/204]	Loss 0.0046 (0.0003)	
training:	Epoch: [161][75/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][76/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][77/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][78/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][79/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][80/204]	Loss 0.0010 (0.0003)	
training:	Epoch: [161][81/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][82/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][83/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][84/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][85/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [161][86/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][87/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][88/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][89/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][90/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][91/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][92/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][93/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][94/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][95/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [161][96/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][97/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][98/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][99/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][100/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][101/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [161][102/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][103/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][104/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][105/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][106/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][107/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][108/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][109/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][110/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][111/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][112/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][113/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][114/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][115/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][116/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][117/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][118/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][119/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [161][120/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][121/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][122/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][123/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][124/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][125/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][126/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][127/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][128/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][129/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][130/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][131/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][132/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [161][133/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [161][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][135/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][137/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][139/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][141/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][142/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][143/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][144/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][145/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][146/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][147/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][148/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][149/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [161][150/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][153/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][154/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][155/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][156/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][158/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][161/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][163/204]	Loss 0.0013 (0.0002)	
training:	Epoch: [161][164/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][165/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][168/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][171/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][172/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][173/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][174/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][175/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][176/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][177/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][178/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][179/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][180/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][181/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][182/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [161][183/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [161][184/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][186/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][187/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][189/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][190/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][191/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [161][192/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][193/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][194/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][195/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][196/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [161][197/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][198/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][199/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][200/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][201/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [161][202/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][203/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [161][204/204]	Loss 0.0002 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7740 0.7747 0.7912 0.7567
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6204
Pretraining:	Epoch 162/500
----------
training:	Epoch: [162][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][2/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][8/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [162][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][12/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [162][13/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [162][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][18/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [162][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][26/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [162][27/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [162][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][30/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [162][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][34/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [162][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [162][36/204]	Loss 0.0010 (0.0002)	
training:	Epoch: [162][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][43/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][48/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [162][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][50/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][56/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][57/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][58/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][59/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][60/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][61/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][62/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [162][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][66/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][67/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][68/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][69/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][70/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][71/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][72/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][73/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][74/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][75/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][76/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][77/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][78/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][79/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][80/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [162][81/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][84/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][85/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][86/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][87/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][88/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][89/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [162][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][92/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][93/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][94/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][95/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [162][96/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][97/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][98/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][99/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][100/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][101/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][102/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][103/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][104/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][105/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][107/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][108/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][109/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][110/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][111/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][113/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][114/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][115/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [162][116/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][118/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [162][119/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][120/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][121/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][122/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][123/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][124/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][125/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][126/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][127/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [162][128/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][129/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [162][130/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][131/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][132/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][134/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][135/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [162][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][137/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][139/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][141/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][142/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][143/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][144/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][145/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][146/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][147/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][148/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][149/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][150/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][153/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][154/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][155/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][156/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][158/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][161/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][163/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][164/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][165/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][168/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][171/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][172/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][173/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][174/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][175/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][176/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][177/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][178/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [162][179/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][181/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][182/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][183/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [162][184/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][186/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][187/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][189/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][190/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][191/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][192/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][193/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][194/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][195/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][196/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][197/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][198/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][199/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][200/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][201/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [162][202/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][203/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [162][204/204]	Loss 0.0001 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7721 0.7731 0.7953 0.7489
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6386
Pretraining:	Epoch 163/500
----------
training:	Epoch: [163][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][5/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][6/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [163][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][8/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][9/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][11/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][15/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][16/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][18/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [163][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][22/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][24/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [163][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][30/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [163][31/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][50/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][53/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [163][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][59/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][63/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][67/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][68/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [163][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][82/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][88/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][89/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][93/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][97/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][98/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][100/204]	Loss 0.0011 (0.0002)	
training:	Epoch: [163][101/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][102/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][103/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [163][104/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][105/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][107/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][108/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][109/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][110/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][111/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][113/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][114/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][115/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][116/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][118/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][119/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][120/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][121/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][126/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][128/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [163][129/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [163][130/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][131/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][132/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][135/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][137/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][139/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][141/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][142/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][143/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][144/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][145/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][146/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [163][147/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][148/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][149/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][150/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][153/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [163][154/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][155/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][156/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][158/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][161/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][162/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][163/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][164/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][165/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][168/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][170/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][171/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [163][172/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][173/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][174/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][175/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][176/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][177/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][178/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][179/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][181/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][182/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][183/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][184/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][186/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][187/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [163][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][189/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][190/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][191/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [163][192/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][193/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][194/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][195/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][196/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][197/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][198/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [163][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [163][204/204]	Loss 0.0002 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7726 0.7737 0.7963 0.7489
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6521
Pretraining:	Epoch 164/500
----------
training:	Epoch: [164][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][4/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [164][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][9/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [164][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][20/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [164][21/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [164][22/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][34/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [164][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][38/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [164][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][41/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [164][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][49/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][58/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][59/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][60/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][61/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][66/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][67/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][68/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [164][69/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][70/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][72/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][79/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [164][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][87/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [164][88/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][89/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][92/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][93/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [164][95/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][96/204]	Loss 0.0014 (0.0002)	
training:	Epoch: [164][97/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][98/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][99/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][100/204]	Loss 0.0038 (0.0002)	
training:	Epoch: [164][101/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][102/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][103/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][104/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][105/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][107/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][108/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][109/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][110/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][111/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][113/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][114/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][115/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][116/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][118/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][119/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][120/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][121/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][122/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][123/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][124/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][125/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][126/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][127/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][128/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][129/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][130/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][131/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][132/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][135/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][137/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][139/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][141/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][142/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [164][143/204]	Loss 0.0123 (0.0003)	
training:	Epoch: [164][144/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][145/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][146/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][147/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][148/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][149/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [164][150/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][151/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][152/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][153/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][154/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][155/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][156/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][158/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][161/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [164][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][163/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][164/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][165/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][168/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][171/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][172/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][173/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][174/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][175/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][176/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][177/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][178/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][179/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][181/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][182/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][183/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][184/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][186/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][187/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][189/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][190/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][191/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][192/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][193/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [164][194/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [164][195/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [164][196/204]	Loss 0.0033 (0.0002)	
training:	Epoch: [164][197/204]	Loss 0.0033 (0.0003)	
training:	Epoch: [164][198/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][199/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][200/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [164][201/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][202/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][203/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [164][204/204]	Loss 0.0002 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7734 0.7742 0.7922 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6542
Pretraining:	Epoch 165/500
----------
training:	Epoch: [165][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][11/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [165][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][17/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [165][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][25/204]	Loss 0.0009 (0.0001)	
training:	Epoch: [165][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][29/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [165][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][34/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [165][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][42/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][45/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][49/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][57/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [165][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][64/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [165][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][76/204]	Loss 0.0008 (0.0001)	
training:	Epoch: [165][77/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [165][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][81/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [165][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][84/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][85/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][86/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [165][91/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [165][92/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][93/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][94/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][95/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][96/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][97/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][98/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][99/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][100/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [165][101/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][102/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][103/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][104/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][105/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][107/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [165][108/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][109/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][110/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][111/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][113/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][114/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][115/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][116/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][118/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][119/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][120/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][121/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][122/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][123/204]	Loss 0.0122 (0.0002)	
training:	Epoch: [165][124/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][125/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][126/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][127/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][128/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][129/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][130/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][131/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][132/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][134/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][135/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [165][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][137/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [165][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][139/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [165][141/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [165][142/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [165][143/204]	Loss 0.0061 (0.0003)	
training:	Epoch: [165][144/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][145/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [165][146/204]	Loss 0.0014 (0.0003)	
training:	Epoch: [165][147/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][148/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [165][149/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][150/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][151/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][152/204]	Loss 0.0088 (0.0003)	
training:	Epoch: [165][153/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [165][154/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][155/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][156/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][157/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][158/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][159/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][160/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [165][161/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][162/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [165][163/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [165][164/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [165][165/204]	Loss 0.0295 (0.0005)	
training:	Epoch: [165][166/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][167/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][168/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [165][169/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][170/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][171/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][172/204]	Loss 0.0008 (0.0005)	
training:	Epoch: [165][173/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][174/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][175/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][176/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][177/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][178/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [165][179/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][180/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][181/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][182/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][183/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][184/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][185/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][186/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][187/204]	Loss 0.0018 (0.0005)	
training:	Epoch: [165][188/204]	Loss 0.0092 (0.0005)	
training:	Epoch: [165][189/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][190/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][191/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][192/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [165][193/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][194/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][195/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [165][196/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][197/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][198/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][199/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][200/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][201/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][202/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [165][203/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [165][204/204]	Loss 0.0001 (0.0005)	
Training:	 Loss: 0.0005

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7758 0.7764 0.7871 0.7646
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6856
Pretraining:	Epoch 166/500
----------
training:	Epoch: [166][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][3/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [166][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][12/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [166][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][17/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [166][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [166][24/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [166][25/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [166][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][32/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [166][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [166][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][39/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [166][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [166][41/204]	Loss 0.1086 (0.0028)	
training:	Epoch: [166][42/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [166][43/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [166][44/204]	Loss 0.0012 (0.0026)	
training:	Epoch: [166][45/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [166][46/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][47/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][48/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][49/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][50/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [166][51/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [166][52/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [166][53/204]	Loss 0.0030 (0.0023)	
training:	Epoch: [166][54/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [166][55/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [166][56/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [166][57/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [166][58/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [166][59/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [166][60/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [166][61/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [166][62/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [166][63/204]	Loss 0.0914 (0.0034)	
training:	Epoch: [166][64/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [166][65/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [166][66/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [166][67/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [166][68/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [166][69/204]	Loss 0.0077 (0.0032)	
training:	Epoch: [166][70/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [166][71/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [166][72/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [166][73/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [166][74/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [166][75/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [166][76/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [166][77/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [166][78/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [166][79/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [166][80/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [166][81/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [166][82/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [166][83/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [166][84/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [166][85/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [166][86/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [166][87/204]	Loss 0.0004 (0.0026)	
training:	Epoch: [166][88/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][89/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][90/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [166][91/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][92/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][93/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][94/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][95/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][96/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [166][97/204]	Loss 0.0011 (0.0023)	
training:	Epoch: [166][98/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [166][99/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [166][100/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [166][101/204]	Loss 0.0081 (0.0023)	
training:	Epoch: [166][102/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [166][103/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [166][104/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [166][105/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [166][106/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [166][107/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [166][108/204]	Loss 0.0316 (0.0025)	
training:	Epoch: [166][109/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][110/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [166][111/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][112/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][113/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][114/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][115/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [166][116/204]	Loss 0.0016 (0.0023)	
training:	Epoch: [166][117/204]	Loss 0.0554 (0.0028)	
training:	Epoch: [166][118/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [166][119/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [166][120/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [166][121/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [166][122/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [166][123/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [166][124/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [166][125/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [166][126/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [166][127/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [166][128/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [166][129/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][130/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][131/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][132/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [166][133/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [166][134/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][135/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][136/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][137/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][138/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [166][139/204]	Loss 0.1391 (0.0034)	
training:	Epoch: [166][140/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [166][141/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [166][142/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [166][143/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [166][144/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [166][145/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [166][146/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [166][147/204]	Loss 0.0024 (0.0032)	
training:	Epoch: [166][148/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [166][149/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [166][150/204]	Loss 0.0002 (0.0031)	
training:	Epoch: [166][151/204]	Loss 0.1100 (0.0038)	
training:	Epoch: [166][152/204]	Loss 0.1805 (0.0050)	
training:	Epoch: [166][153/204]	Loss 0.0002 (0.0050)	
training:	Epoch: [166][154/204]	Loss 0.0004 (0.0050)	
training:	Epoch: [166][155/204]	Loss 0.0001 (0.0049)	
training:	Epoch: [166][156/204]	Loss 0.0002 (0.0049)	
training:	Epoch: [166][157/204]	Loss 0.0003 (0.0049)	
training:	Epoch: [166][158/204]	Loss 0.0054 (0.0049)	
training:	Epoch: [166][159/204]	Loss 0.0001 (0.0048)	
training:	Epoch: [166][160/204]	Loss 0.0086 (0.0049)	
training:	Epoch: [166][161/204]	Loss 0.0001 (0.0048)	
training:	Epoch: [166][162/204]	Loss 0.0029 (0.0048)	
training:	Epoch: [166][163/204]	Loss 0.0004 (0.0048)	
training:	Epoch: [166][164/204]	Loss 0.1854 (0.0059)	
training:	Epoch: [166][165/204]	Loss 0.0009 (0.0059)	
training:	Epoch: [166][166/204]	Loss 0.0011 (0.0058)	
training:	Epoch: [166][167/204]	Loss 0.0002 (0.0058)	
training:	Epoch: [166][168/204]	Loss 0.0170 (0.0059)	
training:	Epoch: [166][169/204]	Loss 0.0003 (0.0058)	
training:	Epoch: [166][170/204]	Loss 0.0001 (0.0058)	
training:	Epoch: [166][171/204]	Loss 0.0001 (0.0058)	
training:	Epoch: [166][172/204]	Loss 0.0001 (0.0057)	
training:	Epoch: [166][173/204]	Loss 0.0001 (0.0057)	
training:	Epoch: [166][174/204]	Loss 0.0001 (0.0057)	
training:	Epoch: [166][175/204]	Loss 0.0012 (0.0056)	
training:	Epoch: [166][176/204]	Loss 0.0723 (0.0060)	
training:	Epoch: [166][177/204]	Loss 0.0005 (0.0060)	
training:	Epoch: [166][178/204]	Loss 0.0002 (0.0060)	
training:	Epoch: [166][179/204]	Loss 0.0002 (0.0059)	
training:	Epoch: [166][180/204]	Loss 0.0002 (0.0059)	
training:	Epoch: [166][181/204]	Loss 0.0004 (0.0059)	
training:	Epoch: [166][182/204]	Loss 0.0002 (0.0058)	
training:	Epoch: [166][183/204]	Loss 0.0021 (0.0058)	
training:	Epoch: [166][184/204]	Loss 0.0012 (0.0058)	
training:	Epoch: [166][185/204]	Loss 0.0006 (0.0058)	
training:	Epoch: [166][186/204]	Loss 0.3171 (0.0074)	
training:	Epoch: [166][187/204]	Loss 0.0001 (0.0074)	
training:	Epoch: [166][188/204]	Loss 0.0002 (0.0074)	
training:	Epoch: [166][189/204]	Loss 0.0004 (0.0073)	
training:	Epoch: [166][190/204]	Loss 0.0018 (0.0073)	
training:	Epoch: [166][191/204]	Loss 0.0003 (0.0073)	
training:	Epoch: [166][192/204]	Loss 0.0005 (0.0072)	
training:	Epoch: [166][193/204]	Loss 0.0002 (0.0072)	
training:	Epoch: [166][194/204]	Loss 0.0002 (0.0071)	
training:	Epoch: [166][195/204]	Loss 0.0024 (0.0071)	
training:	Epoch: [166][196/204]	Loss 0.0002 (0.0071)	
training:	Epoch: [166][197/204]	Loss 0.0002 (0.0070)	
training:	Epoch: [166][198/204]	Loss 0.0003 (0.0070)	
training:	Epoch: [166][199/204]	Loss 0.0002 (0.0070)	
training:	Epoch: [166][200/204]	Loss 0.0001 (0.0069)	
training:	Epoch: [166][201/204]	Loss 0.0003 (0.0069)	
training:	Epoch: [166][202/204]	Loss 0.0452 (0.0071)	
training:	Epoch: [166][203/204]	Loss 0.0002 (0.0071)	
training:	Epoch: [166][204/204]	Loss 0.0054 (0.0071)	
Training:	 Loss: 0.0071

Training:	 ACC: 0.9981 0.9982 1.0000 0.9962
Validation:	 ACC: 0.7656 0.7694 0.8485 0.6827
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5838
Pretraining:	Epoch 167/500
----------
training:	Epoch: [167][1/204]	Loss 0.0425 (0.0425)	
training:	Epoch: [167][2/204]	Loss 0.0027 (0.0226)	
training:	Epoch: [167][3/204]	Loss 0.0003 (0.0151)	
training:	Epoch: [167][4/204]	Loss 0.0001 (0.0114)	
training:	Epoch: [167][5/204]	Loss 0.0001 (0.0091)	
training:	Epoch: [167][6/204]	Loss 0.0001 (0.0076)	
training:	Epoch: [167][7/204]	Loss 0.0001 (0.0066)	
training:	Epoch: [167][8/204]	Loss 0.0003 (0.0058)	
training:	Epoch: [167][9/204]	Loss 0.0001 (0.0051)	
training:	Epoch: [167][10/204]	Loss 0.0002 (0.0047)	
training:	Epoch: [167][11/204]	Loss 0.0010 (0.0043)	
training:	Epoch: [167][12/204]	Loss 0.0001 (0.0040)	
training:	Epoch: [167][13/204]	Loss 0.0122 (0.0046)	
training:	Epoch: [167][14/204]	Loss 0.0006 (0.0043)	
training:	Epoch: [167][15/204]	Loss 0.0049 (0.0044)	
training:	Epoch: [167][16/204]	Loss 0.0002 (0.0041)	
training:	Epoch: [167][17/204]	Loss 0.0001 (0.0039)	
training:	Epoch: [167][18/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [167][19/204]	Loss 0.0002 (0.0035)	
training:	Epoch: [167][20/204]	Loss 0.0251 (0.0046)	
training:	Epoch: [167][21/204]	Loss 0.0002 (0.0044)	
training:	Epoch: [167][22/204]	Loss 0.0002 (0.0042)	
training:	Epoch: [167][23/204]	Loss 0.0029 (0.0041)	
training:	Epoch: [167][24/204]	Loss 0.0266 (0.0051)	
training:	Epoch: [167][25/204]	Loss 0.0002 (0.0049)	
training:	Epoch: [167][26/204]	Loss 0.0002 (0.0047)	
training:	Epoch: [167][27/204]	Loss 0.0002 (0.0045)	
training:	Epoch: [167][28/204]	Loss 0.0002 (0.0044)	
training:	Epoch: [167][29/204]	Loss 0.0003 (0.0042)	
training:	Epoch: [167][30/204]	Loss 0.0003 (0.0041)	
training:	Epoch: [167][31/204]	Loss 0.0014 (0.0040)	
training:	Epoch: [167][32/204]	Loss 0.0031 (0.0040)	
training:	Epoch: [167][33/204]	Loss 0.0010 (0.0039)	
training:	Epoch: [167][34/204]	Loss 0.0005 (0.0038)	
training:	Epoch: [167][35/204]	Loss 0.0001 (0.0037)	
training:	Epoch: [167][36/204]	Loss 0.0002 (0.0036)	
training:	Epoch: [167][37/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [167][38/204]	Loss 0.0023 (0.0035)	
training:	Epoch: [167][39/204]	Loss 0.0028 (0.0034)	
training:	Epoch: [167][40/204]	Loss 0.0002 (0.0034)	
training:	Epoch: [167][41/204]	Loss 0.0077 (0.0035)	
training:	Epoch: [167][42/204]	Loss 0.0033 (0.0035)	
training:	Epoch: [167][43/204]	Loss 0.0889 (0.0054)	
training:	Epoch: [167][44/204]	Loss 0.0004 (0.0053)	
training:	Epoch: [167][45/204]	Loss 0.0003 (0.0052)	
training:	Epoch: [167][46/204]	Loss 0.0001 (0.0051)	
training:	Epoch: [167][47/204]	Loss 0.0001 (0.0050)	
training:	Epoch: [167][48/204]	Loss 0.0001 (0.0049)	
training:	Epoch: [167][49/204]	Loss 0.0002 (0.0048)	
training:	Epoch: [167][50/204]	Loss 0.0002 (0.0047)	
training:	Epoch: [167][51/204]	Loss 0.0002 (0.0046)	
training:	Epoch: [167][52/204]	Loss 0.0001 (0.0045)	
training:	Epoch: [167][53/204]	Loss 0.0001 (0.0044)	
training:	Epoch: [167][54/204]	Loss 0.0002 (0.0044)	
training:	Epoch: [167][55/204]	Loss 0.0013 (0.0043)	
training:	Epoch: [167][56/204]	Loss 0.0004 (0.0042)	
training:	Epoch: [167][57/204]	Loss 0.0002 (0.0042)	
training:	Epoch: [167][58/204]	Loss 0.0004 (0.0041)	
training:	Epoch: [167][59/204]	Loss 0.0002 (0.0040)	
training:	Epoch: [167][60/204]	Loss 0.0555 (0.0049)	
training:	Epoch: [167][61/204]	Loss 0.0220 (0.0052)	
training:	Epoch: [167][62/204]	Loss 0.0002 (0.0051)	
training:	Epoch: [167][63/204]	Loss 0.0002 (0.0050)	
training:	Epoch: [167][64/204]	Loss 0.0002 (0.0049)	
training:	Epoch: [167][65/204]	Loss 0.0001 (0.0049)	
training:	Epoch: [167][66/204]	Loss 0.0001 (0.0048)	
training:	Epoch: [167][67/204]	Loss 0.0001 (0.0047)	
training:	Epoch: [167][68/204]	Loss 0.0005 (0.0047)	
training:	Epoch: [167][69/204]	Loss 0.0002 (0.0046)	
training:	Epoch: [167][70/204]	Loss 0.0012 (0.0046)	
training:	Epoch: [167][71/204]	Loss 0.0021 (0.0045)	
training:	Epoch: [167][72/204]	Loss 0.0008 (0.0045)	
training:	Epoch: [167][73/204]	Loss 0.0001 (0.0044)	
training:	Epoch: [167][74/204]	Loss 0.0001 (0.0043)	
training:	Epoch: [167][75/204]	Loss 0.0003 (0.0043)	
training:	Epoch: [167][76/204]	Loss 0.0002 (0.0042)	
training:	Epoch: [167][77/204]	Loss 0.0001 (0.0042)	
training:	Epoch: [167][78/204]	Loss 0.0010 (0.0041)	
training:	Epoch: [167][79/204]	Loss 0.0006 (0.0041)	
training:	Epoch: [167][80/204]	Loss 0.0002 (0.0041)	
training:	Epoch: [167][81/204]	Loss 0.0003 (0.0040)	
training:	Epoch: [167][82/204]	Loss 0.0062 (0.0040)	
training:	Epoch: [167][83/204]	Loss 0.0105 (0.0041)	
training:	Epoch: [167][84/204]	Loss 0.0001 (0.0041)	
training:	Epoch: [167][85/204]	Loss 0.0008 (0.0040)	
training:	Epoch: [167][86/204]	Loss 0.0007 (0.0040)	
training:	Epoch: [167][87/204]	Loss 0.0002 (0.0039)	
training:	Epoch: [167][88/204]	Loss 0.0003 (0.0039)	
training:	Epoch: [167][89/204]	Loss 0.0002 (0.0039)	
training:	Epoch: [167][90/204]	Loss 0.0001 (0.0038)	
training:	Epoch: [167][91/204]	Loss 0.0002 (0.0038)	
training:	Epoch: [167][92/204]	Loss 0.0001 (0.0037)	
training:	Epoch: [167][93/204]	Loss 0.0001 (0.0037)	
training:	Epoch: [167][94/204]	Loss 0.0003 (0.0037)	
training:	Epoch: [167][95/204]	Loss 0.0002 (0.0036)	
training:	Epoch: [167][96/204]	Loss 0.0001 (0.0036)	
training:	Epoch: [167][97/204]	Loss 0.0001 (0.0036)	
training:	Epoch: [167][98/204]	Loss 0.0002 (0.0035)	
training:	Epoch: [167][99/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [167][100/204]	Loss 0.0003 (0.0035)	
training:	Epoch: [167][101/204]	Loss 0.0001 (0.0034)	
training:	Epoch: [167][102/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [167][103/204]	Loss 0.0001 (0.0034)	
training:	Epoch: [167][104/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [167][105/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [167][106/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [167][107/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [167][108/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [167][109/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [167][110/204]	Loss 0.0011 (0.0032)	
training:	Epoch: [167][111/204]	Loss 0.0002 (0.0031)	
training:	Epoch: [167][112/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [167][113/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [167][114/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [167][115/204]	Loss 0.0002 (0.0030)	
training:	Epoch: [167][116/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [167][117/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [167][118/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [167][119/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [167][120/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [167][121/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [167][122/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [167][123/204]	Loss 0.0008 (0.0029)	
training:	Epoch: [167][124/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [167][125/204]	Loss 0.0003 (0.0028)	
training:	Epoch: [167][126/204]	Loss 0.0123 (0.0029)	
training:	Epoch: [167][127/204]	Loss 0.1492 (0.0040)	
training:	Epoch: [167][128/204]	Loss 0.0001 (0.0040)	
training:	Epoch: [167][129/204]	Loss 0.0002 (0.0040)	
training:	Epoch: [167][130/204]	Loss 0.0001 (0.0040)	
training:	Epoch: [167][131/204]	Loss 0.0021 (0.0039)	
training:	Epoch: [167][132/204]	Loss 0.0013 (0.0039)	
training:	Epoch: [167][133/204]	Loss 0.0001 (0.0039)	
training:	Epoch: [167][134/204]	Loss 0.0002 (0.0039)	
training:	Epoch: [167][135/204]	Loss 0.0002 (0.0038)	
training:	Epoch: [167][136/204]	Loss 0.0020 (0.0038)	
training:	Epoch: [167][137/204]	Loss 0.0001 (0.0038)	
training:	Epoch: [167][138/204]	Loss 0.0012 (0.0038)	
training:	Epoch: [167][139/204]	Loss 0.0001 (0.0038)	
training:	Epoch: [167][140/204]	Loss 0.0001 (0.0037)	
training:	Epoch: [167][141/204]	Loss 0.0002 (0.0037)	
training:	Epoch: [167][142/204]	Loss 0.0002 (0.0037)	
training:	Epoch: [167][143/204]	Loss 0.0001 (0.0036)	
training:	Epoch: [167][144/204]	Loss 0.0001 (0.0036)	
training:	Epoch: [167][145/204]	Loss 0.0002 (0.0036)	
training:	Epoch: [167][146/204]	Loss 0.0001 (0.0036)	
training:	Epoch: [167][147/204]	Loss 0.0001 (0.0036)	
training:	Epoch: [167][148/204]	Loss 0.0004 (0.0035)	
training:	Epoch: [167][149/204]	Loss 0.0002 (0.0035)	
training:	Epoch: [167][150/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [167][151/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [167][152/204]	Loss 0.0001 (0.0034)	
training:	Epoch: [167][153/204]	Loss 0.0003 (0.0034)	
training:	Epoch: [167][154/204]	Loss 0.0001 (0.0034)	
training:	Epoch: [167][155/204]	Loss 0.0001 (0.0034)	
training:	Epoch: [167][156/204]	Loss 0.0001 (0.0034)	
training:	Epoch: [167][157/204]	Loss 0.0002 (0.0033)	
training:	Epoch: [167][158/204]	Loss 0.0053 (0.0034)	
training:	Epoch: [167][159/204]	Loss 0.0004 (0.0033)	
training:	Epoch: [167][160/204]	Loss 0.0002 (0.0033)	
training:	Epoch: [167][161/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [167][162/204]	Loss 0.0002 (0.0033)	
training:	Epoch: [167][163/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [167][164/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [167][165/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [167][166/204]	Loss 0.0218 (0.0033)	
training:	Epoch: [167][167/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [167][168/204]	Loss 0.0002 (0.0033)	
training:	Epoch: [167][169/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [167][170/204]	Loss 0.0002 (0.0033)	
training:	Epoch: [167][171/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [167][172/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [167][173/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [167][174/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [167][175/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [167][176/204]	Loss 0.0030 (0.0032)	
training:	Epoch: [167][177/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [167][178/204]	Loss 0.0002 (0.0031)	
training:	Epoch: [167][179/204]	Loss 0.0005 (0.0031)	
training:	Epoch: [167][180/204]	Loss 0.0002 (0.0031)	
training:	Epoch: [167][181/204]	Loss 0.0017 (0.0031)	
training:	Epoch: [167][182/204]	Loss 0.0002 (0.0031)	
training:	Epoch: [167][183/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [167][184/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [167][185/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [167][186/204]	Loss 0.0002 (0.0030)	
training:	Epoch: [167][187/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [167][188/204]	Loss 0.0002 (0.0030)	
training:	Epoch: [167][189/204]	Loss 0.0008 (0.0030)	
training:	Epoch: [167][190/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [167][191/204]	Loss 0.0010 (0.0029)	
training:	Epoch: [167][192/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [167][193/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [167][194/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [167][195/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [167][196/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [167][197/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [167][198/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [167][199/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [167][200/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [167][201/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [167][202/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [167][203/204]	Loss 0.0007 (0.0028)	
training:	Epoch: [167][204/204]	Loss 0.0002 (0.0028)	
Training:	 Loss: 0.0028

Training:	 ACC: 0.9997 0.9997 1.0000 0.9994
Validation:	 ACC: 0.7625 0.7646 0.8076 0.7175
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5992
Pretraining:	Epoch 168/500
----------
training:	Epoch: [168][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [168][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [168][3/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [168][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [168][5/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [168][6/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [168][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [168][8/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [168][9/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [168][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [168][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [168][12/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [168][13/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [168][14/204]	Loss 0.0072 (0.0007)	
training:	Epoch: [168][15/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [168][16/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [168][17/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [168][18/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [168][19/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [168][20/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [168][21/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [168][22/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [168][23/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [168][24/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [168][25/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [168][26/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [168][27/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [168][28/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][29/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [168][30/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][31/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][32/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [168][33/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [168][34/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [168][35/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [168][36/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][37/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [168][38/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [168][39/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [168][40/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][41/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][42/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][43/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][44/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][45/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][46/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][47/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][48/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [168][49/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][50/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][51/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][52/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][53/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][54/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][55/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][56/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][57/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][58/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][59/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][60/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][61/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][62/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][63/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][64/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][65/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][66/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][67/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][68/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][69/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][70/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][71/204]	Loss 0.0043 (0.0003)	
training:	Epoch: [168][72/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][73/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][74/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][75/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][76/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][77/204]	Loss 0.0011 (0.0003)	
training:	Epoch: [168][78/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [168][79/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][80/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [168][81/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][82/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][83/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][84/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][85/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][86/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][87/204]	Loss 0.0031 (0.0003)	
training:	Epoch: [168][88/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][89/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][90/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][91/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][92/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][93/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][94/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][95/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][96/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [168][97/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][98/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][99/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][100/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][101/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][102/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][103/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][104/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][105/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][106/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][107/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][108/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][109/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][110/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][111/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [168][112/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][113/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][114/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][115/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][116/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][117/204]	Loss 0.0017 (0.0003)	
training:	Epoch: [168][118/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][119/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][120/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][121/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [168][122/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][123/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][124/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][125/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][126/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][127/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][128/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [168][129/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][130/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [168][131/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [168][132/204]	Loss 0.0034 (0.0003)	
training:	Epoch: [168][133/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][134/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [168][135/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][136/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][137/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [168][138/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][139/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][140/204]	Loss 0.0010 (0.0003)	
training:	Epoch: [168][141/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][142/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][143/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [168][144/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][145/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][146/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][147/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][148/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][149/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][150/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][151/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][152/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [168][153/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][154/204]	Loss 0.0051 (0.0003)	
training:	Epoch: [168][155/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][156/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][157/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][158/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][159/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][160/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [168][161/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [168][162/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][163/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][164/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [168][165/204]	Loss 0.0042 (0.0004)	
training:	Epoch: [168][166/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][167/204]	Loss 0.0074 (0.0004)	
training:	Epoch: [168][168/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][169/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][170/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][171/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [168][172/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][173/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][174/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [168][175/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][176/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][177/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][178/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][179/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [168][180/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][181/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][182/204]	Loss 0.0116 (0.0004)	
training:	Epoch: [168][183/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][184/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [168][185/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][186/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][187/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][188/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][189/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][190/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][191/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [168][192/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][193/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [168][194/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][195/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][196/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][197/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][198/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][199/204]	Loss 0.0011 (0.0004)	
training:	Epoch: [168][200/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [168][201/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [168][202/204]	Loss 0.0035 (0.0004)	
training:	Epoch: [168][203/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [168][204/204]	Loss 0.0001 (0.0004)	
Training:	 Loss: 0.0004

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7629 0.7640 0.7871 0.7388
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6332
Pretraining:	Epoch 169/500
----------
training:	Epoch: [169][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][2/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [169][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][6/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [169][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][11/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [169][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [169][17/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [169][18/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [169][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][21/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [169][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][24/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [169][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][28/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [169][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [169][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [169][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [169][36/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [169][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [169][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][47/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [169][48/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [169][49/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [169][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [169][54/204]	Loss 0.0978 (0.0020)	
training:	Epoch: [169][55/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [169][56/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [169][57/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [169][58/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [169][59/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [169][60/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [169][61/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [169][62/204]	Loss 0.0024 (0.0018)	
training:	Epoch: [169][63/204]	Loss 0.0014 (0.0018)	
training:	Epoch: [169][64/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [169][65/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [169][66/204]	Loss 0.0002 (0.0017)	
training:	Epoch: [169][67/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [169][68/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [169][69/204]	Loss 0.0007 (0.0017)	
training:	Epoch: [169][70/204]	Loss 0.0126 (0.0018)	
training:	Epoch: [169][71/204]	Loss 0.0109 (0.0019)	
training:	Epoch: [169][72/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [169][73/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [169][74/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [169][75/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [169][76/204]	Loss 0.0255 (0.0022)	
training:	Epoch: [169][77/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [169][78/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [169][79/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [169][80/204]	Loss 0.0148 (0.0022)	
training:	Epoch: [169][81/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [169][82/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [169][83/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [169][84/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [169][85/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [169][86/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [169][87/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [169][88/204]	Loss 0.0012 (0.0021)	
training:	Epoch: [169][89/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [169][90/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [169][91/204]	Loss 0.0075 (0.0021)	
training:	Epoch: [169][92/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [169][93/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [169][94/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [169][95/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [169][96/204]	Loss 0.0028 (0.0020)	
training:	Epoch: [169][97/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [169][98/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [169][99/204]	Loss 0.0014 (0.0020)	
training:	Epoch: [169][100/204]	Loss 0.0062 (0.0020)	
training:	Epoch: [169][101/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [169][102/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [169][103/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [169][104/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [169][105/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [169][106/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [169][107/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [169][108/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [169][109/204]	Loss 0.0061 (0.0019)	
training:	Epoch: [169][110/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [169][111/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [169][112/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [169][113/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [169][114/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [169][115/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [169][116/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [169][117/204]	Loss 0.0044 (0.0018)	
training:	Epoch: [169][118/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [169][119/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [169][120/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [169][121/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [169][122/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [169][123/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [169][124/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [169][125/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [169][126/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [169][127/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [169][128/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [169][129/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [169][130/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [169][131/204]	Loss 0.0002 (0.0017)	
training:	Epoch: [169][132/204]	Loss 0.0009 (0.0016)	
training:	Epoch: [169][133/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [169][134/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [169][135/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [169][136/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [169][137/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [169][138/204]	Loss 0.0009 (0.0016)	
training:	Epoch: [169][139/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [169][140/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [169][141/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [169][142/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [169][143/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [169][144/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [169][145/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [169][146/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [169][147/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [169][148/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [169][149/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [169][150/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [169][151/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [169][152/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [169][153/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][154/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][155/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][156/204]	Loss 0.0005 (0.0014)	
training:	Epoch: [169][157/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][158/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][159/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][160/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][161/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][162/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][163/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [169][164/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][165/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [169][166/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][167/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][168/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][169/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [169][170/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][171/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][172/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][173/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][174/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][175/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][176/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][177/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][178/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [169][179/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [169][180/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][181/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [169][182/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][183/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][184/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [169][185/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][186/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][187/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][188/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][189/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][190/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][191/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][192/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][193/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][194/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][195/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][196/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][197/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [169][198/204]	Loss 0.0009 (0.0011)	
training:	Epoch: [169][199/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [169][200/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [169][201/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [169][202/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [169][203/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [169][204/204]	Loss 0.0001 (0.0011)	
Training:	 Loss: 0.0011

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7661 0.7667 0.7799 0.7522
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6259
Pretraining:	Epoch 170/500
----------
training:	Epoch: [170][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [170][2/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][3/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][4/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][5/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][6/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [170][8/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [170][9/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [170][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][11/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][12/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][13/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [170][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][15/204]	Loss 0.0017 (0.0003)	
training:	Epoch: [170][16/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][17/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][18/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][19/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][26/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [170][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][28/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [170][29/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [170][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [170][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [170][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][34/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [170][35/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [170][36/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [170][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [170][43/204]	Loss 0.0108 (0.0004)	
training:	Epoch: [170][44/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][45/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][46/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [170][47/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][48/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][49/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][50/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][51/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][52/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][53/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][54/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [170][55/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][56/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][57/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][58/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][59/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][60/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][61/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][62/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][63/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [170][64/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [170][65/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [170][66/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [170][67/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][68/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][69/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][70/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][71/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][72/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][73/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][74/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][75/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][76/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][77/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][78/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][79/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][80/204]	Loss 0.0024 (0.0003)	
training:	Epoch: [170][81/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][82/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][83/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][84/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [170][85/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [170][86/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][87/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][88/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][89/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][90/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][91/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][92/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][93/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][94/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][95/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][96/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][97/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][98/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [170][99/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [170][100/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][101/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][102/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][103/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][104/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [170][105/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][106/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][107/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][108/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][109/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][110/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][111/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [170][112/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][113/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][114/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][115/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][116/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][117/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][118/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][119/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][120/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][121/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][122/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][123/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][124/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][125/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][126/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][127/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][128/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][129/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [170][130/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][131/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][132/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][133/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][134/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][135/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][136/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][137/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][138/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][139/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][140/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][141/204]	Loss 0.0014 (0.0003)	
training:	Epoch: [170][142/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][143/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][144/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][145/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][146/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][147/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][148/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][149/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][150/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][151/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][152/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][153/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][154/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][155/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][156/204]	Loss 0.0028 (0.0003)	
training:	Epoch: [170][157/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][158/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][159/204]	Loss 0.0014 (0.0003)	
training:	Epoch: [170][160/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [170][161/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][162/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][163/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][164/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][165/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][166/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [170][167/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][168/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][169/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [170][170/204]	Loss 0.1330 (0.0011)	
training:	Epoch: [170][171/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [170][172/204]	Loss 0.0433 (0.0013)	
training:	Epoch: [170][173/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [170][174/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [170][175/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [170][176/204]	Loss 0.0029 (0.0013)	
training:	Epoch: [170][177/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [170][178/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [170][179/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [170][180/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [170][181/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [170][182/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [170][183/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [170][184/204]	Loss 0.0077 (0.0013)	
training:	Epoch: [170][185/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [170][186/204]	Loss 0.0347 (0.0014)	
training:	Epoch: [170][187/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [170][188/204]	Loss 0.0009 (0.0014)	
training:	Epoch: [170][189/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][190/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][191/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [170][192/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [170][193/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][194/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][195/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][196/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][197/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][198/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][199/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][200/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][201/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [170][202/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [170][203/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [170][204/204]	Loss 0.0001 (0.0013)	
Training:	 Loss: 0.0013

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7669 0.7673 0.7738 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6415
Pretraining:	Epoch 171/500
----------
training:	Epoch: [171][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][4/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [171][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][10/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [171][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][12/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [171][13/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [171][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [171][15/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [171][16/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][18/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][19/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [171][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][24/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][26/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [171][27/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [171][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][29/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [171][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][36/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][38/204]	Loss 0.0010 (0.0002)	
training:	Epoch: [171][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][48/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [171][49/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][50/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [171][51/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [171][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][53/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][54/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][58/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][59/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][60/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [171][61/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][66/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][67/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][68/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][69/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][70/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][72/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][73/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][74/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][75/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][76/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][77/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][78/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][79/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][80/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [171][81/204]	Loss 0.0019 (0.0002)	
training:	Epoch: [171][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][84/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [171][85/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][86/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][89/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][92/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][93/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][94/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][95/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][96/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][97/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][98/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][99/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][100/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][101/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][102/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][103/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][104/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][105/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][107/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][108/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][109/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][110/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][111/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [171][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][113/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][114/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][115/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][116/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][118/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][119/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][120/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [171][121/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][122/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][123/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][124/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][125/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][126/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][127/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][128/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][129/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][130/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][131/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][132/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][135/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][137/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][139/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][140/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [171][141/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][142/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][143/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][144/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][145/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][146/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][147/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][148/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][149/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][150/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][153/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [171][154/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][155/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][156/204]	Loss 0.0025 (0.0002)	
training:	Epoch: [171][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][158/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][161/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [171][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][163/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][164/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][165/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][168/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][171/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][172/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][173/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][174/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][175/204]	Loss 0.0034 (0.0002)	
training:	Epoch: [171][176/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][177/204]	Loss 0.0023 (0.0002)	
training:	Epoch: [171][178/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][179/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][181/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [171][182/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][183/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][184/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][186/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][187/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [171][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][189/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][190/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][191/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][192/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][193/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][194/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [171][195/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [171][196/204]	Loss 0.0209 (0.0003)	
training:	Epoch: [171][197/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [171][198/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [171][199/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [171][200/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [171][201/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [171][202/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [171][203/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [171][204/204]	Loss 0.0002 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7676 0.7689 0.7963 0.7388
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6596
Pretraining:	Epoch 172/500
----------
training:	Epoch: [172][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [172][2/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [172][3/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [172][4/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][5/204]	Loss 0.0011 (0.0005)	
training:	Epoch: [172][6/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [172][7/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [172][8/204]	Loss 0.0021 (0.0006)	
training:	Epoch: [172][9/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [172][10/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [172][11/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [172][12/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [172][13/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [172][14/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [172][15/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [172][16/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [172][17/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [172][18/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [172][19/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][20/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [172][21/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][22/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][23/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][24/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][25/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][26/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][27/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][28/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [172][29/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][30/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][31/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][32/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [172][33/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][34/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][35/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][36/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][37/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][38/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][39/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][40/204]	Loss 0.0011 (0.0003)	
training:	Epoch: [172][41/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][42/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][43/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][44/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][45/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][46/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][47/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][49/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][50/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][54/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][55/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][57/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][58/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][59/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][60/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][61/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][66/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][67/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][68/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][69/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][70/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][71/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][72/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][74/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][75/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][76/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [172][77/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][78/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [172][79/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][80/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][81/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][84/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [172][85/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [172][86/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][89/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][92/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][93/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [172][94/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][95/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][96/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [172][97/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][98/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][99/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][100/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][101/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][102/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][103/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][104/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][105/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][107/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][108/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][109/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][110/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [172][111/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][112/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [172][113/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][114/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][115/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][116/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][118/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][119/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][120/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][121/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][122/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][123/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][124/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][125/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][126/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][127/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][128/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][129/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][130/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][131/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][132/204]	Loss 0.0026 (0.0002)	
training:	Epoch: [172][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][135/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][137/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][139/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][140/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][141/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][142/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][143/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][144/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][145/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][146/204]	Loss 0.0077 (0.0003)	
training:	Epoch: [172][147/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][148/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][149/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][150/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][151/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][152/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [172][153/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [172][154/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][155/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][156/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][157/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][158/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][159/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][160/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][161/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][162/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [172][163/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][164/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][165/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][167/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [172][168/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][169/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][171/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][172/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][173/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][174/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][175/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][176/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][177/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][178/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][179/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][180/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][181/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][182/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][183/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][184/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][186/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][187/204]	Loss 0.0012 (0.0002)	
training:	Epoch: [172][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][189/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][190/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][191/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][192/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [172][193/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][194/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][195/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][196/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [172][197/204]	Loss 0.0075 (0.0003)	
training:	Epoch: [172][198/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][199/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][200/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][201/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][202/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [172][203/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [172][204/204]	Loss 0.0001 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7644 0.7662 0.8045 0.7242
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6740
Pretraining:	Epoch 173/500
----------
training:	Epoch: [173][1/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [173][2/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][3/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][4/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][5/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][11/204]	Loss 0.0010 (0.0002)	
training:	Epoch: [173][12/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][15/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][16/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][20/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [173][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][23/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [173][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][25/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [173][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [173][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [173][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][38/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [173][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][45/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [173][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][47/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][54/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [173][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][59/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [173][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][89/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][91/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [173][92/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [173][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][94/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][95/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][97/204]	Loss 0.0008 (0.0001)	
training:	Epoch: [173][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][118/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][129/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [173][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][139/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [173][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][141/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][152/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][153/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][159/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][174/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][176/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][178/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][183/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][190/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][193/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][199/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][200/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][201/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][202/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [173][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [173][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7679 0.7694 0.8004 0.7354
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6761
Pretraining:	Epoch 174/500
----------
training:	Epoch: [174][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][3/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [174][4/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [174][5/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [174][6/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [174][7/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [174][8/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [174][9/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][11/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][12/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][15/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][16/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][21/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [174][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][23/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][24/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [174][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][30/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [174][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [174][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][42/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][50/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][56/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][65/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][68/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [174][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][92/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][108/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [174][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][115/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][116/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [174][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][119/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][138/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][146/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][148/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][155/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][174/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][197/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][200/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [174][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [174][204/204]	Loss 0.0002 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7708 0.7721 0.7994 0.7422
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6765
Pretraining:	Epoch 175/500
----------
training:	Epoch: [175][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][2/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][5/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][9/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [175][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [175][11/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [175][12/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [175][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [175][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [175][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][16/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [175][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [175][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [175][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [175][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][22/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][27/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][36/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][59/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][60/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [175][61/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][66/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][77/204]	Loss 0.0017 (0.0001)	
training:	Epoch: [175][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][81/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][91/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][125/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][134/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][149/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [175][150/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][155/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [175][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][161/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][183/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][185/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][186/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][190/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][193/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [175][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][195/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [175][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [175][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7703 0.7715 0.7973 0.7433
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6824
Pretraining:	Epoch 176/500
----------
training:	Epoch: [176][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][4/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [176][5/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][6/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][8/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][9/204]	Loss 0.0017 (0.0003)	
training:	Epoch: [176][10/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [176][11/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [176][12/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [176][13/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [176][14/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [176][15/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [176][16/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][18/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [176][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [176][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][43/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [176][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][49/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][51/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [176][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [176][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][86/204]	Loss 0.0011 (0.0001)	
training:	Epoch: [176][87/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [176][88/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [176][89/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [176][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][95/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [176][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][130/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [176][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][143/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [176][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][152/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [176][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][192/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [176][193/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [176][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [176][204/204]	Loss 0.0002 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7708 0.7721 0.7994 0.7422
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6925
Pretraining:	Epoch 177/500
----------
training:	Epoch: [177][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][22/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [177][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [177][37/204]	Loss 0.0283 (0.0009)	
training:	Epoch: [177][38/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [177][39/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][40/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [177][41/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][42/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][43/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][44/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [177][45/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][46/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][47/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][48/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][49/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][50/204]	Loss 0.0037 (0.0007)	
training:	Epoch: [177][51/204]	Loss 0.0117 (0.0010)	
training:	Epoch: [177][52/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [177][53/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [177][54/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [177][55/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [177][56/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [177][57/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [177][58/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [177][59/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][60/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][61/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][62/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][63/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][64/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][65/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][66/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][67/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [177][68/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][69/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][70/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][71/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][72/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][73/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][74/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][75/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][76/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][77/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][78/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [177][79/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [177][80/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][81/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][82/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][83/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][84/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][85/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][86/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][87/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][88/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][89/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][90/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][91/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][92/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][93/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][94/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][95/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][96/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [177][97/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][98/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][99/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][100/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][101/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [177][102/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][103/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][104/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][105/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][106/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][107/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][108/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [177][109/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][110/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][111/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][112/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [177][113/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][114/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][115/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][116/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [177][117/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][118/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][119/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][120/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][121/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][122/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][123/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][124/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][125/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [177][126/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][127/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][128/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][129/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][130/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][131/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][132/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][133/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][134/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [177][135/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][136/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][137/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][138/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][139/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][140/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][141/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][142/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [177][143/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][144/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][145/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][146/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][147/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][148/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][149/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][150/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][151/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][152/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][153/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][154/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][155/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][156/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][157/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][158/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][159/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][160/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][161/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][162/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [177][163/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][164/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][165/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][166/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][167/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][168/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][169/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][170/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][171/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][172/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][173/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [177][174/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][175/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][176/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][177/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [177][178/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][179/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][180/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][181/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][182/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][183/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][184/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][185/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][186/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][187/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][188/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][189/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][190/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][191/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][192/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][193/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][194/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][195/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][196/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][197/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][198/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][199/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][200/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [177][201/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][202/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][203/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [177][204/204]	Loss 0.0001 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7711 0.7721 0.7922 0.7500
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7131
Pretraining:	Epoch 178/500
----------
training:	Epoch: [178][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][7/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [178][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][11/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [178][12/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [178][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][14/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [178][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][27/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [178][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][83/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [178][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][85/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [178][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][95/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [178][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][97/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [178][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][127/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [178][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][182/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [178][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [178][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7725 0.7737 0.7994 0.7455
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7210
Pretraining:	Epoch 179/500
----------
training:	Epoch: [179][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][11/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [179][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][14/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [179][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [179][27/204]	Loss 0.0121 (0.0005)	
training:	Epoch: [179][28/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [179][29/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [179][30/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [179][31/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [179][32/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [179][33/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [179][34/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [179][35/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][36/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][37/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][38/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [179][39/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][40/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][41/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][42/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][43/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][44/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][45/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][46/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][47/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][48/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [179][49/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [179][50/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][51/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][52/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][53/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [179][54/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][55/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][56/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][57/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][58/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][59/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [179][60/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][61/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][62/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [179][63/204]	Loss 0.0600 (0.0013)	
training:	Epoch: [179][64/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [179][65/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [179][66/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [179][67/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [179][68/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [179][69/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [179][70/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [179][71/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [179][72/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [179][73/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [179][74/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [179][75/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [179][76/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [179][77/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [179][78/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [179][79/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [179][80/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [179][81/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [179][82/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [179][83/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [179][84/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [179][85/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [179][86/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][87/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][88/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][89/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][90/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][91/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][92/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][93/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [179][94/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][95/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][96/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [179][97/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [179][98/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [179][99/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [179][100/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [179][101/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [179][102/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [179][103/204]	Loss 0.0546 (0.0013)	
training:	Epoch: [179][104/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [179][105/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [179][106/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [179][107/204]	Loss 0.0004 (0.0013)	
training:	Epoch: [179][108/204]	Loss 0.0015 (0.0013)	
training:	Epoch: [179][109/204]	Loss 0.0128 (0.0014)	
training:	Epoch: [179][110/204]	Loss 0.0150 (0.0015)	
training:	Epoch: [179][111/204]	Loss 0.0122 (0.0016)	
training:	Epoch: [179][112/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [179][113/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [179][114/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [179][115/204]	Loss 0.0832 (0.0023)	
training:	Epoch: [179][116/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [179][117/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [179][118/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [179][119/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [179][120/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [179][121/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [179][122/204]	Loss 0.0035 (0.0022)	
training:	Epoch: [179][123/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [179][124/204]	Loss 0.0057 (0.0022)	
training:	Epoch: [179][125/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [179][126/204]	Loss 0.1305 (0.0032)	
training:	Epoch: [179][127/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [179][128/204]	Loss 0.0003 (0.0032)	
training:	Epoch: [179][129/204]	Loss 0.0002 (0.0031)	
training:	Epoch: [179][130/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [179][131/204]	Loss 0.0003 (0.0031)	
training:	Epoch: [179][132/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [179][133/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [179][134/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [179][135/204]	Loss 0.0005 (0.0030)	
training:	Epoch: [179][136/204]	Loss 0.0045 (0.0030)	
training:	Epoch: [179][137/204]	Loss 0.0003 (0.0030)	
training:	Epoch: [179][138/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [179][139/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [179][140/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [179][141/204]	Loss 0.0003 (0.0029)	
training:	Epoch: [179][142/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [179][143/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [179][144/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [179][145/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [179][146/204]	Loss 0.0020 (0.0028)	
training:	Epoch: [179][147/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][148/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [179][149/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][150/204]	Loss 0.0102 (0.0028)	
training:	Epoch: [179][151/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][152/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][153/204]	Loss 0.0005 (0.0028)	
training:	Epoch: [179][154/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [179][155/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [179][156/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [179][157/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [179][158/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [179][159/204]	Loss 0.0022 (0.0027)	
training:	Epoch: [179][160/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [179][161/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [179][162/204]	Loss 0.0084 (0.0027)	
training:	Epoch: [179][163/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [179][164/204]	Loss 0.0057 (0.0027)	
training:	Epoch: [179][165/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [179][166/204]	Loss 0.0308 (0.0029)	
training:	Epoch: [179][167/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][168/204]	Loss 0.0008 (0.0028)	
training:	Epoch: [179][169/204]	Loss 0.0012 (0.0028)	
training:	Epoch: [179][170/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [179][171/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [179][172/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][173/204]	Loss 0.0576 (0.0031)	
training:	Epoch: [179][174/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [179][175/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [179][176/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [179][177/204]	Loss 0.0016 (0.0030)	
training:	Epoch: [179][178/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [179][179/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [179][180/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [179][181/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [179][182/204]	Loss 0.0018 (0.0030)	
training:	Epoch: [179][183/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [179][184/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [179][185/204]	Loss 0.0004 (0.0029)	
training:	Epoch: [179][186/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [179][187/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [179][188/204]	Loss 0.0005 (0.0029)	
training:	Epoch: [179][189/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [179][190/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][191/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][192/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][193/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][194/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [179][195/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [179][196/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][197/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [179][198/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [179][199/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [179][200/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [179][201/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [179][202/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [179][203/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [179][204/204]	Loss 0.0001 (0.0027)	
Training:	 Loss: 0.0027

Training:	 ACC: 0.9990 0.9989 0.9982 0.9997
Validation:	 ACC: 0.7748 0.7747 0.7728 0.7769
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6331
Pretraining:	Epoch 180/500
----------
training:	Epoch: [180][1/204]	Loss 0.0351 (0.0351)	
training:	Epoch: [180][2/204]	Loss 0.0006 (0.0178)	
training:	Epoch: [180][3/204]	Loss 0.0003 (0.0120)	
training:	Epoch: [180][4/204]	Loss 0.0001 (0.0090)	
training:	Epoch: [180][5/204]	Loss 0.0001 (0.0072)	
training:	Epoch: [180][6/204]	Loss 0.0145 (0.0085)	
training:	Epoch: [180][7/204]	Loss 0.0001 (0.0073)	
training:	Epoch: [180][8/204]	Loss 0.0001 (0.0064)	
training:	Epoch: [180][9/204]	Loss 0.0001 (0.0057)	
training:	Epoch: [180][10/204]	Loss 0.0001 (0.0051)	
training:	Epoch: [180][11/204]	Loss 0.0008 (0.0047)	
training:	Epoch: [180][12/204]	Loss 0.0001 (0.0043)	
training:	Epoch: [180][13/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [180][14/204]	Loss 0.0002 (0.0038)	
training:	Epoch: [180][15/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [180][16/204]	Loss 0.0003 (0.0033)	
training:	Epoch: [180][17/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [180][18/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [180][19/204]	Loss 0.0004 (0.0028)	
training:	Epoch: [180][20/204]	Loss 0.0042 (0.0029)	
training:	Epoch: [180][21/204]	Loss 0.0011 (0.0028)	
training:	Epoch: [180][22/204]	Loss 0.2125 (0.0124)	
training:	Epoch: [180][23/204]	Loss 0.0001 (0.0118)	
training:	Epoch: [180][24/204]	Loss 0.0001 (0.0113)	
training:	Epoch: [180][25/204]	Loss 0.0083 (0.0112)	
training:	Epoch: [180][26/204]	Loss 0.0001 (0.0108)	
training:	Epoch: [180][27/204]	Loss 0.0001 (0.0104)	
training:	Epoch: [180][28/204]	Loss 0.0050 (0.0102)	
training:	Epoch: [180][29/204]	Loss 0.0093 (0.0102)	
training:	Epoch: [180][30/204]	Loss 0.0001 (0.0098)	
training:	Epoch: [180][31/204]	Loss 0.0002 (0.0095)	
training:	Epoch: [180][32/204]	Loss 0.0002 (0.0092)	
training:	Epoch: [180][33/204]	Loss 0.0001 (0.0090)	
training:	Epoch: [180][34/204]	Loss 0.0557 (0.0103)	
training:	Epoch: [180][35/204]	Loss 0.0001 (0.0100)	
training:	Epoch: [180][36/204]	Loss 0.0001 (0.0098)	
training:	Epoch: [180][37/204]	Loss 0.0003 (0.0095)	
training:	Epoch: [180][38/204]	Loss 0.0001 (0.0093)	
training:	Epoch: [180][39/204]	Loss 0.0002 (0.0090)	
training:	Epoch: [180][40/204]	Loss 0.0001 (0.0088)	
training:	Epoch: [180][41/204]	Loss 0.0001 (0.0086)	
training:	Epoch: [180][42/204]	Loss 0.0001 (0.0084)	
training:	Epoch: [180][43/204]	Loss 0.0002 (0.0082)	
training:	Epoch: [180][44/204]	Loss 0.0001 (0.0080)	
training:	Epoch: [180][45/204]	Loss 0.0001 (0.0078)	
training:	Epoch: [180][46/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [180][47/204]	Loss 0.0001 (0.0075)	
training:	Epoch: [180][48/204]	Loss 0.0002 (0.0074)	
training:	Epoch: [180][49/204]	Loss 0.0517 (0.0083)	
training:	Epoch: [180][50/204]	Loss 0.0001 (0.0081)	
training:	Epoch: [180][51/204]	Loss 0.0003 (0.0079)	
training:	Epoch: [180][52/204]	Loss 0.0001 (0.0078)	
training:	Epoch: [180][53/204]	Loss 0.0001 (0.0076)	
training:	Epoch: [180][54/204]	Loss 0.0001 (0.0075)	
training:	Epoch: [180][55/204]	Loss 0.0003 (0.0074)	
training:	Epoch: [180][56/204]	Loss 0.0415 (0.0080)	
training:	Epoch: [180][57/204]	Loss 0.0004 (0.0079)	
training:	Epoch: [180][58/204]	Loss 0.0030 (0.0078)	
training:	Epoch: [180][59/204]	Loss 0.0016 (0.0077)	
training:	Epoch: [180][60/204]	Loss 0.0526 (0.0084)	
training:	Epoch: [180][61/204]	Loss 0.0001 (0.0083)	
training:	Epoch: [180][62/204]	Loss 0.0032 (0.0082)	
training:	Epoch: [180][63/204]	Loss 0.0001 (0.0081)	
training:	Epoch: [180][64/204]	Loss 0.0001 (0.0079)	
training:	Epoch: [180][65/204]	Loss 0.0001 (0.0078)	
training:	Epoch: [180][66/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [180][67/204]	Loss 0.1051 (0.0092)	
training:	Epoch: [180][68/204]	Loss 0.0001 (0.0090)	
training:	Epoch: [180][69/204]	Loss 0.0014 (0.0089)	
training:	Epoch: [180][70/204]	Loss 0.0002 (0.0088)	
training:	Epoch: [180][71/204]	Loss 0.0001 (0.0087)	
training:	Epoch: [180][72/204]	Loss 0.0001 (0.0085)	
training:	Epoch: [180][73/204]	Loss 0.0002 (0.0084)	
training:	Epoch: [180][74/204]	Loss 0.0002 (0.0083)	
training:	Epoch: [180][75/204]	Loss 0.0001 (0.0082)	
training:	Epoch: [180][76/204]	Loss 0.0001 (0.0081)	
training:	Epoch: [180][77/204]	Loss 0.0001 (0.0080)	
training:	Epoch: [180][78/204]	Loss 0.0001 (0.0079)	
training:	Epoch: [180][79/204]	Loss 0.0001 (0.0078)	
training:	Epoch: [180][80/204]	Loss 0.0003 (0.0077)	
training:	Epoch: [180][81/204]	Loss 0.0002 (0.0076)	
training:	Epoch: [180][82/204]	Loss 0.0004 (0.0075)	
training:	Epoch: [180][83/204]	Loss 0.0001 (0.0074)	
training:	Epoch: [180][84/204]	Loss 0.0001 (0.0073)	
training:	Epoch: [180][85/204]	Loss 0.0001 (0.0073)	
training:	Epoch: [180][86/204]	Loss 0.0003 (0.0072)	
training:	Epoch: [180][87/204]	Loss 0.0001 (0.0071)	
training:	Epoch: [180][88/204]	Loss 0.0001 (0.0070)	
training:	Epoch: [180][89/204]	Loss 0.0001 (0.0069)	
training:	Epoch: [180][90/204]	Loss 0.0004 (0.0069)	
training:	Epoch: [180][91/204]	Loss 0.0002 (0.0068)	
training:	Epoch: [180][92/204]	Loss 0.0001 (0.0067)	
training:	Epoch: [180][93/204]	Loss 0.0012 (0.0067)	
training:	Epoch: [180][94/204]	Loss 0.0001 (0.0066)	
training:	Epoch: [180][95/204]	Loss 0.0001 (0.0065)	
training:	Epoch: [180][96/204]	Loss 0.0001 (0.0065)	
training:	Epoch: [180][97/204]	Loss 0.0501 (0.0069)	
training:	Epoch: [180][98/204]	Loss 0.0001 (0.0068)	
training:	Epoch: [180][99/204]	Loss 0.0001 (0.0068)	
training:	Epoch: [180][100/204]	Loss 0.0004 (0.0067)	
training:	Epoch: [180][101/204]	Loss 0.0001 (0.0066)	
training:	Epoch: [180][102/204]	Loss 0.0001 (0.0066)	
training:	Epoch: [180][103/204]	Loss 0.0001 (0.0065)	
training:	Epoch: [180][104/204]	Loss 0.0006 (0.0065)	
training:	Epoch: [180][105/204]	Loss 0.2061 (0.0084)	
training:	Epoch: [180][106/204]	Loss 0.0002 (0.0083)	
training:	Epoch: [180][107/204]	Loss 0.1743 (0.0098)	
training:	Epoch: [180][108/204]	Loss 0.0022 (0.0098)	
training:	Epoch: [180][109/204]	Loss 0.0001 (0.0097)	
training:	Epoch: [180][110/204]	Loss 0.0001 (0.0096)	
training:	Epoch: [180][111/204]	Loss 0.0001 (0.0095)	
training:	Epoch: [180][112/204]	Loss 0.0003 (0.0094)	
training:	Epoch: [180][113/204]	Loss 0.0001 (0.0093)	
training:	Epoch: [180][114/204]	Loss 0.0003 (0.0093)	
training:	Epoch: [180][115/204]	Loss 0.0001 (0.0092)	
training:	Epoch: [180][116/204]	Loss 0.0004 (0.0091)	
training:	Epoch: [180][117/204]	Loss 0.0005 (0.0090)	
training:	Epoch: [180][118/204]	Loss 0.0003 (0.0090)	
training:	Epoch: [180][119/204]	Loss 0.0005 (0.0089)	
training:	Epoch: [180][120/204]	Loss 0.0001 (0.0088)	
training:	Epoch: [180][121/204]	Loss 0.0001 (0.0087)	
training:	Epoch: [180][122/204]	Loss 0.0003 (0.0087)	
training:	Epoch: [180][123/204]	Loss 0.0019 (0.0086)	
training:	Epoch: [180][124/204]	Loss 0.0002 (0.0085)	
training:	Epoch: [180][125/204]	Loss 0.0022 (0.0085)	
training:	Epoch: [180][126/204]	Loss 0.0015 (0.0084)	
training:	Epoch: [180][127/204]	Loss 0.0002 (0.0084)	
training:	Epoch: [180][128/204]	Loss 0.0110 (0.0084)	
training:	Epoch: [180][129/204]	Loss 0.0639 (0.0088)	
training:	Epoch: [180][130/204]	Loss 0.0001 (0.0088)	
training:	Epoch: [180][131/204]	Loss 0.0001 (0.0087)	
training:	Epoch: [180][132/204]	Loss 0.0004 (0.0086)	
training:	Epoch: [180][133/204]	Loss 0.0001 (0.0086)	
training:	Epoch: [180][134/204]	Loss 0.0001 (0.0085)	
training:	Epoch: [180][135/204]	Loss 0.0001 (0.0084)	
training:	Epoch: [180][136/204]	Loss 0.0004 (0.0084)	
training:	Epoch: [180][137/204]	Loss 0.0001 (0.0083)	
training:	Epoch: [180][138/204]	Loss 0.0001 (0.0083)	
training:	Epoch: [180][139/204]	Loss 0.0001 (0.0082)	
training:	Epoch: [180][140/204]	Loss 0.0103 (0.0082)	
training:	Epoch: [180][141/204]	Loss 0.0002 (0.0082)	
training:	Epoch: [180][142/204]	Loss 0.0001 (0.0081)	
training:	Epoch: [180][143/204]	Loss 0.0002 (0.0081)	
training:	Epoch: [180][144/204]	Loss 0.0002 (0.0080)	
training:	Epoch: [180][145/204]	Loss 0.0001 (0.0079)	
training:	Epoch: [180][146/204]	Loss 0.0005 (0.0079)	
training:	Epoch: [180][147/204]	Loss 0.1132 (0.0086)	
training:	Epoch: [180][148/204]	Loss 0.0003 (0.0086)	
training:	Epoch: [180][149/204]	Loss 0.0001 (0.0085)	
training:	Epoch: [180][150/204]	Loss 0.0033 (0.0085)	
training:	Epoch: [180][151/204]	Loss 0.0001 (0.0084)	
training:	Epoch: [180][152/204]	Loss 0.0002 (0.0083)	
training:	Epoch: [180][153/204]	Loss 0.0022 (0.0083)	
training:	Epoch: [180][154/204]	Loss 0.0001 (0.0083)	
training:	Epoch: [180][155/204]	Loss 0.0006 (0.0082)	
training:	Epoch: [180][156/204]	Loss 0.0026 (0.0082)	
training:	Epoch: [180][157/204]	Loss 0.0001 (0.0081)	
training:	Epoch: [180][158/204]	Loss 0.0002 (0.0081)	
training:	Epoch: [180][159/204]	Loss 0.0022 (0.0080)	
training:	Epoch: [180][160/204]	Loss 0.0128 (0.0081)	
training:	Epoch: [180][161/204]	Loss 0.0001 (0.0080)	
training:	Epoch: [180][162/204]	Loss 0.0013 (0.0080)	
training:	Epoch: [180][163/204]	Loss 0.0008 (0.0079)	
training:	Epoch: [180][164/204]	Loss 0.0005 (0.0079)	
training:	Epoch: [180][165/204]	Loss 0.0043 (0.0079)	
training:	Epoch: [180][166/204]	Loss 0.0001 (0.0078)	
training:	Epoch: [180][167/204]	Loss 0.0464 (0.0080)	
training:	Epoch: [180][168/204]	Loss 0.0001 (0.0080)	
training:	Epoch: [180][169/204]	Loss 0.0019 (0.0080)	
training:	Epoch: [180][170/204]	Loss 0.0001 (0.0079)	
training:	Epoch: [180][171/204]	Loss 0.0002 (0.0079)	
training:	Epoch: [180][172/204]	Loss 0.0003 (0.0078)	
training:	Epoch: [180][173/204]	Loss 0.0048 (0.0078)	
training:	Epoch: [180][174/204]	Loss 0.0001 (0.0078)	
training:	Epoch: [180][175/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [180][176/204]	Loss 0.0005 (0.0077)	
training:	Epoch: [180][177/204]	Loss 0.0001 (0.0076)	
training:	Epoch: [180][178/204]	Loss 0.0002 (0.0076)	
training:	Epoch: [180][179/204]	Loss 0.0410 (0.0078)	
training:	Epoch: [180][180/204]	Loss 0.1037 (0.0083)	
training:	Epoch: [180][181/204]	Loss 0.0025 (0.0083)	
training:	Epoch: [180][182/204]	Loss 0.0008 (0.0082)	
training:	Epoch: [180][183/204]	Loss 0.0002 (0.0082)	
training:	Epoch: [180][184/204]	Loss 0.0001 (0.0082)	
training:	Epoch: [180][185/204]	Loss 0.0001 (0.0081)	
training:	Epoch: [180][186/204]	Loss 0.0006 (0.0081)	
training:	Epoch: [180][187/204]	Loss 0.0023 (0.0080)	
training:	Epoch: [180][188/204]	Loss 0.0004 (0.0080)	
training:	Epoch: [180][189/204]	Loss 0.0005 (0.0080)	
training:	Epoch: [180][190/204]	Loss 0.0001 (0.0079)	
training:	Epoch: [180][191/204]	Loss 0.0003 (0.0079)	
training:	Epoch: [180][192/204]	Loss 0.0002 (0.0078)	
training:	Epoch: [180][193/204]	Loss 0.0005 (0.0078)	
training:	Epoch: [180][194/204]	Loss 0.0001 (0.0078)	
training:	Epoch: [180][195/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [180][196/204]	Loss 0.0087 (0.0077)	
training:	Epoch: [180][197/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [180][198/204]	Loss 0.0002 (0.0076)	
training:	Epoch: [180][199/204]	Loss 0.0004 (0.0076)	
training:	Epoch: [180][200/204]	Loss 0.0001 (0.0076)	
training:	Epoch: [180][201/204]	Loss 0.0001 (0.0075)	
training:	Epoch: [180][202/204]	Loss 0.0002 (0.0075)	
training:	Epoch: [180][203/204]	Loss 0.0001 (0.0075)	
training:	Epoch: [180][204/204]	Loss 0.0001 (0.0074)	
Training:	 Loss: 0.0074

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7651 0.7662 0.7892 0.7410
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5606
Pretraining:	Epoch 181/500
----------
training:	Epoch: [181][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [181][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [181][3/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [181][4/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [181][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [181][6/204]	Loss 0.0011 (0.0003)	
training:	Epoch: [181][7/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [181][8/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [181][9/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][10/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [181][11/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [181][12/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][13/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [181][14/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][15/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][16/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][17/204]	Loss 0.0016 (0.0003)	
training:	Epoch: [181][18/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][19/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][20/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [181][21/204]	Loss 0.0022 (0.0004)	
training:	Epoch: [181][22/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [181][23/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [181][24/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [181][25/204]	Loss 0.0008 (0.0004)	
training:	Epoch: [181][26/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [181][27/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [181][28/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [181][29/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [181][30/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][31/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][32/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][33/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [181][34/204]	Loss 0.0568 (0.0020)	
training:	Epoch: [181][35/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [181][36/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [181][37/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [181][38/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [181][39/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [181][40/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [181][41/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [181][42/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [181][43/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [181][44/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [181][45/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [181][46/204]	Loss 0.0007 (0.0015)	
training:	Epoch: [181][47/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [181][48/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [181][49/204]	Loss 0.0023 (0.0015)	
training:	Epoch: [181][50/204]	Loss 0.0075 (0.0016)	
training:	Epoch: [181][51/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [181][52/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [181][53/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [181][54/204]	Loss 0.0017 (0.0015)	
training:	Epoch: [181][55/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [181][56/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [181][57/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [181][58/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [181][59/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [181][60/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [181][61/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [181][62/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [181][63/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [181][64/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [181][65/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [181][66/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [181][67/204]	Loss 0.0062 (0.0014)	
training:	Epoch: [181][68/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [181][69/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [181][70/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [181][71/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [181][72/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [181][73/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [181][74/204]	Loss 0.0004 (0.0012)	
training:	Epoch: [181][75/204]	Loss 0.0687 (0.0021)	
training:	Epoch: [181][76/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][77/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [181][78/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [181][79/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [181][80/204]	Loss 0.0917 (0.0032)	
training:	Epoch: [181][81/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [181][82/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [181][83/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [181][84/204]	Loss 0.0002 (0.0030)	
training:	Epoch: [181][85/204]	Loss 0.0013 (0.0030)	
training:	Epoch: [181][86/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [181][87/204]	Loss 0.0002 (0.0029)	
training:	Epoch: [181][88/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [181][89/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [181][90/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [181][91/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [181][92/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [181][93/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [181][94/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [181][95/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [181][96/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [181][97/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [181][98/204]	Loss 0.0152 (0.0028)	
training:	Epoch: [181][99/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [181][100/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [181][101/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [181][102/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [181][103/204]	Loss 0.0005 (0.0027)	
training:	Epoch: [181][104/204]	Loss 0.0003 (0.0026)	
training:	Epoch: [181][105/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [181][106/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [181][107/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [181][108/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [181][109/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [181][110/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [181][111/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [181][112/204]	Loss 0.0013 (0.0025)	
training:	Epoch: [181][113/204]	Loss 0.0004 (0.0024)	
training:	Epoch: [181][114/204]	Loss 0.0167 (0.0026)	
training:	Epoch: [181][115/204]	Loss 0.0020 (0.0026)	
training:	Epoch: [181][116/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [181][117/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [181][118/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [181][119/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [181][120/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [181][121/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [181][122/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [181][123/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][124/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][125/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][126/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][127/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [181][128/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][129/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [181][130/204]	Loss 0.0161 (0.0024)	
training:	Epoch: [181][131/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][132/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [181][133/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][134/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][135/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][136/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][137/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][138/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][139/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][140/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][141/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [181][142/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [181][143/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [181][144/204]	Loss 0.0053 (0.0022)	
training:	Epoch: [181][145/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [181][146/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [181][147/204]	Loss 0.0004 (0.0022)	
training:	Epoch: [181][148/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [181][149/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [181][150/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][151/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][152/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][153/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][154/204]	Loss 0.0007 (0.0021)	
training:	Epoch: [181][155/204]	Loss 0.0663 (0.0025)	
training:	Epoch: [181][156/204]	Loss 0.0004 (0.0025)	
training:	Epoch: [181][157/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [181][158/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [181][159/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [181][160/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][161/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][162/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][163/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [181][164/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][165/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [181][166/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [181][167/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][168/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][169/204]	Loss 0.0017 (0.0023)	
training:	Epoch: [181][170/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][171/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [181][172/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][173/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][174/204]	Loss 0.0027 (0.0023)	
training:	Epoch: [181][175/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [181][176/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [181][177/204]	Loss 0.0065 (0.0023)	
training:	Epoch: [181][178/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [181][179/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [181][180/204]	Loss 0.0003 (0.0022)	
training:	Epoch: [181][181/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [181][182/204]	Loss 0.0018 (0.0022)	
training:	Epoch: [181][183/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [181][184/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [181][185/204]	Loss 0.0017 (0.0022)	
training:	Epoch: [181][186/204]	Loss 0.0026 (0.0022)	
training:	Epoch: [181][187/204]	Loss 0.0018 (0.0022)	
training:	Epoch: [181][188/204]	Loss 0.0011 (0.0022)	
training:	Epoch: [181][189/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [181][190/204]	Loss 0.0036 (0.0022)	
training:	Epoch: [181][191/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [181][192/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [181][193/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [181][194/204]	Loss 0.0006 (0.0022)	
training:	Epoch: [181][195/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][196/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][197/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][198/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][199/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][200/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][201/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [181][202/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [181][203/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [181][204/204]	Loss 0.0023 (0.0021)	
Training:	 Loss: 0.0021

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7693 0.7705 0.7953 0.7433
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5647
Pretraining:	Epoch 182/500
----------
training:	Epoch: [182][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][2/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][3/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][4/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [182][6/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [182][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][8/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][10/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][11/204]	Loss 0.0013 (0.0003)	
training:	Epoch: [182][12/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [182][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][15/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][16/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][18/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][21/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][22/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][23/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][24/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [182][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][26/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][27/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][30/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][32/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][33/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [182][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][35/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][36/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [182][37/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][40/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][42/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][44/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][45/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][49/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][50/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][52/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [182][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][57/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][58/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][59/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][60/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [182][61/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][64/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [182][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][66/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [182][67/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [182][68/204]	Loss 0.0459 (0.0009)	
training:	Epoch: [182][69/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [182][70/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [182][71/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [182][72/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [182][73/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [182][74/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [182][75/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [182][76/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [182][77/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [182][78/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [182][79/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [182][80/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [182][81/204]	Loss 0.0007 (0.0008)	
training:	Epoch: [182][82/204]	Loss 0.0006 (0.0008)	
training:	Epoch: [182][83/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [182][84/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][85/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [182][86/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [182][87/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [182][88/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [182][89/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][90/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [182][91/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [182][92/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [182][93/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][94/204]	Loss 0.0008 (0.0007)	
training:	Epoch: [182][95/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][96/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [182][97/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][98/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [182][99/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][100/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][101/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [182][102/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][103/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][104/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [182][105/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [182][106/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][107/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [182][108/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][109/204]	Loss 0.0016 (0.0006)	
training:	Epoch: [182][110/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][111/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [182][112/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][113/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][114/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][115/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [182][116/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][117/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][118/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][119/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][120/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][121/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][122/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][123/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][124/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][125/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][126/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [182][127/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][128/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [182][129/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [182][130/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][131/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][132/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][133/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][134/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][135/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [182][136/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][137/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][138/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][139/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][140/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][141/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [182][142/204]	Loss 0.0050 (0.0006)	
training:	Epoch: [182][143/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][144/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [182][145/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][146/204]	Loss 0.0016 (0.0006)	
training:	Epoch: [182][147/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][148/204]	Loss 0.0031 (0.0006)	
training:	Epoch: [182][149/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][150/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][151/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [182][152/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][153/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][154/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][155/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][156/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][157/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [182][158/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][159/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][160/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][161/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][162/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][163/204]	Loss 0.0075 (0.0006)	
training:	Epoch: [182][164/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][165/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][166/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][167/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [182][168/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [182][169/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][170/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][171/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [182][172/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][173/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][174/204]	Loss 0.0009 (0.0006)	
training:	Epoch: [182][175/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][176/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][177/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][178/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][179/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][180/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][181/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][182/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][183/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][184/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][185/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][186/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [182][187/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [182][188/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [182][189/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][190/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][191/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [182][192/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][193/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][194/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][195/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [182][196/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][197/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [182][198/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][199/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][200/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [182][201/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [182][202/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][203/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [182][204/204]	Loss 0.0002 (0.0005)	
Training:	 Loss: 0.0005

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7679 0.7689 0.7881 0.7478
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6071
Pretraining:	Epoch 183/500
----------
training:	Epoch: [183][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [183][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [183][3/204]	Loss 0.0271 (0.0091)	
training:	Epoch: [183][4/204]	Loss 0.0002 (0.0069)	
training:	Epoch: [183][5/204]	Loss 0.0001 (0.0055)	
training:	Epoch: [183][6/204]	Loss 0.0001 (0.0046)	
training:	Epoch: [183][7/204]	Loss 0.0004 (0.0040)	
training:	Epoch: [183][8/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [183][9/204]	Loss 0.0263 (0.0061)	
training:	Epoch: [183][10/204]	Loss 0.0010 (0.0056)	
training:	Epoch: [183][11/204]	Loss 0.0002 (0.0051)	
training:	Epoch: [183][12/204]	Loss 0.0001 (0.0047)	
training:	Epoch: [183][13/204]	Loss 0.0002 (0.0043)	
training:	Epoch: [183][14/204]	Loss 0.0027 (0.0042)	
training:	Epoch: [183][15/204]	Loss 0.0001 (0.0039)	
training:	Epoch: [183][16/204]	Loss 0.0001 (0.0037)	
training:	Epoch: [183][17/204]	Loss 0.0002 (0.0035)	
training:	Epoch: [183][18/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [183][19/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [183][20/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [183][21/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [183][22/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [183][23/204]	Loss 0.0066 (0.0029)	
training:	Epoch: [183][24/204]	Loss 0.0002 (0.0028)	
training:	Epoch: [183][25/204]	Loss 0.0003 (0.0027)	
training:	Epoch: [183][26/204]	Loss 0.0026 (0.0027)	
training:	Epoch: [183][27/204]	Loss 0.0002 (0.0026)	
training:	Epoch: [183][28/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [183][29/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [183][30/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [183][31/204]	Loss 0.0002 (0.0023)	
training:	Epoch: [183][32/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [183][33/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [183][34/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [183][35/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [183][36/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [183][37/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [183][38/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [183][39/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [183][40/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [183][41/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [183][42/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [183][43/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [183][44/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [183][45/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [183][46/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [183][47/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [183][48/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [183][49/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [183][50/204]	Loss 0.0004 (0.0015)	
training:	Epoch: [183][51/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [183][52/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [183][53/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [183][54/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [183][55/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [183][56/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [183][57/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [183][58/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [183][59/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [183][60/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [183][61/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [183][62/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [183][63/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [183][64/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [183][65/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [183][66/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [183][67/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [183][68/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [183][69/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [183][70/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [183][71/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [183][72/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [183][73/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [183][74/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [183][75/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [183][76/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [183][77/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [183][78/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [183][79/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [183][80/204]	Loss 0.0005 (0.0010)	
training:	Epoch: [183][81/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [183][82/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [183][83/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [183][84/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][85/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [183][86/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][87/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][88/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [183][89/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][90/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][91/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][92/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][93/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][94/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [183][95/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][96/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [183][97/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][98/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][99/204]	Loss 0.0015 (0.0008)	
training:	Epoch: [183][100/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][101/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][102/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][103/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][104/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][105/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [183][106/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][107/204]	Loss 0.0009 (0.0008)	
training:	Epoch: [183][108/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [183][109/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][110/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][111/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [183][112/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [183][113/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][114/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][115/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [183][116/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [183][117/204]	Loss 0.0009 (0.0007)	
training:	Epoch: [183][118/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][119/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [183][120/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][121/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [183][122/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [183][123/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][124/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][125/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][126/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][127/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][128/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][129/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][130/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][131/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [183][132/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][133/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][134/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][135/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][136/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][137/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [183][138/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [183][139/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [183][140/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [183][141/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [183][142/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][143/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][144/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][145/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][146/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][147/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [183][148/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][149/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][150/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [183][151/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][152/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [183][153/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [183][154/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][155/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [183][156/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][157/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][158/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][159/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][160/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][161/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [183][162/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [183][163/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [183][164/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][165/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][166/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][167/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][168/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][169/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][170/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][171/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][172/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][173/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][174/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][175/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][176/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][177/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][178/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][179/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][180/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][181/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][182/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [183][183/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][184/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [183][185/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][186/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][187/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [183][188/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][189/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][190/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][191/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [183][192/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][193/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][194/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][195/204]	Loss 0.0063 (0.0005)	
training:	Epoch: [183][196/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [183][197/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][198/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [183][199/204]	Loss 0.0067 (0.0006)	
training:	Epoch: [183][200/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][201/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][202/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][203/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [183][204/204]	Loss 0.0003 (0.0006)	
Training:	 Loss: 0.0006

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7724 0.7726 0.7769 0.7679
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6264
Pretraining:	Epoch 184/500
----------
training:	Epoch: [184][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][6/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][11/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [184][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][19/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][29/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][30/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][31/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [184][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][38/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][48/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [184][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][54/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][55/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][63/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [184][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][68/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][69/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [184][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][72/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][78/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][81/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][82/204]	Loss 0.0021 (0.0002)	
training:	Epoch: [184][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][84/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][85/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][86/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][88/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [184][89/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][90/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [184][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][92/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][93/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][94/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][95/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][96/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][97/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][103/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][108/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [184][109/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [184][110/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][111/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][116/204]	Loss 0.0013 (0.0002)	
training:	Epoch: [184][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][118/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][119/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][120/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][121/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][122/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][123/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][124/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][125/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [184][126/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][127/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][128/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][129/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][130/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][131/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][132/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][133/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [184][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][135/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][137/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][138/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [184][139/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][141/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][142/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][143/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [184][144/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][145/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][146/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][147/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][148/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][149/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][150/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][152/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [184][153/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][154/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [184][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][160/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][168/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][176/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][177/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][179/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [184][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][189/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][192/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [184][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][200/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [184][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [184][204/204]	Loss 0.0002 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7720 0.7726 0.7861 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6459
Pretraining:	Epoch 185/500
----------
training:	Epoch: [185][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [185][2/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [185][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [185][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [185][6/204]	Loss 0.0037 (0.0007)	
training:	Epoch: [185][7/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [185][8/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [185][9/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [185][10/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [185][11/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [185][12/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [185][13/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [185][14/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [185][15/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [185][16/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [185][17/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [185][18/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [185][19/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [185][20/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [185][21/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [185][22/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [185][23/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [185][24/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [185][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][31/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][32/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][34/204]	Loss 0.0011 (0.0002)	
training:	Epoch: [185][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][41/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][43/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][46/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][49/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][54/204]	Loss 0.0020 (0.0002)	
training:	Epoch: [185][55/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][57/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][58/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][59/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [185][60/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][61/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][62/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][64/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [185][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][66/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][67/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][68/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][69/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][70/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][71/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][72/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][73/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][74/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][75/204]	Loss 0.0015 (0.0002)	
training:	Epoch: [185][76/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][77/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][78/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][79/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][80/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][81/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][84/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][85/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][86/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][88/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][89/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][90/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][91/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][92/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][93/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][94/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][95/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][96/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][97/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][98/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][99/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][100/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][101/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][102/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][103/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][104/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][105/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][106/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][107/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][108/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][109/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][110/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][111/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][113/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][114/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][115/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][116/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][118/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][119/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][120/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][121/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][122/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][123/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][124/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][125/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][126/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][127/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][128/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][129/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][130/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][131/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][132/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][133/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][135/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][136/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][137/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][139/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][141/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][142/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][143/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][144/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][145/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][146/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][147/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][148/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][149/204]	Loss 0.0010 (0.0002)	
training:	Epoch: [185][150/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][153/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][154/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][155/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][156/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][158/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][161/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][163/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][164/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][165/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][168/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][170/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][171/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][172/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][173/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][174/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][175/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][176/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][177/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][178/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][179/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][181/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][182/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][183/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][184/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][186/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][187/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][188/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][189/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][190/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][191/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][192/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][193/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][194/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][195/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][196/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][197/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][198/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][199/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][200/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [185][201/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][202/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][203/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [185][204/204]	Loss 0.0001 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7705 0.7710 0.7820 0.7590
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6684
Pretraining:	Epoch 186/500
----------
training:	Epoch: [186][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][11/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [186][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][14/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][18/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][22/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [186][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][36/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [186][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][38/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][40/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [186][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][48/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][53/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][82/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][85/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][124/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [186][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][139/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][151/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][156/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [186][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][177/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [186][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][185/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [186][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][189/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [186][203/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [186][204/204]	Loss 0.0003 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7715 0.7721 0.7851 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6818
Pretraining:	Epoch 187/500
----------
training:	Epoch: [187][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][35/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [187][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][48/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][53/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][63/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [187][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][65/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][79/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][83/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [187][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][107/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][127/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][139/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][165/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][169/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][176/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [187][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][180/204]	Loss 0.0008 (0.0001)	
training:	Epoch: [187][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [187][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7705 0.7851 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6929
Pretraining:	Epoch 188/500
----------
training:	Epoch: [188][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][13/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [188][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][42/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [188][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][44/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [188][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][57/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [188][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][98/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [188][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][108/204]	Loss 0.0016 (0.0001)	
training:	Epoch: [188][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][118/204]	Loss 0.0014 (0.0001)	
training:	Epoch: [188][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][134/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [188][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][143/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [188][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][169/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [188][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [188][204/204]	Loss 0.0003 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7693 0.7699 0.7840 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7016
Pretraining:	Epoch 189/500
----------
training:	Epoch: [189][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][56/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [189][57/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [189][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][71/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [189][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][78/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [189][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][91/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [189][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][127/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [189][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][174/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [189][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [189][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7692 0.7699 0.7851 0.7534
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7099
Pretraining:	Epoch 190/500
----------
training:	Epoch: [190][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][46/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [190][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][54/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [190][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][57/204]	Loss 0.0021 (0.0001)	
training:	Epoch: [190][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][75/204]	Loss 0.0008 (0.0001)	
training:	Epoch: [190][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][98/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [190][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][115/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [190][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][140/204]	Loss 0.0021 (0.0001)	
training:	Epoch: [190][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][193/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [190][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][198/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [190][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [190][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7687 0.7694 0.7840 0.7534
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7168
Pretraining:	Epoch 191/500
----------
training:	Epoch: [191][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][11/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [191][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][65/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [191][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][67/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [191][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][98/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [191][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][107/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [191][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][158/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [191][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][194/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [191][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [191][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7687 0.7694 0.7840 0.7534
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7303
Pretraining:	Epoch 192/500
----------
training:	Epoch: [192][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][97/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [192][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][121/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [192][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][183/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [192][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [192][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7687 0.7694 0.7840 0.7534
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7554
Pretraining:	Epoch 193/500
----------
training:	Epoch: [193][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][15/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [193][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][194/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [193][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [193][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7693 0.7699 0.7840 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7519
Pretraining:	Epoch 194/500
----------
training:	Epoch: [194][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][66/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [194][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][93/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [194][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][136/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [194][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][148/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [194][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [194][204/204]	Loss 0.0002 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7693 0.7699 0.7830 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7741
Pretraining:	Epoch 195/500
----------
training:	Epoch: [195][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][34/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [195][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][53/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [195][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][61/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [195][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [195][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7705 0.7840 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7821
Pretraining:	Epoch 196/500
----------
training:	Epoch: [196][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][83/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [196][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][143/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [196][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [196][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7705 0.7840 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7909
Pretraining:	Epoch 197/500
----------
training:	Epoch: [197][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][36/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [197][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][92/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [197][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][184/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [197][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [197][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7705 0.7840 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8027
Pretraining:	Epoch 198/500
----------
training:	Epoch: [198][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][42/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [198][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [198][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [198][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7705 0.7840 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8181
Pretraining:	Epoch 199/500
----------
training:	Epoch: [199][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][63/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [199][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [199][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [199][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [199][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [199][131/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [199][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [199][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [199][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [199][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [199][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7705 0.7840 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8207
Pretraining:	Epoch 200/500
----------
training:	Epoch: [200][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [200][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][50/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [200][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [200][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7705 0.7840 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8366
Pretraining:	Epoch 201/500
----------
training:	Epoch: [201][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [201][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [201][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7705 0.7840 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8429
Pretraining:	Epoch 202/500
----------
training:	Epoch: [202][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][2/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][6/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [202][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [202][12/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [202][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [202][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [202][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [202][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [202][17/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [202][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [202][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [202][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][123/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][154/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][190/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [202][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][201/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [202][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7693 0.7699 0.7830 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8640
Pretraining:	Epoch 203/500
----------
training:	Epoch: [203][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][2/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][10/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][12/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][15/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][24/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][25/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][28/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][30/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][31/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][32/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][35/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][44/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][47/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][49/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][55/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][57/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][61/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][65/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][72/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][76/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][78/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][79/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][80/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][85/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][90/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][91/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][103/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][147/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][149/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][154/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [203][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [203][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [203][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][199/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [203][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [203][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7688 0.7694 0.7820 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8713
Pretraining:	Epoch 204/500
----------
training:	Epoch: [204][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][4/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [204][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][11/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][14/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][16/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][20/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][23/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][34/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][36/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][39/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][46/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][50/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][65/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][70/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][82/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][83/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][87/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][88/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][91/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][97/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][106/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][111/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][124/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][146/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][163/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][168/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][169/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][170/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][172/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][175/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][182/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][185/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][188/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][193/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][195/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [204][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [204][204/204]	Loss 0.0001 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7693 0.7699 0.7840 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8758
Pretraining:	Epoch 205/500
----------
training:	Epoch: [205][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [205][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [205][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][8/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][9/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][19/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][44/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][50/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][54/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][78/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][87/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][95/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][98/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][113/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][124/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][128/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][133/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][145/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][148/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][151/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][155/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][157/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][173/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][179/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][185/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][188/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [205][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [205][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7693 0.7699 0.7840 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8945
Pretraining:	Epoch 206/500
----------
training:	Epoch: [206][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][3/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][10/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][17/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][20/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][24/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][26/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][33/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][35/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][44/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][56/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][62/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][67/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][78/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][103/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][109/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][115/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][136/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][173/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [206][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [206][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7688 0.7694 0.7820 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9167
Pretraining:	Epoch 207/500
----------
training:	Epoch: [207][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][12/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [207][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][66/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [207][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][102/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [207][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][109/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [207][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][119/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [207][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][178/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [207][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][184/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [207][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][196/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [207][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [207][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7693 0.7699 0.7840 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9234
Pretraining:	Epoch 208/500
----------
training:	Epoch: [208][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][22/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [208][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][35/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [208][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][131/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [208][132/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [208][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][166/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [208][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][173/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [208][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][196/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [208][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][199/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [208][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [208][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7682 0.7689 0.7820 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9454
Pretraining:	Epoch 209/500
----------
training:	Epoch: [209][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][27/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [209][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][62/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [209][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][106/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [209][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][126/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [209][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][172/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [209][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [209][204/204]	Loss 0.0001 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7687 0.7694 0.7830 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9553
Pretraining:	Epoch 210/500
----------
training:	Epoch: [210][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][2/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [210][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][37/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [210][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][49/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [210][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][91/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [210][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][99/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [210][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][112/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [210][113/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [210][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [210][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7687 0.7694 0.7830 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9713
Pretraining:	Epoch 211/500
----------
training:	Epoch: [211][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][22/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [211][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][83/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [211][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][97/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [211][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][124/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [211][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][179/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [211][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [211][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7687 0.7694 0.7830 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9849
Pretraining:	Epoch 212/500
----------
training:	Epoch: [212][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [212][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7687 0.7694 0.7830 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 2.0002
Pretraining:	Epoch 213/500
----------
training:	Epoch: [213][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][59/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [213][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [213][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7693 0.7699 0.7840 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 2.0110
Pretraining:	Epoch 214/500
----------
training:	Epoch: [214][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [214][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7698 0.7705 0.7851 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 2.0357
Pretraining:	Epoch 215/500
----------
training:	Epoch: [215][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [215][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7687 0.7694 0.7830 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 2.0467
Pretraining:	Epoch 216/500
----------
training:	Epoch: [216][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][122/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [216][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][177/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [216][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [216][182/204]	Loss 0.0094 (0.0001)	
training:	Epoch: [216][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [216][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [216][185/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [216][186/204]	Loss 0.1013 (0.0006)	
training:	Epoch: [216][187/204]	Loss 0.0196 (0.0007)	
training:	Epoch: [216][188/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [216][189/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [216][190/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [216][191/204]	Loss 0.0055 (0.0007)	
training:	Epoch: [216][192/204]	Loss 0.0935 (0.0012)	
training:	Epoch: [216][193/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [216][194/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [216][195/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [216][196/204]	Loss 0.0616 (0.0015)	
training:	Epoch: [216][197/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [216][198/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [216][199/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [216][200/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [216][201/204]	Loss 0.0005 (0.0015)	
training:	Epoch: [216][202/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [216][203/204]	Loss 0.0135 (0.0015)	
training:	Epoch: [216][204/204]	Loss 0.0231 (0.0016)	
Training:	 Loss: 0.0016

Training:	 ACC: 0.9728 0.9717 0.9456 1.0000
Validation:	 ACC: 0.7659 0.7624 0.6899 0.8419
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 2.0871
Pretraining:	Epoch 217/500
----------
training:	Epoch: [217][1/204]	Loss 0.5566 (0.5566)	
training:	Epoch: [217][2/204]	Loss 0.0000 (0.2783)	
training:	Epoch: [217][3/204]	Loss 0.0132 (0.1899)	
training:	Epoch: [217][4/204]	Loss 0.0004 (0.1425)	
training:	Epoch: [217][5/204]	Loss 0.1252 (0.1391)	
training:	Epoch: [217][6/204]	Loss 0.0000 (0.1159)	
training:	Epoch: [217][7/204]	Loss 0.0267 (0.1032)	
training:	Epoch: [217][8/204]	Loss 0.0028 (0.0906)	
training:	Epoch: [217][9/204]	Loss 0.0001 (0.0806)	
training:	Epoch: [217][10/204]	Loss 0.0001 (0.0725)	
training:	Epoch: [217][11/204]	Loss 0.0001 (0.0659)	
training:	Epoch: [217][12/204]	Loss 0.0003 (0.0605)	
training:	Epoch: [217][13/204]	Loss 0.2876 (0.0779)	
training:	Epoch: [217][14/204]	Loss 0.0281 (0.0744)	
training:	Epoch: [217][15/204]	Loss 0.0001 (0.0694)	
training:	Epoch: [217][16/204]	Loss 0.0001 (0.0651)	
training:	Epoch: [217][17/204]	Loss 0.0000 (0.0613)	
training:	Epoch: [217][18/204]	Loss 0.0258 (0.0593)	
training:	Epoch: [217][19/204]	Loss 0.0001 (0.0562)	
training:	Epoch: [217][20/204]	Loss 0.0146 (0.0541)	
training:	Epoch: [217][21/204]	Loss 0.0017 (0.0516)	
training:	Epoch: [217][22/204]	Loss 0.0001 (0.0493)	
training:	Epoch: [217][23/204]	Loss 0.0014 (0.0472)	
training:	Epoch: [217][24/204]	Loss 0.1933 (0.0533)	
training:	Epoch: [217][25/204]	Loss 0.0063 (0.0514)	
training:	Epoch: [217][26/204]	Loss 0.0012 (0.0495)	
training:	Epoch: [217][27/204]	Loss 0.0015 (0.0477)	
training:	Epoch: [217][28/204]	Loss 0.0000 (0.0460)	
training:	Epoch: [217][29/204]	Loss 0.0000 (0.0444)	
training:	Epoch: [217][30/204]	Loss 0.0001 (0.0429)	
training:	Epoch: [217][31/204]	Loss 0.0450 (0.0430)	
training:	Epoch: [217][32/204]	Loss 0.0334 (0.0427)	
training:	Epoch: [217][33/204]	Loss 0.0000 (0.0414)	
training:	Epoch: [217][34/204]	Loss 0.0001 (0.0402)	
training:	Epoch: [217][35/204]	Loss 0.0001 (0.0390)	
training:	Epoch: [217][36/204]	Loss 0.1453 (0.0420)	
training:	Epoch: [217][37/204]	Loss 0.0000 (0.0409)	
training:	Epoch: [217][38/204]	Loss 0.0000 (0.0398)	
training:	Epoch: [217][39/204]	Loss 0.1975 (0.0438)	
training:	Epoch: [217][40/204]	Loss 0.0883 (0.0449)	
training:	Epoch: [217][41/204]	Loss 0.0003 (0.0439)	
training:	Epoch: [217][42/204]	Loss 0.0005 (0.0428)	
training:	Epoch: [217][43/204]	Loss 0.3713 (0.0505)	
training:	Epoch: [217][44/204]	Loss 0.0000 (0.0493)	
training:	Epoch: [217][45/204]	Loss 0.0000 (0.0482)	
training:	Epoch: [217][46/204]	Loss 0.0001 (0.0472)	
training:	Epoch: [217][47/204]	Loss 0.0170 (0.0465)	
training:	Epoch: [217][48/204]	Loss 0.0010 (0.0456)	
training:	Epoch: [217][49/204]	Loss 0.0002 (0.0447)	
training:	Epoch: [217][50/204]	Loss 0.0132 (0.0440)	
training:	Epoch: [217][51/204]	Loss 0.0163 (0.0435)	
training:	Epoch: [217][52/204]	Loss 0.0016 (0.0427)	
training:	Epoch: [217][53/204]	Loss 0.0629 (0.0431)	
training:	Epoch: [217][54/204]	Loss 0.0005 (0.0423)	
training:	Epoch: [217][55/204]	Loss 0.0296 (0.0420)	
training:	Epoch: [217][56/204]	Loss 0.0001 (0.0413)	
training:	Epoch: [217][57/204]	Loss 0.0001 (0.0406)	
training:	Epoch: [217][58/204]	Loss 0.0000 (0.0399)	
training:	Epoch: [217][59/204]	Loss 0.0001 (0.0392)	
training:	Epoch: [217][60/204]	Loss 0.0001 (0.0385)	
training:	Epoch: [217][61/204]	Loss 0.0020 (0.0379)	
training:	Epoch: [217][62/204]	Loss 0.0001 (0.0373)	
training:	Epoch: [217][63/204]	Loss 0.1039 (0.0384)	
training:	Epoch: [217][64/204]	Loss 0.0000 (0.0378)	
training:	Epoch: [217][65/204]	Loss 0.0013 (0.0372)	
training:	Epoch: [217][66/204]	Loss 0.0001 (0.0367)	
training:	Epoch: [217][67/204]	Loss 0.0002 (0.0361)	
training:	Epoch: [217][68/204]	Loss 0.1180 (0.0373)	
training:	Epoch: [217][69/204]	Loss 0.0002 (0.0368)	
training:	Epoch: [217][70/204]	Loss 0.0001 (0.0363)	
training:	Epoch: [217][71/204]	Loss 0.0496 (0.0365)	
training:	Epoch: [217][72/204]	Loss 0.0001 (0.0359)	
training:	Epoch: [217][73/204]	Loss 0.0684 (0.0364)	
training:	Epoch: [217][74/204]	Loss 0.1227 (0.0376)	
training:	Epoch: [217][75/204]	Loss 0.3159 (0.0413)	
training:	Epoch: [217][76/204]	Loss 0.0000 (0.0407)	
training:	Epoch: [217][77/204]	Loss 0.0000 (0.0402)	
training:	Epoch: [217][78/204]	Loss 0.0001 (0.0397)	
training:	Epoch: [217][79/204]	Loss 0.0007 (0.0392)	
training:	Epoch: [217][80/204]	Loss 0.0001 (0.0387)	
training:	Epoch: [217][81/204]	Loss 0.0001 (0.0382)	
training:	Epoch: [217][82/204]	Loss 0.0000 (0.0378)	
training:	Epoch: [217][83/204]	Loss 0.0003 (0.0373)	
training:	Epoch: [217][84/204]	Loss 0.0238 (0.0371)	
training:	Epoch: [217][85/204]	Loss 0.0002 (0.0367)	
training:	Epoch: [217][86/204]	Loss 0.0364 (0.0367)	
training:	Epoch: [217][87/204]	Loss 0.0007 (0.0363)	
training:	Epoch: [217][88/204]	Loss 0.0225 (0.0361)	
training:	Epoch: [217][89/204]	Loss 0.0001 (0.0357)	
training:	Epoch: [217][90/204]	Loss 0.0001 (0.0353)	
training:	Epoch: [217][91/204]	Loss 0.0201 (0.0352)	
training:	Epoch: [217][92/204]	Loss 0.0001 (0.0348)	
training:	Epoch: [217][93/204]	Loss 0.0526 (0.0350)	
training:	Epoch: [217][94/204]	Loss 0.0009 (0.0346)	
training:	Epoch: [217][95/204]	Loss 0.0003 (0.0343)	
training:	Epoch: [217][96/204]	Loss 0.0000 (0.0339)	
training:	Epoch: [217][97/204]	Loss 0.0001 (0.0336)	
training:	Epoch: [217][98/204]	Loss 0.1322 (0.0346)	
training:	Epoch: [217][99/204]	Loss 0.0006 (0.0342)	
training:	Epoch: [217][100/204]	Loss 0.1049 (0.0349)	
training:	Epoch: [217][101/204]	Loss 0.0005 (0.0346)	
training:	Epoch: [217][102/204]	Loss 0.0133 (0.0344)	
training:	Epoch: [217][103/204]	Loss 0.0003 (0.0340)	
training:	Epoch: [217][104/204]	Loss 0.0009 (0.0337)	
training:	Epoch: [217][105/204]	Loss 0.0001 (0.0334)	
training:	Epoch: [217][106/204]	Loss 0.0001 (0.0331)	
training:	Epoch: [217][107/204]	Loss 0.0013 (0.0328)	
training:	Epoch: [217][108/204]	Loss 0.0288 (0.0328)	
training:	Epoch: [217][109/204]	Loss 0.0007 (0.0325)	
training:	Epoch: [217][110/204]	Loss 0.0188 (0.0323)	
training:	Epoch: [217][111/204]	Loss 0.0005 (0.0320)	
training:	Epoch: [217][112/204]	Loss 0.0060 (0.0318)	
training:	Epoch: [217][113/204]	Loss 0.0001 (0.0315)	
training:	Epoch: [217][114/204]	Loss 0.0049 (0.0313)	
training:	Epoch: [217][115/204]	Loss 0.0001 (0.0310)	
training:	Epoch: [217][116/204]	Loss 0.0009 (0.0308)	
training:	Epoch: [217][117/204]	Loss 0.0064 (0.0306)	
training:	Epoch: [217][118/204]	Loss 0.0002 (0.0303)	
training:	Epoch: [217][119/204]	Loss 0.0001 (0.0301)	
training:	Epoch: [217][120/204]	Loss 0.0001 (0.0298)	
training:	Epoch: [217][121/204]	Loss 0.0014 (0.0296)	
training:	Epoch: [217][122/204]	Loss 0.0048 (0.0294)	
training:	Epoch: [217][123/204]	Loss 0.0037 (0.0292)	
training:	Epoch: [217][124/204]	Loss 0.0003 (0.0289)	
training:	Epoch: [217][125/204]	Loss 0.0195 (0.0288)	
training:	Epoch: [217][126/204]	Loss 0.0001 (0.0286)	
training:	Epoch: [217][127/204]	Loss 0.0001 (0.0284)	
training:	Epoch: [217][128/204]	Loss 0.0001 (0.0282)	
training:	Epoch: [217][129/204]	Loss 0.0261 (0.0282)	
training:	Epoch: [217][130/204]	Loss 0.0002 (0.0279)	
training:	Epoch: [217][131/204]	Loss 0.0001 (0.0277)	
training:	Epoch: [217][132/204]	Loss 0.0004 (0.0275)	
training:	Epoch: [217][133/204]	Loss 0.0000 (0.0273)	
training:	Epoch: [217][134/204]	Loss 0.0001 (0.0271)	
training:	Epoch: [217][135/204]	Loss 0.0004 (0.0269)	
training:	Epoch: [217][136/204]	Loss 0.0035 (0.0267)	
training:	Epoch: [217][137/204]	Loss 0.0196 (0.0267)	
training:	Epoch: [217][138/204]	Loss 0.0005 (0.0265)	
training:	Epoch: [217][139/204]	Loss 0.0009 (0.0263)	
training:	Epoch: [217][140/204]	Loss 0.0001 (0.0261)	
training:	Epoch: [217][141/204]	Loss 0.0003 (0.0259)	
training:	Epoch: [217][142/204]	Loss 0.0002 (0.0258)	
training:	Epoch: [217][143/204]	Loss 0.0013 (0.0256)	
training:	Epoch: [217][144/204]	Loss 0.0013 (0.0254)	
training:	Epoch: [217][145/204]	Loss 0.0215 (0.0254)	
training:	Epoch: [217][146/204]	Loss 0.0000 (0.0252)	
training:	Epoch: [217][147/204]	Loss 0.0001 (0.0251)	
training:	Epoch: [217][148/204]	Loss 0.0001 (0.0249)	
training:	Epoch: [217][149/204]	Loss 0.0000 (0.0247)	
training:	Epoch: [217][150/204]	Loss 0.0002 (0.0246)	
training:	Epoch: [217][151/204]	Loss 0.0008 (0.0244)	
training:	Epoch: [217][152/204]	Loss 0.0015 (0.0242)	
training:	Epoch: [217][153/204]	Loss 0.0004 (0.0241)	
training:	Epoch: [217][154/204]	Loss 0.0037 (0.0240)	
training:	Epoch: [217][155/204]	Loss 0.0001 (0.0238)	
training:	Epoch: [217][156/204]	Loss 0.0003 (0.0237)	
training:	Epoch: [217][157/204]	Loss 0.0004 (0.0235)	
training:	Epoch: [217][158/204]	Loss 0.0000 (0.0234)	
training:	Epoch: [217][159/204]	Loss 0.0001 (0.0232)	
training:	Epoch: [217][160/204]	Loss 0.0006 (0.0231)	
training:	Epoch: [217][161/204]	Loss 0.0005 (0.0229)	
training:	Epoch: [217][162/204]	Loss 0.0001 (0.0228)	
training:	Epoch: [217][163/204]	Loss 0.0001 (0.0226)	
training:	Epoch: [217][164/204]	Loss 0.0002 (0.0225)	
training:	Epoch: [217][165/204]	Loss 0.0011 (0.0224)	
training:	Epoch: [217][166/204]	Loss 0.0017 (0.0223)	
training:	Epoch: [217][167/204]	Loss 0.0001 (0.0221)	
training:	Epoch: [217][168/204]	Loss 0.0002 (0.0220)	
training:	Epoch: [217][169/204]	Loss 0.0388 (0.0221)	
training:	Epoch: [217][170/204]	Loss 0.0002 (0.0220)	
training:	Epoch: [217][171/204]	Loss 0.0155 (0.0219)	
training:	Epoch: [217][172/204]	Loss 0.0006 (0.0218)	
training:	Epoch: [217][173/204]	Loss 0.0000 (0.0217)	
training:	Epoch: [217][174/204]	Loss 0.0001 (0.0216)	
training:	Epoch: [217][175/204]	Loss 0.0005 (0.0214)	
training:	Epoch: [217][176/204]	Loss 0.0001 (0.0213)	
training:	Epoch: [217][177/204]	Loss 0.0001 (0.0212)	
training:	Epoch: [217][178/204]	Loss 0.0002 (0.0211)	
training:	Epoch: [217][179/204]	Loss 0.0027 (0.0210)	
training:	Epoch: [217][180/204]	Loss 0.0001 (0.0209)	
training:	Epoch: [217][181/204]	Loss 0.0001 (0.0207)	
training:	Epoch: [217][182/204]	Loss 0.0009 (0.0206)	
training:	Epoch: [217][183/204]	Loss 0.0014 (0.0205)	
training:	Epoch: [217][184/204]	Loss 0.0000 (0.0204)	
training:	Epoch: [217][185/204]	Loss 0.0002 (0.0203)	
training:	Epoch: [217][186/204]	Loss 0.0001 (0.0202)	
training:	Epoch: [217][187/204]	Loss 0.0003 (0.0201)	
training:	Epoch: [217][188/204]	Loss 0.0001 (0.0200)	
training:	Epoch: [217][189/204]	Loss 0.0001 (0.0199)	
training:	Epoch: [217][190/204]	Loss 0.0123 (0.0198)	
training:	Epoch: [217][191/204]	Loss 0.0001 (0.0197)	
training:	Epoch: [217][192/204]	Loss 0.0011 (0.0196)	
training:	Epoch: [217][193/204]	Loss 0.0038 (0.0196)	
training:	Epoch: [217][194/204]	Loss 0.0001 (0.0195)	
training:	Epoch: [217][195/204]	Loss 0.0001 (0.0194)	
training:	Epoch: [217][196/204]	Loss 0.0001 (0.0193)	
training:	Epoch: [217][197/204]	Loss 0.0003 (0.0192)	
training:	Epoch: [217][198/204]	Loss 0.0001 (0.0191)	
training:	Epoch: [217][199/204]	Loss 0.0002 (0.0190)	
training:	Epoch: [217][200/204]	Loss 0.0000 (0.0189)	
training:	Epoch: [217][201/204]	Loss 0.0014 (0.0188)	
training:	Epoch: [217][202/204]	Loss 0.0003 (0.0187)	
training:	Epoch: [217][203/204]	Loss 0.0010 (0.0186)	
training:	Epoch: [217][204/204]	Loss 0.0000 (0.0185)	
Training:	 Loss: 0.0185

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7756 0.7758 0.7799 0.7713
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5296
Pretraining:	Epoch 218/500
----------
training:	Epoch: [218][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [218][2/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [218][3/204]	Loss 0.0011 (0.0005)	
training:	Epoch: [218][4/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [218][5/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][6/204]	Loss 0.0028 (0.0007)	
training:	Epoch: [218][7/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][8/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][9/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][10/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][11/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [218][12/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [218][13/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [218][14/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [218][15/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [218][16/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [218][17/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [218][18/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [218][19/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [218][20/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [218][21/204]	Loss 0.0007 (0.0004)	
training:	Epoch: [218][22/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [218][23/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [218][24/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [218][25/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [218][26/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][27/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][28/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][29/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][30/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][31/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][32/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [218][33/204]	Loss 0.0014 (0.0003)	
training:	Epoch: [218][34/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [218][35/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][36/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][37/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][38/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][39/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][40/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][41/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [218][42/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [218][43/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][44/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [218][45/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][46/204]	Loss 0.0040 (0.0004)	
training:	Epoch: [218][47/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [218][48/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][49/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][50/204]	Loss 0.0006 (0.0003)	
training:	Epoch: [218][51/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][52/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][53/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [218][54/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [218][55/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [218][56/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [218][57/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [218][58/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [218][59/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][60/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [218][61/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [218][62/204]	Loss 0.0163 (0.0006)	
training:	Epoch: [218][63/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][64/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][65/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][66/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [218][67/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [218][68/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][69/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][70/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][71/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][72/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [218][73/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][74/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [218][75/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][76/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][77/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][78/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][79/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][80/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][81/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][82/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [218][83/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][84/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][85/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][86/204]	Loss 0.0049 (0.0005)	
training:	Epoch: [218][87/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][88/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][89/204]	Loss 0.0150 (0.0007)	
training:	Epoch: [218][90/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [218][91/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][92/204]	Loss 0.0072 (0.0007)	
training:	Epoch: [218][93/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][94/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][95/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][96/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][97/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [218][98/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][99/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][100/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [218][101/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][102/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][103/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [218][104/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][105/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [218][106/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][107/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][108/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [218][109/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][110/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][111/204]	Loss 0.0008 (0.0006)	
training:	Epoch: [218][112/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][113/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [218][114/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [218][115/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][116/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][117/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][118/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][119/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][120/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [218][121/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][122/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][123/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [218][124/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][125/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [218][126/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [218][127/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [218][128/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [218][129/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][130/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][131/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][132/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][133/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][134/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][135/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [218][136/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [218][137/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][138/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [218][139/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][140/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][141/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][142/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][143/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][144/204]	Loss 0.0014 (0.0005)	
training:	Epoch: [218][145/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [218][146/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [218][147/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][148/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][149/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][150/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [218][151/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][152/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [218][153/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][154/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][155/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][156/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][157/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][158/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][159/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][160/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][161/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][162/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][163/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][164/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [218][165/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][166/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][167/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [218][168/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][169/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][170/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][171/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [218][172/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][173/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][174/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][175/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][176/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][177/204]	Loss 0.0020 (0.0005)	
training:	Epoch: [218][178/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][179/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][180/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][181/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [218][182/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [218][183/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [218][184/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [218][185/204]	Loss 0.0126 (0.0005)	
training:	Epoch: [218][186/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][187/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][188/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][189/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][190/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][191/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [218][192/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][193/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][194/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [218][195/204]	Loss 0.0261 (0.0006)	
training:	Epoch: [218][196/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][197/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][198/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][199/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][200/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [218][201/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [218][202/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [218][203/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [218][204/204]	Loss 0.0011 (0.0006)	
Training:	 Loss: 0.0006

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7772 0.7785 0.8055 0.7489
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.5923
Pretraining:	Epoch 219/500
----------
training:	Epoch: [219][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [219][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [219][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [219][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [219][5/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [219][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [219][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [219][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [219][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [219][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [219][11/204]	Loss 0.0266 (0.0025)	
training:	Epoch: [219][12/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [219][13/204]	Loss 0.0010 (0.0022)	
training:	Epoch: [219][14/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [219][15/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [219][16/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [219][17/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [219][18/204]	Loss 0.0005 (0.0016)	
training:	Epoch: [219][19/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [219][20/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [219][21/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [219][22/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [219][23/204]	Loss 0.0010 (0.0013)	
training:	Epoch: [219][24/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [219][25/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [219][26/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [219][27/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [219][28/204]	Loss 0.0010 (0.0012)	
training:	Epoch: [219][29/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [219][30/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [219][31/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [219][32/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [219][33/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [219][34/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [219][35/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [219][36/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [219][37/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [219][38/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [219][39/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [219][40/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [219][41/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [219][42/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [219][43/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [219][44/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [219][45/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [219][46/204]	Loss 0.0019 (0.0008)	
training:	Epoch: [219][47/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [219][48/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [219][49/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][50/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][51/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][52/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][53/204]	Loss 0.0015 (0.0007)	
training:	Epoch: [219][54/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][55/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][56/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][57/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][58/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][59/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [219][60/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][61/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [219][62/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [219][63/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][64/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][65/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][66/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][67/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [219][68/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][69/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][70/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [219][71/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][72/204]	Loss 0.0014 (0.0006)	
training:	Epoch: [219][73/204]	Loss 0.0013 (0.0006)	
training:	Epoch: [219][74/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][75/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][76/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][77/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][78/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][79/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][80/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][81/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [219][82/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][83/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][84/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][85/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][86/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][87/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [219][88/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][89/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][90/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][91/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][92/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][93/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][94/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][95/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][96/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][97/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [219][98/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][99/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][100/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][101/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][102/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][103/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][104/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [219][105/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][106/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [219][107/204]	Loss 0.0060 (0.0005)	
training:	Epoch: [219][108/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][109/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][110/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][111/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][112/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][113/204]	Loss 0.0268 (0.0007)	
training:	Epoch: [219][114/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][115/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [219][116/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][117/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][118/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][119/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][120/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][121/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][122/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][123/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [219][124/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][125/204]	Loss 0.0103 (0.0007)	
training:	Epoch: [219][126/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][127/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][128/204]	Loss 0.0024 (0.0007)	
training:	Epoch: [219][129/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [219][130/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][131/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][132/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][133/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][134/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][135/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][136/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][137/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [219][138/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][139/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][140/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][141/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][142/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][143/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][144/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [219][145/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][146/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][147/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [219][148/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [219][149/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [219][150/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [219][151/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][152/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][153/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][154/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][155/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][156/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][157/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][158/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][159/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][160/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][161/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][162/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [219][163/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][164/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][165/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][166/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][167/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][168/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][169/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][170/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [219][171/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][172/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][173/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [219][174/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][175/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [219][176/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][177/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][178/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][179/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][180/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][181/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][182/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][183/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][184/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][185/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][186/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][187/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][188/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][189/204]	Loss 0.0046 (0.0006)	
training:	Epoch: [219][190/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][191/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][192/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][193/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][194/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][195/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [219][196/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [219][197/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [219][198/204]	Loss 0.0076 (0.0006)	
training:	Epoch: [219][199/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][200/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][201/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][202/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [219][203/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [219][204/204]	Loss 0.0001 (0.0006)	
Training:	 Loss: 0.0006

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7759 0.7774 0.8086 0.7433
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6445
Pretraining:	Epoch 220/500
----------
training:	Epoch: [220][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [220][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [220][3/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [220][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][5/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [220][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [220][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][8/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][9/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [220][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][13/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [220][14/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][21/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [220][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][28/204]	Loss 0.0016 (0.0002)	
training:	Epoch: [220][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][37/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [220][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][45/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [220][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [220][47/204]	Loss 0.0233 (0.0006)	
training:	Epoch: [220][48/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [220][49/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [220][50/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [220][51/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [220][52/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [220][53/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [220][54/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [220][55/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [220][56/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [220][57/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [220][58/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [220][59/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [220][60/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [220][61/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [220][62/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [220][63/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [220][64/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [220][65/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [220][66/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [220][67/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [220][68/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][69/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [220][70/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][71/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][72/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][73/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][74/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][75/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][76/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][77/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][78/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][79/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][80/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][81/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [220][82/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][83/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][84/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][85/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][86/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][87/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][88/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][89/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][90/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [220][91/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][92/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][93/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [220][94/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][95/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [220][96/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][97/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][98/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][99/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][100/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][101/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][102/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][103/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][104/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][105/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][106/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][107/204]	Loss 0.0039 (0.0004)	
training:	Epoch: [220][108/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][109/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [220][110/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [220][111/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [220][112/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][113/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][114/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][115/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][116/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][117/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][118/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][119/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][120/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][121/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][122/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][123/204]	Loss 0.0030 (0.0003)	
training:	Epoch: [220][124/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][125/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][126/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][127/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][128/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][129/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][130/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][131/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][132/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][133/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][134/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][135/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][136/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][137/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][138/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][139/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][140/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][141/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][142/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][143/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][144/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][145/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][146/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][147/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][148/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][149/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [220][150/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][151/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][152/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][153/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][154/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][155/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [220][156/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][157/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][158/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][159/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][160/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][161/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][162/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][163/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][164/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][165/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][166/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][167/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][168/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][169/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][170/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][171/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][172/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][173/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][174/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][175/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][176/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][177/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][178/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][179/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][180/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [220][181/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][182/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][183/204]	Loss 0.0010 (0.0003)	
training:	Epoch: [220][184/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][185/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][186/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [220][187/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][188/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [220][189/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][190/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][191/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [220][192/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][193/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [220][194/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [220][195/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [220][196/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [220][197/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [220][198/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [220][199/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [220][200/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [220][201/204]	Loss 0.0008 (0.0003)	
training:	Epoch: [220][202/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [220][203/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [220][204/204]	Loss 0.0001 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7756 0.7764 0.7922 0.7590
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6617
Pretraining:	Epoch 221/500
----------
training:	Epoch: [221][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][6/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][8/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][12/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][14/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [221][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][17/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][51/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][55/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][58/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][64/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][86/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][98/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [221][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][105/204]	Loss 0.0028 (0.0001)	
training:	Epoch: [221][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][110/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [221][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][127/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][128/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][130/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][135/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [221][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][139/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][144/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [221][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][151/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [221][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][157/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [221][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][171/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][180/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][188/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [221][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][190/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [221][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [221][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [221][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7754 0.7764 0.7973 0.7534
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6796
Pretraining:	Epoch 222/500
----------
training:	Epoch: [222][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][4/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [222][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][6/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][9/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][12/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][13/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][15/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][16/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][17/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][23/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [222][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][50/204]	Loss 0.0036 (0.0001)	
training:	Epoch: [222][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][58/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [222][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][60/204]	Loss 0.0011 (0.0001)	
training:	Epoch: [222][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][70/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [222][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][78/204]	Loss 0.0013 (0.0001)	
training:	Epoch: [222][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][82/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][121/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [222][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][123/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [222][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][149/204]	Loss 0.0016 (0.0001)	
training:	Epoch: [222][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][170/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][171/204]	Loss 0.0008 (0.0001)	
training:	Epoch: [222][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][176/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [222][203/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [222][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7748 0.7753 0.7861 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6985
Pretraining:	Epoch 223/500
----------
training:	Epoch: [223][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [223][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [223][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [223][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [223][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [223][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [223][7/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [223][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [223][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [223][10/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [223][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [223][12/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [223][13/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][23/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [223][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][27/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][40/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][47/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][65/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][85/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [223][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][104/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [223][105/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [223][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][117/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [223][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][145/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][148/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][153/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [223][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][172/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][173/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][178/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][189/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [223][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][196/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [223][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [223][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7727 0.7737 0.7932 0.7522
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7125
Pretraining:	Epoch 224/500
----------
training:	Epoch: [224][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][7/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][12/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][28/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][34/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][37/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][44/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][48/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [224][49/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [224][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][55/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][56/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][70/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][73/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][78/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [224][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][82/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][83/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][88/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][93/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [224][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][100/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][103/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][105/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [224][116/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [224][117/204]	Loss 0.0139 (0.0002)	
training:	Epoch: [224][118/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][119/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][120/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][121/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][122/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][123/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][124/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [224][125/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][126/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][127/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][128/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][129/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][130/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][131/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][132/204]	Loss 0.0014 (0.0002)	
training:	Epoch: [224][133/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][134/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][135/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][136/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [224][137/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][138/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][139/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [224][140/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][141/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][142/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][143/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][144/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [224][145/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][146/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][147/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][148/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [224][149/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [224][150/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][152/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [224][153/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][154/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][155/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][156/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][157/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [224][158/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][159/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][160/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][161/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][162/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [224][163/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][164/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][165/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][166/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][167/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][168/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][169/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][170/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][171/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][172/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][173/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][174/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [224][175/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][176/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][177/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][178/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][179/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [224][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [224][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [224][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [224][189/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [224][190/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [224][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [224][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [224][198/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [224][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [224][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [224][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [224][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7758 0.7753 0.7636 0.7881
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7387
Pretraining:	Epoch 225/500
----------
training:	Epoch: [225][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [225][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [225][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [225][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [225][6/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [225][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [225][8/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [225][9/204]	Loss 0.0014 (0.0002)	
training:	Epoch: [225][10/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [225][11/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [225][12/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [225][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [225][14/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][15/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][17/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][20/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][23/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][28/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [225][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][39/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [225][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][49/204]	Loss 0.0017 (0.0001)	
training:	Epoch: [225][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][75/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [225][76/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [225][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][84/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [225][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][87/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [225][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [225][89/204]	Loss 0.0359 (0.0005)	
training:	Epoch: [225][90/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [225][91/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [225][92/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [225][93/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [225][94/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [225][95/204]	Loss 0.0020 (0.0005)	
training:	Epoch: [225][96/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [225][97/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [225][98/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [225][99/204]	Loss 0.0300 (0.0008)	
training:	Epoch: [225][100/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [225][101/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [225][102/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [225][103/204]	Loss 0.0017 (0.0008)	
training:	Epoch: [225][104/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [225][105/204]	Loss 0.0256 (0.0010)	
training:	Epoch: [225][106/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][107/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][108/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][109/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][110/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][111/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][112/204]	Loss 0.0011 (0.0009)	
training:	Epoch: [225][113/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][114/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][115/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][116/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [225][117/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][118/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][119/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][120/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][121/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][122/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][123/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][124/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][125/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][126/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [225][127/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [225][128/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [225][129/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [225][130/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [225][131/204]	Loss 0.0368 (0.0011)	
training:	Epoch: [225][132/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [225][133/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [225][134/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [225][135/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [225][136/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [225][137/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [225][138/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][139/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][140/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][141/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][142/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][143/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [225][144/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][145/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][146/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][147/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][148/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][149/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [225][150/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][151/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [225][152/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][153/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][154/204]	Loss 0.0032 (0.0010)	
training:	Epoch: [225][155/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [225][156/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][157/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][158/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [225][159/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][160/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][161/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][162/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][163/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][164/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][165/204]	Loss 0.0012 (0.0009)	
training:	Epoch: [225][166/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][167/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [225][168/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][169/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][170/204]	Loss 0.0225 (0.0010)	
training:	Epoch: [225][171/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][172/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][173/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][174/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [225][175/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][176/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][177/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][178/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][179/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][180/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][181/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][182/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][183/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][184/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [225][185/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [225][186/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][187/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][188/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][189/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][190/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][191/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][192/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][193/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][194/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][195/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][196/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][197/204]	Loss 0.0082 (0.0009)	
training:	Epoch: [225][198/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [225][199/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][200/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][201/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [225][202/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [225][203/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [225][204/204]	Loss 0.0000 (0.0009)	
Training:	 Loss: 0.0009

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7752 0.7753 0.7779 0.7724
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7610
Pretraining:	Epoch 226/500
----------
training:	Epoch: [226][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [226][2/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [226][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [226][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [226][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [226][6/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [226][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [226][8/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [226][9/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [226][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [226][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [226][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [226][13/204]	Loss 0.1122 (0.0087)	
training:	Epoch: [226][14/204]	Loss 0.0011 (0.0081)	
training:	Epoch: [226][15/204]	Loss 0.0000 (0.0076)	
training:	Epoch: [226][16/204]	Loss 0.0000 (0.0071)	
training:	Epoch: [226][17/204]	Loss 0.0000 (0.0067)	
training:	Epoch: [226][18/204]	Loss 0.0000 (0.0063)	
training:	Epoch: [226][19/204]	Loss 0.0000 (0.0060)	
training:	Epoch: [226][20/204]	Loss 0.0000 (0.0057)	
training:	Epoch: [226][21/204]	Loss 0.0002 (0.0054)	
training:	Epoch: [226][22/204]	Loss 0.0000 (0.0052)	
training:	Epoch: [226][23/204]	Loss 0.0001 (0.0050)	
training:	Epoch: [226][24/204]	Loss 0.0001 (0.0048)	
training:	Epoch: [226][25/204]	Loss 0.0000 (0.0046)	
training:	Epoch: [226][26/204]	Loss 0.0001 (0.0044)	
training:	Epoch: [226][27/204]	Loss 0.0000 (0.0042)	
training:	Epoch: [226][28/204]	Loss 0.0001 (0.0041)	
training:	Epoch: [226][29/204]	Loss 0.0000 (0.0040)	
training:	Epoch: [226][30/204]	Loss 0.0000 (0.0038)	
training:	Epoch: [226][31/204]	Loss 0.0000 (0.0037)	
training:	Epoch: [226][32/204]	Loss 0.0002 (0.0036)	
training:	Epoch: [226][33/204]	Loss 0.0002 (0.0035)	
training:	Epoch: [226][34/204]	Loss 0.0000 (0.0034)	
training:	Epoch: [226][35/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [226][36/204]	Loss 0.0000 (0.0032)	
training:	Epoch: [226][37/204]	Loss 0.0000 (0.0031)	
training:	Epoch: [226][38/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [226][39/204]	Loss 0.0000 (0.0030)	
training:	Epoch: [226][40/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [226][41/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [226][42/204]	Loss 0.0000 (0.0027)	
training:	Epoch: [226][43/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [226][44/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [226][45/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [226][46/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [226][47/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [226][48/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [226][49/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [226][50/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [226][51/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [226][52/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [226][53/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [226][54/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [226][55/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [226][56/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [226][57/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [226][58/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [226][59/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [226][60/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [226][61/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [226][62/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [226][63/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [226][64/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [226][65/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [226][66/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [226][67/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [226][68/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [226][69/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [226][70/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [226][71/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [226][72/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [226][73/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [226][74/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [226][75/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [226][76/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [226][77/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [226][78/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [226][79/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [226][80/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [226][81/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [226][82/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [226][83/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [226][84/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [226][85/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [226][86/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [226][87/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [226][88/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [226][89/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [226][90/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [226][91/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [226][92/204]	Loss 0.0009 (0.0013)	
training:	Epoch: [226][93/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [226][94/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [226][95/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [226][96/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [226][97/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [226][98/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [226][99/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [226][100/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [226][101/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [226][102/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [226][103/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [226][104/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [226][105/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][106/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][107/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][108/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][109/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [226][110/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][111/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [226][112/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [226][113/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [226][114/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][115/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [226][116/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][117/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][118/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][119/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][120/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][121/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][122/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][123/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][124/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][125/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][126/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][127/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][128/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][129/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][130/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][131/204]	Loss 0.0227 (0.0011)	
training:	Epoch: [226][132/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][133/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][134/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][135/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [226][136/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [226][137/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [226][138/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][139/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][140/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [226][141/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][142/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][143/204]	Loss 0.0003 (0.0010)	
training:	Epoch: [226][144/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [226][145/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][146/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][147/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][148/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][149/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][150/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [226][151/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][152/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][153/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [226][154/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][155/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][156/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [226][157/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][158/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][159/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][160/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][161/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][162/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][163/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][164/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][165/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][166/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][167/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][168/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [226][169/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][170/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][171/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][172/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [226][173/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][174/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [226][175/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][176/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][177/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][178/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][179/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][180/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][181/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][182/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][183/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][184/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][185/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][186/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][187/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][188/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][189/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [226][190/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [226][191/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][192/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][193/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [226][194/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][195/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][196/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [226][197/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [226][198/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [226][199/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [226][200/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [226][201/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [226][202/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [226][203/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [226][204/204]	Loss 0.0000 (0.0007)	
Training:	 Loss: 0.0007

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7683 0.7694 0.7922 0.7444
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7945
Pretraining:	Epoch 227/500
----------
training:	Epoch: [227][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][2/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [227][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][9/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [227][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][11/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [227][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][32/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [227][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][34/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [227][35/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [227][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][50/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [227][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][56/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [227][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][59/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [227][60/204]	Loss 0.0009 (0.0001)	
training:	Epoch: [227][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][63/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][68/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][88/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][92/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [227][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [227][125/204]	Loss 0.0011 (0.0001)	
training:	Epoch: [227][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][156/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][177/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [227][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [227][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [227][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7672 0.7683 0.7922 0.7422
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8092
Pretraining:	Epoch 228/500
----------
training:	Epoch: [228][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][19/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [228][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][23/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [228][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][46/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][50/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][57/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][68/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][92/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][97/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][100/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][101/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][111/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][113/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][125/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][147/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][151/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][153/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [228][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][155/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][160/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][165/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][168/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [228][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][173/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][189/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][190/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][195/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][197/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][201/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [228][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [228][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7678 0.7689 0.7902 0.7455
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8149
Pretraining:	Epoch 229/500
----------
training:	Epoch: [229][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][6/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][8/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][15/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][20/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][25/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][31/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][46/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][54/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][57/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][88/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][102/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][117/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][127/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][128/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][148/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [229][149/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][156/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][157/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][170/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][181/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][182/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][183/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][192/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][199/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [229][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [229][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7673 0.7683 0.7892 0.7455
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8289
Pretraining:	Epoch 230/500
----------
training:	Epoch: [230][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][10/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [230][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [230][13/204]	Loss 0.0032 (0.0003)	
training:	Epoch: [230][14/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [230][15/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][16/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][17/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][18/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][19/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][20/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][21/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [230][22/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][23/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][24/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][25/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][26/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][27/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [230][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][31/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [230][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][34/204]	Loss 0.0054 (0.0003)	
training:	Epoch: [230][35/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [230][36/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [230][37/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [230][38/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [230][39/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [230][40/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [230][41/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][42/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][43/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][44/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][45/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][46/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][47/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][48/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][49/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [230][50/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][51/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][52/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][53/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][54/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][55/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][56/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][57/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][58/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][59/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][60/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][61/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][62/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][63/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][64/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][65/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][66/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][67/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][68/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][69/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][70/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][71/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][72/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][73/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][74/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [230][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [230][80/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [230][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][86/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [230][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][109/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [230][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [230][134/204]	Loss 0.0664 (0.0006)	
training:	Epoch: [230][135/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][136/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][137/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [230][138/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][139/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][140/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [230][141/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][142/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][143/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][144/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][145/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [230][146/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][147/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][148/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][149/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][150/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [230][151/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][152/204]	Loss 0.0099 (0.0006)	
training:	Epoch: [230][153/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [230][154/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [230][155/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][156/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][157/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [230][158/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][159/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][160/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][161/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][162/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][163/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][164/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][165/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [230][166/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][167/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [230][168/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [230][169/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][170/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][171/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][172/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][173/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][174/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][175/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][176/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][177/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][178/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][179/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][180/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [230][181/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][182/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [230][183/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][184/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][185/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][186/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][187/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [230][188/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][189/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][190/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][191/204]	Loss 0.0104 (0.0005)	
training:	Epoch: [230][192/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][193/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [230][194/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][195/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][196/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][197/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][198/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [230][199/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][200/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][201/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [230][202/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [230][203/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [230][204/204]	Loss 0.0001 (0.0005)	
Training:	 Loss: 0.0005

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7672 0.7651 0.7216 0.8128
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8702
Pretraining:	Epoch 231/500
----------
training:	Epoch: [231][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [231][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [231][3/204]	Loss 0.0020 (0.0007)	
training:	Epoch: [231][4/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [231][5/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][6/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [231][7/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][8/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [231][9/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][10/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][11/204]	Loss 0.0195 (0.0021)	
training:	Epoch: [231][12/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [231][13/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [231][14/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [231][15/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [231][16/204]	Loss 0.0004 (0.0014)	
training:	Epoch: [231][17/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [231][18/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [231][19/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [231][20/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [231][21/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [231][22/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [231][23/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [231][24/204]	Loss 0.0007 (0.0010)	
training:	Epoch: [231][25/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [231][26/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [231][27/204]	Loss 0.0097 (0.0013)	
training:	Epoch: [231][28/204]	Loss 0.0006 (0.0012)	
training:	Epoch: [231][29/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [231][30/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [231][31/204]	Loss 0.0055 (0.0013)	
training:	Epoch: [231][32/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [231][33/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [231][34/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [231][35/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [231][36/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [231][37/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [231][38/204]	Loss 0.0007 (0.0011)	
training:	Epoch: [231][39/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [231][40/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [231][41/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [231][42/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [231][43/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [231][44/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [231][45/204]	Loss 0.0005 (0.0009)	
training:	Epoch: [231][46/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [231][47/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [231][48/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [231][49/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [231][50/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [231][51/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [231][52/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [231][53/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [231][54/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [231][55/204]	Loss 0.0004 (0.0008)	
training:	Epoch: [231][56/204]	Loss 0.0002 (0.0008)	
training:	Epoch: [231][57/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [231][58/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [231][59/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [231][60/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [231][61/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [231][62/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [231][63/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [231][64/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [231][65/204]	Loss 0.0006 (0.0007)	
training:	Epoch: [231][66/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [231][67/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][68/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][69/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][70/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][71/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][72/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][73/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][74/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][75/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][76/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][77/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][78/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][79/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [231][80/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [231][81/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][82/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][83/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [231][84/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][85/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][86/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][87/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [231][88/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][89/204]	Loss 0.0009 (0.0005)	
training:	Epoch: [231][90/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [231][91/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][92/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][93/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][94/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][95/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][96/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][97/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][98/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][99/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][100/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [231][101/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][102/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][103/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][104/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [231][105/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][106/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][107/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][108/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [231][109/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][110/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][111/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][112/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][113/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][114/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][115/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][116/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [231][117/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][118/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][119/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][120/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][121/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][122/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][123/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][124/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][125/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][126/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][127/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][128/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][129/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][130/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][131/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [231][132/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][133/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][134/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][135/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][136/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][137/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][138/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [231][139/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [231][140/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][141/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][142/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][143/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [231][144/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [231][145/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][146/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][147/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][148/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][149/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][150/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][151/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][152/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][153/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [231][154/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][155/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][156/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][157/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][158/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][159/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][160/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][161/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [231][162/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][163/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][164/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][165/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [231][166/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][167/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][168/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][169/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][170/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [231][171/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][172/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [231][173/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][174/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][175/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [231][176/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][177/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][178/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][179/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][180/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][181/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][182/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][183/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][184/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [231][185/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][186/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][187/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][188/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][189/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][190/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][191/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][192/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][193/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][194/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][195/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][196/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][197/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][198/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][199/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][200/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][201/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][202/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][203/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [231][204/204]	Loss 0.0000 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7681 0.7689 0.7851 0.7511
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8868
Pretraining:	Epoch 232/500
----------
training:	Epoch: [232][1/204]	Loss 0.0037 (0.0037)	
training:	Epoch: [232][2/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [232][3/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [232][4/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [232][5/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [232][6/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [232][7/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [232][8/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [232][9/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [232][10/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [232][11/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [232][12/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [232][13/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [232][14/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [232][15/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [232][16/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [232][17/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [232][18/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [232][19/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [232][20/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [232][21/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][22/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [232][23/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][24/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][25/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][26/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][27/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][28/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [232][29/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][30/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][31/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][32/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][33/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][34/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][35/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][36/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][39/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [232][40/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [232][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][54/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [232][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][63/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [232][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][68/204]	Loss 0.0022 (0.0001)	
training:	Epoch: [232][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][74/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][88/204]	Loss 0.0011 (0.0001)	
training:	Epoch: [232][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][108/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [232][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][139/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [232][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][162/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [232][163/204]	Loss 0.0009 (0.0001)	
training:	Epoch: [232][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][166/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [232][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][175/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [232][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [232][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [232][203/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [232][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7678 0.7683 0.7799 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9199
Pretraining:	Epoch 233/500
----------
training:	Epoch: [233][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [233][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][4/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [233][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [233][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][11/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [233][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][13/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [233][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][47/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [233][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][49/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [233][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][98/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [233][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][108/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [233][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][111/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [233][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][128/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [233][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [233][147/204]	Loss 0.0161 (0.0001)	
training:	Epoch: [233][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][155/204]	Loss 0.0011 (0.0001)	
training:	Epoch: [233][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][159/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [233][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [233][164/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [233][165/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [233][166/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [233][167/204]	Loss 0.0019 (0.0002)	
training:	Epoch: [233][168/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [233][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [233][170/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][171/204]	Loss 0.0061 (0.0002)	
training:	Epoch: [233][172/204]	Loss 0.0009 (0.0002)	
training:	Epoch: [233][173/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][174/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [233][175/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][176/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [233][177/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][178/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][179/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][180/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][181/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][182/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][183/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][184/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][185/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][186/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][187/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][188/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][189/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][190/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][191/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][192/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][193/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][194/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][195/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][196/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][197/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][198/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][199/204]	Loss 0.0077 (0.0002)	
training:	Epoch: [233][200/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][201/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][202/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][203/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [233][204/204]	Loss 0.0000 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7658 0.7667 0.7861 0.7455
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9543
Pretraining:	Epoch 234/500
----------
training:	Epoch: [234][1/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [234][2/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [234][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][6/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][9/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][12/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][13/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][15/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [234][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [234][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [234][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [234][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [234][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [234][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [234][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [234][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [234][25/204]	Loss 0.0026 (0.0001)	
training:	Epoch: [234][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][33/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [234][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][41/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [234][42/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][67/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][70/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [234][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][81/204]	Loss 0.0015 (0.0001)	
training:	Epoch: [234][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][135/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [234][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][158/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [234][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [234][162/204]	Loss 0.2299 (0.0015)	
training:	Epoch: [234][163/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [234][164/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [234][165/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [234][166/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][167/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][168/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [234][169/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][170/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][171/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][172/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][173/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][174/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][175/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][176/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][177/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][178/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [234][179/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][180/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][181/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][182/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][183/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][184/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][185/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][186/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][187/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][188/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [234][189/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][190/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][191/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][192/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [234][193/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][194/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][195/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][196/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][197/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][198/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][199/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][200/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][201/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][202/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][203/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [234][204/204]	Loss 0.0000 (0.0012)	
Training:	 Loss: 0.0012

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7695 0.7710 0.8035 0.7354
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9778
Pretraining:	Epoch 235/500
----------
training:	Epoch: [235][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][10/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [235][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][26/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [235][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][29/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [235][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][35/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [235][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][37/204]	Loss 0.0005 (0.0000)	
training:	Epoch: [235][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][46/204]	Loss 0.0015 (0.0001)	
training:	Epoch: [235][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][62/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [235][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][64/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [235][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [235][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [235][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [235][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [235][120/204]	Loss 0.0259 (0.0003)	
training:	Epoch: [235][121/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [235][122/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [235][123/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [235][124/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [235][125/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [235][126/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [235][127/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [235][128/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [235][129/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][130/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][131/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][132/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [235][133/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][134/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][135/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][136/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][137/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][138/204]	Loss 0.0016 (0.0002)	
training:	Epoch: [235][139/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][140/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][141/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][142/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][143/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][144/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][145/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][146/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][147/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][148/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][149/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][150/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][151/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][152/204]	Loss 0.0013 (0.0002)	
training:	Epoch: [235][153/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][154/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][155/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][156/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][157/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [235][158/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][159/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][160/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][161/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][162/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][163/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][164/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][165/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][166/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][167/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [235][168/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][169/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [235][170/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][171/204]	Loss 0.0042 (0.0002)	
training:	Epoch: [235][172/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][173/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][174/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][175/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][176/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][177/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][178/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][179/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [235][181/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [235][182/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][183/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][184/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [235][185/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][186/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][187/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][188/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][189/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][190/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][191/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][192/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][193/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [235][194/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][195/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][196/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][197/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][198/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][199/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][200/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][201/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][202/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][203/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [235][204/204]	Loss 0.0003 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 0.9998 0.9998 1.0000 0.9997
Validation:	 ACC: 0.7714 0.7737 0.8219 0.7209
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 2.0172
Pretraining:	Epoch 236/500
----------
training:	Epoch: [236][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [236][11/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [236][12/204]	Loss 0.0024 (0.0002)	
training:	Epoch: [236][13/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][14/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][15/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][16/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][17/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][18/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][19/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][20/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][22/204]	Loss 0.0026 (0.0003)	
training:	Epoch: [236][23/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [236][24/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][25/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][26/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][27/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][28/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][29/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][30/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][31/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][32/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][33/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][34/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][35/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][36/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][37/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][38/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][39/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][40/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [236][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [236][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][61/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [236][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][63/204]	Loss 0.0012 (0.0001)	
training:	Epoch: [236][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [236][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][91/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [236][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [236][152/204]	Loss 0.1048 (0.0008)	
training:	Epoch: [236][153/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [236][154/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][155/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][156/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][157/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][158/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][159/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][160/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][161/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [236][162/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][163/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][164/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][165/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [236][166/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][167/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][168/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][169/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][170/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][171/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [236][172/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [236][173/204]	Loss 0.0464 (0.0009)	
training:	Epoch: [236][174/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [236][175/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][176/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [236][177/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][178/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][179/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][180/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][181/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][182/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][183/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][184/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][185/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][186/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [236][187/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][188/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][189/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][190/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][191/204]	Loss 0.0004 (0.0009)	
training:	Epoch: [236][192/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][193/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [236][194/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [236][195/204]	Loss 0.0280 (0.0010)	
training:	Epoch: [236][196/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [236][197/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [236][198/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [236][199/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [236][200/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [236][201/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [236][202/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [236][203/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [236][204/204]	Loss 0.0000 (0.0009)	
Training:	 Loss: 0.0009

Training:	 ACC: 0.9967 0.9968 1.0000 0.9933
Validation:	 ACC: 0.7635 0.7678 0.8588 0.6682
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 2.0610
Pretraining:	Epoch 237/500
----------
training:	Epoch: [237][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [237][2/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [237][3/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [237][4/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [237][5/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [237][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [237][7/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [237][8/204]	Loss 0.0988 (0.0125)	
training:	Epoch: [237][9/204]	Loss 0.0147 (0.0127)	
training:	Epoch: [237][10/204]	Loss 0.0000 (0.0115)	
training:	Epoch: [237][11/204]	Loss 0.0000 (0.0104)	
training:	Epoch: [237][12/204]	Loss 0.0000 (0.0096)	
training:	Epoch: [237][13/204]	Loss 0.0036 (0.0091)	
training:	Epoch: [237][14/204]	Loss 0.0001 (0.0085)	
training:	Epoch: [237][15/204]	Loss 0.1403 (0.0172)	
training:	Epoch: [237][16/204]	Loss 0.0000 (0.0162)	
training:	Epoch: [237][17/204]	Loss 0.0430 (0.0177)	
training:	Epoch: [237][18/204]	Loss 0.0001 (0.0168)	
training:	Epoch: [237][19/204]	Loss 0.0020 (0.0160)	
training:	Epoch: [237][20/204]	Loss 0.0019 (0.0153)	
training:	Epoch: [237][21/204]	Loss 0.0000 (0.0146)	
training:	Epoch: [237][22/204]	Loss 0.0000 (0.0139)	
training:	Epoch: [237][23/204]	Loss 0.0001 (0.0133)	
training:	Epoch: [237][24/204]	Loss 0.0001 (0.0127)	
training:	Epoch: [237][25/204]	Loss 0.0002 (0.0122)	
training:	Epoch: [237][26/204]	Loss 0.2514 (0.0214)	
training:	Epoch: [237][27/204]	Loss 0.0039 (0.0208)	
training:	Epoch: [237][28/204]	Loss 0.0002 (0.0201)	
training:	Epoch: [237][29/204]	Loss 0.0001 (0.0194)	
training:	Epoch: [237][30/204]	Loss 0.0001 (0.0187)	
training:	Epoch: [237][31/204]	Loss 0.0000 (0.0181)	
training:	Epoch: [237][32/204]	Loss 0.0022 (0.0176)	
training:	Epoch: [237][33/204]	Loss 0.0012 (0.0171)	
training:	Epoch: [237][34/204]	Loss 0.0002 (0.0166)	
training:	Epoch: [237][35/204]	Loss 0.0009 (0.0162)	
training:	Epoch: [237][36/204]	Loss 0.0000 (0.0157)	
training:	Epoch: [237][37/204]	Loss 0.0060 (0.0155)	
training:	Epoch: [237][38/204]	Loss 0.0001 (0.0151)	
training:	Epoch: [237][39/204]	Loss 0.0000 (0.0147)	
training:	Epoch: [237][40/204]	Loss 0.0005 (0.0143)	
training:	Epoch: [237][41/204]	Loss 0.0000 (0.0140)	
training:	Epoch: [237][42/204]	Loss 0.0000 (0.0136)	
training:	Epoch: [237][43/204]	Loss 0.0000 (0.0133)	
training:	Epoch: [237][44/204]	Loss 0.0235 (0.0136)	
training:	Epoch: [237][45/204]	Loss 0.0069 (0.0134)	
training:	Epoch: [237][46/204]	Loss 0.0009 (0.0131)	
training:	Epoch: [237][47/204]	Loss 0.0004 (0.0129)	
training:	Epoch: [237][48/204]	Loss 0.0002 (0.0126)	
training:	Epoch: [237][49/204]	Loss 0.0008 (0.0124)	
training:	Epoch: [237][50/204]	Loss 0.0000 (0.0121)	
training:	Epoch: [237][51/204]	Loss 0.0001 (0.0119)	
training:	Epoch: [237][52/204]	Loss 0.0000 (0.0116)	
training:	Epoch: [237][53/204]	Loss 0.0002 (0.0114)	
training:	Epoch: [237][54/204]	Loss 0.2059 (0.0150)	
training:	Epoch: [237][55/204]	Loss 0.0001 (0.0148)	
training:	Epoch: [237][56/204]	Loss 0.0000 (0.0145)	
training:	Epoch: [237][57/204]	Loss 0.0003 (0.0143)	
training:	Epoch: [237][58/204]	Loss 0.0000 (0.0140)	
training:	Epoch: [237][59/204]	Loss 0.1450 (0.0162)	
training:	Epoch: [237][60/204]	Loss 0.0002 (0.0160)	
training:	Epoch: [237][61/204]	Loss 0.0001 (0.0157)	
training:	Epoch: [237][62/204]	Loss 0.0000 (0.0154)	
training:	Epoch: [237][63/204]	Loss 0.0000 (0.0152)	
training:	Epoch: [237][64/204]	Loss 0.0002 (0.0150)	
training:	Epoch: [237][65/204]	Loss 0.0000 (0.0147)	
training:	Epoch: [237][66/204]	Loss 0.0000 (0.0145)	
training:	Epoch: [237][67/204]	Loss 0.0001 (0.0143)	
training:	Epoch: [237][68/204]	Loss 0.1411 (0.0162)	
training:	Epoch: [237][69/204]	Loss 0.0697 (0.0169)	
training:	Epoch: [237][70/204]	Loss 0.0000 (0.0167)	
training:	Epoch: [237][71/204]	Loss 0.0000 (0.0165)	
training:	Epoch: [237][72/204]	Loss 0.0000 (0.0162)	
training:	Epoch: [237][73/204]	Loss 0.0066 (0.0161)	
training:	Epoch: [237][74/204]	Loss 0.0000 (0.0159)	
training:	Epoch: [237][75/204]	Loss 0.1373 (0.0175)	
training:	Epoch: [237][76/204]	Loss 0.0069 (0.0174)	
training:	Epoch: [237][77/204]	Loss 0.0000 (0.0171)	
training:	Epoch: [237][78/204]	Loss 0.0001 (0.0169)	
training:	Epoch: [237][79/204]	Loss 0.0001 (0.0167)	
training:	Epoch: [237][80/204]	Loss 0.0089 (0.0166)	
training:	Epoch: [237][81/204]	Loss 0.0015 (0.0164)	
training:	Epoch: [237][82/204]	Loss 0.0022 (0.0162)	
training:	Epoch: [237][83/204]	Loss 0.0000 (0.0161)	
training:	Epoch: [237][84/204]	Loss 0.0017 (0.0159)	
training:	Epoch: [237][85/204]	Loss 0.0000 (0.0157)	
training:	Epoch: [237][86/204]	Loss 0.0000 (0.0155)	
training:	Epoch: [237][87/204]	Loss 0.0001 (0.0153)	
training:	Epoch: [237][88/204]	Loss 0.0000 (0.0152)	
training:	Epoch: [237][89/204]	Loss 0.0002 (0.0150)	
training:	Epoch: [237][90/204]	Loss 0.0005 (0.0148)	
training:	Epoch: [237][91/204]	Loss 0.0001 (0.0147)	
training:	Epoch: [237][92/204]	Loss 0.0002 (0.0145)	
training:	Epoch: [237][93/204]	Loss 0.0000 (0.0144)	
training:	Epoch: [237][94/204]	Loss 0.0192 (0.0144)	
training:	Epoch: [237][95/204]	Loss 0.0001 (0.0143)	
training:	Epoch: [237][96/204]	Loss 0.0000 (0.0141)	
training:	Epoch: [237][97/204]	Loss 0.0000 (0.0140)	
training:	Epoch: [237][98/204]	Loss 0.0098 (0.0139)	
training:	Epoch: [237][99/204]	Loss 0.0037 (0.0138)	
training:	Epoch: [237][100/204]	Loss 0.0000 (0.0137)	
training:	Epoch: [237][101/204]	Loss 0.0001 (0.0135)	
training:	Epoch: [237][102/204]	Loss 0.0142 (0.0136)	
training:	Epoch: [237][103/204]	Loss 0.0001 (0.0134)	
training:	Epoch: [237][104/204]	Loss 0.0000 (0.0133)	
training:	Epoch: [237][105/204]	Loss 0.0001 (0.0132)	
training:	Epoch: [237][106/204]	Loss 0.0025 (0.0131)	
training:	Epoch: [237][107/204]	Loss 0.0031 (0.0130)	
training:	Epoch: [237][108/204]	Loss 0.0476 (0.0133)	
training:	Epoch: [237][109/204]	Loss 0.0528 (0.0137)	
training:	Epoch: [237][110/204]	Loss 0.0001 (0.0135)	
training:	Epoch: [237][111/204]	Loss 0.0001 (0.0134)	
training:	Epoch: [237][112/204]	Loss 0.0000 (0.0133)	
training:	Epoch: [237][113/204]	Loss 0.0001 (0.0132)	
training:	Epoch: [237][114/204]	Loss 0.0000 (0.0131)	
training:	Epoch: [237][115/204]	Loss 0.0010 (0.0130)	
training:	Epoch: [237][116/204]	Loss 0.0000 (0.0128)	
training:	Epoch: [237][117/204]	Loss 0.0001 (0.0127)	
training:	Epoch: [237][118/204]	Loss 0.0001 (0.0126)	
training:	Epoch: [237][119/204]	Loss 0.0000 (0.0125)	
training:	Epoch: [237][120/204]	Loss 0.0000 (0.0124)	
training:	Epoch: [237][121/204]	Loss 0.0001 (0.0123)	
training:	Epoch: [237][122/204]	Loss 0.0841 (0.0129)	
training:	Epoch: [237][123/204]	Loss 0.0000 (0.0128)	
training:	Epoch: [237][124/204]	Loss 0.0340 (0.0130)	
training:	Epoch: [237][125/204]	Loss 0.0054 (0.0129)	
training:	Epoch: [237][126/204]	Loss 0.0057 (0.0129)	
training:	Epoch: [237][127/204]	Loss 0.0001 (0.0128)	
training:	Epoch: [237][128/204]	Loss 0.0000 (0.0127)	
training:	Epoch: [237][129/204]	Loss 0.0005 (0.0126)	
training:	Epoch: [237][130/204]	Loss 0.0008 (0.0125)	
training:	Epoch: [237][131/204]	Loss 0.0000 (0.0124)	
training:	Epoch: [237][132/204]	Loss 0.0001 (0.0123)	
training:	Epoch: [237][133/204]	Loss 0.0448 (0.0125)	
training:	Epoch: [237][134/204]	Loss 0.0198 (0.0126)	
training:	Epoch: [237][135/204]	Loss 0.0000 (0.0125)	
training:	Epoch: [237][136/204]	Loss 0.0225 (0.0126)	
training:	Epoch: [237][137/204]	Loss 0.0002 (0.0125)	
training:	Epoch: [237][138/204]	Loss 0.0000 (0.0124)	
training:	Epoch: [237][139/204]	Loss 0.0000 (0.0123)	
training:	Epoch: [237][140/204]	Loss 0.0000 (0.0122)	
training:	Epoch: [237][141/204]	Loss 0.0000 (0.0121)	
training:	Epoch: [237][142/204]	Loss 0.0128 (0.0121)	
training:	Epoch: [237][143/204]	Loss 0.0001 (0.0120)	
training:	Epoch: [237][144/204]	Loss 0.0000 (0.0120)	
training:	Epoch: [237][145/204]	Loss 0.0004 (0.0119)	
training:	Epoch: [237][146/204]	Loss 0.0000 (0.0118)	
training:	Epoch: [237][147/204]	Loss 0.0000 (0.0117)	
training:	Epoch: [237][148/204]	Loss 0.0000 (0.0116)	
training:	Epoch: [237][149/204]	Loss 0.0001 (0.0116)	
training:	Epoch: [237][150/204]	Loss 0.0000 (0.0115)	
training:	Epoch: [237][151/204]	Loss 0.0001 (0.0114)	
training:	Epoch: [237][152/204]	Loss 0.0001 (0.0113)	
training:	Epoch: [237][153/204]	Loss 0.0000 (0.0113)	
training:	Epoch: [237][154/204]	Loss 0.0000 (0.0112)	
training:	Epoch: [237][155/204]	Loss 0.0005 (0.0111)	
training:	Epoch: [237][156/204]	Loss 0.0001 (0.0110)	
training:	Epoch: [237][157/204]	Loss 0.0033 (0.0110)	
training:	Epoch: [237][158/204]	Loss 0.0001 (0.0109)	
training:	Epoch: [237][159/204]	Loss 0.0000 (0.0109)	
training:	Epoch: [237][160/204]	Loss 0.0000 (0.0108)	
training:	Epoch: [237][161/204]	Loss 0.0000 (0.0107)	
training:	Epoch: [237][162/204]	Loss 0.1071 (0.0113)	
training:	Epoch: [237][163/204]	Loss 0.0000 (0.0113)	
training:	Epoch: [237][164/204]	Loss 0.0003 (0.0112)	
training:	Epoch: [237][165/204]	Loss 0.0000 (0.0111)	
training:	Epoch: [237][166/204]	Loss 0.0041 (0.0111)	
training:	Epoch: [237][167/204]	Loss 0.0000 (0.0110)	
training:	Epoch: [237][168/204]	Loss 0.0000 (0.0109)	
training:	Epoch: [237][169/204]	Loss 0.1460 (0.0117)	
training:	Epoch: [237][170/204]	Loss 0.0000 (0.0117)	
training:	Epoch: [237][171/204]	Loss 0.0488 (0.0119)	
training:	Epoch: [237][172/204]	Loss 0.0000 (0.0118)	
training:	Epoch: [237][173/204]	Loss 0.0001 (0.0118)	
training:	Epoch: [237][174/204]	Loss 0.0000 (0.0117)	
training:	Epoch: [237][175/204]	Loss 0.0008 (0.0116)	
training:	Epoch: [237][176/204]	Loss 0.0000 (0.0116)	
training:	Epoch: [237][177/204]	Loss 0.0000 (0.0115)	
training:	Epoch: [237][178/204]	Loss 0.0001 (0.0114)	
training:	Epoch: [237][179/204]	Loss 0.0001 (0.0114)	
training:	Epoch: [237][180/204]	Loss 0.0014 (0.0113)	
training:	Epoch: [237][181/204]	Loss 0.0002 (0.0112)	
training:	Epoch: [237][182/204]	Loss 0.0000 (0.0112)	
training:	Epoch: [237][183/204]	Loss 0.0001 (0.0111)	
training:	Epoch: [237][184/204]	Loss 0.0000 (0.0111)	
training:	Epoch: [237][185/204]	Loss 0.0002 (0.0110)	
training:	Epoch: [237][186/204]	Loss 0.0002 (0.0110)	
training:	Epoch: [237][187/204]	Loss 0.0003 (0.0109)	
training:	Epoch: [237][188/204]	Loss 0.0000 (0.0108)	
training:	Epoch: [237][189/204]	Loss 0.0120 (0.0108)	
training:	Epoch: [237][190/204]	Loss 0.0106 (0.0108)	
training:	Epoch: [237][191/204]	Loss 0.0001 (0.0108)	
training:	Epoch: [237][192/204]	Loss 0.0001 (0.0107)	
training:	Epoch: [237][193/204]	Loss 0.0001 (0.0107)	
training:	Epoch: [237][194/204]	Loss 0.0002 (0.0106)	
training:	Epoch: [237][195/204]	Loss 0.0001 (0.0106)	
training:	Epoch: [237][196/204]	Loss 0.0007 (0.0105)	
training:	Epoch: [237][197/204]	Loss 0.0001 (0.0105)	
training:	Epoch: [237][198/204]	Loss 0.0001 (0.0104)	
training:	Epoch: [237][199/204]	Loss 0.0001 (0.0104)	
training:	Epoch: [237][200/204]	Loss 0.0001 (0.0103)	
training:	Epoch: [237][201/204]	Loss 0.0001 (0.0103)	
training:	Epoch: [237][202/204]	Loss 0.0000 (0.0102)	
training:	Epoch: [237][203/204]	Loss 0.0006 (0.0102)	
training:	Epoch: [237][204/204]	Loss 0.0032 (0.0101)	
Training:	 Loss: 0.0101

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7851 0.7854 0.7932 0.7769
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6503
Pretraining:	Epoch 238/500
----------
training:	Epoch: [238][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [238][2/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [238][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [238][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [238][5/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [238][6/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [238][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [238][8/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [238][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [238][10/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [238][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [238][12/204]	Loss 0.0227 (0.0020)	
training:	Epoch: [238][13/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][14/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [238][15/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [238][16/204]	Loss 0.0003 (0.0016)	
training:	Epoch: [238][17/204]	Loss 0.0003 (0.0015)	
training:	Epoch: [238][18/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [238][19/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][20/204]	Loss 0.0014 (0.0013)	
training:	Epoch: [238][21/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][22/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][23/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][24/204]	Loss 0.0332 (0.0025)	
training:	Epoch: [238][25/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [238][26/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [238][27/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [238][28/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [238][29/204]	Loss 0.0191 (0.0027)	
training:	Epoch: [238][30/204]	Loss 0.0000 (0.0027)	
training:	Epoch: [238][31/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [238][32/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [238][33/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [238][34/204]	Loss 0.0005 (0.0024)	
training:	Epoch: [238][35/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [238][36/204]	Loss 0.0144 (0.0026)	
training:	Epoch: [238][37/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [238][38/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [238][39/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [238][40/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [238][41/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [238][42/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [238][43/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [238][44/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [238][45/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [238][46/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [238][47/204]	Loss 0.0004 (0.0020)	
training:	Epoch: [238][48/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [238][49/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [238][50/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][51/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][52/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][53/204]	Loss 0.0051 (0.0019)	
training:	Epoch: [238][54/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [238][55/204]	Loss 0.0065 (0.0020)	
training:	Epoch: [238][56/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [238][57/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][58/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [238][59/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [238][60/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [238][61/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [238][62/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [238][63/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [238][64/204]	Loss 0.0123 (0.0019)	
training:	Epoch: [238][65/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][66/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [238][67/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [238][68/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [238][69/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [238][70/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [238][71/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [238][72/204]	Loss 0.0808 (0.0028)	
training:	Epoch: [238][73/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [238][74/204]	Loss 0.0000 (0.0027)	
training:	Epoch: [238][75/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [238][76/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [238][77/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [238][78/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [238][79/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [238][80/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [238][81/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [238][82/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [238][83/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [238][84/204]	Loss 0.0003 (0.0024)	
training:	Epoch: [238][85/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [238][86/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [238][87/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [238][88/204]	Loss 0.0007 (0.0023)	
training:	Epoch: [238][89/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [238][90/204]	Loss 0.0003 (0.0023)	
training:	Epoch: [238][91/204]	Loss 0.0011 (0.0023)	
training:	Epoch: [238][92/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [238][93/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [238][94/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [238][95/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [238][96/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [238][97/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [238][98/204]	Loss 0.0024 (0.0021)	
training:	Epoch: [238][99/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [238][100/204]	Loss 0.0075 (0.0022)	
training:	Epoch: [238][101/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [238][102/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [238][103/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [238][104/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [238][105/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [238][106/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [238][107/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [238][108/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [238][109/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [238][110/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [238][111/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [238][112/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][113/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][114/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [238][115/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [238][116/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][117/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [238][118/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [238][119/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [238][120/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [238][121/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [238][122/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [238][123/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [238][124/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [238][125/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [238][126/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [238][127/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [238][128/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [238][129/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [238][130/204]	Loss 0.0002 (0.0017)	
training:	Epoch: [238][131/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [238][132/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [238][133/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [238][134/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [238][135/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [238][136/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [238][137/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [238][138/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [238][139/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [238][140/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [238][141/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [238][142/204]	Loss 0.0004 (0.0016)	
training:	Epoch: [238][143/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [238][144/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [238][145/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [238][146/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [238][147/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [238][148/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [238][149/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [238][150/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [238][151/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [238][152/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [238][153/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [238][154/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [238][155/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [238][156/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [238][157/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [238][158/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [238][159/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [238][160/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [238][161/204]	Loss 0.0002 (0.0014)	
training:	Epoch: [238][162/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [238][163/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [238][164/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [238][165/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][166/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][167/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][168/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][169/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [238][170/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][171/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][172/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [238][173/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [238][174/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][175/204]	Loss 0.0047 (0.0013)	
training:	Epoch: [238][176/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [238][177/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][178/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [238][179/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][180/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][181/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [238][182/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [238][183/204]	Loss 0.0007 (0.0012)	
training:	Epoch: [238][184/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][185/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][186/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][187/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][188/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [238][189/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][190/204]	Loss 0.0008 (0.0012)	
training:	Epoch: [238][191/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [238][192/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [238][193/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][194/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][195/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [238][196/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][197/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [238][198/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [238][199/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [238][200/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][201/204]	Loss 0.0116 (0.0012)	
training:	Epoch: [238][202/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [238][203/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [238][204/204]	Loss 0.0000 (0.0012)	
Training:	 Loss: 0.0012

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7834 0.7838 0.7922 0.7747
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7091
Pretraining:	Epoch 239/500
----------
training:	Epoch: [239][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [239][2/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [239][3/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][4/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][6/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][8/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][12/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][13/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][14/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][15/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [239][16/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][17/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [239][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][19/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [239][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][23/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][33/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [239][34/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][45/204]	Loss 0.0062 (0.0002)	
training:	Epoch: [239][46/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [239][47/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [239][48/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][49/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [239][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][51/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][52/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][55/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][56/204]	Loss 0.0010 (0.0002)	
training:	Epoch: [239][57/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][58/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][59/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][60/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][61/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][62/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [239][63/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [239][64/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [239][65/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][66/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][67/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][68/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][69/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][70/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][71/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][72/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][73/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][74/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [239][75/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [239][76/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][77/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][78/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][79/204]	Loss 0.0019 (0.0002)	
training:	Epoch: [239][80/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][81/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][82/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][83/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][84/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][85/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][86/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][87/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][88/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [239][89/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][90/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][91/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][92/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][93/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][94/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][95/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][96/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][97/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][98/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][99/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][100/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][101/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][102/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][103/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][104/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][105/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][106/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [239][107/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][108/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][109/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][110/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][111/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][112/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][113/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][114/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][115/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][116/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][117/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][118/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][119/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [239][120/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][121/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][122/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][123/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][124/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [239][125/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [239][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][131/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][132/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [239][133/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [239][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [239][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [239][145/204]	Loss 0.0215 (0.0003)	
training:	Epoch: [239][146/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [239][147/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [239][148/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [239][149/204]	Loss 0.0429 (0.0006)	
training:	Epoch: [239][150/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [239][151/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [239][152/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [239][153/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [239][154/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [239][155/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][156/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][157/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][158/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [239][159/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][160/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [239][161/204]	Loss 0.0013 (0.0005)	
training:	Epoch: [239][162/204]	Loss 0.0010 (0.0005)	
training:	Epoch: [239][163/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [239][164/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [239][165/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [239][166/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][167/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][168/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [239][169/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [239][170/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][171/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [239][172/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [239][173/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [239][174/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][175/204]	Loss 0.0011 (0.0005)	
training:	Epoch: [239][176/204]	Loss 0.0035 (0.0005)	
training:	Epoch: [239][177/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [239][178/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [239][179/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][180/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [239][181/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [239][182/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [239][183/204]	Loss 0.0410 (0.0007)	
training:	Epoch: [239][184/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [239][185/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][186/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][187/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [239][188/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][189/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [239][190/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [239][191/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][192/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][193/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [239][194/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][195/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][196/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][197/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][198/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][199/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][200/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][201/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [239][202/204]	Loss 0.0036 (0.0007)	
training:	Epoch: [239][203/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [239][204/204]	Loss 0.0000 (0.0007)	
Training:	 Loss: 0.0007

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7881 0.7887 0.7994 0.7769
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6913
Pretraining:	Epoch 240/500
----------
training:	Epoch: [240][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [240][2/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [240][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [240][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [240][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [240][6/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [240][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [240][8/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [240][9/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [240][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [240][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [240][12/204]	Loss 0.0104 (0.0009)	
training:	Epoch: [240][13/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [240][14/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [240][15/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [240][16/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [240][17/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [240][18/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [240][19/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [240][20/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [240][21/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [240][22/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [240][23/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [240][24/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [240][25/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [240][26/204]	Loss 0.0042 (0.0006)	
training:	Epoch: [240][27/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [240][28/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [240][29/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [240][30/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [240][31/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [240][32/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [240][33/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [240][34/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [240][35/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [240][36/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [240][37/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [240][38/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [240][39/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [240][40/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [240][41/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [240][42/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [240][43/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [240][44/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][45/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [240][46/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [240][47/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [240][48/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][49/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][50/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [240][51/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][52/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][53/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][54/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][55/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][56/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [240][57/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][58/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][59/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [240][60/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [240][61/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [240][62/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][63/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][64/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][65/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [240][66/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [240][67/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][68/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][69/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][70/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][71/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][72/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][73/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][74/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][75/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][76/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][77/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][78/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][79/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [240][80/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][81/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][82/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][83/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][84/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][85/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][86/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][87/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][88/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][89/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][90/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][91/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][92/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [240][93/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][94/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][95/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][96/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][97/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][98/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [240][99/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][100/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][101/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][102/204]	Loss 0.0012 (0.0003)	
training:	Epoch: [240][103/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][104/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][105/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][106/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][107/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][108/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][109/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][110/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][111/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][112/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][113/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][114/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][115/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][116/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][117/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [240][118/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][119/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][120/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][121/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][122/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][123/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][124/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][125/204]	Loss 0.0053 (0.0003)	
training:	Epoch: [240][126/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][127/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][128/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][129/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][130/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][131/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][132/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [240][133/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][134/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [240][135/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][136/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][137/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][138/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][139/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][140/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][141/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][142/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][143/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][144/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][145/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][146/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][147/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][148/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][149/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][150/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][151/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][153/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][154/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][155/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][156/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][157/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][158/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][159/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][161/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][163/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][164/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][165/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][166/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][167/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][168/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][169/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][170/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][171/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][172/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][173/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][174/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][175/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][176/204]	Loss 0.0011 (0.0002)	
training:	Epoch: [240][177/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][178/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][179/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][180/204]	Loss 0.0008 (0.0002)	
training:	Epoch: [240][181/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][182/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [240][183/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][184/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][185/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][186/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][187/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][188/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][189/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][190/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][191/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][192/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][193/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][194/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][195/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [240][196/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][197/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][198/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][199/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][200/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][201/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [240][202/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][203/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [240][204/204]	Loss 0.0003 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7854 0.7865 0.8106 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7280
Pretraining:	Epoch 241/500
----------
training:	Epoch: [241][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][7/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [241][8/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][9/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][12/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][14/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][15/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][16/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][17/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][23/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][36/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [241][37/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [241][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][44/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][54/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [241][55/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [241][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][57/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [241][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][66/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][78/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [241][79/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [241][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][96/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][103/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [241][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][111/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [241][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][113/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [241][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][116/204]	Loss 0.0010 (0.0001)	
training:	Epoch: [241][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][124/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][128/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [241][129/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [241][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][145/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [241][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][147/204]	Loss 0.0016 (0.0001)	
training:	Epoch: [241][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][159/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][160/204]	Loss 0.0012 (0.0001)	
training:	Epoch: [241][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][162/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][175/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][182/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [241][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [241][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [241][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7827 0.7828 0.7840 0.7814
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7356
Pretraining:	Epoch 242/500
----------
training:	Epoch: [242][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [242][12/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [242][13/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][15/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][16/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [242][17/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][23/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [242][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][29/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][44/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [242][45/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][46/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][61/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [242][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][71/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [242][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][79/204]	Loss 0.0013 (0.0001)	
training:	Epoch: [242][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][81/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][101/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [242][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][113/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][118/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][122/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [242][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][140/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [242][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][169/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [242][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][177/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [242][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][191/204]	Loss 0.0009 (0.0001)	
training:	Epoch: [242][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][200/204]	Loss 0.0029 (0.0001)	
training:	Epoch: [242][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [242][203/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [242][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7842 0.7849 0.7994 0.7691
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7474
Pretraining:	Epoch 243/500
----------
training:	Epoch: [243][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][14/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][28/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [243][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][30/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][33/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][37/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [243][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][45/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][47/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][48/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][56/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][67/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [243][68/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][69/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][70/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][73/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][74/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][77/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][83/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [243][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][87/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [243][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [243][89/204]	Loss 0.0009 (0.0001)	
training:	Epoch: [243][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][97/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][100/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [243][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][108/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][126/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [243][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][140/204]	Loss 0.0035 (0.0001)	
training:	Epoch: [243][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][143/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [243][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][153/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [243][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][155/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][159/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [243][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][182/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][184/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [243][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][191/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][202/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [243][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [243][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7836 0.7838 0.7881 0.7791
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7534
Pretraining:	Epoch 244/500
----------
training:	Epoch: [244][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][7/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][10/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][11/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][14/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][36/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][39/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][43/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][45/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][53/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][68/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][78/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][82/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][83/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][85/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][86/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][112/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][113/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][121/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][122/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][131/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][136/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][138/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [244][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][141/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][144/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][150/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][161/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][162/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][164/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][171/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][181/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][197/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][198/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][199/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [244][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [244][203/204]	Loss 0.0043 (0.0001)	
training:	Epoch: [244][204/204]	Loss 0.0349 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7836 0.7838 0.7881 0.7791
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7604
Pretraining:	Epoch 245/500
----------
training:	Epoch: [245][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [245][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [245][3/204]	Loss 0.0010 (0.0004)	
training:	Epoch: [245][4/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [245][5/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][6/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][7/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][8/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][9/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [245][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [245][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [245][12/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [245][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [245][14/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [245][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [245][16/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [245][17/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [245][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [245][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [245][20/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [245][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [245][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [245][23/204]	Loss 0.0021 (0.0002)	
training:	Epoch: [245][24/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [245][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [245][26/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [245][27/204]	Loss 0.0024 (0.0003)	
training:	Epoch: [245][28/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [245][29/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [245][30/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [245][31/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [245][32/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [245][33/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [245][34/204]	Loss 0.0011 (0.0003)	
training:	Epoch: [245][35/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [245][36/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [245][37/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [245][38/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [245][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [245][40/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][41/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][42/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][43/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][44/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][45/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][46/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][47/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [245][48/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][49/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][50/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][51/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [245][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [245][53/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][54/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][55/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][56/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][57/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][58/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][59/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][60/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [245][61/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][62/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][63/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [245][64/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][65/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][66/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][67/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][68/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][69/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][70/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][71/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][72/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [245][73/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [245][74/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][75/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][76/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [245][77/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [245][78/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [245][79/204]	Loss 0.0432 (0.0007)	
training:	Epoch: [245][80/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [245][81/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [245][82/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [245][83/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [245][84/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [245][85/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [245][86/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][87/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [245][88/204]	Loss 0.0050 (0.0007)	
training:	Epoch: [245][89/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [245][90/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [245][91/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [245][92/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [245][93/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [245][94/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [245][95/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][96/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [245][97/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][98/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][99/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][100/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][101/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [245][102/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][103/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][104/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][105/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][106/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][107/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][108/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][109/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][110/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][111/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][112/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][113/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [245][114/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][115/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][116/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][117/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][118/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][119/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [245][120/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][121/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][122/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][123/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][124/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][125/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][126/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [245][127/204]	Loss 0.2039 (0.0021)	
training:	Epoch: [245][128/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [245][129/204]	Loss 0.0026 (0.0021)	
training:	Epoch: [245][130/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [245][131/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [245][132/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [245][133/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [245][134/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [245][135/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [245][136/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [245][137/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [245][138/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [245][139/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [245][140/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [245][141/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [245][142/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [245][143/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [245][144/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [245][145/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [245][146/204]	Loss 0.0044 (0.0019)	
training:	Epoch: [245][147/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [245][148/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [245][149/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][150/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][151/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][152/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][153/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][154/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][155/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][156/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][157/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][158/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [245][159/204]	Loss 0.0010 (0.0017)	
training:	Epoch: [245][160/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [245][161/204]	Loss 0.0163 (0.0018)	
training:	Epoch: [245][162/204]	Loss 0.0003 (0.0018)	
training:	Epoch: [245][163/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [245][164/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][165/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [245][166/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][167/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [245][168/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [245][169/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [245][170/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [245][171/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [245][172/204]	Loss 0.0006 (0.0017)	
training:	Epoch: [245][173/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [245][174/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [245][175/204]	Loss 0.0004 (0.0017)	
training:	Epoch: [245][176/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [245][177/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [245][178/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [245][179/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [245][180/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [245][181/204]	Loss 0.0022 (0.0016)	
training:	Epoch: [245][182/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [245][183/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [245][184/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [245][185/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [245][186/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [245][187/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [245][188/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [245][189/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [245][190/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [245][191/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [245][192/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [245][193/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [245][194/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [245][195/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [245][196/204]	Loss 0.1336 (0.0022)	
training:	Epoch: [245][197/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [245][198/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [245][199/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [245][200/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [245][201/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [245][202/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [245][203/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [245][204/204]	Loss 0.0001 (0.0021)	
Training:	 Loss: 0.0021

Training:	 ACC: 0.9995 0.9995 1.0000 0.9990
Validation:	 ACC: 0.7761 0.7796 0.8526 0.6996
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7800
Pretraining:	Epoch 246/500
----------
training:	Epoch: [246][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [246][2/204]	Loss 0.0095 (0.0048)	
training:	Epoch: [246][3/204]	Loss 0.0037 (0.0044)	
training:	Epoch: [246][4/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [246][5/204]	Loss 0.0013 (0.0029)	
training:	Epoch: [246][6/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [246][7/204]	Loss 0.0141 (0.0041)	
training:	Epoch: [246][8/204]	Loss 0.0000 (0.0036)	
training:	Epoch: [246][9/204]	Loss 0.0000 (0.0032)	
training:	Epoch: [246][10/204]	Loss 0.0000 (0.0029)	
training:	Epoch: [246][11/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [246][12/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [246][13/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [246][14/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [246][15/204]	Loss 0.0029 (0.0021)	
training:	Epoch: [246][16/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [246][17/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [246][18/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [246][19/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [246][20/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [246][21/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [246][22/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [246][23/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [246][24/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [246][25/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [246][26/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [246][27/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [246][28/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [246][29/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [246][30/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][31/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][32/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][33/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][34/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][35/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][36/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][37/204]	Loss 0.0029 (0.0010)	
training:	Epoch: [246][38/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][39/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][40/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][41/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [246][42/204]	Loss 0.0001 (0.0009)	
training:	Epoch: [246][43/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [246][44/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [246][45/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [246][46/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [246][47/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [246][48/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [246][49/204]	Loss 0.0003 (0.0007)	
training:	Epoch: [246][50/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [246][51/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [246][52/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [246][53/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [246][54/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [246][55/204]	Loss 0.0025 (0.0007)	
training:	Epoch: [246][56/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [246][57/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [246][58/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [246][59/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [246][60/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [246][61/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][62/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [246][63/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][64/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][65/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][66/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][67/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][68/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][69/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][70/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][71/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][72/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [246][73/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][74/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [246][75/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][76/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][77/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][78/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][79/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][80/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][81/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][82/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [246][83/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [246][84/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [246][85/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][86/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [246][87/204]	Loss 0.0587 (0.0011)	
training:	Epoch: [246][88/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [246][89/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [246][90/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][91/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][92/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][93/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [246][94/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][95/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][96/204]	Loss 0.0004 (0.0010)	
training:	Epoch: [246][97/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][98/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [246][99/204]	Loss 0.0008 (0.0010)	
training:	Epoch: [246][100/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][101/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][102/204]	Loss 0.0002 (0.0010)	
training:	Epoch: [246][103/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [246][104/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][105/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][106/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][107/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][108/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [246][109/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][110/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][111/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][112/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][113/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][114/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][115/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][116/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][117/204]	Loss 0.0024 (0.0009)	
training:	Epoch: [246][118/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [246][119/204]	Loss 0.0369 (0.0012)	
training:	Epoch: [246][120/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [246][121/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [246][122/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [246][123/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [246][124/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][125/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][126/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][127/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][128/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][129/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][130/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][131/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][132/204]	Loss 0.0005 (0.0011)	
training:	Epoch: [246][133/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][134/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][135/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [246][136/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [246][137/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][138/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [246][139/204]	Loss 0.1504 (0.0021)	
training:	Epoch: [246][140/204]	Loss 0.0002 (0.0021)	
training:	Epoch: [246][141/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [246][142/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [246][143/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [246][144/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [246][145/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [246][146/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [246][147/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [246][148/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [246][149/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [246][150/204]	Loss 0.0016 (0.0020)	
training:	Epoch: [246][151/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [246][152/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [246][153/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [246][154/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [246][155/204]	Loss 0.0010 (0.0019)	
training:	Epoch: [246][156/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [246][157/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [246][158/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [246][159/204]	Loss 0.0003 (0.0019)	
training:	Epoch: [246][160/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [246][161/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [246][162/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [246][163/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [246][164/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [246][165/204]	Loss 0.0021 (0.0018)	
training:	Epoch: [246][166/204]	Loss 0.0022 (0.0018)	
training:	Epoch: [246][167/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [246][168/204]	Loss 0.0094 (0.0019)	
training:	Epoch: [246][169/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [246][170/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [246][171/204]	Loss 0.0664 (0.0022)	
training:	Epoch: [246][172/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [246][173/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [246][174/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [246][175/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [246][176/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [246][177/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [246][178/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [246][179/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [246][180/204]	Loss 0.0753 (0.0025)	
training:	Epoch: [246][181/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [246][182/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [246][183/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [246][184/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [246][185/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [246][186/204]	Loss 0.0025 (0.0025)	
training:	Epoch: [246][187/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [246][188/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [246][189/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [246][190/204]	Loss 0.0015 (0.0024)	
training:	Epoch: [246][191/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [246][192/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [246][193/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [246][194/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [246][195/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [246][196/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [246][197/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [246][198/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [246][199/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [246][200/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [246][201/204]	Loss 0.0233 (0.0024)	
training:	Epoch: [246][202/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [246][203/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [246][204/204]	Loss 0.0000 (0.0024)	
Training:	 Loss: 0.0024

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7810 0.7822 0.8076 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7538
Pretraining:	Epoch 247/500
----------
training:	Epoch: [247][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][2/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [247][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][5/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][6/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [247][7/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][8/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][9/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][10/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][12/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][13/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][15/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][16/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][18/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][23/204]	Loss 0.0026 (0.0002)	
training:	Epoch: [247][24/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][25/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [247][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][27/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [247][28/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][29/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [247][30/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][31/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][32/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][34/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][35/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][36/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][37/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][38/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][39/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][42/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][43/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [247][44/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][45/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][46/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][47/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][48/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][49/204]	Loss 0.0017 (0.0002)	
training:	Epoch: [247][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][51/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][52/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][53/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][54/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][57/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][58/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][59/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [247][60/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][61/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][62/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][63/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [247][65/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][66/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][67/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][68/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [247][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][73/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [247][74/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [247][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [247][76/204]	Loss 0.1504 (0.0021)	
training:	Epoch: [247][77/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [247][78/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [247][79/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [247][80/204]	Loss 0.0003 (0.0020)	
training:	Epoch: [247][81/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [247][82/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [247][83/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [247][84/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [247][85/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [247][86/204]	Loss 0.0017 (0.0019)	
training:	Epoch: [247][87/204]	Loss 0.0039 (0.0019)	
training:	Epoch: [247][88/204]	Loss 0.0017 (0.0019)	
training:	Epoch: [247][89/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [247][90/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [247][91/204]	Loss 0.0034 (0.0019)	
training:	Epoch: [247][92/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [247][93/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [247][94/204]	Loss 0.0002 (0.0018)	
training:	Epoch: [247][95/204]	Loss 0.0269 (0.0021)	
training:	Epoch: [247][96/204]	Loss 0.0003 (0.0021)	
training:	Epoch: [247][97/204]	Loss 0.0057 (0.0021)	
training:	Epoch: [247][98/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [247][99/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [247][100/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [247][101/204]	Loss 0.0006 (0.0020)	
training:	Epoch: [247][102/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [247][103/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [247][104/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [247][105/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [247][106/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [247][107/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [247][108/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [247][109/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [247][110/204]	Loss 0.0002 (0.0019)	
training:	Epoch: [247][111/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [247][112/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [247][113/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [247][114/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [247][115/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [247][116/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [247][117/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [247][118/204]	Loss 0.0005 (0.0018)	
training:	Epoch: [247][119/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [247][120/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [247][121/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [247][122/204]	Loss 0.0003 (0.0017)	
training:	Epoch: [247][123/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [247][124/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [247][125/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [247][126/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [247][127/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [247][128/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [247][129/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [247][130/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [247][131/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [247][132/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [247][133/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [247][134/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [247][135/204]	Loss 0.0001 (0.0016)	
training:	Epoch: [247][136/204]	Loss 0.0008 (0.0015)	
training:	Epoch: [247][137/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [247][138/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [247][139/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [247][140/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [247][141/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [247][142/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [247][143/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [247][144/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [247][145/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [247][146/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][147/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][148/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [247][149/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [247][150/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][151/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][152/204]	Loss 0.0006 (0.0014)	
training:	Epoch: [247][153/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][154/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][155/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][156/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][157/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][158/204]	Loss 0.0174 (0.0015)	
training:	Epoch: [247][159/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [247][160/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][161/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][162/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][163/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][164/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][165/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][166/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][167/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [247][168/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [247][169/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [247][170/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [247][171/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [247][172/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][173/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][174/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][175/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][176/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [247][177/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][178/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [247][179/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][180/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][181/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][182/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][183/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][184/204]	Loss 0.0008 (0.0013)	
training:	Epoch: [247][185/204]	Loss 0.0013 (0.0013)	
training:	Epoch: [247][186/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [247][187/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [247][188/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [247][189/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [247][190/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [247][191/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [247][192/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [247][193/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [247][194/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [247][195/204]	Loss 0.0046 (0.0012)	
training:	Epoch: [247][196/204]	Loss 0.0023 (0.0012)	
training:	Epoch: [247][197/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [247][198/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [247][199/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [247][200/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [247][201/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [247][202/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [247][203/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [247][204/204]	Loss 0.0000 (0.0012)	
Training:	 Loss: 0.0012

Training:	 ACC: 0.9998 0.9998 1.0000 0.9997
Validation:	 ACC: 0.7824 0.7844 0.8260 0.7388
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7684
Pretraining:	Epoch 248/500
----------
training:	Epoch: [248][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [248][2/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [248][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [248][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [248][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [248][6/204]	Loss 0.0022 (0.0004)	
training:	Epoch: [248][7/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [248][8/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [248][9/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][10/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][11/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][12/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [248][13/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][15/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][16/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][17/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][18/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][19/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][20/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][21/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][22/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][23/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][24/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [248][25/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][26/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][27/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][28/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][29/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [248][31/204]	Loss 0.0027 (0.0002)	
training:	Epoch: [248][32/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][33/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][34/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][35/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][36/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [248][37/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][38/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][39/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][40/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][41/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][42/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][43/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][44/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][45/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][46/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][47/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][48/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][49/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][50/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][51/204]	Loss 0.0035 (0.0002)	
training:	Epoch: [248][52/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][53/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][54/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][55/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][56/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][57/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][58/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][59/204]	Loss 0.0014 (0.0002)	
training:	Epoch: [248][60/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][61/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][62/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][63/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][64/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][65/204]	Loss 0.0105 (0.0004)	
training:	Epoch: [248][66/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [248][67/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [248][68/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [248][69/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [248][70/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [248][71/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][72/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][73/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [248][74/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [248][75/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [248][76/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][77/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][78/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][79/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][80/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][81/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][82/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [248][83/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][84/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][85/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [248][86/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][87/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][88/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][89/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [248][90/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [248][91/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [248][92/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][93/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][94/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][95/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][96/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][97/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][98/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][99/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [248][100/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][101/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][102/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][103/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [248][104/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][105/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][106/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][107/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][108/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][109/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][110/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][111/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][112/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][113/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][114/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][115/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][116/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][117/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][118/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][119/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][120/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [248][121/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][122/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][123/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][124/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][125/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][126/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][127/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][128/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][129/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][130/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][131/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][132/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][133/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][134/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][135/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][136/204]	Loss 0.0013 (0.0002)	
training:	Epoch: [248][137/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][138/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][139/204]	Loss 0.0006 (0.0002)	
training:	Epoch: [248][140/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][141/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][142/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][143/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][144/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][145/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][146/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][147/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][148/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][149/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][150/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][151/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][152/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][153/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][154/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][155/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][156/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][157/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][158/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [248][159/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][160/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][161/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [248][162/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][163/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][164/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][165/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][166/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][167/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][168/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][169/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][170/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][171/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][172/204]	Loss 0.0125 (0.0003)	
training:	Epoch: [248][173/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][174/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [248][175/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][176/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][177/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][178/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [248][179/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][180/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][181/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][182/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][183/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][184/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][185/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][186/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][187/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][188/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][189/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][190/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][191/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][192/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][193/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][194/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][195/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][196/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][197/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][198/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][199/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][200/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][201/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [248][202/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [248][203/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [248][204/204]	Loss 0.0001 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7818 0.7838 0.8260 0.7377
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7487
Pretraining:	Epoch 249/500
----------
training:	Epoch: [249][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [249][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [249][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [249][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [249][5/204]	Loss 0.0220 (0.0044)	
training:	Epoch: [249][6/204]	Loss 0.0000 (0.0037)	
training:	Epoch: [249][7/204]	Loss 0.0000 (0.0032)	
training:	Epoch: [249][8/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [249][9/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [249][10/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [249][11/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [249][12/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [249][13/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [249][14/204]	Loss 0.0022 (0.0018)	
training:	Epoch: [249][15/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [249][16/204]	Loss 0.0006 (0.0016)	
training:	Epoch: [249][17/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [249][18/204]	Loss 0.0892 (0.0064)	
training:	Epoch: [249][19/204]	Loss 0.0003 (0.0061)	
training:	Epoch: [249][20/204]	Loss 0.0000 (0.0058)	
training:	Epoch: [249][21/204]	Loss 0.0000 (0.0055)	
training:	Epoch: [249][22/204]	Loss 0.0000 (0.0052)	
training:	Epoch: [249][23/204]	Loss 0.0000 (0.0050)	
training:	Epoch: [249][24/204]	Loss 0.0000 (0.0048)	
training:	Epoch: [249][25/204]	Loss 0.0000 (0.0046)	
training:	Epoch: [249][26/204]	Loss 0.0000 (0.0044)	
training:	Epoch: [249][27/204]	Loss 0.0010 (0.0043)	
training:	Epoch: [249][28/204]	Loss 0.0000 (0.0042)	
training:	Epoch: [249][29/204]	Loss 0.0000 (0.0040)	
training:	Epoch: [249][30/204]	Loss 0.0000 (0.0039)	
training:	Epoch: [249][31/204]	Loss 0.0001 (0.0038)	
training:	Epoch: [249][32/204]	Loss 0.0025 (0.0037)	
training:	Epoch: [249][33/204]	Loss 0.0122 (0.0040)	
training:	Epoch: [249][34/204]	Loss 0.0000 (0.0039)	
training:	Epoch: [249][35/204]	Loss 0.0000 (0.0037)	
training:	Epoch: [249][36/204]	Loss 0.0001 (0.0036)	
training:	Epoch: [249][37/204]	Loss 0.0000 (0.0035)	
training:	Epoch: [249][38/204]	Loss 0.0062 (0.0036)	
training:	Epoch: [249][39/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [249][40/204]	Loss 0.0002 (0.0034)	
training:	Epoch: [249][41/204]	Loss 0.0000 (0.0034)	
training:	Epoch: [249][42/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [249][43/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [249][44/204]	Loss 0.0056 (0.0033)	
training:	Epoch: [249][45/204]	Loss 0.0000 (0.0032)	
training:	Epoch: [249][46/204]	Loss 0.0000 (0.0031)	
training:	Epoch: [249][47/204]	Loss 0.0008 (0.0031)	
training:	Epoch: [249][48/204]	Loss 0.0000 (0.0030)	
training:	Epoch: [249][49/204]	Loss 0.0000 (0.0029)	
training:	Epoch: [249][50/204]	Loss 0.0000 (0.0029)	
training:	Epoch: [249][51/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [249][52/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [249][53/204]	Loss 0.0000 (0.0027)	
training:	Epoch: [249][54/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [249][55/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][56/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [249][57/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [249][58/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [249][59/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [249][60/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [249][61/204]	Loss 0.0002 (0.0024)	
training:	Epoch: [249][62/204]	Loss 0.0004 (0.0023)	
training:	Epoch: [249][63/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [249][64/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [249][65/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [249][66/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [249][67/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [249][68/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [249][69/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [249][70/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [249][71/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [249][72/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [249][73/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [249][74/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [249][75/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [249][76/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [249][77/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [249][78/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [249][79/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [249][80/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [249][81/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [249][82/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [249][83/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [249][84/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [249][85/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [249][86/204]	Loss 0.0465 (0.0022)	
training:	Epoch: [249][87/204]	Loss 0.0005 (0.0022)	
training:	Epoch: [249][88/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [249][89/204]	Loss 0.0002 (0.0022)	
training:	Epoch: [249][90/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [249][91/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [249][92/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [249][93/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [249][94/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [249][95/204]	Loss 0.0008 (0.0021)	
training:	Epoch: [249][96/204]	Loss 0.0002 (0.0020)	
training:	Epoch: [249][97/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [249][98/204]	Loss 0.1851 (0.0039)	
training:	Epoch: [249][99/204]	Loss 0.0001 (0.0038)	
training:	Epoch: [249][100/204]	Loss 0.0000 (0.0038)	
training:	Epoch: [249][101/204]	Loss 0.0000 (0.0038)	
training:	Epoch: [249][102/204]	Loss 0.0001 (0.0037)	
training:	Epoch: [249][103/204]	Loss 0.0000 (0.0037)	
training:	Epoch: [249][104/204]	Loss 0.0000 (0.0037)	
training:	Epoch: [249][105/204]	Loss 0.0000 (0.0036)	
training:	Epoch: [249][106/204]	Loss 0.0000 (0.0036)	
training:	Epoch: [249][107/204]	Loss 0.0000 (0.0036)	
training:	Epoch: [249][108/204]	Loss 0.0000 (0.0035)	
training:	Epoch: [249][109/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [249][110/204]	Loss 0.0000 (0.0035)	
training:	Epoch: [249][111/204]	Loss 0.0064 (0.0035)	
training:	Epoch: [249][112/204]	Loss 0.0002 (0.0035)	
training:	Epoch: [249][113/204]	Loss 0.0001 (0.0034)	
training:	Epoch: [249][114/204]	Loss 0.0000 (0.0034)	
training:	Epoch: [249][115/204]	Loss 0.0000 (0.0034)	
training:	Epoch: [249][116/204]	Loss 0.0000 (0.0033)	
training:	Epoch: [249][117/204]	Loss 0.0000 (0.0033)	
training:	Epoch: [249][118/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [249][119/204]	Loss 0.0000 (0.0033)	
training:	Epoch: [249][120/204]	Loss 0.0000 (0.0032)	
training:	Epoch: [249][121/204]	Loss 0.0357 (0.0035)	
training:	Epoch: [249][122/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [249][123/204]	Loss 0.0000 (0.0034)	
training:	Epoch: [249][124/204]	Loss 0.0000 (0.0034)	
training:	Epoch: [249][125/204]	Loss 0.0001 (0.0034)	
training:	Epoch: [249][126/204]	Loss 0.0001 (0.0034)	
training:	Epoch: [249][127/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [249][128/204]	Loss 0.0000 (0.0033)	
training:	Epoch: [249][129/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [249][130/204]	Loss 0.0001 (0.0033)	
training:	Epoch: [249][131/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [249][132/204]	Loss 0.0001 (0.0032)	
training:	Epoch: [249][133/204]	Loss 0.0000 (0.0032)	
training:	Epoch: [249][134/204]	Loss 0.0000 (0.0032)	
training:	Epoch: [249][135/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [249][136/204]	Loss 0.0000 (0.0031)	
training:	Epoch: [249][137/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [249][138/204]	Loss 0.0001 (0.0031)	
training:	Epoch: [249][139/204]	Loss 0.0000 (0.0031)	
training:	Epoch: [249][140/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [249][141/204]	Loss 0.0016 (0.0030)	
training:	Epoch: [249][142/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [249][143/204]	Loss 0.0004 (0.0030)	
training:	Epoch: [249][144/204]	Loss 0.0001 (0.0030)	
training:	Epoch: [249][145/204]	Loss 0.0000 (0.0029)	
training:	Epoch: [249][146/204]	Loss 0.0006 (0.0029)	
training:	Epoch: [249][147/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [249][148/204]	Loss 0.0000 (0.0029)	
training:	Epoch: [249][149/204]	Loss 0.0000 (0.0029)	
training:	Epoch: [249][150/204]	Loss 0.0000 (0.0029)	
training:	Epoch: [249][151/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [249][152/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [249][153/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [249][154/204]	Loss 0.0001 (0.0028)	
training:	Epoch: [249][155/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [249][156/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [249][157/204]	Loss 0.0000 (0.0027)	
training:	Epoch: [249][158/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [249][159/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [249][160/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [249][161/204]	Loss 0.0000 (0.0027)	
training:	Epoch: [249][162/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][163/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [249][164/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][165/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][166/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][167/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][168/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][169/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [249][170/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [249][171/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [249][172/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [249][173/204]	Loss 0.0003 (0.0025)	
training:	Epoch: [249][174/204]	Loss 0.0006 (0.0025)	
training:	Epoch: [249][175/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [249][176/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [249][177/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [249][178/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [249][179/204]	Loss 0.0012 (0.0024)	
training:	Epoch: [249][180/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [249][181/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [249][182/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [249][183/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [249][184/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [249][185/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [249][186/204]	Loss 0.0001 (0.0023)	
training:	Epoch: [249][187/204]	Loss 0.0691 (0.0027)	
training:	Epoch: [249][188/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [249][189/204]	Loss 0.0001 (0.0027)	
training:	Epoch: [249][190/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][191/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][192/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][193/204]	Loss 0.0001 (0.0026)	
training:	Epoch: [249][194/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][195/204]	Loss 0.0005 (0.0026)	
training:	Epoch: [249][196/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [249][197/204]	Loss 0.0001 (0.0025)	
training:	Epoch: [249][198/204]	Loss 0.0026 (0.0025)	
training:	Epoch: [249][199/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [249][200/204]	Loss 0.0002 (0.0025)	
training:	Epoch: [249][201/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [249][202/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [249][203/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [249][204/204]	Loss 0.0000 (0.0025)	
Training:	 Loss: 0.0025

Training:	 ACC: 0.9990 0.9989 0.9979 1.0000
Validation:	 ACC: 0.7822 0.7812 0.7584 0.8061
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6865
Pretraining:	Epoch 250/500
----------
training:	Epoch: [250][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [250][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [250][3/204]	Loss 0.0004 (0.0002)	
training:	Epoch: [250][4/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [250][5/204]	Loss 0.0018 (0.0005)	
training:	Epoch: [250][6/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [250][7/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][8/204]	Loss 0.0080 (0.0013)	
training:	Epoch: [250][9/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [250][10/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [250][11/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [250][12/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [250][13/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [250][14/204]	Loss 0.0226 (0.0024)	
training:	Epoch: [250][15/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [250][16/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [250][17/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [250][18/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [250][19/204]	Loss 0.0004 (0.0018)	
training:	Epoch: [250][20/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [250][21/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [250][22/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [250][23/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [250][24/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [250][25/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [250][26/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [250][27/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [250][28/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [250][29/204]	Loss 0.0002 (0.0012)	
training:	Epoch: [250][30/204]	Loss 0.0066 (0.0014)	
training:	Epoch: [250][31/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [250][32/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [250][33/204]	Loss 0.0002 (0.0013)	
training:	Epoch: [250][34/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [250][35/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [250][36/204]	Loss 0.0003 (0.0012)	
training:	Epoch: [250][37/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [250][38/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [250][39/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [250][40/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [250][41/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [250][42/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [250][43/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [250][44/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [250][45/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [250][46/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [250][47/204]	Loss 0.0006 (0.0009)	
training:	Epoch: [250][48/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [250][49/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [250][50/204]	Loss 0.0003 (0.0009)	
training:	Epoch: [250][51/204]	Loss 0.0016 (0.0009)	
training:	Epoch: [250][52/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [250][53/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [250][54/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [250][55/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [250][56/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [250][57/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [250][58/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [250][59/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [250][60/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [250][61/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [250][62/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [250][63/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][64/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [250][65/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][66/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [250][67/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][68/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][69/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [250][70/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [250][71/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][72/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][73/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][74/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][75/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [250][76/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][77/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][78/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][79/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][80/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][81/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [250][82/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [250][83/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [250][84/204]	Loss 0.0045 (0.0006)	
training:	Epoch: [250][85/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][86/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][87/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][88/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][89/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][90/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][91/204]	Loss 0.0105 (0.0007)	
training:	Epoch: [250][92/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [250][93/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][94/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][95/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][96/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][97/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [250][98/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][99/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [250][100/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [250][101/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [250][102/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [250][103/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][104/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [250][105/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][106/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][107/204]	Loss 0.0004 (0.0006)	
training:	Epoch: [250][108/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [250][109/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][110/204]	Loss 0.0016 (0.0006)	
training:	Epoch: [250][111/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][112/204]	Loss 0.0011 (0.0006)	
training:	Epoch: [250][113/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][114/204]	Loss 0.0031 (0.0006)	
training:	Epoch: [250][115/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [250][116/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [250][117/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][118/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][119/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][120/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][121/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][122/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [250][123/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][124/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][125/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [250][126/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][127/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][128/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][129/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][130/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [250][131/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][132/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][133/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][134/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][135/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][136/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][137/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][138/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [250][139/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [250][140/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][141/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][142/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][143/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][144/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][145/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][146/204]	Loss 0.0010 (0.0005)	
training:	Epoch: [250][147/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][148/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][149/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][150/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][151/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][152/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][153/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][154/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [250][155/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][156/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][157/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][158/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][159/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][160/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][161/204]	Loss 0.0006 (0.0005)	
training:	Epoch: [250][162/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][163/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][164/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][165/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][166/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][167/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][168/204]	Loss 0.0005 (0.0005)	
training:	Epoch: [250][169/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][170/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][171/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][172/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][173/204]	Loss 0.0028 (0.0005)	
training:	Epoch: [250][174/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [250][175/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][176/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][177/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [250][178/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][179/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][180/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][181/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][182/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][183/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][184/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][185/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [250][186/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][187/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][188/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][189/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][190/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][191/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][192/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][193/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [250][194/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][195/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [250][196/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][197/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [250][198/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [250][199/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [250][200/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [250][201/204]	Loss 0.0113 (0.0005)	
training:	Epoch: [250][202/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][203/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [250][204/204]	Loss 0.0000 (0.0005)	
Training:	 Loss: 0.0005

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7821 0.7838 0.8199 0.7444
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7256
Pretraining:	Epoch 251/500
----------
training:	Epoch: [251][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [251][2/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][3/204]	Loss 0.0007 (0.0003)	
training:	Epoch: [251][4/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][5/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][6/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [251][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][8/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][9/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][10/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][12/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][13/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][14/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][16/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][17/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][19/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][23/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][24/204]	Loss 0.0032 (0.0002)	
training:	Epoch: [251][25/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][26/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][27/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][28/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][29/204]	Loss 0.0017 (0.0002)	
training:	Epoch: [251][30/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][31/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][32/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][33/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][34/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][36/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][37/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][38/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][39/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][40/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][41/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][42/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][43/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][44/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][45/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][46/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][47/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][48/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][49/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [251][50/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][51/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][52/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][53/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][54/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][55/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][56/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][57/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][63/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [251][64/204]	Loss 0.0012 (0.0002)	
training:	Epoch: [251][65/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][66/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][67/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][68/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][80/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [251][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][91/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][92/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][95/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [251][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][97/204]	Loss 0.0011 (0.0001)	
training:	Epoch: [251][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][102/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [251][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][117/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][121/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [251][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][135/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [251][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][145/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [251][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][147/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][150/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [251][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][153/204]	Loss 0.0012 (0.0001)	
training:	Epoch: [251][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][165/204]	Loss 0.0013 (0.0001)	
training:	Epoch: [251][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][184/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][185/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][187/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][188/204]	Loss 0.0035 (0.0001)	
training:	Epoch: [251][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [251][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [251][199/204]	Loss 0.0253 (0.0002)	
training:	Epoch: [251][200/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][201/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [251][202/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [251][203/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [251][204/204]	Loss 0.0001 (0.0002)	
Training:	 Loss: 0.0002

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7873 0.7871 0.7820 0.7926
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7158
Pretraining:	Epoch 252/500
----------
training:	Epoch: [252][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [252][2/204]	Loss 0.0048 (0.0025)	
training:	Epoch: [252][3/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [252][4/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [252][5/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][6/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [252][7/204]	Loss 0.0919 (0.0139)	
training:	Epoch: [252][8/204]	Loss 0.0002 (0.0122)	
training:	Epoch: [252][9/204]	Loss 0.0000 (0.0108)	
training:	Epoch: [252][10/204]	Loss 0.0000 (0.0097)	
training:	Epoch: [252][11/204]	Loss 0.0000 (0.0089)	
training:	Epoch: [252][12/204]	Loss 0.0001 (0.0081)	
training:	Epoch: [252][13/204]	Loss 0.0001 (0.0075)	
training:	Epoch: [252][14/204]	Loss 0.0000 (0.0070)	
training:	Epoch: [252][15/204]	Loss 0.0000 (0.0065)	
training:	Epoch: [252][16/204]	Loss 0.0001 (0.0061)	
training:	Epoch: [252][17/204]	Loss 0.0000 (0.0057)	
training:	Epoch: [252][18/204]	Loss 0.0000 (0.0054)	
training:	Epoch: [252][19/204]	Loss 0.0000 (0.0051)	
training:	Epoch: [252][20/204]	Loss 0.0000 (0.0049)	
training:	Epoch: [252][21/204]	Loss 0.0000 (0.0047)	
training:	Epoch: [252][22/204]	Loss 0.0001 (0.0045)	
training:	Epoch: [252][23/204]	Loss 0.0004 (0.0043)	
training:	Epoch: [252][24/204]	Loss 0.0001 (0.0041)	
training:	Epoch: [252][25/204]	Loss 0.0000 (0.0039)	
training:	Epoch: [252][26/204]	Loss 0.0000 (0.0038)	
training:	Epoch: [252][27/204]	Loss 0.0001 (0.0036)	
training:	Epoch: [252][28/204]	Loss 0.0001 (0.0035)	
training:	Epoch: [252][29/204]	Loss 0.0000 (0.0034)	
training:	Epoch: [252][30/204]	Loss 0.0069 (0.0035)	
training:	Epoch: [252][31/204]	Loss 0.0000 (0.0034)	
training:	Epoch: [252][32/204]	Loss 0.0000 (0.0033)	
training:	Epoch: [252][33/204]	Loss 0.0002 (0.0032)	
training:	Epoch: [252][34/204]	Loss 0.0002 (0.0031)	
training:	Epoch: [252][35/204]	Loss 0.0000 (0.0030)	
training:	Epoch: [252][36/204]	Loss 0.0001 (0.0029)	
training:	Epoch: [252][37/204]	Loss 0.0000 (0.0029)	
training:	Epoch: [252][38/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [252][39/204]	Loss 0.0000 (0.0027)	
training:	Epoch: [252][40/204]	Loss 0.0002 (0.0027)	
training:	Epoch: [252][41/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [252][42/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [252][43/204]	Loss 0.0264 (0.0031)	
training:	Epoch: [252][44/204]	Loss 0.0000 (0.0030)	
training:	Epoch: [252][45/204]	Loss 0.0000 (0.0030)	
training:	Epoch: [252][46/204]	Loss 0.0000 (0.0029)	
training:	Epoch: [252][47/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [252][48/204]	Loss 0.0000 (0.0028)	
training:	Epoch: [252][49/204]	Loss 0.0000 (0.0027)	
training:	Epoch: [252][50/204]	Loss 0.0000 (0.0027)	
training:	Epoch: [252][51/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [252][52/204]	Loss 0.0000 (0.0026)	
training:	Epoch: [252][53/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [252][54/204]	Loss 0.0000 (0.0025)	
training:	Epoch: [252][55/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [252][56/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [252][57/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [252][58/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [252][59/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [252][60/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [252][61/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [252][62/204]	Loss 0.0001 (0.0022)	
training:	Epoch: [252][63/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [252][64/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [252][65/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [252][66/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [252][67/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [252][68/204]	Loss 0.0307 (0.0024)	
training:	Epoch: [252][69/204]	Loss 0.0001 (0.0024)	
training:	Epoch: [252][70/204]	Loss 0.0000 (0.0024)	
training:	Epoch: [252][71/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [252][72/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [252][73/204]	Loss 0.0000 (0.0023)	
training:	Epoch: [252][74/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [252][75/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [252][76/204]	Loss 0.0000 (0.0022)	
training:	Epoch: [252][77/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [252][78/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [252][79/204]	Loss 0.0009 (0.0021)	
training:	Epoch: [252][80/204]	Loss 0.0000 (0.0021)	
training:	Epoch: [252][81/204]	Loss 0.0001 (0.0021)	
training:	Epoch: [252][82/204]	Loss 0.0001 (0.0020)	
training:	Epoch: [252][83/204]	Loss 0.0019 (0.0020)	
training:	Epoch: [252][84/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [252][85/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [252][86/204]	Loss 0.0000 (0.0020)	
training:	Epoch: [252][87/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [252][88/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [252][89/204]	Loss 0.0000 (0.0019)	
training:	Epoch: [252][90/204]	Loss 0.0004 (0.0019)	
training:	Epoch: [252][91/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [252][92/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [252][93/204]	Loss 0.0009 (0.0018)	
training:	Epoch: [252][94/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [252][95/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [252][96/204]	Loss 0.0009 (0.0018)	
training:	Epoch: [252][97/204]	Loss 0.0000 (0.0018)	
training:	Epoch: [252][98/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [252][99/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [252][100/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [252][101/204]	Loss 0.0001 (0.0017)	
training:	Epoch: [252][102/204]	Loss 0.0000 (0.0017)	
training:	Epoch: [252][103/204]	Loss 0.0005 (0.0017)	
training:	Epoch: [252][104/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [252][105/204]	Loss 0.0002 (0.0016)	
training:	Epoch: [252][106/204]	Loss 0.0009 (0.0016)	
training:	Epoch: [252][107/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [252][108/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [252][109/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [252][110/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [252][111/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [252][112/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [252][113/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [252][114/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [252][115/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [252][116/204]	Loss 0.0001 (0.0015)	
training:	Epoch: [252][117/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [252][118/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [252][119/204]	Loss 0.0006 (0.0015)	
training:	Epoch: [252][120/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [252][121/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [252][122/204]	Loss 0.0003 (0.0014)	
training:	Epoch: [252][123/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [252][124/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [252][125/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [252][126/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [252][127/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [252][128/204]	Loss 0.0001 (0.0014)	
training:	Epoch: [252][129/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [252][130/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [252][131/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [252][132/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [252][133/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [252][134/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [252][135/204]	Loss 0.0003 (0.0013)	
training:	Epoch: [252][136/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [252][137/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [252][138/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [252][139/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [252][140/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [252][141/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [252][142/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [252][143/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [252][144/204]	Loss 0.0005 (0.0012)	
training:	Epoch: [252][145/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [252][146/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [252][147/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [252][148/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [252][149/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [252][150/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [252][151/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [252][152/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [252][153/204]	Loss 0.0001 (0.0012)	
training:	Epoch: [252][154/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][155/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][156/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [252][157/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][158/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][159/204]	Loss 0.0003 (0.0011)	
training:	Epoch: [252][160/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][161/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][162/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [252][163/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][164/204]	Loss 0.0002 (0.0011)	
training:	Epoch: [252][165/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][166/204]	Loss 0.0001 (0.0011)	
training:	Epoch: [252][167/204]	Loss 0.0006 (0.0011)	
training:	Epoch: [252][168/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][169/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][170/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [252][171/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][172/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][173/204]	Loss 0.0010 (0.0010)	
training:	Epoch: [252][174/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][175/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][176/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][177/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][178/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][179/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][180/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][181/204]	Loss 0.0092 (0.0010)	
training:	Epoch: [252][182/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [252][183/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [252][184/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][185/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][186/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][187/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][188/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][189/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][190/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][191/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][192/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][193/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][194/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][195/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [252][196/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [252][197/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][198/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][199/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [252][200/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [252][201/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [252][202/204]	Loss 0.0011 (0.0009)	
training:	Epoch: [252][203/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [252][204/204]	Loss 0.0001 (0.0009)	
Training:	 Loss: 0.0009

Training:	 ACC: 0.9999 0.9998 0.9997 1.0000
Validation:	 ACC: 0.7858 0.7860 0.7902 0.7814
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7208
Pretraining:	Epoch 253/500
----------
training:	Epoch: [253][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][7/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [253][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][17/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [253][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][19/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [253][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][21/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [253][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][24/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [253][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][27/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [253][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][31/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [253][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][34/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [253][35/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [253][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [253][37/204]	Loss 0.0049 (0.0002)	
training:	Epoch: [253][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [253][39/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][40/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][41/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [253][42/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [253][43/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][44/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][45/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [253][46/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][47/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][48/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][49/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][50/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [253][51/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [253][52/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][53/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][54/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [253][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][62/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][70/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][77/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [253][78/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [253][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][80/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][86/204]	Loss 0.0011 (0.0001)	
training:	Epoch: [253][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][88/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [253][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][90/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][92/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [253][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][112/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][125/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [253][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][139/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][143/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [253][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][150/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [253][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][156/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [253][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [253][159/204]	Loss 0.0254 (0.0003)	
training:	Epoch: [253][160/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][161/204]	Loss 0.0100 (0.0003)	
training:	Epoch: [253][162/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [253][163/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][164/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][165/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][166/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][167/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][168/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][169/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [253][170/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][171/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][172/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][173/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][174/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [253][175/204]	Loss 0.0034 (0.0003)	
training:	Epoch: [253][176/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][177/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [253][178/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [253][179/204]	Loss 0.0018 (0.0003)	
training:	Epoch: [253][180/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [253][181/204]	Loss 0.0106 (0.0004)	
training:	Epoch: [253][182/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [253][183/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][184/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][185/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][186/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][187/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [253][188/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [253][189/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [253][190/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][191/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][192/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][193/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][194/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][195/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][196/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [253][197/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][198/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][199/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][200/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][201/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [253][202/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][203/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [253][204/204]	Loss 0.0000 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7873 0.7887 0.8178 0.7567
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7476
Pretraining:	Epoch 254/500
----------
training:	Epoch: [254][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][12/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [254][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][17/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [254][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][24/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [254][25/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [254][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][30/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [254][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][34/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [254][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][68/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [254][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][71/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [254][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [254][92/204]	Loss 0.0024 (0.0001)	
training:	Epoch: [254][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][94/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][100/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [254][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][116/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][121/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][130/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][136/204]	Loss 0.0010 (0.0001)	
training:	Epoch: [254][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][142/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][146/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][148/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [254][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][162/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [254][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][164/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][167/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][184/204]	Loss 0.0028 (0.0001)	
training:	Epoch: [254][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][192/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [254][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [254][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7864 0.7876 0.8127 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7632
Pretraining:	Epoch 255/500
----------
training:	Epoch: [255][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][4/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [255][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [255][6/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [255][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [255][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][42/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][46/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][50/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][53/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][59/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][60/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][69/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][73/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][85/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [255][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][87/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][94/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][107/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][119/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][125/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][138/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [255][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][143/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][157/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][165/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][176/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [255][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][185/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][195/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [255][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][202/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [255][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [255][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7847 0.7860 0.8137 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7728
Pretraining:	Epoch 256/500
----------
training:	Epoch: [256][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [256][2/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [256][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [256][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [256][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [256][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][11/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][24/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][38/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][39/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][46/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][48/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [256][49/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][52/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][53/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [256][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][63/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][74/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][82/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][85/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][87/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][89/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][163/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][179/204]	Loss 0.0006 (0.0000)	
training:	Epoch: [256][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][193/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][195/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][201/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [256][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [256][204/204]	Loss 0.0001 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7845 0.7860 0.8168 0.7522
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7850
Pretraining:	Epoch 257/500
----------
training:	Epoch: [257][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][18/204]	Loss 0.0019 (0.0001)	
training:	Epoch: [257][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][23/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [257][24/204]	Loss 0.0005 (0.0002)	
training:	Epoch: [257][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][43/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [257][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [257][61/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [257][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [257][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][101/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [257][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [257][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [257][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [257][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [257][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [257][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][157/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [257][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][177/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [257][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [257][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7859 0.7871 0.8106 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7843
Pretraining:	Epoch 258/500
----------
training:	Epoch: [258][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][4/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][10/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][16/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][35/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][55/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][67/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][91/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][92/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][109/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][115/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][118/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][141/204]	Loss 0.0005 (0.0000)	
training:	Epoch: [258][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][161/204]	Loss 0.0009 (0.0000)	
training:	Epoch: [258][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][175/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][185/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [258][186/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [258][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [258][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7852 0.7865 0.8137 0.7567
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7903
Pretraining:	Epoch 259/500
----------
training:	Epoch: [259][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][16/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [259][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][20/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [259][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][30/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [259][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][40/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [259][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [259][50/204]	Loss 0.0017 (0.0001)	
training:	Epoch: [259][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][77/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][89/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][96/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [259][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][103/204]	Loss 0.0083 (0.0001)	
training:	Epoch: [259][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][114/204]	Loss 0.0026 (0.0001)	
training:	Epoch: [259][115/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][116/204]	Loss 0.0007 (0.0002)	
training:	Epoch: [259][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][125/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][132/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][148/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [259][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][163/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [259][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][168/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][171/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][172/204]	Loss 0.0070 (0.0002)	
training:	Epoch: [259][173/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][174/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][175/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [259][176/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][177/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][178/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][179/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][180/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [259][181/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][182/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][183/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][184/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [259][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [259][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [259][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7839 0.7844 0.7943 0.7735
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8306
Pretraining:	Epoch 260/500
----------
training:	Epoch: [260][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][8/204]	Loss 0.0017 (0.0002)	
training:	Epoch: [260][9/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [260][10/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [260][11/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [260][12/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [260][13/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [260][14/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][15/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][16/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][17/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][23/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [260][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][51/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [260][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][54/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [260][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][81/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [260][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][86/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [260][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][88/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [260][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [260][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][103/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [260][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][116/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [260][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][128/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [260][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][140/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [260][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][144/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [260][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][150/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [260][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][155/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [260][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][201/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [260][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [260][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7849 0.7860 0.8086 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8384
Pretraining:	Epoch 261/500
----------
training:	Epoch: [261][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][9/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [261][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][20/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [261][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][67/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [261][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][82/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [261][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][135/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [261][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][169/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [261][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][178/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [261][179/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [261][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][185/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [261][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [261][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7842 0.7854 0.8106 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8447
Pretraining:	Epoch 262/500
----------
training:	Epoch: [262][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][13/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][14/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][27/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][89/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][115/204]	Loss 0.0010 (0.0000)	
training:	Epoch: [262][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][142/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][146/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][149/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][177/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][181/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][201/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [262][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [262][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7833 0.7844 0.8076 0.7590
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8504
Pretraining:	Epoch 263/500
----------
training:	Epoch: [263][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][4/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [263][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][16/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [263][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][62/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [263][63/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [263][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][109/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [263][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][129/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [263][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][188/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [263][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][195/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [263][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][200/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [263][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [263][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7848 0.7860 0.8117 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8501
Pretraining:	Epoch 264/500
----------
training:	Epoch: [264][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][26/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [264][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][31/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [264][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][45/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [264][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][56/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [264][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][93/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [264][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][142/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [264][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][172/204]	Loss 0.0013 (0.0000)	
training:	Epoch: [264][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][180/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [264][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][191/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [264][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][201/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [264][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [264][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7850 0.7854 0.7943 0.7758
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8516
Pretraining:	Epoch 265/500
----------
training:	Epoch: [265][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][33/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [265][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][44/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [265][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][58/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [265][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][76/204]	Loss 0.0010 (0.0000)	
training:	Epoch: [265][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][111/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [265][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][118/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [265][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][128/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [265][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][134/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [265][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][163/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [265][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][178/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [265][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][200/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [265][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [265][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7860 0.7871 0.8086 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8508
Pretraining:	Epoch 266/500
----------
training:	Epoch: [266][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][88/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [266][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][102/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [266][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][110/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [266][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][141/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [266][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [266][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7865 0.7876 0.8096 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8631
Pretraining:	Epoch 267/500
----------
training:	Epoch: [267][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][120/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [267][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][139/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [267][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][184/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [267][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [267][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7858 0.7871 0.8137 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8868
Pretraining:	Epoch 268/500
----------
training:	Epoch: [268][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][48/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [268][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][54/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [268][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][113/204]	Loss 0.0009 (0.0000)	
training:	Epoch: [268][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][168/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [268][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [268][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7865 0.7876 0.8106 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8844
Pretraining:	Epoch 269/500
----------
training:	Epoch: [269][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][20/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [269][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][88/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [269][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][163/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [269][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [269][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7870 0.7881 0.8117 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8919
Pretraining:	Epoch 270/500
----------
training:	Epoch: [270][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][33/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [270][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][123/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [270][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][141/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [270][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [270][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7860 0.7871 0.8086 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9024
Pretraining:	Epoch 271/500
----------
training:	Epoch: [271][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][95/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [271][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][116/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [271][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][177/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [271][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][197/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [271][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [271][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7864 0.7876 0.8117 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9022
Pretraining:	Epoch 272/500
----------
training:	Epoch: [272][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][72/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [272][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][106/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [272][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [272][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7864 0.7876 0.8127 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9123
Pretraining:	Epoch 273/500
----------
training:	Epoch: [273][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][39/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [273][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][134/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [273][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [273][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7864 0.7876 0.8127 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9245
Pretraining:	Epoch 274/500
----------
training:	Epoch: [274][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][2/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [274][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][19/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [274][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [274][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7864 0.7876 0.8117 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9329
Pretraining:	Epoch 275/500
----------
training:	Epoch: [275][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][128/204]	Loss 0.0019 (0.0000)	
training:	Epoch: [275][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][135/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [275][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][141/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [275][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [275][143/204]	Loss 0.1873 (0.0013)	
training:	Epoch: [275][144/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [275][145/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [275][146/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [275][147/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [275][148/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [275][149/204]	Loss 0.0001 (0.0013)	
training:	Epoch: [275][150/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [275][151/204]	Loss 0.0042 (0.0013)	
training:	Epoch: [275][152/204]	Loss 0.0262 (0.0015)	
training:	Epoch: [275][153/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [275][154/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [275][155/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [275][156/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [275][157/204]	Loss 0.0041 (0.0014)	
training:	Epoch: [275][158/204]	Loss 0.0023 (0.0014)	
training:	Epoch: [275][159/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [275][160/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [275][161/204]	Loss 0.3323 (0.0035)	
training:	Epoch: [275][162/204]	Loss 0.0000 (0.0035)	
training:	Epoch: [275][163/204]	Loss 0.7019 (0.0077)	
training:	Epoch: [275][164/204]	Loss 0.0041 (0.0077)	
training:	Epoch: [275][165/204]	Loss 0.0000 (0.0077)	
training:	Epoch: [275][166/204]	Loss 0.0000 (0.0076)	
training:	Epoch: [275][167/204]	Loss 0.0000 (0.0076)	
training:	Epoch: [275][168/204]	Loss 0.3040 (0.0094)	
training:	Epoch: [275][169/204]	Loss 0.0058 (0.0093)	
training:	Epoch: [275][170/204]	Loss 0.9813 (0.0150)	
training:	Epoch: [275][171/204]	Loss 0.0001 (0.0150)	
training:	Epoch: [275][172/204]	Loss 0.0023 (0.0149)	
training:	Epoch: [275][173/204]	Loss 0.0000 (0.0148)	
training:	Epoch: [275][174/204]	Loss 0.0002 (0.0147)	
training:	Epoch: [275][175/204]	Loss 0.0000 (0.0146)	
training:	Epoch: [275][176/204]	Loss 0.0007 (0.0146)	
training:	Epoch: [275][177/204]	Loss 0.0004 (0.0145)	
training:	Epoch: [275][178/204]	Loss 0.0000 (0.0144)	
training:	Epoch: [275][179/204]	Loss 0.0063 (0.0143)	
training:	Epoch: [275][180/204]	Loss 0.0001 (0.0143)	
training:	Epoch: [275][181/204]	Loss 0.0002 (0.0142)	
training:	Epoch: [275][182/204]	Loss 0.0566 (0.0144)	
training:	Epoch: [275][183/204]	Loss 0.0002 (0.0143)	
training:	Epoch: [275][184/204]	Loss 0.0000 (0.0143)	
training:	Epoch: [275][185/204]	Loss 0.0014 (0.0142)	
training:	Epoch: [275][186/204]	Loss 0.0529 (0.0144)	
training:	Epoch: [275][187/204]	Loss 0.0000 (0.0143)	
training:	Epoch: [275][188/204]	Loss 0.0000 (0.0143)	
training:	Epoch: [275][189/204]	Loss 0.0171 (0.0143)	
training:	Epoch: [275][190/204]	Loss 0.0000 (0.0142)	
training:	Epoch: [275][191/204]	Loss 0.0000 (0.0141)	
training:	Epoch: [275][192/204]	Loss 0.0000 (0.0140)	
training:	Epoch: [275][193/204]	Loss 0.0001 (0.0140)	
training:	Epoch: [275][194/204]	Loss 0.0004 (0.0139)	
training:	Epoch: [275][195/204]	Loss 0.0001 (0.0138)	
training:	Epoch: [275][196/204]	Loss 0.0135 (0.0138)	
training:	Epoch: [275][197/204]	Loss 0.0005 (0.0138)	
training:	Epoch: [275][198/204]	Loss 0.0144 (0.0138)	
training:	Epoch: [275][199/204]	Loss 0.0001 (0.0137)	
training:	Epoch: [275][200/204]	Loss 0.0018 (0.0136)	
training:	Epoch: [275][201/204]	Loss 0.1917 (0.0145)	
training:	Epoch: [275][202/204]	Loss 0.0005 (0.0145)	
training:	Epoch: [275][203/204]	Loss 0.1508 (0.0151)	
training:	Epoch: [275][204/204]	Loss 0.0005 (0.0151)	
Training:	 Loss: 0.0150

Training:	 ACC: 0.9959 0.9960 0.9991 0.9927
Validation:	 ACC: 0.7682 0.7710 0.8301 0.7063
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8346
Pretraining:	Epoch 276/500
----------
training:	Epoch: [276][1/204]	Loss 0.0814 (0.0814)	
training:	Epoch: [276][2/204]	Loss 0.0001 (0.0407)	
training:	Epoch: [276][3/204]	Loss 0.0178 (0.0331)	
training:	Epoch: [276][4/204]	Loss 0.0000 (0.0248)	
training:	Epoch: [276][5/204]	Loss 0.0001 (0.0199)	
training:	Epoch: [276][6/204]	Loss 0.0328 (0.0220)	
training:	Epoch: [276][7/204]	Loss 0.0001 (0.0189)	
training:	Epoch: [276][8/204]	Loss 0.1455 (0.0347)	
training:	Epoch: [276][9/204]	Loss 0.0042 (0.0313)	
training:	Epoch: [276][10/204]	Loss 0.0000 (0.0282)	
training:	Epoch: [276][11/204]	Loss 0.0093 (0.0265)	
training:	Epoch: [276][12/204]	Loss 0.0001 (0.0243)	
training:	Epoch: [276][13/204]	Loss 0.0025 (0.0226)	
training:	Epoch: [276][14/204]	Loss 0.0001 (0.0210)	
training:	Epoch: [276][15/204]	Loss 0.0001 (0.0196)	
training:	Epoch: [276][16/204]	Loss 0.0000 (0.0184)	
training:	Epoch: [276][17/204]	Loss 0.0000 (0.0173)	
training:	Epoch: [276][18/204]	Loss 0.0005 (0.0164)	
training:	Epoch: [276][19/204]	Loss 0.0000 (0.0155)	
training:	Epoch: [276][20/204]	Loss 0.0001 (0.0147)	
training:	Epoch: [276][21/204]	Loss 0.0001 (0.0140)	
training:	Epoch: [276][22/204]	Loss 0.0001 (0.0134)	
training:	Epoch: [276][23/204]	Loss 0.0142 (0.0134)	
training:	Epoch: [276][24/204]	Loss 0.1018 (0.0171)	
training:	Epoch: [276][25/204]	Loss 0.0003 (0.0164)	
training:	Epoch: [276][26/204]	Loss 0.0001 (0.0158)	
training:	Epoch: [276][27/204]	Loss 0.0001 (0.0152)	
training:	Epoch: [276][28/204]	Loss 0.0002 (0.0147)	
training:	Epoch: [276][29/204]	Loss 0.0002 (0.0142)	
training:	Epoch: [276][30/204]	Loss 0.0000 (0.0137)	
training:	Epoch: [276][31/204]	Loss 0.0000 (0.0133)	
training:	Epoch: [276][32/204]	Loss 0.0346 (0.0139)	
training:	Epoch: [276][33/204]	Loss 0.0001 (0.0135)	
training:	Epoch: [276][34/204]	Loss 0.0009 (0.0132)	
training:	Epoch: [276][35/204]	Loss 0.0436 (0.0140)	
training:	Epoch: [276][36/204]	Loss 0.0006 (0.0137)	
training:	Epoch: [276][37/204]	Loss 0.0029 (0.0134)	
training:	Epoch: [276][38/204]	Loss 0.0000 (0.0130)	
training:	Epoch: [276][39/204]	Loss 0.0001 (0.0127)	
training:	Epoch: [276][40/204]	Loss 0.0001 (0.0124)	
training:	Epoch: [276][41/204]	Loss 0.0009 (0.0121)	
training:	Epoch: [276][42/204]	Loss 0.0000 (0.0118)	
training:	Epoch: [276][43/204]	Loss 0.0001 (0.0115)	
training:	Epoch: [276][44/204]	Loss 0.0000 (0.0113)	
training:	Epoch: [276][45/204]	Loss 0.0000 (0.0110)	
training:	Epoch: [276][46/204]	Loss 0.0001 (0.0108)	
training:	Epoch: [276][47/204]	Loss 0.1002 (0.0127)	
training:	Epoch: [276][48/204]	Loss 0.0001 (0.0124)	
training:	Epoch: [276][49/204]	Loss 0.0055 (0.0123)	
training:	Epoch: [276][50/204]	Loss 0.0006 (0.0120)	
training:	Epoch: [276][51/204]	Loss 0.0025 (0.0119)	
training:	Epoch: [276][52/204]	Loss 0.0000 (0.0116)	
training:	Epoch: [276][53/204]	Loss 0.0001 (0.0114)	
training:	Epoch: [276][54/204]	Loss 0.0029 (0.0113)	
training:	Epoch: [276][55/204]	Loss 0.0000 (0.0111)	
training:	Epoch: [276][56/204]	Loss 0.0000 (0.0109)	
training:	Epoch: [276][57/204]	Loss 0.0003 (0.0107)	
training:	Epoch: [276][58/204]	Loss 0.0013 (0.0105)	
training:	Epoch: [276][59/204]	Loss 0.0006 (0.0103)	
training:	Epoch: [276][60/204]	Loss 0.0000 (0.0102)	
training:	Epoch: [276][61/204]	Loss 0.0000 (0.0100)	
training:	Epoch: [276][62/204]	Loss 0.0006 (0.0098)	
training:	Epoch: [276][63/204]	Loss 0.0001 (0.0097)	
training:	Epoch: [276][64/204]	Loss 0.0000 (0.0095)	
training:	Epoch: [276][65/204]	Loss 0.0001 (0.0094)	
training:	Epoch: [276][66/204]	Loss 0.0000 (0.0093)	
training:	Epoch: [276][67/204]	Loss 0.0000 (0.0091)	
training:	Epoch: [276][68/204]	Loss 0.0000 (0.0090)	
training:	Epoch: [276][69/204]	Loss 0.0048 (0.0089)	
training:	Epoch: [276][70/204]	Loss 0.0012 (0.0088)	
training:	Epoch: [276][71/204]	Loss 0.0001 (0.0087)	
training:	Epoch: [276][72/204]	Loss 0.0071 (0.0087)	
training:	Epoch: [276][73/204]	Loss 0.0003 (0.0086)	
training:	Epoch: [276][74/204]	Loss 0.0219 (0.0087)	
training:	Epoch: [276][75/204]	Loss 0.0150 (0.0088)	
training:	Epoch: [276][76/204]	Loss 0.0003 (0.0087)	
training:	Epoch: [276][77/204]	Loss 0.0004 (0.0086)	
training:	Epoch: [276][78/204]	Loss 0.0000 (0.0085)	
training:	Epoch: [276][79/204]	Loss 0.0002 (0.0084)	
training:	Epoch: [276][80/204]	Loss 0.0001 (0.0083)	
training:	Epoch: [276][81/204]	Loss 0.0255 (0.0085)	
training:	Epoch: [276][82/204]	Loss 0.0002 (0.0084)	
training:	Epoch: [276][83/204]	Loss 0.0001 (0.0083)	
training:	Epoch: [276][84/204]	Loss 0.0000 (0.0082)	
training:	Epoch: [276][85/204]	Loss 0.0001 (0.0081)	
training:	Epoch: [276][86/204]	Loss 0.0000 (0.0080)	
training:	Epoch: [276][87/204]	Loss 0.0001 (0.0079)	
training:	Epoch: [276][88/204]	Loss 0.0000 (0.0078)	
training:	Epoch: [276][89/204]	Loss 0.0000 (0.0077)	
training:	Epoch: [276][90/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [276][91/204]	Loss 0.0010 (0.0076)	
training:	Epoch: [276][92/204]	Loss 0.0006 (0.0075)	
training:	Epoch: [276][93/204]	Loss 0.0349 (0.0078)	
training:	Epoch: [276][94/204]	Loss 0.0110 (0.0078)	
training:	Epoch: [276][95/204]	Loss 0.0248 (0.0080)	
training:	Epoch: [276][96/204]	Loss 0.0012 (0.0079)	
training:	Epoch: [276][97/204]	Loss 0.0001 (0.0079)	
training:	Epoch: [276][98/204]	Loss 0.0000 (0.0078)	
training:	Epoch: [276][99/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [276][100/204]	Loss 0.0001 (0.0076)	
training:	Epoch: [276][101/204]	Loss 0.0003 (0.0076)	
training:	Epoch: [276][102/204]	Loss 0.0002 (0.0075)	
training:	Epoch: [276][103/204]	Loss 0.0409 (0.0078)	
training:	Epoch: [276][104/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [276][105/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [276][106/204]	Loss 0.0001 (0.0076)	
training:	Epoch: [276][107/204]	Loss 0.0005 (0.0075)	
training:	Epoch: [276][108/204]	Loss 0.0001 (0.0074)	
training:	Epoch: [276][109/204]	Loss 0.0002 (0.0074)	
training:	Epoch: [276][110/204]	Loss 0.0000 (0.0073)	
training:	Epoch: [276][111/204]	Loss 0.0001 (0.0072)	
training:	Epoch: [276][112/204]	Loss 0.0001 (0.0072)	
training:	Epoch: [276][113/204]	Loss 0.0001 (0.0071)	
training:	Epoch: [276][114/204]	Loss 0.0001 (0.0071)	
training:	Epoch: [276][115/204]	Loss 0.0000 (0.0070)	
training:	Epoch: [276][116/204]	Loss 0.0307 (0.0072)	
training:	Epoch: [276][117/204]	Loss 0.0010 (0.0072)	
training:	Epoch: [276][118/204]	Loss 0.0892 (0.0078)	
training:	Epoch: [276][119/204]	Loss 0.0000 (0.0078)	
training:	Epoch: [276][120/204]	Loss 0.0000 (0.0077)	
training:	Epoch: [276][121/204]	Loss 0.0000 (0.0077)	
training:	Epoch: [276][122/204]	Loss 0.0000 (0.0076)	
training:	Epoch: [276][123/204]	Loss 0.0002 (0.0075)	
training:	Epoch: [276][124/204]	Loss 0.0154 (0.0076)	
training:	Epoch: [276][125/204]	Loss 0.0349 (0.0078)	
training:	Epoch: [276][126/204]	Loss 0.0004 (0.0078)	
training:	Epoch: [276][127/204]	Loss 0.0611 (0.0082)	
training:	Epoch: [276][128/204]	Loss 0.0000 (0.0081)	
training:	Epoch: [276][129/204]	Loss 0.0001 (0.0080)	
training:	Epoch: [276][130/204]	Loss 0.0016 (0.0080)	
training:	Epoch: [276][131/204]	Loss 0.0000 (0.0079)	
training:	Epoch: [276][132/204]	Loss 0.0025 (0.0079)	
training:	Epoch: [276][133/204]	Loss 0.0009 (0.0078)	
training:	Epoch: [276][134/204]	Loss 0.0000 (0.0078)	
training:	Epoch: [276][135/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [276][136/204]	Loss 0.0001 (0.0077)	
training:	Epoch: [276][137/204]	Loss 0.0007 (0.0076)	
training:	Epoch: [276][138/204]	Loss 0.0000 (0.0076)	
training:	Epoch: [276][139/204]	Loss 0.0003 (0.0075)	
training:	Epoch: [276][140/204]	Loss 0.0010 (0.0075)	
training:	Epoch: [276][141/204]	Loss 0.0039 (0.0074)	
training:	Epoch: [276][142/204]	Loss 0.0001 (0.0074)	
training:	Epoch: [276][143/204]	Loss 0.0004 (0.0073)	
training:	Epoch: [276][144/204]	Loss 0.0410 (0.0076)	
training:	Epoch: [276][145/204]	Loss 0.0025 (0.0075)	
training:	Epoch: [276][146/204]	Loss 0.0000 (0.0075)	
training:	Epoch: [276][147/204]	Loss 0.0000 (0.0074)	
training:	Epoch: [276][148/204]	Loss 0.0001 (0.0074)	
training:	Epoch: [276][149/204]	Loss 0.0002 (0.0073)	
training:	Epoch: [276][150/204]	Loss 0.0001 (0.0073)	
training:	Epoch: [276][151/204]	Loss 0.0001 (0.0072)	
training:	Epoch: [276][152/204]	Loss 0.0002 (0.0072)	
training:	Epoch: [276][153/204]	Loss 0.0005 (0.0072)	
training:	Epoch: [276][154/204]	Loss 0.0000 (0.0071)	
training:	Epoch: [276][155/204]	Loss 0.0001 (0.0071)	
training:	Epoch: [276][156/204]	Loss 0.0001 (0.0070)	
training:	Epoch: [276][157/204]	Loss 0.0742 (0.0074)	
training:	Epoch: [276][158/204]	Loss 0.0001 (0.0074)	
training:	Epoch: [276][159/204]	Loss 0.0001 (0.0074)	
training:	Epoch: [276][160/204]	Loss 0.0006 (0.0073)	
training:	Epoch: [276][161/204]	Loss 0.0000 (0.0073)	
training:	Epoch: [276][162/204]	Loss 0.0000 (0.0072)	
training:	Epoch: [276][163/204]	Loss 0.0001 (0.0072)	
training:	Epoch: [276][164/204]	Loss 0.0000 (0.0071)	
training:	Epoch: [276][165/204]	Loss 0.0072 (0.0071)	
training:	Epoch: [276][166/204]	Loss 0.0000 (0.0071)	
training:	Epoch: [276][167/204]	Loss 0.0008 (0.0071)	
training:	Epoch: [276][168/204]	Loss 0.0000 (0.0070)	
training:	Epoch: [276][169/204]	Loss 0.0050 (0.0070)	
training:	Epoch: [276][170/204]	Loss 0.0000 (0.0070)	
training:	Epoch: [276][171/204]	Loss 0.0000 (0.0069)	
training:	Epoch: [276][172/204]	Loss 0.0081 (0.0069)	
training:	Epoch: [276][173/204]	Loss 0.0001 (0.0069)	
training:	Epoch: [276][174/204]	Loss 0.0001 (0.0068)	
training:	Epoch: [276][175/204]	Loss 0.0001 (0.0068)	
training:	Epoch: [276][176/204]	Loss 0.0252 (0.0069)	
training:	Epoch: [276][177/204]	Loss 0.0000 (0.0069)	
training:	Epoch: [276][178/204]	Loss 0.0000 (0.0068)	
training:	Epoch: [276][179/204]	Loss 0.0001 (0.0068)	
training:	Epoch: [276][180/204]	Loss 0.0001 (0.0068)	
training:	Epoch: [276][181/204]	Loss 0.0000 (0.0067)	
training:	Epoch: [276][182/204]	Loss 0.0116 (0.0068)	
training:	Epoch: [276][183/204]	Loss 0.0018 (0.0067)	
training:	Epoch: [276][184/204]	Loss 0.0431 (0.0069)	
training:	Epoch: [276][185/204]	Loss 0.0000 (0.0069)	
training:	Epoch: [276][186/204]	Loss 0.0000 (0.0068)	
training:	Epoch: [276][187/204]	Loss 0.0000 (0.0068)	
training:	Epoch: [276][188/204]	Loss 0.0004 (0.0068)	
training:	Epoch: [276][189/204]	Loss 0.0001 (0.0067)	
training:	Epoch: [276][190/204]	Loss 0.0000 (0.0067)	
training:	Epoch: [276][191/204]	Loss 0.0023 (0.0067)	
training:	Epoch: [276][192/204]	Loss 0.0001 (0.0066)	
training:	Epoch: [276][193/204]	Loss 0.0000 (0.0066)	
training:	Epoch: [276][194/204]	Loss 0.0000 (0.0066)	
training:	Epoch: [276][195/204]	Loss 0.0000 (0.0065)	
training:	Epoch: [276][196/204]	Loss 0.0000 (0.0065)	
training:	Epoch: [276][197/204]	Loss 0.0010 (0.0065)	
training:	Epoch: [276][198/204]	Loss 0.0002 (0.0065)	
training:	Epoch: [276][199/204]	Loss 0.0001 (0.0064)	
training:	Epoch: [276][200/204]	Loss 0.0000 (0.0064)	
training:	Epoch: [276][201/204]	Loss 0.0000 (0.0064)	
training:	Epoch: [276][202/204]	Loss 0.0000 (0.0063)	
training:	Epoch: [276][203/204]	Loss 0.0000 (0.0063)	
training:	Epoch: [276][204/204]	Loss 0.0001 (0.0063)	
Training:	 Loss: 0.0063

Training:	 ACC: 0.9997 0.9997 0.9994 1.0000
Validation:	 ACC: 0.7786 0.7790 0.7871 0.7702
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6483
Pretraining:	Epoch 277/500
----------
training:	Epoch: [277][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [277][2/204]	Loss 0.0003 (0.0002)	
training:	Epoch: [277][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [277][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][6/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][8/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][9/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [277][10/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [277][11/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [277][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [277][13/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [277][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [277][16/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [277][17/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][20/204]	Loss 0.0007 (0.0001)	
training:	Epoch: [277][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][23/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [277][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [277][26/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [277][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [277][28/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [277][29/204]	Loss 0.0019 (0.0002)	
training:	Epoch: [277][30/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [277][31/204]	Loss 0.0188 (0.0008)	
training:	Epoch: [277][32/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [277][33/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][34/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][35/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][36/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][37/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][38/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][39/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][40/204]	Loss 0.0003 (0.0006)	
training:	Epoch: [277][41/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][42/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [277][43/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][44/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][45/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][46/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][47/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [277][48/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [277][49/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [277][50/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [277][51/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [277][52/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [277][53/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [277][54/204]	Loss 0.0010 (0.0005)	
training:	Epoch: [277][55/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [277][56/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [277][57/204]	Loss 0.0007 (0.0005)	
training:	Epoch: [277][58/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [277][59/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [277][60/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [277][61/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [277][62/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [277][63/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [277][64/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][65/204]	Loss 0.0003 (0.0004)	
training:	Epoch: [277][66/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][67/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][68/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][69/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][70/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [277][71/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][72/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][73/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [277][74/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [277][75/204]	Loss 0.0012 (0.0004)	
training:	Epoch: [277][76/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][77/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][78/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][79/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][80/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][81/204]	Loss 0.0004 (0.0004)	
training:	Epoch: [277][82/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][83/204]	Loss 0.0002 (0.0004)	
training:	Epoch: [277][84/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][85/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][86/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][87/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][88/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][89/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][90/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][91/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][92/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [277][93/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][94/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [277][95/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [277][96/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][97/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][98/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][99/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [277][100/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [277][101/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][102/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [277][103/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [277][104/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][105/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][106/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [277][107/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][108/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][109/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][110/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][111/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][112/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][113/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [277][114/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [277][115/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][116/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [277][117/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][118/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][119/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][120/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [277][121/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [277][122/204]	Loss 0.0004 (0.0003)	
training:	Epoch: [277][123/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][124/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [277][125/204]	Loss 0.0528 (0.0007)	
training:	Epoch: [277][126/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [277][127/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][128/204]	Loss 0.0011 (0.0007)	
training:	Epoch: [277][129/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][130/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][131/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][132/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][133/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][134/204]	Loss 0.0007 (0.0007)	
training:	Epoch: [277][135/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][136/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [277][137/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [277][138/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][139/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][140/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][141/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][142/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][143/204]	Loss 0.0058 (0.0007)	
training:	Epoch: [277][144/204]	Loss 0.0022 (0.0007)	
training:	Epoch: [277][145/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][146/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][147/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][148/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [277][149/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][150/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][151/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][152/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][153/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][154/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][155/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][156/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][157/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][158/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][159/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][160/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][161/204]	Loss 0.0041 (0.0007)	
training:	Epoch: [277][162/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][163/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][164/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][165/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [277][166/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][167/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][168/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][169/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][170/204]	Loss 0.0002 (0.0006)	
training:	Epoch: [277][171/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][172/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][173/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][174/204]	Loss 0.0131 (0.0007)	
training:	Epoch: [277][175/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][176/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][177/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][178/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [277][179/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][180/204]	Loss 0.0074 (0.0007)	
training:	Epoch: [277][181/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][182/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][183/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][184/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][185/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][186/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][187/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][188/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][189/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][190/204]	Loss 0.0005 (0.0007)	
training:	Epoch: [277][191/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][192/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][193/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][194/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][195/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][196/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][197/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [277][198/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [277][199/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][200/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][201/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][202/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [277][203/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [277][204/204]	Loss 0.0000 (0.0006)	
Training:	 Loss: 0.0006

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7711 0.7731 0.8158 0.7265
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7257
Pretraining:	Epoch 278/500
----------
training:	Epoch: [278][1/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [278][2/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [278][3/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [278][4/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [278][5/204]	Loss 0.0010 (0.0003)	
training:	Epoch: [278][6/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [278][7/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [278][8/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [278][9/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [278][10/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [278][11/204]	Loss 0.0211 (0.0021)	
training:	Epoch: [278][12/204]	Loss 0.0001 (0.0019)	
training:	Epoch: [278][13/204]	Loss 0.0001 (0.0018)	
training:	Epoch: [278][14/204]	Loss 0.0000 (0.0016)	
training:	Epoch: [278][15/204]	Loss 0.0000 (0.0015)	
training:	Epoch: [278][16/204]	Loss 0.0002 (0.0015)	
training:	Epoch: [278][17/204]	Loss 0.0000 (0.0014)	
training:	Epoch: [278][18/204]	Loss 0.0000 (0.0013)	
training:	Epoch: [278][19/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [278][20/204]	Loss 0.0000 (0.0012)	
training:	Epoch: [278][21/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [278][22/204]	Loss 0.0000 (0.0011)	
training:	Epoch: [278][23/204]	Loss 0.0000 (0.0010)	
training:	Epoch: [278][24/204]	Loss 0.0007 (0.0010)	
training:	Epoch: [278][25/204]	Loss 0.0001 (0.0010)	
training:	Epoch: [278][26/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [278][27/204]	Loss 0.0000 (0.0009)	
training:	Epoch: [278][28/204]	Loss 0.0002 (0.0009)	
training:	Epoch: [278][29/204]	Loss 0.0001 (0.0008)	
training:	Epoch: [278][30/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [278][31/204]	Loss 0.0010 (0.0008)	
training:	Epoch: [278][32/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [278][33/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [278][34/204]	Loss 0.0000 (0.0008)	
training:	Epoch: [278][35/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [278][36/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [278][37/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [278][38/204]	Loss 0.0002 (0.0007)	
training:	Epoch: [278][39/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [278][40/204]	Loss 0.0001 (0.0007)	
training:	Epoch: [278][41/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [278][42/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [278][43/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [278][44/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [278][45/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [278][46/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [278][47/204]	Loss 0.0007 (0.0006)	
training:	Epoch: [278][48/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [278][49/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [278][50/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [278][51/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [278][52/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [278][53/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [278][54/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [278][55/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [278][56/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [278][57/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [278][58/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [278][59/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [278][60/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [278][61/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [278][62/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [278][63/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [278][64/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][65/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][66/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][67/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][68/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][69/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][70/204]	Loss 0.0015 (0.0004)	
training:	Epoch: [278][71/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][72/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][73/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][74/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][75/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][76/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][77/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][78/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][79/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][80/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][81/204]	Loss 0.0061 (0.0005)	
training:	Epoch: [278][82/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][83/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][84/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][85/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][86/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][87/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][88/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][89/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][90/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][91/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][92/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][93/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][94/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][95/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][96/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][97/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][98/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][99/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][100/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][101/204]	Loss 0.0005 (0.0004)	
training:	Epoch: [278][102/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][103/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][104/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][105/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][106/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][107/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][108/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][109/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][110/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][111/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][112/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [278][113/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][114/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][115/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][116/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][117/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][118/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][119/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][120/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][121/204]	Loss 0.0066 (0.0004)	
training:	Epoch: [278][122/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][123/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][124/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][125/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][126/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][127/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][128/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][129/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][130/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][131/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][132/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][133/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][134/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][135/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][136/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [278][137/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][138/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][139/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][140/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [278][141/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][142/204]	Loss 0.0029 (0.0004)	
training:	Epoch: [278][143/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [278][144/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [278][145/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][146/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][147/204]	Loss 0.0009 (0.0003)	
training:	Epoch: [278][148/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][149/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][150/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][151/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][152/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][153/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][154/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][155/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][156/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][157/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][158/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][159/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][160/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][161/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][162/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][163/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][164/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [278][165/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][166/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][167/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][168/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][169/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][170/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][171/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][172/204]	Loss 0.0035 (0.0003)	
training:	Epoch: [278][173/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][174/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][175/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][176/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][177/204]	Loss 0.0003 (0.0003)	
training:	Epoch: [278][178/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][179/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][180/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][181/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][182/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][183/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][184/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][185/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][186/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][187/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][188/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][189/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][190/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][191/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][192/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][193/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [278][194/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][195/204]	Loss 0.0038 (0.0003)	
training:	Epoch: [278][196/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][197/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][198/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][199/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][200/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [278][201/204]	Loss 0.0002 (0.0003)	
training:	Epoch: [278][202/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [278][203/204]	Loss 0.0005 (0.0003)	
training:	Epoch: [278][204/204]	Loss 0.0001 (0.0003)	
Training:	 Loss: 0.0003

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7751 0.7758 0.7912 0.7590
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6863
Pretraining:	Epoch 279/500
----------
training:	Epoch: [279][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [279][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [279][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [279][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [279][5/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [279][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [279][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [279][8/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [279][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [279][10/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [279][11/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][12/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][13/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][14/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][16/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][17/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][18/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [279][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][23/204]	Loss 0.0020 (0.0001)	
training:	Epoch: [279][24/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][25/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][30/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][33/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][36/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][38/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][42/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [279][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][52/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][59/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][60/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][72/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][77/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [279][78/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][81/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [279][82/204]	Loss 0.0008 (0.0001)	
training:	Epoch: [279][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][93/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][98/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][107/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][110/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [279][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][112/204]	Loss 0.0006 (0.0001)	
training:	Epoch: [279][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][119/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [279][120/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][128/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][138/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][140/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][143/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][153/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [279][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][160/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][164/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [279][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][166/204]	Loss 0.0011 (0.0001)	
training:	Epoch: [279][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][174/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][179/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][181/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][189/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [279][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][193/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][194/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [279][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][199/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [279][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [279][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7762 0.7769 0.7922 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6838
Pretraining:	Epoch 280/500
----------
training:	Epoch: [280][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][3/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [280][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][8/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [280][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][10/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [280][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][14/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [280][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][16/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][19/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [280][20/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [280][21/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [280][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][25/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [280][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][29/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [280][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [280][32/204]	Loss 0.0012 (0.0001)	
training:	Epoch: [280][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][35/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][37/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [280][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][39/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][48/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][49/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][51/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][53/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][54/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [280][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][71/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][79/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][84/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][85/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][87/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][99/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][100/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][101/204]	Loss 0.0014 (0.0001)	
training:	Epoch: [280][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][104/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][110/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][111/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][122/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][127/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][129/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][133/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][134/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][136/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][137/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][141/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][142/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [280][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][151/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][152/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][156/204]	Loss 0.0022 (0.0001)	
training:	Epoch: [280][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][158/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][163/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][183/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][186/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][189/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][197/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][200/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [280][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [280][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7760 0.7769 0.7963 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.6948
Pretraining:	Epoch 281/500
----------
training:	Epoch: [281][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][6/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][13/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][16/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][29/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][41/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][55/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [281][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][67/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][78/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][83/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][89/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][97/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [281][98/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][100/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [281][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][105/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][106/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][114/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][118/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][119/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][123/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][124/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][126/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][127/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][142/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][146/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][148/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][163/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][165/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][166/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [281][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][174/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][177/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][178/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [281][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][182/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][188/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][194/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][197/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [281][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [281][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7760 0.7769 0.7953 0.7567
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7091
Pretraining:	Epoch 282/500
----------
training:	Epoch: [282][1/204]	Loss 0.0002 (0.0002)	
training:	Epoch: [282][2/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][3/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][4/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][5/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][6/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][7/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][8/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][9/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [282][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [282][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [282][13/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [282][15/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [282][17/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [282][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][23/204]	Loss 0.0052 (0.0003)	
training:	Epoch: [282][24/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [282][25/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [282][26/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [282][27/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][28/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][29/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [282][30/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][31/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][32/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][33/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][34/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][35/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [282][36/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][37/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][38/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [282][39/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][40/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][41/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][42/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][43/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][44/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][45/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][46/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][47/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][48/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [282][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][50/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [282][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][53/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][55/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][56/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][59/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [282][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][64/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][66/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][69/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][71/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][75/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][77/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][83/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][95/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][102/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][106/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][109/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [282][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][114/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][119/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][126/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][129/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][136/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [282][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][144/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][149/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][153/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][157/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][161/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][166/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][169/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][170/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [282][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][172/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][174/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][176/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][183/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][188/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][194/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][195/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [282][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [282][204/204]	Loss 0.0000 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7772 0.7780 0.7932 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7207
Pretraining:	Epoch 283/500
----------
training:	Epoch: [283][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][4/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][13/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][14/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][28/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][35/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][39/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][51/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][64/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [283][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][68/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][82/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [283][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][100/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][102/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][105/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [283][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][109/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][117/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][121/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][131/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][136/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][139/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][146/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][149/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][176/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][184/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [283][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][187/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [283][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [283][204/204]	Loss 0.0001 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7777 0.7785 0.7943 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7291
Pretraining:	Epoch 284/500
----------
training:	Epoch: [284][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][4/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][7/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][10/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][11/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][34/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][51/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][74/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][77/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][80/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [284][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][91/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][92/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [284][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][94/204]	Loss 0.0017 (0.0001)	
training:	Epoch: [284][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][96/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][102/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [284][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][105/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [284][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][114/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [284][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [284][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][126/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][148/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][153/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][168/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][171/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][177/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][192/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][200/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [284][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [284][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7759 0.7769 0.7973 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7359
Pretraining:	Epoch 285/500
----------
training:	Epoch: [285][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][9/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [285][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][11/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [285][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][13/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [285][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][18/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [285][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][33/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [285][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][35/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [285][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][43/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [285][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][74/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [285][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][97/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [285][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [285][103/204]	Loss 0.0460 (0.0005)	
training:	Epoch: [285][104/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][105/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][106/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][107/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][108/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][109/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][110/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][111/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [285][112/204]	Loss 0.0068 (0.0005)	
training:	Epoch: [285][113/204]	Loss 0.0176 (0.0007)	
training:	Epoch: [285][114/204]	Loss 0.0004 (0.0007)	
training:	Epoch: [285][115/204]	Loss 0.0011 (0.0007)	
training:	Epoch: [285][116/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [285][117/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][118/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][119/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [285][120/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [285][121/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][122/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][123/204]	Loss 0.0005 (0.0006)	
training:	Epoch: [285][124/204]	Loss 0.0001 (0.0006)	
training:	Epoch: [285][125/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][126/204]	Loss 0.0006 (0.0006)	
training:	Epoch: [285][127/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][128/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][129/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][130/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][131/204]	Loss 0.0010 (0.0006)	
training:	Epoch: [285][132/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][133/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][134/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][135/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][136/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][137/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][138/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][139/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][140/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][141/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][142/204]	Loss 0.0000 (0.0006)	
training:	Epoch: [285][143/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [285][144/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][145/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][146/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][147/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][148/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [285][149/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [285][150/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][151/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][152/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][153/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][154/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][155/204]	Loss 0.0001 (0.0005)	
training:	Epoch: [285][156/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][157/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][158/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [285][159/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][160/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][161/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][162/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][163/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][164/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][165/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][166/204]	Loss 0.0004 (0.0005)	
training:	Epoch: [285][167/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][168/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][169/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][170/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][171/204]	Loss 0.0003 (0.0005)	
training:	Epoch: [285][172/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][173/204]	Loss 0.0002 (0.0005)	
training:	Epoch: [285][174/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][175/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][176/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][177/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][178/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][179/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [285][180/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][181/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][182/204]	Loss 0.0001 (0.0004)	
training:	Epoch: [285][183/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][184/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][185/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][186/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][187/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][188/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][189/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][190/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][191/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][192/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][193/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][194/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][195/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][196/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][197/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][198/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][199/204]	Loss 0.0052 (0.0004)	
training:	Epoch: [285][200/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][201/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][202/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][203/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [285][204/204]	Loss 0.0000 (0.0004)	
Training:	 Loss: 0.0004

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7760 0.7774 0.8066 0.7455
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7604
Pretraining:	Epoch 286/500
----------
training:	Epoch: [286][1/204]	Loss 0.0015 (0.0015)	
training:	Epoch: [286][2/204]	Loss 0.0000 (0.0007)	
training:	Epoch: [286][3/204]	Loss 0.0000 (0.0005)	
training:	Epoch: [286][4/204]	Loss 0.0000 (0.0004)	
training:	Epoch: [286][5/204]	Loss 0.0001 (0.0003)	
training:	Epoch: [286][6/204]	Loss 0.0006 (0.0004)	
training:	Epoch: [286][7/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [286][8/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [286][9/204]	Loss 0.0000 (0.0003)	
training:	Epoch: [286][10/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [286][11/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [286][12/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [286][13/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [286][14/204]	Loss 0.0001 (0.0002)	
training:	Epoch: [286][15/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [286][16/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [286][17/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [286][18/204]	Loss 0.0000 (0.0002)	
training:	Epoch: [286][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][21/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][22/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][23/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][25/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [286][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][29/204]	Loss 0.0008 (0.0001)	
training:	Epoch: [286][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][31/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][32/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][41/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][47/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [286][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][49/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][50/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][51/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][52/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][53/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [286][54/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][55/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][56/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][57/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][58/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][59/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][60/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][61/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][62/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][63/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][64/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][65/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][66/204]	Loss 0.0004 (0.0001)	
training:	Epoch: [286][67/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][68/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][69/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][70/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][71/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [286][72/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][73/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][74/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][75/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][76/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][77/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [286][78/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][79/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][80/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][81/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][82/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][83/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][84/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][85/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][86/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][87/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][88/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][89/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][90/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][91/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][92/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][93/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][94/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][95/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][96/204]	Loss 0.0005 (0.0001)	
training:	Epoch: [286][97/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][98/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][99/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][100/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][101/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][102/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [286][103/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][104/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][105/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][106/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][107/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][108/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][109/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][110/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][111/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][112/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][113/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][114/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [286][115/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][116/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][117/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][118/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][119/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][120/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][121/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][122/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][123/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][124/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][125/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][126/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][127/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][128/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][129/204]	Loss 0.0013 (0.0001)	
training:	Epoch: [286][130/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][131/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][132/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][133/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][134/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][135/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][136/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][137/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][138/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][139/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][140/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][141/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][142/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][143/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][144/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][145/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][146/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][147/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][148/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][149/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][150/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][151/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][152/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][153/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][154/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][155/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][156/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][157/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][158/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][159/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][160/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][161/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][162/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][163/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][164/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][165/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][166/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][167/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][168/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][169/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][170/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][171/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][172/204]	Loss 0.0002 (0.0001)	
training:	Epoch: [286][173/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][174/204]	Loss 0.0009 (0.0001)	
training:	Epoch: [286][175/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][176/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [286][177/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][178/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][179/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][180/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][181/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][182/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][183/204]	Loss 0.0012 (0.0001)	
training:	Epoch: [286][184/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][185/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][186/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [286][187/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][188/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][189/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][190/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][191/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][192/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][193/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][194/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][195/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][196/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][197/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][198/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][199/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][200/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][201/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][202/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][203/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [286][204/204]	Loss 0.0001 (0.0001)	
Training:	 Loss: 0.0001

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7773 0.7780 0.7912 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7666
Pretraining:	Epoch 287/500
----------
training:	Epoch: [287][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][9/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][20/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [287][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][24/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][37/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [287][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][41/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][53/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][91/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][101/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [287][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][105/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][115/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][121/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][151/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][157/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][165/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][166/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [287][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][179/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][183/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][187/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][189/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [287][190/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [287][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [287][203/204]	Loss 0.0009 (0.0000)	
training:	Epoch: [287][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7798 0.7806 0.7973 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7673
Pretraining:	Epoch 288/500
----------
training:	Epoch: [288][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][16/204]	Loss 0.0009 (0.0001)	
training:	Epoch: [288][17/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][18/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][19/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][20/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][21/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][22/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][23/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][24/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][25/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][26/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][27/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][28/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][29/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][30/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][31/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][32/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][44/204]	Loss 0.0003 (0.0001)	
training:	Epoch: [288][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][46/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][47/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][48/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [288][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][63/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][65/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][69/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [288][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][82/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][89/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [288][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][103/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][105/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [288][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][109/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][113/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][132/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [288][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][147/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][150/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][155/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][161/204]	Loss 0.0006 (0.0000)	
training:	Epoch: [288][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][163/204]	Loss 0.0005 (0.0000)	
training:	Epoch: [288][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][181/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][186/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [288][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [288][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7799 0.7806 0.7953 0.7646
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.7824
Pretraining:	Epoch 289/500
----------
training:	Epoch: [289][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][7/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][38/204]	Loss 0.0005 (0.0000)	
training:	Epoch: [289][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][58/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][77/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][84/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][116/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][135/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][156/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][165/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][178/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][199/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [289][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [289][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7783 0.7790 0.7953 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8001
Pretraining:	Epoch 290/500
----------
training:	Epoch: [290][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][55/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [290][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][94/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [290][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][113/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [290][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][128/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [290][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][131/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [290][132/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [290][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][136/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [290][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][152/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [290][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][186/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [290][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][188/204]	Loss 0.0005 (0.0000)	
training:	Epoch: [290][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [290][204/204]	Loss 0.0001 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7794 0.7801 0.7953 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8041
Pretraining:	Epoch 291/500
----------
training:	Epoch: [291][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][19/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][32/204]	Loss 0.0012 (0.0001)	
training:	Epoch: [291][33/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][34/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][35/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][36/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][37/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][38/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [291][39/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][40/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][41/204]	Loss 0.0001 (0.0001)	
training:	Epoch: [291][42/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][43/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][44/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][45/204]	Loss 0.0000 (0.0001)	
training:	Epoch: [291][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][63/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [291][64/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][79/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][112/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][118/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][128/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][150/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][165/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][166/204]	Loss 0.0003 (0.0000)	
training:	Epoch: [291][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][178/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][182/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][200/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [291][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [291][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7787 0.7796 0.7984 0.7590
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8176
Pretraining:	Epoch 292/500
----------
training:	Epoch: [292][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][41/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [292][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][90/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [292][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][129/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [292][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [292][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7803 0.7812 0.7984 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8248
Pretraining:	Epoch 293/500
----------
training:	Epoch: [293][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][51/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [293][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][110/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [293][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][133/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [293][134/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [293][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][141/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [293][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][153/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [293][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [293][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7793 0.7801 0.7973 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8249
Pretraining:	Epoch 294/500
----------
training:	Epoch: [294][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][71/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [294][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][120/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [294][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][159/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [294][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][179/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [294][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][196/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [294][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [294][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7799 0.7806 0.7953 0.7646
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8411
Pretraining:	Epoch 295/500
----------
training:	Epoch: [295][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][69/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [295][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][81/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [295][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][88/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [295][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][99/204]	Loss 0.0005 (0.0000)	
training:	Epoch: [295][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][136/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [295][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][143/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [295][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][191/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [295][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [295][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7810 0.7817 0.7963 0.7657
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8406
Pretraining:	Epoch 296/500
----------
training:	Epoch: [296][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][85/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [296][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][135/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [296][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][157/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [296][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][195/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [296][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [296][204/204]	Loss 0.0001 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7793 0.7801 0.7963 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8591
Pretraining:	Epoch 297/500
----------
training:	Epoch: [297][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][69/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [297][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [297][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7788 0.7796 0.7963 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8657
Pretraining:	Epoch 298/500
----------
training:	Epoch: [298][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][70/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [298][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [298][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7793 0.7801 0.7963 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8730
Pretraining:	Epoch 299/500
----------
training:	Epoch: [299][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][6/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [299][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][8/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [299][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][153/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [299][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [299][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7782 0.7790 0.7963 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8770
Pretraining:	Epoch 300/500
----------
training:	Epoch: [300][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][14/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [300][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][179/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [300][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [300][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7782 0.7790 0.7963 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8759
Pretraining:	Epoch 301/500
----------
training:	Epoch: [301][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][44/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [301][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [301][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7788 0.7796 0.7963 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8766
Pretraining:	Epoch 302/500
----------
training:	Epoch: [302][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][13/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [302][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][16/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [302][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][22/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [302][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][127/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [302][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [302][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7782 0.7790 0.7963 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8810
Pretraining:	Epoch 303/500
----------
training:	Epoch: [303][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][106/204]	Loss 0.0015 (0.0000)	
training:	Epoch: [303][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [303][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7794 0.7801 0.7953 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8851
Pretraining:	Epoch 304/500
----------
training:	Epoch: [304][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][33/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [304][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][115/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [304][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][142/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [304][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][185/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [304][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [304][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7777 0.7785 0.7943 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8932
Pretraining:	Epoch 305/500
----------
training:	Epoch: [305][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][139/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [305][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][143/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [305][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [305][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7777 0.7785 0.7953 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8885
Pretraining:	Epoch 306/500
----------
training:	Epoch: [306][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][147/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [306][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [306][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7777 0.7785 0.7953 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8920
Pretraining:	Epoch 307/500
----------
training:	Epoch: [307][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][83/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [307][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][143/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [307][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [307][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7788 0.7796 0.7963 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8881
Pretraining:	Epoch 308/500
----------
training:	Epoch: [308][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][183/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [308][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [308][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7777 0.7785 0.7953 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8947
Pretraining:	Epoch 309/500
----------
training:	Epoch: [309][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][149/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [309][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][155/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [309][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [309][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7777 0.7785 0.7953 0.7601
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8923
Pretraining:	Epoch 310/500
----------
training:	Epoch: [310][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][85/204]	Loss 0.0027 (0.0000)	
training:	Epoch: [310][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][149/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [310][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [310][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7788 0.7796 0.7963 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9001
Pretraining:	Epoch 311/500
----------
training:	Epoch: [311][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][132/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [311][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [311][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7776 0.7785 0.7973 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.8959
Pretraining:	Epoch 312/500
----------
training:	Epoch: [312][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][18/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [312][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][195/204]	Loss 0.0004 (0.0000)	
training:	Epoch: [312][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [312][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7788 0.7796 0.7953 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9014
Pretraining:	Epoch 313/500
----------
training:	Epoch: [313][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][20/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [313][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [313][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7789 0.7796 0.7943 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9110
Pretraining:	Epoch 314/500
----------
training:	Epoch: [314][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][81/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [314][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][177/204]	Loss 0.0002 (0.0000)	
training:	Epoch: [314][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [314][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7794 0.7801 0.7953 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9021
Pretraining:	Epoch 315/500
----------
training:	Epoch: [315][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [315][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7793 0.7801 0.7963 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9063
Pretraining:	Epoch 316/500
----------
training:	Epoch: [316][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][107/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [316][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [316][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7792 0.7801 0.7994 0.7590
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9083
Pretraining:	Epoch 317/500
----------
training:	Epoch: [317][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][35/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [317][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][74/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [317][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][180/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [317][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [317][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7783 0.7790 0.7953 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9151
Pretraining:	Epoch 318/500
----------
training:	Epoch: [318][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][30/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [318][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][116/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [318][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [318][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7775 0.7785 0.7994 0.7556
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9200
Pretraining:	Epoch 319/500
----------
training:	Epoch: [319][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][40/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [319][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][124/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [319][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [319][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7809 0.7817 0.7994 0.7623
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9118
Pretraining:	Epoch 320/500
----------
training:	Epoch: [320][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [320][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7798 0.7806 0.7984 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9202
Pretraining:	Epoch 321/500
----------
training:	Epoch: [321][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][34/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [321][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [321][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7788 0.7796 0.7963 0.7612
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9292
Pretraining:	Epoch 322/500
----------
training:	Epoch: [322][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][166/204]	Loss 0.0001 (0.0000)	
training:	Epoch: [322][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [322][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7809 0.7817 0.7984 0.7635
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9234
Pretraining:	Epoch 323/500
----------
training:	Epoch: [323][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [323][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7797 0.7806 0.8004 0.7590
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9317
Pretraining:	Epoch 324/500
----------
training:	Epoch: [324][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [324][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7781 0.7790 0.7994 0.7567
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9398
Pretraining:	Epoch 325/500
----------
training:	Epoch: [325][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [325][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7775 0.7785 0.7984 0.7567
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9507
Pretraining:	Epoch 326/500
----------
training:	Epoch: [326][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [326][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7774 0.7785 0.8004 0.7545
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9505
Pretraining:	Epoch 327/500
----------
training:	Epoch: [327][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [327][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7781 0.7790 0.7994 0.7567
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9550
Pretraining:	Epoch 328/500
----------
training:	Epoch: [328][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [328][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

Training:	 ACC: 1.0000 1.0000 1.0000 1.0000
Validation:	 ACC: 0.7781 0.7790 0.7984 0.7578
Validation:	 Best_BACC: 0.8233 0.8250 0.8608 0.7859
Validation:	 Loss: 1.9662
Pretraining:	Epoch 329/500
----------
training:	Epoch: [329][1/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][2/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][3/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][4/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][5/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][6/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][7/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][8/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][9/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][10/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][11/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][12/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][13/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][14/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][15/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][16/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][17/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][18/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][19/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][20/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][21/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][22/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][23/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][24/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][25/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][26/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][27/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][28/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][29/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][30/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][31/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][32/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][33/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][34/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][35/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][36/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][37/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][38/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][39/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][40/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][41/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][42/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][43/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][44/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][45/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][46/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][47/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][48/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][49/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][50/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][51/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][52/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][53/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][54/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][55/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][56/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][57/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][58/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][59/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][60/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][61/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][62/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][63/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][64/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][65/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][66/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][67/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][68/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][69/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][70/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][71/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][72/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][73/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][74/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][75/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][76/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][77/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][78/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][79/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][80/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][81/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][82/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][83/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][84/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][85/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][86/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][87/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][88/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][89/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][90/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][91/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][92/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][93/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][94/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][95/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][96/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][97/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][98/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][99/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][100/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][101/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][102/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][103/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][104/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][105/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][106/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][107/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][108/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][109/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][110/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][111/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][112/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][113/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][114/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][115/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][116/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][117/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][118/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][119/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][120/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][121/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][122/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][123/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][124/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][125/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][126/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][127/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][128/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][129/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][130/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][131/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][132/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][133/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][134/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][135/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][136/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][137/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][138/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][139/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][140/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][141/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][142/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][143/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][144/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][145/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][146/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][147/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][148/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][149/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][150/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][151/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][152/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][153/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][154/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][155/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][156/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][157/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][158/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][159/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][160/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][161/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][162/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][163/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][164/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][165/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][166/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][167/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][168/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][169/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][170/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][171/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][172/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][173/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][174/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][175/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][176/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][177/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][178/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][179/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][180/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][181/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][182/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][183/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][184/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][185/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][186/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][187/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][188/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][189/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][190/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][191/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][192/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][193/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][194/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][195/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][196/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][197/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][198/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][199/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][200/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][201/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][202/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][203/204]	Loss 0.0000 (0.0000)	
training:	Epoch: [329][204/204]	Loss 0.0000 (0.0000)	
Training:	 Loss: 0.0000

